binfo_select_all':
mysql-cluster-programs-ndbinfo-select-all.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndbinfo_select_all program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Set the delay in         
' --delay=# '            seconds between loops.   All MySQL 5.5 based
                         Default is 5.            releases
                                                  
                         Set the number of        
'--loops=#',             times to perform the     All MySQL 5.5 based
                         select.  Default is 1.   releases
' -l '                                            

'--database=db_name',    Name of the database     All MySQL 5.5 based
                         where the table          releases
' -d '                   located.                 
                         
                         Set the degree of        
'--parallelism=#',       parallelism.             All MySQL 5.5 based
                                                  releases
' -p '

   * 
     '--delay=seconds'

     Property               Value
                            
     *Command-Line          '--delay=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '5'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        'MAX_INT'

     This option sets the number of seconds to wait between executing
     loops.  Has no effect if '--loops' is set to 0 or 1.

   * 
     '--loops=number', '-l NUMBER'

     Property               Value
                            
     *Command-Line          '--loops=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '1'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        'MAX_INT'

     This option sets the number of times to execute the select.  Use
     '--delay' to set the time between loops.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndbmtd,  Next: mysql-cluster-programs-ndb-mgmd,  Prev: mysql-cluster-programs-ndbinfo-select-all,  Up: mysql-cluster-programs

18.4.3 'ndbmtd' -- The NDB Cluster Data Node Daemon (Multi-Threaded)
--------------------------------------------------------------------

*note 'ndbmtd': mysql-cluster-programs-ndbmtd. is a multithreaded
version of *note 'ndbd': mysql-cluster-programs-ndbd, the process that
is used to handle all the data in tables using the *note 'NDBCLUSTER':
mysql-cluster. storage engine.  *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. is intended for use on host computers
having multiple CPU cores.  Except where otherwise noted, *note
'ndbmtd': mysql-cluster-programs-ndbmtd. functions in the same way as
*note 'ndbd': mysql-cluster-programs-ndbd.; therefore, in this section,
we concentrate on the ways in which *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. differs from *note 'ndbd':
mysql-cluster-programs-ndbd, and you should consult *note
mysql-cluster-programs-ndbd::, for additional information about running
NDB Cluster data nodes that apply to both the single-threaded and
multithreaded versions of the data node process.

Command-line options and configuration parameters used with *note
'ndbd': mysql-cluster-programs-ndbd. also apply to *note 'ndbmtd':
mysql-cluster-programs-ndbmtd.  For more information about these options
and parameters, see *note mysql-cluster-programs-ndbd::, and *note
mysql-cluster-ndbd-definition::, respectively.

*note 'ndbmtd': mysql-cluster-programs-ndbmtd. is also file
system-compatible with *note 'ndbd': mysql-cluster-programs-ndbd.  In
other words, a data node running *note 'ndbd':
mysql-cluster-programs-ndbd. can be stopped, the binary replaced with
*note 'ndbmtd': mysql-cluster-programs-ndbmtd, and then restarted
without any loss of data.  (However, when doing this, you must make sure
that 'MaxNoOfExecutionThreads' is set to an apppriate value before
restarting the node if you wish for *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. to run in multithreaded fashion.)
Similarly, an *note 'ndbmtd': mysql-cluster-programs-ndbmtd. binary can
be replaced with *note 'ndbd': mysql-cluster-programs-ndbd. simply by
stopping the node and then starting *note 'ndbd':
mysql-cluster-programs-ndbd. in place of the multithreaded binary.  It
is not necessary when switching between the two to start the data node
binary using '--initial'.

Using *note 'ndbmtd': mysql-cluster-programs-ndbmtd. differs from using
*note 'ndbd': mysql-cluster-programs-ndbd. in two key respects:

  1. Because *note 'ndbmtd': mysql-cluster-programs-ndbmtd. runs by
     default in single-threaded mode (that is, it behaves like *note
     'ndbd': mysql-cluster-programs-ndbd.), you must configure it to use
     multiple threads.  This can be done by setting an appropriate value
     in the 'config.ini' file for the 'MaxNoOfExecutionThreads'
     configuration parameter or (in NDB 7.2.3 and later) the
     'ThreadConfig' configuration parameter.  Using
     'MaxNoOfExecutionThreads' is simpler, but 'ThreadConfig' offers
     more flexibility.  For more information about these configuration
     parameters and their use, see *note
     mysql-cluster-ndbd-definition-ndbmtd-parameters::.

  2. Trace files are generated by critical errors in *note 'ndbmtd':
     mysql-cluster-programs-ndbmtd. processes in a somewhat different
     fashion from how these are generated by *note 'ndbd':
     mysql-cluster-programs-ndbd. failures.  These differences are
     discussed in more detail in the next few paragraphs.

Like *note 'ndbd': mysql-cluster-programs-ndbd, *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. generates a set of log files which are
placed in the directory specified by 'DataDir' in the 'config.ini'
configuration file.  Except for trace files, these are generated in the
same way and have the same names as those generated by *note 'ndbd':
mysql-cluster-programs-ndbd.

In the event of a critical error, *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. generates trace files describing what
happened just prior to the error' occurrence.  These files, which can be
found in the data node's 'DataDir', are useful for analysis of problems
by the NDB Cluster Development and Support teams.  One trace file is
generated for each *note 'ndbmtd': mysql-cluster-programs-ndbmtd.
thread.  The names of these files have the following pattern:

             ndb_NODE_ID_trace.log.TRACE_ID_tTHREAD_ID,

In this pattern, NODE_ID stands for the data node's unique node ID in
the cluster, TRACE_ID is a trace sequence number, and THREAD_ID is the
thread ID. For example, in the event of the failure of an *note
'ndbmtd': mysql-cluster-programs-ndbmtd. process running as an NDB
Cluster data node having the node ID 3 and with
'MaxNoOfExecutionThreads' equal to 4, four trace files are generated in
the data node's data directory.  If the is the first time this node has
failed, then these files are named 'ndb_3_trace.log.1_t1',
'ndb_3_trace.log.1_t2', 'ndb_3_trace.log.1_t3', and
'ndb_3_trace.log.1_t4'.  Internally, these trace files follow the same
format as *note 'ndbd': mysql-cluster-programs-ndbd. trace files.

The *note 'ndbd': mysql-cluster-programs-ndbd. exit codes and messages
that are generated when a data node process shuts down prematurely are
also used by *note 'ndbmtd': mysql-cluster-programs-ndbmtd.  See Data
Node Error Messages
(https://dev.mysql.com/doc/ndb-internals/en/ndb-node-error-messages.html),
for a listing of these.

*Note*:

It is possible to use *note 'ndbd': mysql-cluster-programs-ndbd. and
*note 'ndbmtd': mysql-cluster-programs-ndbmtd. concurrently on different
data nodes in the same NDB Cluster.  However, such configurations have
not been tested extensively; thus, we cannot recommend doing so in a
production setting at this time.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-mgmd,  Next: mysql-cluster-programs-ndb-mgm,  Prev: mysql-cluster-programs-ndbmtd,  Up: mysql-cluster-programs

18.4.4 'ndb_mgmd' -- The NDB Cluster Management Server Daemon
-------------------------------------------------------------

The management server is the process that reads the cluster
configuration file and distributes this information to all nodes in the
cluster that request it.  It also maintains a log of cluster activities.
Management clients can connect to the management server and check the
cluster's status.

The following table includes options that are specific to the NDB
Cluster management server program *note 'ndb_mgmd':
mysql-cluster-programs-ndb-mgmd.  Additional descriptions follow the
table.  For options common to most NDB Cluster programs (including *note
'ndb_mgmd': mysql-cluster-programs-ndb-mgmd.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_mgmd program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Local bind address       
' --bind-address=host                             All MySQL 5.5 based
'                                                 releases
                                                  
                         Enable the management    
'                        server configuration     All MySQL 5.5 based
--config-cache[=TRUE|FALSE]cache; TRUE by         releases
'                        default.                 
                         
                         Specify the cluster      
'--config-file=file'     configuration file; in   All MySQL 5.5 based
(>=),                    NDB-6.4.0 and later,     releases
                         needs -reload or         
'-f' (>=)                -initial to override
                         configuration cache if
                         present
                         
                         Specify the cluster      
'--configdir=directory', management server's      All MySQL 5.5 based
                         configuration cache      releases
'--config-dir=directory' directory                
(>=7.0.8)                

'--daemon',              Run ndb_mgmd in daemon   All MySQL 5.5 based
                         mode (default)           releases
' -d '                                            

' --initial '            Causes the management    All MySQL 5.5 based
                         server reload its        releases
                         configuration data       
                         from the configuration
                         file, bypassing the
                         configuration cache
                         
                         Used to install the      
' --install[=name] '     management server        All MySQL 5.5 based
                         process as a Windows     releases
                         service.  Does not       
                         apply on non-Windows
                         platforms.
                         
                         Run ndb_mgmd in          
' --interactive '        interactive mode (not    All MySQL 5.5 based
                         officially supported     releases
                         in production; for       
                         testing purposes only)
                         
                         A name to use when       
' --log-name=name '      writing messages         All MySQL 5.5 based
                         applying to this node    releases
                         in the cluster log.      
                         
                         Read cluster             
' --mycnf '              configuration data       All MySQL 5.5 based
                         from the my.cnf file     releases
                                                  
                         Do not provide any       
' --no-nodeid-checks '   node id checks           All MySQL 5.5 based
                                                  releases
                                                  
                         Do not run ndb_mgmd as   
' --nodaemon '           a daemon                 All MySQL 5.5 based
                                                  releases
                                                  
                         Do not wait for these    
' --nowait-nodes=list    management nodes when    All MySQL 5.5 based
'                        starting this            releases
                         management server.       
                         Also requires
                         -ndb-nodeid to be
                         used.
                         
                         Print full               
'--print-full-config',   configuration and exit   All MySQL 5.5 based
                                                  releases
' -P '                                            

' --reload '             Causes the management    All MySQL 5.5 based
                         server to compare the    releases
                         configuration file       
                         with its configuration
                         cache
                         
                         Used to remove a         
' --remove[=name] '      management server        All MySQL 5.5 based
                         process that was         releases
                         previously installed     
                         as a Windows service,
                         optionally specifying
                         the name of the
                         service to be removed.
                         Does not apply on
                         non-Windows platforms.
                         
                         Write additional         
'--verbose',             information to the       All MySQL 5.5 based
                         log.                     releases
' -v '                   

   * 
     '--bind-address=HOST'

     Property               Value
                            
     *Command-Line          '--bind-address=host'
     Format*                

     *Type*                 String
                            
     *Default Value*        '[none]'

     Causes the management server to bind to a specific network
     interface (host name or IP address).  This option has no default
     value.

   * 
     '--daemon', '-d'

     Property               Value
                            
     *Command-Line          '--daemon'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'TRUE'

     Instructs *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. to
     start as a daemon process.  This is the default behavior.

     This option has no effect when running *note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. on Windows platforms.

   * 
     '--config-cache'

     Property               Value
                            
     *Command-Line          '--config-cache[=TRUE|FALSE]'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'TRUE'

     This option, whose default value is '1' (or 'TRUE', or 'ON'), can
     be used to disable the management server's configuration cache, so
     that it reads its configuration from 'config.ini' every time it
     starts (see *note mysql-cluster-config-file::).  You can do this by
     starting the *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd.
     process with any one of the following options:

        * '--config-cache=0'

        * '--config-cache=FALSE'

        * '--config-cache=OFF'

        * '--skip-config-cache'

     Using one of the options just listed is effective only if the
     management server has no stored configuration at the time it is
     started.  If the management server finds any configuration cache
     files, then the '--config-cache' option or the
     '--skip-config-cache' option is ignored.  Therefore, to disable
     configuration caching, the option should be used the _first_ time
     that the management server is started.  Otherwise--that is, if you
     wish to disable configuration caching for a management server that
     has _already_ created a configuration cache--you must stop the
     management server, delete any existing configuration cache files
     manually, then restart the management server with
     '--skip-config-cache' (or with '--config-cache' set equal to 0,
     'OFF', or 'FALSE').

     Configuration cache files are normally created in a directory named
     'mysql-cluster' under the installation directory (unless this
     location has been overridden using the '--configdir' option).  Each
     time the management server updates its configuration data, it
     writes a new cache file.  The files are named sequentially in order
     of creation using the following format:

          ndb_NODE-ID_config.bin.SEQ-NUMBER

     NODE-ID is the management server's node ID; SEQ-NUMBER is a
     sequence number, beginning with 1.  For example, if the management
     server's node ID is 5, then the first three configuration cache
     files would, when they are created, be named 'ndb_5_config.bin.1',
     'ndb_5_config.bin.2', and 'ndb_5_config.bin.3'.

     If your intent is to purge or reload the configuration cache
     without actually disabling caching, you should start *note
     'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. with one of the
     options '--reload' or '--initial' instead of '--skip-config-cache'.

     To re-enable the configuration cache, simply restart the management
     server, but without the '--config-cache' or '--skip-config-cache'
     option that was used previously to disable the configuration cache.

     Beginning with NDB 7.2.5, *note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. no longer checks for the
     configuration directory ('--configdir') or attempts to create one
     when '--skip-config-cache' is used.  (Bug #13428853)

   * 
     '--config-file=FILENAME', '-f FILENAME'

     Property               Value
                            
     *Command-Line          '--config-file=file'
     Format*                

     *Type*                 File name
                            
     *Default Value*        '[none]'

     Instructs the management server as to which file it should use for
     its configuration file.  By default, the management server looks
     for a file named 'config.ini' in the same directory as the *note
     'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. executable; otherwise
     the file name and location must be specified explicitly.

     This option has no default value, and is ignored unless the
     management server is forced to read the configuration file, either
     because *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. was
     started with the '--reload' or '--initial' option, or because the
     management server could not find any configuration cache.  This
     option is also read if *note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. was started with
     '--config-cache=OFF'.  See *note mysql-cluster-config-file::, for
     more information.

     Formerly, using this option together with '--initial' caused
     removal of the configuration cache even if the file was not found.
     This issue was resolved in NDB 7.2.13.  (Bug #1299289)

   * 
     '--configdir=DIR_NAME'

     Property               Value
                            
     *Command-Line          '--configdir=directory' '--config-dir=directory'
     Format*                

     *Type*                 File name
                            
     *Default Value*        '$INSTALLDIR/mysql-cluster'

     Specifies the cluster management server's configuration cache
     directory.  '--config-dir' is an alias for this option.

   * 
     '--initial'

     Property               Value
                            
     *Command-Line          '--initial'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Configuration data is cached internally, rather than being read
     from the cluster global configuration file each time the management
     server is started (see *note mysql-cluster-config-file::).  Using
     the '--initial' option overrides this behavior, by forcing the
     management server to delete any existing cache files, and then to
     re-read the configuration data from the cluster configuration file
     and to build a new cache.

     This differs in two ways from the '--reload' option.  First,
     '--reload' forces the server to check the configuration file
     against the cache and reload its data only if the contents of the
     file are different from the cache.  Second, '--reload' does not
     delete any existing cache files.

     If *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. is invoked
     with '--initial' but cannot find a global configuration file, the
     management server cannot start.

     When a management server starts, it checks for another management
     server in the same NDB Cluster and tries to use the other
     management server's configuration data.  This behavior has
     implications when performing a rolling restart of an NDB Cluster
     with multiple management nodes.  See *note
     mysql-cluster-rolling-restart::, for more information.

     Formerly, using this option together with the '--config-file'
     option caused removal of the configuration cache even if the file
     was not found.  Starting with NDB 7.2.13, the cache is cleared in
     such cases only if the configuration file is actually found.  (Bug
     #1299289)

   * 
     '--install[=NAME]'

     Property               Value
                            
     *Command-Line          '--install[=name]'
     Format*                

     *Platform Specific*    Windows
                            
     *Type*                 String
                            
     *Default Value*        'ndb_mgmd'

     Causes *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. to be
     installed as a Windows service.  Optionally, you can specify a name
     for the service; if not set, the service name defaults to
     'ndb_mgmd'.  Although it is preferable to specify other *note
     'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. program options in a
     'my.ini' or 'my.cnf' configuration file, it is possible to use them
     together with '--install'.  However, in such cases, the '--install'
     option must be specified first, before any other options are given,
     for the Windows service installation to succeed.

     It is generally not advisable to use this option together with the
     '--initial' option, since this causes the configuration cache to be
     wiped and rebuilt every time the service is stopped and started.
     Care should also be taken if you intend to use any other *note
     'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. options that affect
     the starting of the management server, and you should make
     absolutely certain you fully understand and allow for any possible
     consequences of doing so.

     The '--install' option has no effect on non-Windows platforms.

   * 
     '--interactive'

     Property               Value
                            
     *Command-Line          '--interactive'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Starts *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. in
     interactive mode; that is, an *note 'ndb_mgm':
     mysql-cluster-programs-ndb-mgm. client session is started as soon
     as the management server is running.  This option does not start
     any other NDB Cluster nodes.

   * 
     '--log-name=NAME'

     Property               Value
                            
     *Command-Line          '--log-name=name'
     Format*                

     *Type*                 String
                            
     *Default Value*        'MgmtSrvr'

     Provides a name to be used for this node in the cluster log.

   * 
     '--mycnf'

     Property               Value
                            
     *Command-Line          '--mycnf'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Read configuration data from the 'my.cnf' file.

   * 
     '--no-nodeid-checks'

     Property               Value
                            
     *Command-Line          '--no-nodeid-checks'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Do not perform any checks of node IDs.

   * 
     '--nodaemon'

     Property               Value
                            
     *Command-Line          '--nodaemon'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Instructs *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. not to
     start as a daemon process.

     The default behavior for *note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. on Windows is to run in the
     foreground, making this option unnecessary on Windows platforms.

   * 
     '--nowait-nodes'

     Property               Value
                            
     *Command-Line          '--nowait-nodes=list'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        ''
                            
     *Minimum Value*        '1'
                            
     *Maximum Value*        '255'

     When starting an NDB Cluster is configured with two management
     nodes, each management server normally checks to see whether the
     other *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. is also
     operational and whether the other management server's configuration
     is identical to its own.  However, it is sometimes desirable to
     start the cluster with only one management node (and perhaps to
     allow the other *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd.
     to be started later).  This option causes the management node to
     bypass any checks for any other management nodes whose node IDs are
     passed to this option, permitting the cluster to start as though
     configured to use only the management node that was started.

     For purposes of illustration, consider the following portion of a
     'config.ini' file (where we have omitted most of the configuration
     parameters that are not relevant to this example):

          [ndbd]
          NodeId = 1
          HostName = 198.51.100.101

          [ndbd]
          NodeId = 2
          HostName = 198.51.100.102

          [ndbd]
          NodeId = 3
          HostName = 198.51.100.103

          [ndbd]
          NodeId = 4
          HostName = 198.51.100.104

          [ndb_mgmd]
          NodeId = 10
          HostName = 198.51.100.150

          [ndb_mgmd]
          NodeId = 11
          HostName = 198.51.100.151

          [api]
          NodeId = 20
          HostName = 198.51.100.200

          [api]
          NodeId = 21
          HostName = 198.51.100.201

     Assume that you wish to start this cluster using only the
     management server having node ID '10' and running on the host
     having the IP address 198.51.100.150.  (Suppose, for example, that
     the host computer on which you intend to the other management
     server is temporarily unavailable due to a hardware failure, and
     you are waiting for it to be repaired.)  To start the cluster in
     this way, use a command line on the machine at 198.51.100.150 to
     enter the following command:

          shell> ndb_mgmd --ndb-nodeid=10 --nowait-nodes=11

     As shown in the preceding example, when using '--nowait-nodes', you
     must also use the '--ndb-nodeid' option to specify the node ID of
     this *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. process.

     You can then start each of the cluster's data nodes in the usual
     way.  If you wish to start and use the second management server in
     addition to the first management server at a later time without
     restarting the data nodes, you must start each data node with a
     connection string that references both management servers, like
     this:

          shell> ndbd -c 198.51.100.150,198.51.100.151

     The same is true with regard to the connection string used with any
     *note 'mysqld': mysqld. processes that you wish to start as NDB
     Cluster SQL nodes connected to this cluster.  See *note
     mysql-cluster-connection-strings::, for more information.

     When used with *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd,
     this option affects the behavior of the management node with regard
     to other management nodes only.  Do not confuse it with the
     '--nowait-nodes' option used with *note 'ndbd':
     mysql-cluster-programs-ndbd. or *note 'ndbmtd':
     mysql-cluster-programs-ndbmtd. to permit a cluster to start with
     fewer than its full complement of data nodes; when used with data
     nodes, this option affects their behavior only with regard to other
     data nodes.

     Multiple management node IDs may be passed to this option as a
     comma-separated list.  Each node ID must be no less than 1 and no
     greater than 255.  In practice, it is quite rare to use more than
     two management servers for the same NDB Cluster (or to have any
     need for doing so); in most cases you need to pass to this option
     only the single node ID for the one management server that you do
     not wish to use when starting the cluster.

     *Note*:

     When you later start the 'missing' management server, its
     configuration must match that of the management server that is
     already in use by the cluster.  Otherwise, it fails the
     configuration check performed by the existing management server,
     and does not start.

   * 
     '--print-full-config', '-P'

     Property               Value
                            
     *Command-Line          '--print-full-config'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Shows extended information regarding the configuration of the
     cluster.  With this option on the command line the *note
     'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. process prints
     information about the cluster setup including an extensive list of
     the cluster configuration sections as well as parameters and their
     values.  Normally used together with the '--config-file' ('-f')
     option.

   * 
     '--reload'

     Property               Value
                            
     *Command-Line          '--reload'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     NDB Cluster configuration data is stored internally rather than
     being read from the cluster global configuration file each time the
     management server is started (see *note
     mysql-cluster-config-file::).  Using this option forces the
     management server to check its internal data store against the
     cluster configuration file and to reload the configuration if it
     finds that the configuration file does not match the cache.
     Existing configuration cache files are preserved, but not used.

     This differs in two ways from the '--initial' option.  First,
     '--initial' causes all cache files to be deleted.  Second,
     '--initial' forces the management server to re-read the global
     configuration file and construct a new cache.

     If the management server cannot find a global configuration file,
     then the '--reload' option is ignored.

     When '--reload' is used, the management server must be able to
     communicate with data nodes and any other management servers in the
     cluster before it attempts to read the global configuration file;
     otherwise, the management server fails to start.  This can happen
     due to changes in the networking environment, such as new IP
     addresses for nodes or an altered firewall configuration.  In such
     cases, you must use '--initial' instead to force the exsiting
     cached configuration to be discarded and reloaded from the file.
     See *note mysql-cluster-rolling-restart::, for additional
     information.

   * 
     '--remove{=name]'

     Property               Value
                            
     *Command-Line          '--remove[=name]'
     Format*                

     *Platform Specific*    Windows
                            
     *Type*                 String
                            
     *Default Value*        'ndb_mgmd'

     Remove a management server process that has been installed as a
     Windows service, optionally specifying the name of the service to
     be removed.  Applies only to Windows platforms.

   * 
     '--verbose', '-v'

     Property               Value
                            
     *Command-Line          '--verbose'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Remove a management server process that has been installed as a
     Windows service, optionally specifying the name of the service to
     be removed.  Applies only to Windows platforms.

It is not strictly necessary to specify a connection string when
starting the management server.  However, if you are using more than one
management server, a connection string should be provided and each node
in the cluster should specify its node ID explicitly.

See *note mysql-cluster-connection-strings::, for information about
using connection strings.  *note mysql-cluster-programs-ndb-mgmd::,
describes other options for *note 'ndb_mgmd':
mysql-cluster-programs-ndb-mgmd.

The following files are created or used by *note 'ndb_mgmd':
mysql-cluster-programs-ndb-mgmd. in its starting directory, and are
placed in the 'DataDir' as specified in the 'config.ini' configuration
file.  In the list that follows, NODE_ID is the unique node identifier.

   * 
     'config.ini' is the configuration file for the cluster as a whole.
     This file is created by the user and read by the management server.
     *note mysql-cluster-configuration::, discusses how to set up this
     file.

   * 'ndb_NODE_ID_cluster.log' is the cluster events log file.  Examples
     of such events include checkpoint startup and completion, node
     startup events, node failures, and levels of memory usage.  A
     complete listing of cluster events with descriptions may be found
     in *note mysql-cluster-management::.

     By default, when the size of the cluster log reaches one million
     bytes, the file is renamed to 'ndb_NODE_ID_cluster.log.SEQ_ID',
     where SEQ_ID is the sequence number of the cluster log file.  (For
     example: If files with the sequence numbers 1, 2, and 3 already
     exist, the next log file is named using the number '4'.)  You can
     change the size and number of files, and other characteristics of
     the cluster log, using the 'LogDestination' configuration
     parameter.

   * 'ndb_NODE_ID_out.log' is the file used for 'stdout' and 'stderr'
     when running the management server as a daemon.

   * 'ndb_NODE_ID.pid' is the process ID file used when running the
     management server as a daemon.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-mgm,  Next: mysql-cluster-programs-ndb-blob-tool,  Prev: mysql-cluster-programs-ndb-mgmd,  Up: mysql-cluster-programs

18.4.5 'ndb_mgm' -- The NDB Cluster Management Client
-----------------------------------------------------

The *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. management client
process is actually not needed to run the cluster.  Its value lies in
providing a set of commands for checking the cluster's status, starting
backups, and performing other administrative functions.  The management
client accesses the management server using a C API. Advanced users can
also employ this API for programming dedicated management processes to
perform tasks similar to those performed by *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm.

To start the management client, it is necessary to supply the host name
and port number of the management server:

     shell> ndb_mgm [HOST_NAME [PORT_NUM]]

For example:

     shell> ndb_mgm ndb_mgmd.mysql.com 1186

The default host name and port number are 'localhost' and 1186,
respectively.

The following table includes options that are specific to the NDB
Cluster management client program *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm.  Additional descriptions follow the
table.  For options common to most NDB Cluster programs (including *note
'ndb_mgm': mysql-cluster-programs-ndb-mgm.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_mgm program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Set the number of        
'--try-reconnect=#',     times to retry a         All MySQL 5.5 based
                         connection before        releases
' -t '                   giving up; synonym for   
                         -connect-retries
                         
                         Execute command and      
'--execute=name',        exit                     All MySQL 5.5 based
                                                  releases
' -e '

   * 
     '--execute=command', '-e command'

     Property               Value
                            
     *Command-Line          '--execute=name'
     Format*

     This option can be used to send a command to the NDB Cluster
     management client from the system shell.  For example, either of
     the following is equivalent to executing 'SHOW' in the management
     client:

          shell> ndb_mgm -e "SHOW"

          shell> ndb_mgm --execute="SHOW"

     This is analogous to how the '--execute' or '-e' option works with
     the *note 'mysql': mysql. command-line client.  See *note
     command-line-options::.

     *Note*:

     If the management client command to be passed using this option
     contains any space characters, then the command _must_ be enclosed
     in quotation marks.  Either single or double quotation marks may be
     used.  If the management client command contains no space
     characters, the quotation marks are optional.

   * '--try-reconnect=NUMBER'

     Property               Value
                            
     *Command-Line          '--try-reconnect=#'
     Format*                

     *Type*                 Integer
                            
     *Default Value*        '3'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        '4294967295'

     If the connection to the management server is broken, the node
     tries to reconnect to it every 5 seconds until it succeeds.  By
     using this option, it is possible to limit the number of attempts
     to NUMBER before giving up and reporting an error instead.

Additional information about using *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. can be found in *note
mysql-cluster-mgm-client-commands::.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-blob-tool,  Next: mysql-cluster-programs-ndb-config,  Prev: mysql-cluster-programs-ndb-mgm,  Up: mysql-cluster-programs

18.4.6 'ndb_blob_tool' -- Check and Repair BLOB and TEXT columns of NDB Cluster Tables
--------------------------------------------------------------------------------------

This tool can be used to check for and remove orphaned BLOB column parts
from *note 'NDB': mysql-cluster. tables, as well as to generate a file
listing any orphaned parts.  It is sometimes useful in diagnosing and
repairing corrupted or damaged 'NDB' tables containing *note 'BLOB':
blob. or *note 'TEXT': blob. columns.

The basic syntax for *note 'ndb_blob_tool':
mysql-cluster-programs-ndb-blob-tool. is shown here:

     ndb_blob_tool [OPTIONS] TABLE [COLUMN, ...]

Unless you use the '--help' option, you must specify an action to be
performed by including one or more of the options '--check-orphans',
'--delete-orphans', or '--dump-file'.  These options cause *note
'ndb_blob_tool': mysql-cluster-programs-ndb-blob-tool. to check for
orphaned BLOB parts, remove any orphaned BLOB parts, and generate a dump
file listing orphaned BLOB parts, respectively, and are described in
more detail later in this section.

You must also specify the name of a table when invoking *note
'ndb_blob_tool': mysql-cluster-programs-ndb-blob-tool.  In addition, you
can optionally follow the table name with the (comma-separated) names of
one or more *note 'BLOB': blob. or *note 'TEXT': blob. columns from that
table.  If no columns are listed, the tool works on all of the table's
*note 'BLOB': blob. and *note 'TEXT': blob. columns.  If you need to
specify a database, use the '--database' ('-d') option.

The '--verbose' option provides additional information in the output
about the tool's progress.

The following table includes options that are specific to *note
'ndb_blob_tool': mysql-cluster-programs-ndb-blob-tool.  Additional
descriptions follow the table.  For options common to most NDB Cluster
programs (including *note 'ndb_blob_tool':
mysql-cluster-programs-ndb-blob-tool.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_blob_tool program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Check for orphan blob    
' --check-orphans '      parts                    All MySQL 5.5 based
                                                  releases
                                                  
                         Database to find the     
'--database=db_name',    table in.                All MySQL 5.5 based
                                                  releases
' -d '                                            

' --delete-orphans '     Delete orphan blob       All MySQL 5.5 based
                         parts                    releases
                                                  
                         Write orphan keys to     
' --dump-file=file '     specified file           All MySQL 5.5 based
                                                  releases
                                                  
                         Verbose output           
'--verbose',                                      All MySQL 5.5 based
                                                  releases
' -v '

   * 
     '--check-orphans'

     Property               Value
                            
     *Command-Line          '--check-orphans'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Check for orphaned BLOB parts in NDB Cluster tables.

   * 
     '--database=DB_NAME', '-d'

     Property               Value
                            
     *Command-Line          '--database=db_name'
     Format*                

     *Type*                 String
                            
     *Default Value*        '[none]'

     Specify the database to find the table in.

   * 
     '--delete-orphans'

     Property               Value
                            
     *Command-Line          '--delete-orphans'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Remove orphaned BLOB parts from NDB Cluster tables.

   * 
     '--dump-file=FILE'

     Property               Value
                            
     *Command-Line          '--dump-file=file'
     Format*                

     *Type*                 File name
                            
     *Default Value*        '[none]'

     Writes a list of orphaned BLOB column parts to FILE.  The
     information written to the file includes the table key and BLOB
     part number for each orphaned BLOB part.

   * 
     '--verbose'

     Property               Value
                            
     *Command-Line          '--verbose'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Provide extra information in the tool's output regarding its
     progress.

*Example*

First we create an 'NDB' table in the 'test' database, using the *note
'CREATE TABLE': create-table. statement shown here:

     USE test;

     CREATE TABLE btest (
         c0 BIGINT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
         c1 TEXT,
         c2 BLOB
     )   ENGINE=NDB;

Then we insert a few rows into this table, using a series of statements
similar to this one:

     INSERT INTO btest VALUES (NULL, 'x', REPEAT('x', 1000));

When run with '--check-orphans' against this table, *note
'ndb_blob_tool': mysql-cluster-programs-ndb-blob-tool. generates the
following output:

     shell> ndb_blob_tool --check-orphans --verbose -d test btest
     connected
     processing 2 blobs
     processing blob #0 c1 NDB$BLOB_19_1
     NDB$BLOB_19_1: nextResult: res=1
     total parts: 0
     orphan parts: 0
     processing blob #1 c2 NDB$BLOB_19_2
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=0
     NDB$BLOB_19_2: nextResult: res=1
     total parts: 10
     orphan parts: 0
     disconnected

     NDBT_ProgramExit: 0 - OK

The tool reports that there are no 'NDB' BLOB column parts associated
with column 'c1', even though 'c1' is a *note 'TEXT': blob. column.
This is due to the fact that, in an *note 'NDB': mysql-cluster. table,
only the first 256 bytes of a *note 'BLOB': blob. or *note 'TEXT': blob.
column value are stored inline, and only the excess, if any, is stored
separately; thus, if there are no values using more than 256 bytes in a
given column of one of these types, no 'BLOB' column parts are created
by 'NDB' for this column.  See *note storage-requirements::, for more
information.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-config,  Next: mysql-cluster-programs-ndb-cpcd,  Prev: mysql-cluster-programs-ndb-blob-tool,  Up: mysql-cluster-programs

18.4.7 'ndb_config' -- Extract NDB Cluster Configuration Information
--------------------------------------------------------------------

This tool extracts current configuration information for data nodes, SQL
nodes, and API nodes from one of a number of sources: an NDB Cluster
management node, or its 'config.ini' or 'my.cnf' file.  By default, the
management node is the source for the configuration data; to override
the default, execute ndb_config with the '--config-file' or '--mycnf'
option.  It is also possible to use a data node as the source by
specifying its node ID with '--config_from_node=NODE_ID'.

*note 'ndb_config': mysql-cluster-programs-ndb-config. can also provide
an offline dump of all configuration parameters which can be used, along
with their default, maximum, and minimum values and other information.
The dump can be produced in either text or XML format; for more
information, see the discussion of the '--configinfo' and '--xml'
options later in this section).

You can filter the results by section ('DB', 'SYSTEM', or 'CONNECTIONS')
using one of the options '--nodes', '--system', or '--connections'.

The following table includes options that are specific to *note
'ndb_config': mysql-cluster-programs-ndb-config.  Additional
descriptions follow the table.  For options common to most NDB Cluster
programs (including *note 'ndb_config':
mysql-cluster-programs-ndb-config.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_config program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Set the path to          
'                        config.ini file          All MySQL 5.5 based
--config-file=file_name                           releases
'                                                 

' --config_from_node=#   Obtain configuration     All MySQL 5.5 based
'                        data from the node       releases
                         having this ID (must     
                         be a data node).
                         
                         Dumps information        
' --configinfo '         about all NDB            All MySQL 5.5 based
                         configuration            releases
                         parameters in text       
                         format with default,
                         maximum, and minimum
                         values.  Use with -xml
                         to obtain XML output.
                         
                         Print connections        
' --connections '        information ([tcp],      All MySQL 5.5 based
                         [tcp default], [sci],    releases
                         [sci default], [shm],    
                         or [shm default]
                         sections of cluster
                         configuration file)
                         only.  Cannot be used
                         with -system or
                         -nodes.
                         
                         Field separator          
'--fields=string',                                All MySQL 5.5 based
                                                  releases
' -f '                                            

' --host=name '          Specify host             All MySQL 5.5 based
                                                  releases
                                                  
                         Read configuration       
' --mycnf '              data from my.cnf file    All MySQL 5.5 based
                                                  releases
                                                  
                         Get configuration of     
'--nodeid',              node with this ID        All MySQL 5.5 based
                                                  releases
' --id '                                          

' --nodes '              Print node information   All MySQL 5.5 based
                         ([ndbd] or [ndbd         releases
                         default] section of      
                         cluster configuration
                         file) only.  Cannot be
                         used with -system or
                         -connections.
                         
                         Short form for           
' -c '                   -ndb-connectstring       All MySQL 5.5 based
                                                  releases
                                                  
                         One or more query        
'--query=string',        options (attributes)     All MySQL 5.5 based
                                                  releases
' -q '                                            

'--query-all             Dumps all parameters     All MySQL 5.5 based
(https://dev.mysql.com/doc/refman/5.6/en/mysql-cluster-programs-ndb-config.html#option_ndb_config_query-all)',and values to a singlereleases
                         comma-delimited          
' -a                     string.
(https://dev.mysql.com/doc/refman/5.6/en/mysql-cluster-programs-ndb-config.html#option_ndb_config_query-all)
'

'--rows=string',         Row separator            All MySQL 5.5 based
                                                  releases
' -r '                                            

' --system '             Print SYSTEM section     All MySQL 5.5 based
                         information only (see    releases
                         ndb_config -configinfo   
                         output).  Cannot be
                         used with -nodes or
                         -connections.
                         
                         Specify node type        
' --type=name '                                   All MySQL 5.5 based
                                                  releases
                                                  
                         Use -xml with            
' --configinfo --xml '   -configinfo to obtain    All MySQL 5.5 based
                         a dump of all NDB        releases
                         configuration
                         parameters in XML
                         format with default,
                         maximum, and minimum
                         values.
                         

   * 
     '--configinfo'

     The '--configinfo' option causes *note 'ndb_config':
     mysql-cluster-programs-ndb-config. to dump a list of each NDB
     Cluster configuration parameter supported by the NDB Cluster
     distribution of which *note 'ndb_config':
     mysql-cluster-programs-ndb-config. is a part, including the
     following information:

        * A brief description of each parameter's purpose, effects, and
          usage

        * The section of the 'config.ini' file where the parameter may
          be used

        * The parameter's data type or unit of measurement

        * Where applicable, the parameter's default, minimum, and
          maximum values

        * NDB Cluster release version and build information

     By default, this output is in text format.  Part of this output is
     shown here:

          shell> ndb_config --configinfo

          ****** SYSTEM ******

          Name (String)
          Name of system (NDB Cluster)
          MANDATORY

          PrimaryMGMNode (Non-negative Integer)
          Node id of Primary ndb_mgmd(MGM) node
          Default: 0 (Min: 0, Max: 4294967039)

          ConfigGenerationNumber (Non-negative Integer)
          Configuration generation number
          Default: 0 (Min: 0, Max: 4294967039)

          ****** DB ******

          MaxNoOfSubscriptions (Non-negative Integer)
          Max no of subscriptions (default 0 == MaxNoOfTables)
          Default: 0 (Min: 0, Max: 4294967039)

          MaxNoOfSubscribers (Non-negative Integer)
          Max no of subscribers (default 0 == 2 * MaxNoOfTables)
          Default: 0 (Min: 0, Max: 4294967039)

          ...

     Use this option together with the '--xml' option to obtain output
     in XML format.

   * 
     '--config-file=PATH-TO-FILE'

     Property               Value
                            
     *Command-Line          '--config-file=file_name'
     Format*                

     *Type*                 File name
                            
     *Default Value*        ''

     Gives the path to the management server's configuration file
     ('config.ini').  This may be a relative or absolute path.  If the
     management node resides on a different host from the one on which
     *note 'ndb_config': mysql-cluster-programs-ndb-config. is invoked,
     then an absolute path must be used.

   * 
     '--config_from_node=#'

     Property               Value
                            
     *Command-Line          '--config-from-node=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        'none'
                            
     *Minimum Value*        '1'
                            
     *Maximum Value*        '48'

     Obtain the cluster's configuration data from the data node that has
     this ID.

     If the node having this ID is not a data node, *note 'ndb_config':
     mysql-cluster-programs-ndb-config. fails with an error.  (To obtain
     configuration data from the management node instead, simply omit
     this option.)

   * 
     '--connections'

     Property               Value
                            
     *Command-Line          '--connections'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Tells *note 'ndb_config': mysql-cluster-programs-ndb-config. to
     print 'CONNECTIONS' information only--that is, information about
     parameters found in the '[tcp]', '[tcp default]', '[sci]', '[sci
     default]', '[shm]', or '[shm default]' sections of the cluster
     configuration file (see *note mysql-cluster-tcp-definition::, *note
     mysql-cluster-sci-definition::, and *note
     mysql-cluster-shm-definition::, for more information).

     This option is mutually exclusive with '--nodes' and '--system';
     only one of these 3 options can be used.

   * 
     '--fields=DELIMITER', '-f' DELIMITER

     Property               Value
                            
     *Command-Line          '--fields=string'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     Specifies a DELIMITER string used to separate the fields in the
     result.  The default is ',' (the comma character).

     *Note*:

     If the DELIMITER contains spaces or escapes (such as '\n' for the
     linefeed character), then it must be quoted.

   * 
     '--host=HOSTNAME'

     Property               Value
                            
     *Command-Line          '--host=name'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     Specifies the host name of the node for which configuration
     information is to be obtained.

     *Note*:

     While the hostname 'localhost' usually resolves to the IP address
     '127.0.0.1', this may not necessarily be true for all operating
     platforms and configurations.  This means that it is possible, when
     'localhost' is used in 'config.ini', for *note 'ndb_config
     --host=localhost': mysql-cluster-programs-ndb-config. to fail if
     *note 'ndb_config': mysql-cluster-programs-ndb-config. is run on a
     different host where 'localhost' resolves to a different address
     (for example, on some versions of SUSE Linux, this is '127.0.0.2').
     In general, for best results, you should use numeric IP addresses
     for all NDB Cluster configuration values relating to hosts, or
     verify that all NDB Cluster hosts handle 'localhost' in the same
     fashion.

   * 
     '--ndb-connectstring=CONNECTION_STRING', '-c CONNECTION_STRING'

     Property               Value
                            
     *Command-Line          '--ndb-connectstring=connectstring'
     Format*                '--connect-string=connectstring'
                            
     *Type*                 String
                            
     *Default Value*        'localhost:1186'

     Specifies the connection string to use in connecting to the
     management server.  The format for the connection string is the
     same as described in *note mysql-cluster-connection-strings::, and
     defaults to 'localhost:1186'.

   * 
     '--mycnf'

     Property               Value
                            
     *Command-Line          '--mycnf'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Read configuration data from the 'my.cnf' file.

   * 
     '--nodeid=NODE_ID', '--id=NODE_ID'

     Property               Value
                            
     *Command-Line          '--ndb-nodeid=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '0'

     Specify the node ID of the node for which configuration information
     is to be obtained.  '--nodeid' is the preferred form; '--id' is
     deprecated and subject to removal in a later version of NDB
     Cluster.

   * 
     '--nodes'

     Property               Value
                            
     *Command-Line          '--nodes'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Tells *note 'ndb_config': mysql-cluster-programs-ndb-config. to
     print information relating only to parameters defined in an
     '[ndbd]' or '[ndbd default]' section of the cluster configuration
     file (see *note mysql-cluster-ndbd-definition::).

     This option is mutually exclusive with '--connections' and
     '--system'; only one of these 3 options can be used.

   * 
     '--rows=SEPARATOR', '-r' SEPARATOR

     Property               Value
                            
     *Command-Line          '--rows=string'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     Specifies a SEPARATOR string used to separate the rows in the
     result.  The default is a space character.

     *Note*:

     If the SEPARATOR contains spaces or escapes (such as '\n' for the
     linefeed character), then it must be quoted.

   * 
     '--query=QUERY-OPTIONS', '-q' QUERY-OPTIONS

     Property               Value
                            
     *Command-Line          '--query=string'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     This is a comma-delimited list of _query options_--that is, a list
     of one or more node attributes to be returned.  These include
     'nodeid' (node ID), type (node type--that is, 'ndbd', 'mysqld', or
     'ndb_mgmd'), and any configuration parameters whose values are to
     be obtained.

     For example,

     '--query=nodeid,type,indexmemory,datamemory' returns the node ID,
     node type, 'IndexMemory', and 'DataMemory' for each node.

     'id' is accepted as a synonym for 'nodeid', but is deprecated and
     subject to removal in a later version of NDB Cluster.

     *Note*:

     If a given parameter is not applicable to a certain type of node,
     than an empty string is returned for the corresponding value.  See
     the examples later in this section for more information.

   * 
     '--system'

     Property               Value
                            
     *Command-Line          '--system'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Tells *note 'ndb_config': mysql-cluster-programs-ndb-config. to
     print 'SYSTEM' information only.  This consists of system variables
     that cannot be changed at run time; thus, there is no corresponding
     section of the cluster configuration file for them.  They can be
     seen (prefixed with '****** SYSTEM ******') in the output of *note
     'ndb_config': mysql-cluster-programs-ndb-config. '--configinfo'.

     This option is mutually exclusive with '--nodes' and
     '--connections'; only one of these 3 options can be used.

   * 
     '--type=NODE_TYPE'

     Property               Value
                            
     *Command-Line          '--type=name'
     Format*                

     *Type*                 Enumeration
                            
     *Default Value*        '[none]'
                            
     *Valid Values*         'ndbd' 'mysqld' 'ndb_mgmd'

     Filters results so that only configuration values applying to nodes
     of the specified NODE_TYPE ('ndbd', 'mysqld', or 'ndb_mgmd') are
     returned.

   * 
     '--usage', '--help', or '-?'

     Property               Value
                            
     *Command-Line          '--help' '--usage'
     Format*

     Causes *note 'ndb_config': mysql-cluster-programs-ndb-config. to
     print a list of available options, and then exit.

   * 
     '--version', '-V'

     Property               Value
                            
     *Command-Line          '--version'
     Format*

     Causes *note 'ndb_config': mysql-cluster-programs-ndb-config. to
     print a version information string, and then exit.

   * 
     '--configinfo' '--xml'

     Property               Value
                            
     *Command-Line          '--configinfo --xml'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'

     Cause *note 'ndb_config': mysql-cluster-programs-ndb-config.
     '--configinfo' to provide output as XML by adding this option.  A
     portion of such output is shown in this example:

          shell> ndb_config --configinfo --xml

          <configvariables protocolversion="1" ndbversionstring="5.5.65-ndb-7.2.39"
                              ndbversion="458758" ndbversionmajor="7" ndbversionminor="0"
                              ndbversionbuild="6">
            <section name="SYSTEM">
              <param name="Name" comment="Name of system (NDB Cluster)" type="string"
                        mandatory="true"/>
              <param name="PrimaryMGMNode" comment="Node id of Primary ndb_mgmd(MGM) node"
                        type="unsigned" default="0" min="0" max="4294967039"/>
              <param name="ConfigGenerationNumber" comment="Configuration generation number"
                        type="unsigned" default="0" min="0" max="4294967039"/>
            </section>
            <section name="NDBD">
              <param name="MaxNoOfSubscriptions"
                        comment="Max no of subscriptions (default 0 == MaxNoOfTables)"
                        type="unsigned" default="0" min="0" max="4294967039"/>
              <param name="MaxNoOfSubscribers"
                        comment="Max no of subscribers (default 0 == 2 * MaxNoOfTables)"
                        type="unsigned" default="0" min="0" max="4294967039"/>

              ...

            </section>

            ...

          </configvariables>

     *Note*:

     Normally, the XML output produced by *note 'ndb_config':
     mysql-cluster-programs-ndb-config. '--configinfo' '--xml' is
     formatted using one line per element; we have added extra
     whitespace in the previous example, as well as the next one, for
     reasons of legibility.  This should not make any difference to
     applications using this output, since most XML processors either
     ignore nonessential whitespace as a matter of course, or can be
     instructed to do so.

     The XML output also indicates when changing a given parameter
     requires that data nodes be restarted using the '--initial' option.
     This is shown by the presence of an 'initial="true"' attribute in
     the corresponding '<param>' element.  In addition, the restart type
     ('system' or 'node') is also shown; if a given parameter requires a
     system restart, this is indicated by the presence of a
     'restart="system"' attribute in the corresponding '<param>'
     element.  For example, changing the value set for the 'Diskless'
     parameter requires a system initial restart, as shown here (with
     the 'restart' and 'initial' attributes highlighted for visibility):

          <param name="Diskless" comment="Run wo/ disk" type="bool" default="false"
                    _restart="system" initial="true"_/>

     Currently, no 'initial' attribute is included in the XML output for
     '<param>' elements corresponding to parameters which do not require
     initial restarts; in other words, 'initial="false"' is the default,
     and the value 'false' should be assumed if the attribute is not
     present.  Similarly, the default restart type is 'node' (that is,
     an online or 'rolling' restart of the cluster), but the 'restart'
     attribute is included only if the restart type is 'system' (meaning
     that all cluster nodes must be shut down at the same time, then
     restarted).

     *Important*:

     The '--xml' option can be used only with the '--configinfo' option.
     Using '--xml' without '--configinfo' fails with an error.

     Unlike the options used with this program to obtain current
     configuration data, '--configinfo' and '--xml' use information
     obtained from the NDB Cluster sources when *note 'ndb_config':
     mysql-cluster-programs-ndb-config. was compiled.  For this reason,
     no connection to a running NDB Cluster or access to a 'config.ini'
     or 'my.cnf' file is required for these two options.

Combining other *note 'ndb_config': mysql-cluster-programs-ndb-config.
options (such as '--query' or '--type') with '--configinfo' (with or
without the '--xml' option) is not supported.  Currently, if you attempt
to do so, the usual result is that all other options besides
'--configinfo' or '--xml' are simply ignored.  _However, this behavior
is not guaranteed and is subject to change at any time_.  In addition,
since *note 'ndb_config': mysql-cluster-programs-ndb-config, when used
with the '--configinfo' option, does not access the NDB Cluster or read
any files, trying to specify additional options such as
'--ndb-connectstring' or '--config-file' with '--configinfo' serves no
purpose.

*Examples*

  1. To obtain the node ID and type of each node in the cluster:

          shell> ./ndb_config --query=id,type --fields=':' --rows='\n'
          1:ndbd
          2:ndbd
          3:ndbd
          4:ndbd
          5:ndb_mgmd
          6:mysqld
          7:mysqld
          8:mysqld
          9:mysqld

     In this example, we used the '--fields' options to separate the ID
     and type of each node with a colon character (':'), and the
     '--rows' options to place the values for each node on a new line in
     the output.

  2. To produce a connection string that can be used by data, SQL, and
     API nodes to connect to the management server:

          shell> ./ndb_config --config-file=usr/local/mysql/cluster-data/config.ini \
          --query=hostname,portnumber --fields=: --rows=, --type=ndb_mgmd
          198.51.100.179:1186

  3. This invocation of *note 'ndb_config':
     mysql-cluster-programs-ndb-config. checks only data nodes (using
     the '--type' option), and shows the values for each node's ID and
     host name, as well as the values set for its 'DataMemory',
     'IndexMemory', and 'DataDir' parameters:

          shell> ./ndb_config --type=ndbd -q id,host,datamemory,indexmemory,datadir -f ' : ' -r '\n'
          1 : 198.51.100.193 : 83886080 : 18874368 : /usr/local/mysql/cluster-data
          2 : 198.51.100.112 : 83886080 : 18874368 : /usr/local/mysql/cluster-data
          3 : 198.51.100.176 : 83886080 : 18874368 : /usr/local/mysql/cluster-data
          4 : 198.51.100.119 : 83886080 : 18874368 : /usr/local/mysql/cluster-data

     In this example, we used the short options '-f' and '-r' for
     setting the field delimiter and row separator, respectively, as
     well as the short option '-q' to pass a list of parameters to be
     obtained.

  4. To exclude results from any host except one in particular, use the
     '--host' option:

          shell> ./ndb_config --host=198.51.100.176 -f : -r '\n' -q id,type
          3:ndbd
          5:ndb_mgmd

     In this example, we also used the short form '-q' to determine the
     attributes to be queried.

     Similarly, you can limit results to a node with a specific ID using
     the '--nodeid' option.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-cpcd,  Next: mysql-cluster-programs-ndb-delete-all,  Prev: mysql-cluster-programs-ndb-config,  Up: mysql-cluster-programs

18.4.8 'ndb_cpcd' -- Automate Testing for NDB Development
---------------------------------------------------------

A utility having this name was formerly part of an internal automated
test framework used in testing and debugging NDB Cluster.  It was
deprecated in NDB Cluster 7.0, and removed from NDB Cluster
distributions provided by Oracle beginning with NDB 7.2.1.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-delete-all,  Next: mysql-cluster-programs-ndb-desc,  Prev: mysql-cluster-programs-ndb-cpcd,  Up: mysql-cluster-programs

18.4.9 'ndb_delete_all' -- Delete All Rows from an NDB Table
------------------------------------------------------------

*note 'ndb_delete_all': mysql-cluster-programs-ndb-delete-all. deletes
all rows from the given *note 'NDB': mysql-cluster. table.  In some
cases, this can be much faster than *note 'DELETE': delete. or even
*note 'TRUNCATE TABLE': truncate-table.

*Usage*

     ndb_delete_all -c CONNECTION_STRING TBL_NAME -d DB_NAME

This deletes all rows from the table named TBL_NAME in the database
named DB_NAME.  It is exactly equivalent to executing 'TRUNCATE
DB_NAME.TBL_NAME' in MySQL.

The following table includes options that are specific to *note
'ndb_delete_all': mysql-cluster-programs-ndb-delete-all.  Additional
descriptions follow the table.  For options common to most NDB Cluster
programs (including *note 'ndb_delete_all':
mysql-cluster-programs-ndb-delete-all.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_delete_all program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Name of the database     
'--database=dbname',     in which the table is    All MySQL 5.5 based
                         found                    releases
'-d'                                              

'--transactional',       Perform the delete in    All MySQL 5.5 based
                         a single transaction     releases
' -t '                   (may run out of          
                         operations)
                         
                         Run tup scan             
'--tupscan'                                       All MySQL 5.5 based
                                                  releases
                                                  
                         Run disk scan            
'--diskscan'                                      All MySQL 5.5 based
                                                  releases

   * 
     '--transactional', '-t'

     Use of this option causes the delete operation to be performed as a
     single transaction.

     *Warning*:

     With very large tables, using this option may cause the number of
     operations available to the cluster to be exceeded.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-desc,  Next: mysql-cluster-programs-ndb-drop-index,  Prev: mysql-cluster-programs-ndb-delete-all,  Up: mysql-cluster-programs

18.4.10 'ndb_desc' -- Describe NDB Tables
-----------------------------------------

*note 'ndb_desc': mysql-cluster-programs-ndb-desc. provides a detailed
description of one or more *note 'NDB': mysql-cluster. tables.

*Usage*

     ndb_desc -c CONNECTION_STRING TBL_NAME -d DB_NAME [OPTIONS]

(_NDB 7.2.9 and later:_)

     ndb_desc -c CONNECTION_STRING INDEX_NAME -d DB_NAME -t TBL_NAME

Additional options that can be used with *note 'ndb_desc':
mysql-cluster-programs-ndb-desc. are listed later in this section.

*Sample Output*

MySQL table creation and population statements:

     USE test;

     CREATE TABLE fish (
         id INT(11) NOT NULL AUTO_INCREMENT,
         name VARCHAR(20) NOT NULL,
         length_mm INT(11) NOT NULL,
         weight_gm INT(11) NOT NULL,

         PRIMARY KEY pk (id),
         UNIQUE KEY uk (name)
     ) ENGINE=NDB;

     INSERT INTO fish VALUES
         ('','guppy', 35, 2), ('','tuna', 2500, 150000),
         ('','shark', 3000, 110000), ('','manta ray', 1500, 50000),
         ('','grouper', 900, 125000), ('','puffer', 250, 2500);

Output from *note 'ndb_desc': mysql-cluster-programs-ndb-desc.:

     shell> ./ndb_desc -c localhost fish -d test -p
     -- fish --
     Version: 2
     Fragment type: 9
     K Value: 6
     Min load factor: 78
     Max load factor: 80
     Temporary table: no
     Number of attributes: 4
     Number of primary keys: 1
     Length of frm data: 311
     Row Checksum: 1
     Row GCI: 1
     SingleUserMode: 0
     ForceVarPart: 1
     FragmentCount: 2
     TableStatus: Retrieved
     -- Attributes --
     id Int PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY AUTO_INCR
     name Varchar(20;latin1_swedish_ci) NOT NULL AT=SHORT_VAR ST=MEMORY
     length_mm Int NOT NULL AT=FIXED ST=MEMORY
     weight_gm Int NOT NULL AT=FIXED ST=MEMORY

     -- Indexes --
     PRIMARY KEY(id) - UniqueHashIndex
     PRIMARY(id) - OrderedIndex
     uk$unique(name) - UniqueHashIndex
     uk(name) - OrderedIndex

     -- Per partition info --
     Partition  Row count  Commit count  Frag fixed memory ...
     0          2          2             32768             ...
     1          4          4             32768             ...

     ... Frag varsized memory  Extent_space  Free extent_space
     ... 32768                 0             0
     ... 32768                 0             0

     NDBT_ProgramExit: 0 - OK

Information about multiple tables can be obtained in a single invocation
of *note 'ndb_desc': mysql-cluster-programs-ndb-desc. by using their
names, separated by spaces.  All of the tables must be in the same
database.

Beginning with NDB 7.2.9, it is possible to obtain additional
information about a specific index using the '--table' (short form:
'-t') option introduced in this version and supplying the name of the
index as the first argument to *note 'ndb_desc':
mysql-cluster-programs-ndb-desc, as shown here:

     shell> ./ndb_desc uk -d test -t fish
     -- uk --
     Version: 3
     Base table: fish
     Number of attributes: 1
     Logging: 0
     Index type: OrderedIndex
     Index status: Retrieved
     -- Attributes --
     name Varchar(20;latin1_swedish_ci) NOT NULL AT=SHORT_VAR ST=MEMORY
     -- IndexTable 10/uk --
     Version: 3
     Fragment type: FragUndefined
     K Value: 6
     Min load factor: 78
     Max load factor: 80
     Temporary table: yes
     Number of attributes: 2
     Number of primary keys: 1
     Length of frm data: 0
     Row Checksum: 1
     Row GCI: 1
     SingleUserMode: 2
     ForceVarPart: 0
     FragmentCount: 4
     ExtraRowGciBits: 0
     ExtraRowAuthorBits: 0
     TableStatus: Retrieved
     -- Attributes --
     name Varchar(20;latin1_swedish_ci) NOT NULL AT=SHORT_VAR ST=MEMORY
     NDB$TNODE Unsigned [64] PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY
     -- Indexes --
     PRIMARY KEY(NDB$TNODE) - UniqueHashIndex

     NDBT_ProgramExit: 0 - OK

When an index is specified in this way, the '--extra-partition-info' and
'--extra-node-info' options have no effect.

The 'Version' column in the output contains the table's schema object
version.  For information about interpreting this value, see NDB Schema
Object Versions
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-schema-object-versions.html).

The 'Extent_space' and 'Free extent_space' columns are applicable only
to 'NDB' tables having columns on disk; for tables having only in-memory
columns, these columns always contain the value '0'.

To illustrate their use, we modify the previous example.  First, we must
create the necessary Disk Data objects, as shown here:

     CREATE LOGFILE GROUP lg_1
         ADD UNDOFILE 'undo_1.log'
         INITIAL_SIZE 16M
         UNDO_BUFFER_SIZE 2M
         ENGINE NDB;

     ALTER LOGFILE GROUP lg_1
         ADD UNDOFILE 'undo_2.log'
         INITIAL_SIZE 12M
         ENGINE NDB;

     CREATE TABLESPACE ts_1
         ADD DATAFILE 'data_1.dat'
         USE LOGFILE GROUP lg_1
         INITIAL_SIZE 32M
         ENGINE NDB;

     ALTER TABLESPACE ts_1
         ADD DATAFILE 'data_2.dat'
         INITIAL_SIZE 48M
         ENGINE NDB;

(For more information on the statements just shown and the objects
created by them, see *note mysql-cluster-disk-data-objects::, as well as
*note create-logfile-group::, and *note create-tablespace::.)

Now we can create and populate a version of the 'fish' table that stores
2 of its columns on disk (deleting the previous version of the table
first, if it already exists):

     CREATE TABLE fish (
         id INT(11) NOT NULL AUTO_INCREMENT,
         name VARCHAR(20) NOT NULL,
         length_mm INT(11) NOT NULL,
         weight_gm INT(11) NOT NULL,

         PRIMARY KEY pk (id),
         UNIQUE KEY uk (name)
     ) TABLESPACE ts_1 STORAGE DISK
     ENGINE=NDB;

     INSERT INTO fish VALUES
         ('','guppy', 35, 2), ('','tuna', 2500, 150000),
         ('','shark', 3000, 110000), ('','manta ray', 1500, 50000),
         ('','grouper', 900, 125000), ('','puffer', 250, 2500);

When run against this version of the table, *note 'ndb_desc':
mysql-cluster-programs-ndb-desc. displays the following output:

     shell> ./ndb_desc -c localhost fish -d test -p
     -- fish --
     Version: 3
     Fragment type: 9
     K Value: 6
     Min load factor: 78
     Max load factor: 80
     Temporary table: no
     Number of attributes: 4
     Number of primary keys: 1
     Length of frm data: 321
     Row Checksum: 1
     Row GCI: 1
     SingleUserMode: 0
     ForceVarPart: 1
     FragmentCount: 2
     TableStatus: Retrieved
     -- Attributes --
     id Int PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY AUTO_INCR
     name Varchar(20;latin1_swedish_ci) NOT NULL AT=SHORT_VAR ST=MEMORY
     length_mm Int NOT NULL AT=FIXED ST=DISK
     weight_gm Int NOT NULL AT=FIXED ST=DISK

     -- Indexes --
     PRIMARY KEY(id) - UniqueHashIndex
     PRIMARY(id) - OrderedIndex
     uk$unique(name) - UniqueHashIndex
     uk(name) - OrderedIndex
     -- Per partition info --
     Partition  Row count  Commit count  Frag fixed memory ...
     0          2          2             32768             ...
     1          4          4             32768             ...

     ... Frag varsized memory  Extent_space  Free extent_space
     ... 32768                 0             0
     ... 32768                 0             0

     NDBT_ProgramExit: 0 - OK

This means that 1048576 bytes are allocated from the tablespace for this
table on each partition, of which 1044440 bytes remain free for
additional storage.  In other words, 1048576 - 1044440 = 4136 bytes per
partition is currently being used to store the data from this table's
disk-based columns.  The number of bytes shown as 'Free extent_space' is
available for storing on-disk column data from the 'fish' table only;
for this reason, it is not visible when selecting from the *note
'INFORMATION_SCHEMA.FILES': files-table. table.

The following table includes options that are specific to *note
'ndb_desc': mysql-cluster-programs-ndb-desc.  Additional descriptions
follow the table.  For options common to most NDB Cluster programs
(including *note 'ndb_desc': mysql-cluster-programs-ndb-desc.), see
*note mysql-cluster-program-options-common::.

*Command-line options for the ndb_desc program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Include partition        
'--blob-info',           information for BLOB     All MySQL 5.5 based
                         tables in output.        releases
' -b '                   Requires that the -p     
                         option also be used
                         
                         Name of database         
'--database=dbname',     containing table         All MySQL 5.5 based
                                                  releases
' -d '                                            

'--extra-node-info',     Include                  All MySQL 5.5 based
                         partition-to-data-node   releases
' -n '                   mappings in output.      
                         Requires that the -p
                         option also be used
                         
                         Display information      
'--extra-partition-info',about partitions         All MySQL 5.5 based
                                                  releases
' -p '                                            

'--retries=#',           Number of times to       All MySQL 5.5 based
                         retry the connection     releases
' -r '                   (once per second)        
                         
                         Specify the table in     
'--table=tbl_name',      which to find an         ADDED: NDB 7.2.9
                         index.  When this        
' -t '                   option is used, -p and
                         -n have no effect and
                         are ignored.
                         
                         Use unqualified table    
'--unqualified',         names                    All MySQL 5.5 based
                                                  releases
' -u '

   * 
     '--blob-info', '-b'

     Include information about subordinate *note 'BLOB': blob. and *note
     'TEXT': blob. columns.

     Use of this option also requires the use of the
     '--extra-partition-info' ('-p') option.

   * 
     '--database=DB_NAME', '-d'

     Specify the database in which the table should be found.

   * 
     '--extra-node-info', '-n'

     Include information about the mappings between table partitions and
     the data nodes upon which they reside.  This information can be
     useful for verifying distribution awareness mechanisms and
     supporting more efficient application access to the data stored in
     NDB Cluster.

     Use of this option also requires the use of the
     '--extra-partition-info' ('-p') option.

   * 
     '--extra-partition-info', '-p'

     Print additional information about the table's partitions.

   * 
     '--retries=#', '-r'

     Try to connect this many times before giving up.  One connect
     attempt is made per second.

   * 
     '--table=TBL_NAME', '-t'

     Specify the table in which to look for an index.

     This option was added in NDB 7.2.9.

   * 
     '--unqualified', '-u'

     Use unqualified table names.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-drop-index,  Next: mysql-cluster-programs-ndb-drop-table,  Prev: mysql-cluster-programs-ndb-desc,  Up: mysql-cluster-programs

18.4.11 'ndb_drop_index' -- Drop Index from an NDB Table
--------------------------------------------------------

*note 'ndb_drop_index': mysql-cluster-programs-ndb-drop-index. drops the
specified index from an *note 'NDB': mysql-cluster. table.  _It is
recommended that you use this utility only as an example for writing NDB
API applications_--see the Warning later in this section for details.

*Usage*

     ndb_drop_index -c CONNECTION_STRING TABLE_NAME INDEX -d DB_NAME

The statement shown above drops the index named INDEX from the TABLE in
the DATABASE.

The following table includes options that are specific to *note
'ndb_drop_index': mysql-cluster-programs-ndb-drop-index.  Additional
descriptions follow the table.  For options common to most NDB Cluster
programs (including *note 'ndb_drop_index':
mysql-cluster-programs-ndb-drop-index.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_drop_index program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Name of the database     
'--database=dbname',     in which the table is    All MySQL 5.5 based
                         found                    releases
'-d'                     

*Warning*:

_Operations performed on Cluster table indexes using the NDB API are not
visible to MySQL and make the table unusable by a MySQL server_.  If you
use this program to drop an index, then try to access the table from an
SQL node, an error results, as shown here:

     shell> ./ndb_drop_index -c localhost dogs ix -d ctest1
     Dropping index dogs/idx...OK

     NDBT_ProgramExit: 0 - OK

     shell> ./mysql -u jon -p ctest1
     Enter password: *******
     Reading table information for completion of table and column names
     You can turn off this feature to get a quicker startup with -A

     Welcome to the MySQL monitor.  Commands end with ; or \g.
     Your MySQL connection id is 7 to server version: 5.5.65-ndb-7.2.39

     Type 'help;' or '\h' for help. Type '\c' to clear the buffer.

     mysql> SHOW TABLES;
     +------------------+
     | Tables_in_ctest1 |
     +------------------+
     | a                |
     | bt1              |
     | bt2              |
     | dogs             |
     | employees        |
     | fish             |
     +------------------+
     6 rows in set (0.00 sec)

     mysql> SELECT * FROM dogs;
     ERROR 1296 (HY000): Got error 4243 'Index not found' from NDBCLUSTER

In such a case, your _only_ option for making the table available to
MySQL again is to drop the table and re-create it.  You can use either
the SQL statement*note 'DROP TABLE': drop-table. or the *note
'ndb_drop_table': mysql-cluster-programs-ndb-drop-table. utility (see
*note mysql-cluster-programs-ndb-drop-table::) to drop the table.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-drop-table,  Next: mysql-cluster-programs-ndb-error-reporter,  Prev: mysql-cluster-programs-ndb-drop-index,  Up: mysql-cluster-programs

18.4.12 'ndb_drop_table' -- Drop an NDB Table
---------------------------------------------

*note 'ndb_drop_table': mysql-cluster-programs-ndb-drop-table. drops the
specified *note 'NDB': mysql-cluster. table.  (If you try to use this on
a table created with a storage engine other than *note 'NDB':
mysql-cluster, the attempt fails with the error '723: No such table
exists'.)  This operation is extremely fast; in some cases, it can be an
order of magnitude faster than using a MySQL *note 'DROP TABLE':
drop-table. statement on an *note 'NDB': mysql-cluster. table.

*Usage*

     ndb_drop_table -c CONNECTION_STRING TBL_NAME -d DB_NAME

The following table includes options that are specific to *note
'ndb_drop_table': mysql-cluster-programs-ndb-drop-table.  Additional
descriptions follow the table.  For options common to most NDB Cluster
programs (including *note 'ndb_drop_table':
mysql-cluster-programs-ndb-drop-table.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_drop_table program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Name of the database     
'--database=dbname',     in which the table is    All MySQL 5.5 based
                         found                    releases
'-d'                     


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-error-reporter,  Next: mysql-cluster-programs-ndb-index-stat,  Prev: mysql-cluster-programs-ndb-drop-table,  Up: mysql-cluster-programs

18.4.13 'ndb_error_reporter' -- NDB Error-Reporting Utility
-----------------------------------------------------------

*note 'ndb_error_reporter': mysql-cluster-programs-ndb-error-reporter.
creates an archive from data node and management node log files that can
be used to help diagnose bugs or other problems with a cluster.  _It is
highly recommended that you make use of this utility when filing reports
of bugs in NDB Cluster_.

The following table includes command options specific to the NDB Cluster
program *note 'ndb_error_reporter':
mysql-cluster-programs-ndb-error-reporter.  Additional descriptions
follow the table.  For options common to most NDB Cluster programs
(including *note 'ndb_error_reporter':
mysql-cluster-programs-ndb-error-reporter.), see *note
mysql-cluster-program-options-common::.

*note 'ndb_error_reporter': mysql-cluster-programs-ndb-error-reporter.
did not support the '--help' option prior to NDB 7.2.14 (Bug #11756666,
Bug #48606).  The '--connection-timeout' '--dry-scp', and
'--skip-nodegroup' options were also added in this release (Bug
#16602002).

*Command-line options for the ndb_error_reporter program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Number of seconds to     
'                        wait when connecting     ADDED: NDB 7.2.14
--connection-timeout=timeoutto nodes before timing
'                        out.
                         
                         Disable scp with         
' --dry-scp '            remote hosts; used       ADDED: NDB 7.2.14
                         only for testing.        
                         
                         Include file system      
' --fs '                 data in error report;    All MySQL 5.5 based
                         can use a large amount   releases
                         of disk space            
                         
                         Skip all nodes in the    
'                        node group having this   ADDED: NDB 7.2.14
--skip-nodegroup=nodegroup_idID.
'                        

*Usage*

     ndb_error_reporter PATH/TO/CONFIG-FILE [USERNAME] [OPTIONS]

This utility is intended for use on a management node host, and requires
the path to the management host configuration file (usually named
'config.ini').  Optionally, you can supply the name of a user that is
able to access the cluster's data nodes using SSH, to copy the data node
log files.  *note 'ndb_error_reporter':
mysql-cluster-programs-ndb-error-reporter. then includes all of these
files in archive that is created in the same directory in which it is
run.  The archive is named 'ndb_error_report_YYYYMMDDHHMMSS.tar.bz2',
where YYYYMMDDHHMMSS is a datetime string.

*note 'ndb_error_reporter': mysql-cluster-programs-ndb-error-reporter.
also accepts the options listed here:

   * 
     '--connection-timeout=TIMEOUT'

     Property               Value
                            
     *Command-Line          '--connection-timeout=timeout'
     Format*                

     *Introduced*           5.5.34-ndb-7.2.14
                            
     *Type*                 Integer
                            
     *Default Value*        '0'

     Wait this many seconds when trying to connect to nodes before
     timing out.

   * 
     '--dry-scp'

     Property               Value
                            
     *Command-Line          '--dry-scp'
     Format*                

     *Introduced*           5.5.34-ndb-7.2.14
                            
     *Type*                 Boolean
                            
     *Default Value*        'TRUE'

     Run *note 'ndb_error_reporter':
     mysql-cluster-programs-ndb-error-reporter. without using scp from
     remote hosts.  Used for testing only.

   * 
     '--fs'

     Property               Value
                            
     *Command-Line          '--fs'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Copy the data node file systems to the management host and include
     them in the archive.

     Because data node file systems can be extremely large, even after
     being compressed, we ask that you please do _not_ send archives
     created using this option to Oracle unless you are specifically
     requested to do so.

   * 
     '--skip-nodegroup=NODEGROUP_ID'

     Property               Value
                            
     *Command-Line          '--connection-timeout=timeout'
     Format*                

     *Introduced*           5.5.34-ndb-7.2.14
                            
     *Type*                 Integer
                            
     *Default Value*        '0'

     Skip all nodes belong to the node group having the supplied node
     group ID.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-index-stat,  Next: mysql-cluster-programs-ndb-move-data,  Prev: mysql-cluster-programs-ndb-error-reporter,  Up: mysql-cluster-programs

18.4.14 'ndb_index_stat' -- NDB Index Statistics Utility
--------------------------------------------------------

*note 'ndb_index_stat': mysql-cluster-programs-ndb-index-stat. provides
per-fragment statistical information about indexes on 'NDB' tables.
This includes cache version and age, number of index entries per
partition, and memory consumption by indexes.

*Usage*

To obtain basic index statistics about a given *note 'NDB':
mysql-cluster. table, invoke *note 'ndb_index_stat':
mysql-cluster-programs-ndb-index-stat. as shown here, with the name of
the table as the first argument and the name of the database containing
this table specified immediately following it, using the '--database'
('-d') option:

     ndb_index_stat TABLE -d DATABASE

In this example, we use *note 'ndb_index_stat':
mysql-cluster-programs-ndb-index-stat. to obtain such information about
an 'NDB' table named 'mytable' in the 'test' database:

     shell> ndb_index_stat -d test mytable
     table:City index:PRIMARY fragCount:2
     sampleVersion:3 loadTime:1399585986 sampleCount:1994 keyBytes:7976
     query cache: valid:1 sampleCount:1994 totalBytes:27916
     times in ms: save: 7.133 sort: 1.974 sort per sample: 0.000

     NDBT_ProgramExit: 0 - OK

'sampleVersion' is the version number of the cache from which the
statistics data is taken.  Running *note 'ndb_index_stat':
mysql-cluster-programs-ndb-index-stat. with the '--update' option causes
sampleVersion to be incremented.

'loadTime' shows when the cache was last updated.  This is expressed as
seconds since the Unix Epoch.

'sampleCount' is the number of index entries found per partition.  You
can estimate the total number of entries by multiplying this by the
number of fragments (shown as 'fragCount').

'sampleCount' can be compared with the cardinality of *note 'SHOW
INDEX': show-index. or *note 'INFORMATION_SCHEMA.STATISTICS':
statistics-table, although the latter two provide a view of the table as
a whole, while *note 'ndb_index_stat':
mysql-cluster-programs-ndb-index-stat. provides a per-fragment average.

'keyBytes' is the number of bytes used by the index.  In this example,
the primary key is an integer, which requires four bytes for each index,
so 'keyBytes' can be calculated in this case as shown here:

         keyBytes = sampleCount * (4 bytes per index) = 1994 * 4 = 7976

This information can also be obtained using the corresponding column
definitions from *note 'INFORMATION_SCHEMA.COLUMNS': columns-table.
(this requires a MySQL Server and a MySQL client application).

'totalBytes' is the total memory consumed by all indexes on the table,
in bytes.

Timings shown in the preceding examples are specific to each invocation
of *note 'ndb_index_stat': mysql-cluster-programs-ndb-index-stat.

The '--verbose' option provides some additional output, as shown here:

     shell> ndb_index_stat -d test mytable --verbose
     random seed 1337010518
     connected
     loop 1 of 1
     table:mytable index:PRIMARY fragCount:4
     sampleVersion:2 loadTime:1336751773 sampleCount:0 keyBytes:0
     read stats
     query cache created
     query cache: valid:1 sampleCount:0 totalBytes:0
     times in ms: save: 20.766 sort: 0.001
     disconnected

     NDBT_ProgramExit: 0 - OK

     shell>

If the only output from the program is 'NDBT_ProgramExit: 0 - OK', this
may indicate that no statistics yet exist.  To force them to be created
(or updated if they already exist), invoke *note 'ndb_index_stat':
mysql-cluster-programs-ndb-index-stat. with the '--update' option, or
execute *note 'ANALYZE TABLE': analyze-table. on the table in the *note
'mysql': mysql. client.

*Options*

The following table includes options that are specific to the NDB
Cluster *note 'ndb_index_stat': mysql-cluster-programs-ndb-index-stat.
utility.  Additional descriptions are listed following the table.  For
options common to most NDB Cluster programs (including *note
'ndb_index_stat': mysql-cluster-programs-ndb-index-stat.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_index_stat program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Name of the database     
'--database=name',       containing the table.    All MySQL 5.5 based
                                                  releases
' -d '                                            

' --delete '             Delete index             All MySQL 5.5 based
                         statistics for the       releases
                         given table, stopping    
                         any auto-update
                         previously configured.
                         
                         Update index             
' --update '             statistics for the       All MySQL 5.5 based
                         given table,             releases
                         restarting any           
                         auto-update previously
                         configured.
                         
                         Print the query cache.   
' --dump '                                        All MySQL 5.5 based
                                                  releases
                                                  
                         Perform a number of      
' --query=# '            random range queries     All MySQL 5.5 based
                         on first key attr        releases
                         (must be int             
                         unsigned).
                         
                         Drop any statistics      
' --sys-drop '           tables and events in     All MySQL 5.5 based
                         NDB kernel (all          releases
                         statistics are lost)     
                         
                         Create all statistics    
' --sys-create '         tables and events in     All MySQL 5.5 based
                         NDB kernel, if none of   releases
                         them already exist       
                         
                         Create any statistics    
'                        tables and events in     All MySQL 5.5 based
--sys-create-if-not-existNDB kernel that do not   releases
'                        already exist.           
                         
                         Create any statistics    
'                        tables or events that    All MySQL 5.5 based
--sys-create-if-not-validdo not already exist     releases
'                        in the NDB kernel.       
                         after dropping any
                         that are invalid.
                         
                         Verify that NDB system   
' --sys-check '          index statistics and     All MySQL 5.5 based
                         event tables exist.      releases
                                                  
                         Do not apply sys-*       
' --sys-skip-tables '    options to tables.       All MySQL 5.5 based
                                                  releases
                                                  
                         Do not apply sys-*       
' --sys-skip-events '    options to events.       All MySQL 5.5 based
                                                  releases
                                                  
                         Turn on verbose output   
'--verbose',                                      All MySQL 5.5 based
                                                  releases
' -v '                                            

' --loops=# '            Set the number of        All MySQL 5.5 based
                         times to perform a       releases
                         given command.
                         Default is 0.
                         

ndb_index_stat statistics options

The following options are used to generate index statistics.  They work
with a given table and database.  They cannot be mixed with system
options (see *note ndb-index-stat-options-system::).

   * 
     '--database=NAME', '-d NAME'

     Property               Value
                            
     *Command-Line          '--database=name'
     Format*                

     *Type*                 String
                            
     *Default Value*        '[none]'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     The name of the database that contains the table being queried.

   * 
     '--delete'

     Property               Value
                            
     *Command-Line          '--delete'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Delete the index statistics for the given table, stopping any
     auto-update that was previously configured.

   * 
     '--update'

     Property               Value
                            
     *Command-Line          '--update'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Update the index statistics for the given table, and restart any
     auto-update that was previously configured.

   * 
     '--dump'

     Property               Value
                            
     *Command-Line          '--dump'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Dump the contents of the query cache.

   * 
     '--query=#'

     Property               Value
                            
     *Command-Line          '--query=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '0'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        'MAX_INT'

     Perform random range queries on first key attribute (must be int
     unsigned).

ndb_index_stat system options

The following options are used to generate and update the statistics
tables in the NDB kernel.  None of these options can be mixed with
statistics options (see *note ndb-index-stat-options-statistics::).

   * 
     '--sys-drop'

     Property               Value
                            
     *Command-Line          '--sys-drop'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Drop all statistics tables and events in the NDB kernel.  _This
     causes all statistics to be lost_.

   * 
     '--sys-create'

     Property               Value
                            
     *Command-Line          '--sys-create'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Create all statistics tables and events in the NDB kernel.  This
     works only if none of them exist previously.

   * 
     'sys-create-if-not-exist'

     Property               Value
                            
     *Command-Line          '--sys-create-if-not-exist'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Create any NDB system statistics tables or events (or both) that do
     not already exist when the program is invoked.

   * 
     '--sys-create-if-not-valid'

     Property               Value
                            
     *Command-Line          '--sys-create-if-not-valid'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Create any NDB system statistics tables or events that do not
     already exist, after dropping any that are invalid.

   * 
     '--sys-check'

     Property               Value
                            
     *Command-Line          '--sys-check'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Verify that all required system statistics tables and events exist
     in the NDB kernel.

   * 
     '--sys-skip-tables'

     Property               Value
                            
     *Command-Line          '--sys-skip-tables'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Do not apply any '--sys-*' options to any statistics tables.

   * 
     '--sys-skip-events'

     Property               Value
                            
     *Command-Line          '--sys-skip-events'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Do not apply any '--sys-*' options to any events.

   * 
     '--verbose'

     Property               Value
                            
     *Command-Line          '--verbose'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'false'
                            
     *Minimum Value*        ''
                            
     *Maximum Value*        ''

     Turn on verbose output.

   * 
     '--loops=#'

     Property               Value
                            
     *Command-Line          '--loops=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '0'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        'MAX_INT'

     Repeat commands this number of times (for use in testing).


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-move-data,  Next: mysql-cluster-programs-ndb-print-backup-file,  Prev: mysql-cluster-programs-ndb-index-stat,  Up: mysql-cluster-programs

18.4.15 'ndb_move_data' -- NDB Data Copy Utility
------------------------------------------------

*note 'ndb_move_data': mysql-cluster-programs-ndb-move-data. copies data
from one NDB table to another.

*Usage*

The program is invoked with the names of the source and target tables;
either or both of these may be qualified optionally with the database
name.  Both tables must use the NDB storage engine.

     ndb_move_data OPTIONS SOURCE TARGET

The following table includes options that are specific to *note
'ndb_move_data': mysql-cluster-programs-ndb-move-data.  Additional
descriptions follow the table.  For options common to most NDB Cluster
programs (including *note 'ndb_move_data':
mysql-cluster-programs-ndb-move-data.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_move_data program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Dump core on permanent   
' --abort-on-error '     error (debug option)     All MySQL 5.5 based
                                                  releases
                                                  
                         Directory where          
'                        character sets are       All MySQL 5.5 based
--character-sets-dir=name                         releases
'                                                 

'--database=dbname',     Name of the database     All MySQL 5.5 based
                         in which the table is    releases
' -d '                   found                    
                         
                         Drop source table        
' --drop-source '        after all rows have      All MySQL 5.5 based
                         been moved               releases
                                                  
                         Insert random            
' --error-insert '       temporary errors         All MySQL 5.5 based
                         (testing option)         releases
                                                  
                         Ignore extra columns     
'                        in source or target      All MySQL 5.5 based
--exclude-missing-columnstable                    releases
'                                                 

'--lossy-conversions',   Allow attribute data     All MySQL 5.5 based
                         to be truncated when     releases
' -l '                   converted to a smaller   
                         type
                         
                         Allow attribute data     
'--promote-attributes',  to be converted to a     All MySQL 5.5 based
                         larger type              releases
' -A '                                            

'                        Specify tries on         All MySQL 5.5 based
--staging-tries=x[,y[,z]]temporary errors.        releases
'                        Format is x[,y[,z]]      
                         where x=max tries
                         (0=no limit), y=min
                         delay (ms), z=max
                         delay (ms)
                         
                         Enable verbose           
' --verbose '            messages                 All MySQL 5.5 based
                                                  releases

   * 
     '--abort-on-error'

     Property               Value
                            
     *Command-Line          '--abort-on-error'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Dump core on permanent error (debug option).

   * 
     '--character-sets-dir'=NAME

     Property               Value
                            
     *Command-Line          '--character-sets-dir=name'
     Format*                

     *Type*                 String
                            
     *Default Value*        '[none]'

     Directory where character sets are.

   * 
     '--database'=DBNAME, '-d'

     Property               Value
                            
     *Command-Line          '--database=dbname'
     Format*                

     *Type*                 String
                            
     *Default Value*        'TEST_DB'

     Name of the database in which the table is found.

   * 
     '--drop-source'

     Property               Value
                            
     *Command-Line          '--drop-source'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Drop source table after all rows have been moved.

   * 
     '--error-insert'

     Property               Value
                            
     *Command-Line          '--error-insert'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Insert random temporary errors (testing option).

   * 
     '--exclude-missing-columns'

     Property               Value
                            
     *Command-Line          '--exclude-missing-columns'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Ignore extra columns in source or target table.

   * 
     '--lossy-conversions', '-l'

     Property               Value
                            
     *Command-Line          '--lossy-conversions'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Allow attribute data to be truncated when converted to a smaller
     type.

   * 
     '--promote-attributes', '-A'

     Property               Value
                            
     *Command-Line          '--promote-attributes'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Allow attribute data to be converted to a larger type.

   * 
     '--staging-tries'=X[,Y[,Z]]

     Property               Value
                            
     *Command-Line          '--staging-tries=x[,y[,z]]'
     Format*                

     *Type*                 String
                            
     *Default Value*        '0,1000,60000'

     Specify tries on temporary errors.  Format is x[,y[,z]] where x=max
     tries (0=no limit), y=min delay (ms), z=max delay (ms).

   * 
     '--verbose'

     Property               Value
                            
     *Command-Line          '--verbose'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Enable verbose messages.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-print-backup-file,  Next: mysql-cluster-programs-ndb-print-file,  Prev: mysql-cluster-programs-ndb-move-data,  Up: mysql-cluster-programs

18.4.16 'ndb_print_backup_file' -- Print NDB Backup File Contents
-----------------------------------------------------------------

*note 'ndb_print_backup_file':
mysql-cluster-programs-ndb-print-backup-file. obtains diagnostic
information from a cluster backup file.

*Usage*

     ndb_print_backup_file FILE_NAME

FILE_NAME is the name of a cluster backup file.  This can be any of the
files ('.Data', '.ctl', or '.log' file) found in a cluster backup
directory.  These files are found in the data node's backup directory
under the subdirectory 'BACKUP-#', where # is the sequence number for
the backup.  For more information about cluster backup files and their
contents, see *note mysql-cluster-backup-concepts::.

Like *note 'ndb_print_schema_file':
mysql-cluster-programs-ndb-print-schema-file. and *note
'ndb_print_sys_file': mysql-cluster-programs-ndb-print-sys-file. (and
unlike most of the other *note 'NDB': mysql-cluster. utilities that are
intended to be run on a management server host or to connect to a
management server) *note 'ndb_print_backup_file':
mysql-cluster-programs-ndb-print-backup-file. must be run on a cluster
data node, since it accesses the data node file system directly.
Because it does not make use of the management server, this utility can
be used when the management server is not running, and even when the
cluster has been completely shut down.

*Additional Options*

None.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-print-file,  Next: mysql-cluster-programs-ndb-print-schema-file,  Prev: mysql-cluster-programs-ndb-print-backup-file,  Up: mysql-cluster-programs

18.4.17 'ndb_print_file' -- Print NDB Disk Data File Contents
-------------------------------------------------------------

*note 'ndb_print_file': mysql-cluster-programs-ndb-print-file. obtains
information from an NDB Cluster Disk Data file.

*Usage*

     ndb_print_file [-v] [-q] FILE_NAME+

FILE_NAME is the name of an NDB Cluster Disk Data file.  Multiple
filenames are accepted, separated by spaces.

Like *note 'ndb_print_schema_file':
mysql-cluster-programs-ndb-print-schema-file. and *note
'ndb_print_sys_file': mysql-cluster-programs-ndb-print-sys-file. (and
unlike most of the other *note 'NDB': mysql-cluster. utilities that are
intended to be run on a management server host or to connect to a
management server) *note 'ndb_print_file':
mysql-cluster-programs-ndb-print-file. must be run on an NDB Cluster
data node, since it accesses the data node file system directly.
Because it does not make use of the management server, this utility can
be used when the management server is not running, and even when the
cluster has been completely shut down.

*Additional Options*

*note 'ndb_print_file': mysql-cluster-programs-ndb-print-file. supports
the following options:

   * '-v': Make output verbose.

   * '-q': Suppress output (quiet mode).

   * '--help', '-h', '-?': Print help message.

     This option did not work correctly prior to NDB 7.2.18.  (Bug
     #17069285)

For more information, see *note mysql-cluster-disk-data::.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-print-schema-file,  Next: mysql-cluster-programs-ndb-print-sys-file,  Prev: mysql-cluster-programs-ndb-print-file,  Up: mysql-cluster-programs

18.4.18 'ndb_print_schema_file' -- Print NDB Schema File Contents
-----------------------------------------------------------------

*note 'ndb_print_schema_file':
mysql-cluster-programs-ndb-print-schema-file. obtains diagnostic
information from a cluster schema file.

*Usage*

     ndb_print_schema_file FILE_NAME

FILE_NAME is the name of a cluster schema file.  For more information
about cluster schema files, see NDB Cluster Data Node File System
Directory Files
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-ndbd-filesystemdir-files.html).

Like *note 'ndb_print_backup_file':
mysql-cluster-programs-ndb-print-backup-file. and *note
'ndb_print_sys_file': mysql-cluster-programs-ndb-print-sys-file. (and
unlike most of the other *note 'NDB': mysql-cluster. utilities that are
intended to be run on a management server host or to connect to a
management server) *note 'ndb_print_schema_file':
mysql-cluster-programs-ndb-print-schema-file. must be run on a cluster
data node, since it accesses the data node file system directly.
Because it does not make use of the management server, this utility can
be used when the management server is not running, and even when the
cluster has been completely shut down.

*Additional Options*

None.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-print-sys-file,  Next: mysql-cluster-programs-ndb-redo-log-reader,  Prev: mysql-cluster-programs-ndb-print-schema-file,  Up: mysql-cluster-programs

18.4.19 'ndb_print_sys_file' -- Print NDB System File Contents
--------------------------------------------------------------

*note 'ndb_print_sys_file': mysql-cluster-programs-ndb-print-sys-file.
obtains diagnostic information from an NDB Cluster system file.

*Usage*

     ndb_print_sys_file FILE_NAME

FILE_NAME is the name of a cluster system file (sysfile).  Cluster
system files are located in a data node's data directory ('DataDir');
the path under this directory to system files matches the pattern
'ndb_#_fs/D#/DBDIH/P#.sysfile'.  In each case, the # represents a number
(not necessarily the same number).  For more information, see NDB
Cluster Data Node File System Directory Files
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-ndbd-filesystemdir-files.html).

Like *note 'ndb_print_backup_file':
mysql-cluster-programs-ndb-print-backup-file. and *note
'ndb_print_schema_file': mysql-cluster-programs-ndb-print-schema-file.
(and unlike most of the other *note 'NDB': mysql-cluster. utilities that
are intended to be run on a management server host or to connect to a
management server) *note 'ndb_print_backup_file':
mysql-cluster-programs-ndb-print-backup-file. must be run on a cluster
data node, since it accesses the data node file system directly.
Because it does not make use of the management server, this utility can
be used when the management server is not running, and even when the
cluster has been completely shut down.

*Additional Options*

None.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-redo-log-reader,  Next: mysql-cluster-programs-ndb-restore,  Prev: mysql-cluster-programs-ndb-print-sys-file,  Up: mysql-cluster-programs

18.4.20 'ndb_redo_log_reader' -- Check and Print Content of Cluster Redo Log
----------------------------------------------------------------------------

Reads a redo log file, checking it for errors, printing its contents in
a human-readable format, or both.  *note 'ndb_redo_log_reader':
mysql-cluster-programs-ndb-redo-log-reader. is intended for use
primarily by NDB Cluster developers and Support personnel in debugging
and diagnosing problems.

This utility remains under development, and its syntax and behavior are
subject to change in future NDB Cluster releases.

*Note*:

Prior to NDB 7.2, this utility was named 'ndbd_redo_log_reader'.

The C++ source files for *note 'ndb_redo_log_reader':
mysql-cluster-programs-ndb-redo-log-reader. can be found in the
directory '/storage/ndb/src/kernel/blocks/dblqh/redoLogReader'.

The following table includes options that are specific to the NDB
Cluster program *note 'ndb_redo_log_reader':
mysql-cluster-programs-ndb-redo-log-reader.  Additional descriptions
follow the table.  For options common to most NDB Cluster programs
(including *note 'ndb_redo_log_reader':
mysql-cluster-programs-ndb-redo-log-reader.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_redo_log_reader program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Print dump info          
' -dump '                                         All MySQL 5.5 based
                                                  releases
                                                  
                         Print file descriptors   
' -filedescriptors '     only                     All MySQL 5.5 based
                                                  releases
                                                  
                         Print usage              
' --help '               information              ADDED: NDB 7.2.15
                                                  
                         Provide lap info, with   
' -lap '                 max GCI started and      All MySQL 5.5 based
                         completed                releases
                                                  
                         Starting megabyte        
' -mbyte # '                                      All MySQL 5.5 based
                                                  releases
                                                  
                         Show only the first      
' -mbyteheaders '        page header of every     All MySQL 5.5 based
                         megabyte in the file     releases
                                                  
                         Do not check records     
' -nocheck '             for errors               All MySQL 5.5 based
                                                  releases
                                                  
                         Do not print records     
' -noprint '                                      All MySQL 5.5 based
                                                  releases
                                                  
                         Start with this page     
' -page # '                                       All MySQL 5.5 based
                                                  releases
                                                  
                         Show page headers only   
' -pageheaders '                                  All MySQL 5.5 based
                                                  releases
                                                  
                         Start with this page     
' -pageindex # '         index                    All MySQL 5.5 based
                                                  releases
                                                  
                         Bit-shifted dump         
' -twiddle '                                      All MySQL 5.5 based
                                                  releases

*Usage*

     ndb_redo_log_reader FILE_NAME [OPTIONS]

FILE_NAME is the name of a cluster redo log file.  redo log files are
located in the numbered directories under the data node's data directory
('DataDir'); the path under this directory to the redo log files matches
the pattern 'ndb_NODEID_fs/D#/DBLQH/S#.FragLog'.  NODEID is the data
node's node ID. The two instances of # each represent a number (not
necessarily the same number); the number following 'D' is in the range
8-39 inclusive; the range of the number following 'S' varies according
to the value of the 'NoOfFragmentLogFiles' configuration parameter,
whose default value is 16; thus, the default range of the number in the
file name is 0-15 inclusive.  For more information, see NDB Cluster Data
Node File System Directory Files
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-ndbd-filesystemdir-files.html).

The name of the file to be read may be followed by one or more of the
options listed here:

   * 
     '-dump'

     Property               Value
                            
     *Command-Line          '-dump'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Print dump info.

   * 
     Property               Value
                            
     *Command-Line          '-filedescriptors'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     '-filedescriptors': Print file descriptors only.

   * 
     Property               Value
                            
     *Command-Line          '--help'
     Format*                

     *Introduced*           5.5.35-ndb-7.2.15

     '--help': Print usage information.

     Added in NDB 7.2.15.  (Bug #11749591, Bug #36805)

   * 
     '-lap'

     Property               Value
                            
     *Command-Line          '-lap'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Provide lap info, with max GCI started and completed.

   * 
     Property               Value
                            
     *Command-Line          '-mbyte #'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '0'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        '15'

     '-mbyte #': Starting megabyte.

     # is an integer in the range 0 to 15, inclusive.

   * 
     Property               Value
                            
     *Command-Line          '-mbyteheaders'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     '-mbyteheaders': Show only the first page header of every megabyte
     in the file.

   * 
     Property               Value
                            
     *Command-Line          '-noprint'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     '-noprint': Do not print the contents of the log file.

   * 
     Property               Value
                            
     *Command-Line          '-nocheck'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     '-nocheck': Do not check the log file for errors.

   * 
     Property               Value
                            
     *Command-Line          '-page #'
     Format*                

     *Type*                 Integer
                            
     *Default Value*        '0'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        '31'

     '-page #': Start at this page.

     # is an integer in the range 0 to 31, inclusive.

   * 
     Property               Value
                            
     *Command-Line          '-pageheaders'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     '-pageheaders': Show page headers only.

   * 
     Property               Value
                            
     *Command-Line          '-pageindex #'
     Format*                

     *Type*                 Integer
                            
     *Default Value*        '12'
                            
     *Minimum Value*        '12'
                            
     *Maximum Value*        '8191'

     '-pageindex #': Start at this page index.

     # is an integer between 12 and 8191, inclusive.

   * 
     '-twiddle'

     Property               Value
                            
     *Command-Line          '-twiddle'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Bit-shifted dump.

Like *note 'ndb_print_backup_file':
mysql-cluster-programs-ndb-print-backup-file. and *note
'ndb_print_schema_file': mysql-cluster-programs-ndb-print-schema-file.
(and unlike most of the *note 'NDB': mysql-cluster. utilities that are
intended to be run on a management server host or to connect to a
management server) *note 'ndb_redo_log_reader':
mysql-cluster-programs-ndb-redo-log-reader. must be run on a cluster
data node, since it accesses the data node file system directly.
Because it does not make use of the management server, this utility can
be used when the management server is not running, and even when the
cluster has been completely shut down.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-restore,  Next: mysql-cluster-programs-ndb-select-all,  Prev: mysql-cluster-programs-ndb-redo-log-reader,  Up: mysql-cluster-programs

18.4.21 'ndb_restore' -- Restore an NDB Cluster Backup
------------------------------------------------------

* Menu:

* ndb-restore-different-number-nodes::  Restoring to a different number of data nodes

The NDB Cluster restoration program is implemented as a separate
command-line utility *note 'ndb_restore':
mysql-cluster-programs-ndb-restore, which can normally be found in the
MySQL 'bin' directory.  This program reads the files created as a result
of the backup and inserts the stored information into the database.

*Note*:

Beginning with NDB 7.2.38, this program no longer prints
'NDBT_ProgramExit: ...' when it finishes its run.  Applications
depending on this behavior should be modified accordingly when upgrading
from NDB 7.2.37 or earlier to a later NDB 7.2 release.

*note 'ndb_restore': mysql-cluster-programs-ndb-restore. must be
executed once for each of the backup files that were created by the
*note 'START BACKUP': mysql-cluster-backup-using-management-client.
command used to create the backup (see *note
mysql-cluster-backup-using-management-client::).  This is equal to the
number of data nodes in the cluster at the time that the backup was
created.

*Note*:

Before using *note 'ndb_restore': mysql-cluster-programs-ndb-restore, it
is recommended that the cluster be running in single user mode, unless
you are restoring multiple data nodes in parallel.  See *note
mysql-cluster-single-user-mode::, for more information.

The following table includes options that are specific to the NDB
Cluster native backup restoration program *note 'ndb_restore':
mysql-cluster-programs-ndb-restore.  Additional descriptions follow the
table.  For options common to most NDB Cluster programs (including *note
'ndb_restore': mysql-cluster-programs-ndb-restore.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_restore program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Append data to a         
' --append '             tab-delimited file       All MySQL 5.5 based
                                                  releases
                                                  
                         Path to backup files     
'                        directory                All MySQL 5.5 based
--backup_path=dir_name                            releases
'                                                 

'--backupid=#',          Restore from the         All MySQL 5.5 based
                         backup with the given    releases
' -b '                   ID                       
                         
                         Alias for                
'--connect',             -connectstring.          All MySQL 5.5 based
                                                  releases
' -c '                                            

' --disable-indexes '    Causes indexes from a    All MySQL 5.5 based
                         backup to be ignored;    releases
                         may decrease time        
                         needed to restore
                         data.
                         
                         Do not ignore system     
'--dont-ignore-systab-0',table during restore.    All MySQL 5.5 based
                         Experimental only; not   releases
' -f '                   for production use       
                         
                         List of one or more      
'                        databases to exclude     All MySQL 5.5 based
--exclude-databases=db-list(includes those not    releases
'                        named)                   
                         
                         If TRUE (the default),   
'                        do not restore any       ADDED: NDB 7.2.17
--exclude-intermediate-sql-tables[=TRUE|FALSE]intermediate tables
'                        (having names prefixed
                         with '#sql-') that
                         were left over from
                         copying ALTER TABLE
                         operations.
                         
                         Causes columns from      
'                        the backup version of    All MySQL 5.5 based
--exclude-missing-columnsa table that are         releases
'                        missing from the         
                         version of the table
                         in the database to be
                         ignored.
                         
                         Causes tables from the   
'                        backup that are          ADDED: NDB 7.2.18
--exclude-missing-tables missing from the         
'                        database to be
                         ignored.
                         
                         List of one or more      
'                        tables to exclude        All MySQL 5.5 based
--exclude-tables=table-list(includes those in the releases
'                        same database that are   
                         not named); each table
                         reference must include
                         the database name
                         
                         Fields are enclosed      
'                        with the indicated       All MySQL 5.5 based
--fields-enclosed-by=charcharacter                releases
'                                                 

'                        Fields are optionally    All MySQL 5.5 based
--fields-optionally-enclosed-byenclosed with the  releases
'                        indicated character      
                         
                         Fields are terminated    
'                        by the indicated         All MySQL 5.5 based
--fields-terminated-by=charcharacter              releases
'                                                 

' --hex '                Print binary types in    All MySQL 5.5 based
                         hexadecimal format       releases
                                                  
                         List of one or more      
'                        databases to restore     All MySQL 5.5 based
--include-databases=db-list(excludes those not    releases
'                        named)                   
                         
                         List of one or more      
'                        tables to restore        All MySQL 5.5 based
--include-tables=table-list(excludes those in     releases
'                        same database that are   
                         not named); each table
                         reference must include
                         the database name
                         
                         Lines are terminated     
'                        by the indicated         All MySQL 5.5 based
--lines-terminated-by=charcharacter               releases
'                                                 

'--lossy-conversions',   Allow lossy              All MySQL 5.5 based
                         conversions of column    releases
' -L '                   values (type demotions   
                         or changes in sign)
                         when restoring data
                         from backup
                         
                         If a mysqld is           
' --no-binlog '          connected and using      All MySQL 5.5 based
                         binary logging, do not   releases
                         log the restored data    
                         
                         Do not restore objects   
'--no-restore-disk-objects',relating to Disk Data All MySQL 5.5 based
                                                  releases
' -d '                                            

'--no-upgrade',          Do not upgrade array     All MySQL 5.5 based
                         type for varsize         releases
' -u '                   attributes which do      
                         not already resize VAR
                         data, and do not
                         change column
                         attributes
                         
                         Nodegroup map for        
'--ndb-nodegroup-map=map',NDBCLUSTER storage      All MySQL 5.5 based
                         engine.  Syntax: list    releases
' -z '                   of (source_nodegroup,    
                         destination_nodegroup)
                         
                         ID of node where         
'--nodeid=#',            backup was taken         All MySQL 5.5 based
                                                  releases
' -n '                                            

'--parallelism=#',       Number of parallel       All MySQL 5.5 based
                         transactions to use      releases
' -p '                   while restoring data     
                         
                         Allow preservation of    
'--preserve-trailing-spaces',trailing spaces      All MySQL 5.5 based
                         (including padding)      releases
' -P '                   when promoting           
                         fixed-width string
                         types to
                         variable-width types
                         
                         Print metadata, data     
' --print '              and log to stdout        All MySQL 5.5 based
                         (equivalent to           releases
                         -print-meta              
                         -print-data
                         -print-log)
                         
                         Print data to stdout     
' --print-data '                                  All MySQL 5.5 based
                                                  releases
                                                  
                         Print to stdout          
' --print-log '                                   All MySQL 5.5 based
                                                  releases
                                                  
                         Print metadata to        
' --print-meta '         stdout                   All MySQL 5.5 based
                                                  releases
                                                  
                         Print status of          
'                        restoration each given   All MySQL 5.5 based
--progress-frequency=#   number of seconds        releases
'                                                 

'--promote-attributes',  Allow attributes to be   All MySQL 5.5 based
                         promoted when            releases
' -A '                   restoring data from      
                         backup
                         
                         Causes multithreaded     
' --rebuild-indexes '    rebuilding of ordered    All MySQL 5.5 based
                         indexes found in the     releases
                         backup.  Number of       
                         threads used is
                         determined by setting
                         BuildIndexThreads
                         parameter.
                         
                         Restore table data and   
'--restore-data',        logs into NDB Cluster    All MySQL 5.5 based
                         using the NDB API        releases
' -r '                                            

'--restore-epoch',       Restore epoch info       All MySQL 5.5 based
                         into the status table.   releases
' -e '                   Convenient on a MySQL    
                         Cluster replication
                         slave for starting
                         replication.  The row
                         in
                         mysql.ndb_apply_status
                         with id 0 will be
                         updated/inserted.
                         
                         Restore metadata to      
'--restore-meta',        NDB Cluster using the    All MySQL 5.5 based
                         NDB API                  releases
' -m '                                            

'                        Restore MySQL            All MySQL 5.5 based
--restore-privilege-tablesprivilege tables that   releases
'                        were previously moved    
                         to NDB.
                         
                         Restores to a database   
'                        with a different name    All MySQL 5.5 based
--rewrite-database=olddb,newdbthan the original   releases
'                                                 

'                        Causes missing blob      All MySQL 5.5 based
--skip-broken-objects    tables in the backup     releases
'                        file to be ignored.      
                         
                         Skip table structure     
'--skip-table-check',    check during restoring   All MySQL 5.5 based
                         of data                  releases
' -s '                                            

'                        Causes schema objects    All MySQL 5.5 based
--skip-unknown-objects   not recognized by        releases
'                        ndb_restore to be        
                         ignored when restoring
                         a backup made from a
                         newer MySQL Cluster
                         version to an older
                         version.
                         
                         Creates a                
'--tab=dir_name',        tab-separated .txt       All MySQL 5.5 based
                         file for each table in   releases
' -T dir_name '          the given path           
                         
                         Level of verbosity in    
' --verbose=# '          output                   All MySQL 5.5 based
                                                  releases

Typical options for this utility are shown here:

     ndb_restore [-c CONNECTION_STRING] -n NODE_ID -b BACKUP_ID \
           [-m] -r --backup_path=/PATH/TO/BACKUP/FILES

Normally, when restoring from an NDB Cluster backup, *note
'ndb_restore': mysql-cluster-programs-ndb-restore. requires at a minimum
the '--nodeid' (short form: '-n'), '--backupid' (short form: '-b'), and
'--backup_path' options.  In addition, when *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. is used to restore any tables
containing unique indexes, you must include '--disable-indexes' or
'--rebuild-indexes'.  (Bug #57782, Bug #11764893)

The '-c' option is used to specify a connection string which tells
'ndb_restore' where to locate the cluster management server (see *note
mysql-cluster-connection-strings::).  If this option is not used, then
*note 'ndb_restore': mysql-cluster-programs-ndb-restore. attempts to
connect to a management server on 'localhost:1186'.  This utility acts
as a cluster API node, and so requires a free connection 'slot' to
connect to the cluster management server.  This means that there must be
at least one '[api]' or '[mysqld]' section that can be used by it in the
cluster 'config.ini' file.  It is a good idea to keep at least one empty
'[api]' or '[mysqld]' section in 'config.ini' that is not being used for
a MySQL server or other application for this reason (see *note
mysql-cluster-api-definition::).

You can verify that *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. is connected to the cluster by using
the 'SHOW' command in the *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. management client.  You can also
accomplish this from a system shell, as shown here:

     shell> ndb_mgm -e "SHOW"

More detailed information about all options used by *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. can be found in the following list:

   * 
     '--append'

     Property               Value
                            
     *Command-Line          '--append'
     Format*

     When used with the '--tab' and '--print-data' options, this causes
     the data to be appended to any existing files having the same
     names.

   * 
     '--backup_path'=DIR_NAME

     Property               Value
                            
     *Command-Line          '--backup-path=dir_name'
     Format*                

     *Type*                 Directory name
                            
     *Default Value*        './'

     The path to the backup directory is required; this is supplied to
     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. using the
     '--backup_path' option, and must include the subdirectory
     corresponding to the ID backup of the backup to be restored.  For
     example, if the data node's 'DataDir' is '/var/lib/mysql-cluster',
     then the backup directory is '/var/lib/mysql-cluster/BACKUP', and
     the backup files for the backup with the ID 3 can be found in
     '/var/lib/mysql-cluster/BACKUP/BACKUP-3'.  The path may be absolute
     or relative to the directory in which the *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. executable is located, and may
     be optionally prefixed with 'backup_path='.

     It is possible to restore a backup to a database with a different
     configuration than it was created from.  For example, suppose that
     a backup with backup ID '12', created in a cluster with two storage
     nodes having the node IDs '2' and '3', is to be restored to a
     cluster with four nodes.  Then *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. must be run twice--once for
     each storage node in the cluster where the backup was taken.
     However, *note 'ndb_restore': mysql-cluster-programs-ndb-restore.
     cannot always restore backups made from a cluster running one
     version of MySQL to a cluster running a different MySQL version.
     See *note mysql-cluster-upgrade-downgrade::, for more information.

     *Important*:

     It is not possible to restore a backup made from a newer version of
     NDB Cluster using an older version of *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore.  You can restore a backup made
     from a newer version of MySQL to an older cluster, but you must use
     a copy of *note 'ndb_restore': mysql-cluster-programs-ndb-restore.
     from the newer NDB Cluster version to do so.

     For example, to restore a cluster backup taken from a cluster
     running NDB 7.2.5 to a cluster running NDB 7.1.21, you must use the
     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. that comes
     with the NDB 7.2.5 distribution.

     For more rapid restoration, the data may be restored in parallel,
     provided that there is a sufficient number of cluster connections
     available.  That is, when restoring to multiple nodes in parallel,
     you must have an '[api]' or '[mysqld]' section in the cluster
     'config.ini' file available for each concurrent *note
     'ndb_restore': mysql-cluster-programs-ndb-restore. process.
     However, the data files must always be applied before the logs.

   * 
     '--backupid'=#, '-b'

     Property               Value
                            
     *Command-Line          '--backupid=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        'none'

     This option is used to specify the ID or sequence number of the
     backup, and is the same number shown by the management client in
     the 'Backup BACKUP_ID completed' message displayed upon completion
     of a backup.  (See *note
     mysql-cluster-backup-using-management-client::.)

     *Important*:

     When restoring cluster backups, you must be sure to restore all
     data nodes from backups having the same backup ID. Using files from
     different backups will at best result in restoring the cluster to
     an inconsistent state, and may fail altogether.

   * 
     '--connect', '-c'

     Property               Value
                            
     *Command-Line          '--connect'
     Format*                

     *Type*                 String
                            
     *Default Value*        'localhost:1186'

     Alias for '--ndb-connectstring'.

   * 
     '--disable-indexes'

     Property               Value
                            
     *Command-Line          '--disable-indexes'
     Format*

     Disable restoration of indexes during restoration of the data from
     a native 'NDB' backup.  Afterwards, you can restore indexes for all
     tables at once with multithreaded building of indexes using
     '--rebuild-indexes', which should be faster than rebuilding indexes
     concurrently for very large tables.

   * 
     '--dont-ignore-systab-0', '-f'

     Property               Value
                            
     *Command-Line          '--dont-ignore-systab-0'
     Format*

     Normally, when restoring table data and metadata, *note
     'ndb_restore': mysql-cluster-programs-ndb-restore. ignores the copy
     of the *note 'NDB': mysql-cluster. system table that is present in
     the backup.  '--dont-ignore-systab-0' causes the system table to be
     restored.  _This option is intended for experimental and
     development use only, and is not recommended in a production
     environment_.

   * 
     '--exclude-databases'=DB-LIST

     Property               Value
                            
     *Command-Line          '--exclude-databases=db-list'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     Comma-delimited list of one or more databases which should not be
     restored.

     This option is often used in combination with '--exclude-tables';
     see that option's description for further information and examples.

   * 
     '--exclude-intermediate-sql-tables['=TRUE|FALSE]

     Property               Value
                            
     *Command-Line          '--exclude-intermediate-sql-tables[=TRUE|FALSE]'
     Format*                

     *Introduced*           5.5.37-ndb-7.2.17
                            
     *Type*                 Boolean
                            
     *Default Value*        'TRUE'

     When performing copying *note 'ALTER TABLE': alter-table.
     operations, *note 'mysqld': mysqld. creates intermediate tables
     (whose names are prefixed with '#sql-').  When 'TRUE', the
     '--exclude-intermediate-sql-tables' option keeps *note
     'ndb_restore': mysql-cluster-programs-ndb-restore. from restoring
     such tables that may have been left over from these operations.
     This option is 'TRUE' by default.

     This option was introduced in NDB 7.2.17.  (Bug #17882305)

   * 
     '--exclude-missing-columns'

     Property               Value
                            
     *Command-Line          '--exclude-missing-columns'
     Format*

     It is possible to restore only selected table columns using this
     option, which causes *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. to ignore any columns missing
     from tables being restored as compared to the versions of those
     tables found in the backup.  This option applies to all tables
     being restored.  If you wish to apply this option only to selected
     tables or databases, you can use it in combination with one or more
     of the '--include-*' or '--exclude-*' options described elsewhere
     in this section to do so, then restore data to the remaining tables
     using a complementary set of these options.

   * 
     '--exclude-missing-tables'

     Property               Value
                            
     *Command-Line          '--exclude-missing-tables'
     Format*                

     *Introduced*           5.5.40-ndb-7.2.18

     It is possible to restore only selected tables using this option,
     which causes *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. to ignore any tables from the
     backup that are not found in the target database.

     This option was introduced in NDB 7.2.18.

   * 
     '--exclude-tables'=TABLE-LIST

     Property               Value
                            
     *Command-Line          '--exclude-tables=table-list'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     List of one or more tables to exclude; each table reference must
     include the database name.  Often used together with
     '--exclude-databases'.

     When '--exclude-databases' or '--exclude-tables' is used, only
     those databases or tables named by the option are excluded; all
     other databases and tables are restored by *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore.

     This table shows several invocations of *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. usng '--exclude-*' options
     (other options possibly required have been omitted for clarity),
     and the effects these options have on restoring from an NDB Cluster
     backup:

     *Several invocations of ndb_restore using -exclude-* options, and
     the effects these options have on restoring from an NDB Cluster
     backup.*

     Option                               Result
                                          
     '--exclude-databases=db1'            All tables in all databases except
                                          'db1' are restored; no tables in
                                          'db1' are restored
                                          
     '--exclude-databases=db1,db2' (or    All tables in all databases except
     '--exclude-databases=db1'            'db1' and 'db2' are restored; no
     '--exclude-databases=db2')           tables in 'db1' or 'db2' are
                                          restored
                                          
     '--exclude-tables=db1.t1'            All tables except 't1' in database
                                          'db1' are restored; all other
                                          tables in 'db1' are restored; all
                                          tables in all other databases are
                                          restored
                                          
     '--exclude-tables=db1.t2,db2.t1'     All tables in database 'db1'
     (or '--exclude-tables=db1.t2'        except for 't2' and all tables in
     '--exclude-tables=db2.t1)'           database 'db2' except for table
                                          't1' are restored; no other tables
                                          in 'db1' or 'db2' are restored;
                                          all tables in all other databases
                                          are restored

     You can use these two options together.  For example, the following
     causes all tables in all databases _except for_ databases 'db1' and
     'db2', and tables 't1' and 't2' in database 'db3', to be restored:

          shell> ndb_restore [...] --exclude-databases=db1,db2 --exclude-tables=db3.t1,db3.t2

     (Again, we have omitted other possibly necessary options in the
     interest of clarity and brevity from the example just shown.)

     You can use '--include-*' and '--exclude-*' options together,
     subject to the following rules:

        * The actions of all '--include-*' and '--exclude-*' options are
          cumulative.

        * All '--include-*' and '--exclude-*' options are evaluated in
          the order passed to ndb_restore, from right to left.

        * In the event of conflicting options, the first (rightmost)
          option takes precedence.  In other words, the first option
          (going from right to left) that matches against a given
          database or table 'wins'.

     For example, the following set of options causes *note
     'ndb_restore': mysql-cluster-programs-ndb-restore. to restore all
     tables from database 'db1' except 'db1.t1', while restoring no
     other tables from any other databases:


          --include-databases=db1 --exclude-tables=db1.t1

     However, reversing the order of the options just given simply
     causes all tables from database 'db1' to be restored (including
     'db1.t1', but no tables from any other database), because the
     '--include-databases' option, being farthest to the right, is the
     first match against database 'db1' and thus takes precedence over
     any other option that matches 'db1' or any tables in 'db1':


          --exclude-tables=db1.t1 --include-databases=db1

   * 
     '--fields-enclosed-by'=CHAR

     Property               Value
                            
     *Command-Line          '--fields-enclosed-by=char'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     Each column value is enclosed by the string passed to this option
     (regardless of data type; see the description of
     '--fields-optionally-enclosed-by').

   * 
     '--fields-optionally-enclosed-by'

     Property               Value
                            
     *Command-Line          '--fields-optionally-enclosed-by'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     The string passed to this option is used to enclose column values
     containing character data (such as *note 'CHAR': char, *note
     'VARCHAR': char, *note 'BINARY': binary-varbinary, *note 'TEXT':
     blob, or *note 'ENUM': enum.).

   * 
     '--fields-terminated-by'=CHAR

     Property               Value
                            
     *Command-Line          '--fields-terminated-by=char'
     Format*                

     *Type*                 String
                            
     *Default Value*        '\t (tab)'

     The string passed to this option is used to separate column values.
     The default value is a tab character ('\t').

   * 
     '--hex'

     Property               Value
                            
     *Command-Line          '--hex'
     Format*

     If this option is used, all binary values are output in hexadecimal
     format.

   * 
     '--include-databases'=DB-LIST

     Property               Value
                            
     *Command-Line          '--include-databases=db-list'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     Comma-delimited list of one or more databases to restore.  Often
     used together with '--include-tables'; see the description of that
     option for further information and examples.

   * 
     '--include-tables'=TABLE-LIST

     Property               Value
                            
     *Command-Line          '--include-tables=table-list'
     Format*                

     *Type*                 String
                            
     *Default Value*        ''

     Comma-delimited list of tables to restore; each table reference
     must include the database name.

     When '--include-databases' or '--include-tables' is used, only
     those databases or tables named by the option are restored; all
     other databases and tables are excluded by *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore, and are not restored.

     The following table shows several invocations of *note
     'ndb_restore': mysql-cluster-programs-ndb-restore. using
     '--include-*' options (other options possibly required have been
     omitted for clarity), and the effects these have on restoring from
     an NDB Cluster backup:

     *Several invocations of ndb_restore using -include-* options, and
     their effects on restoring from an NDB Cluster backup.*

     Option                               Result
                                          
     '--include-databases=db1'            Only tables in database 'db1' are
                                          restored; all tables in all other
                                          databases are ignored
                                          
     '--include-databases=db1,db2' (or    Only tables in databases 'db1' and
     '--include-databases=db1'            'db2' are restored; all tables in
     '--include-databases=db2')           all other databases are ignored
                                          
     '--include-tables=db1.t1'            Only table 't1' in database 'db1'
                                          is restored; no other tables in
                                          'db1' or in any other database are
                                          restored
                                          
     '--include-tables=db1.t2,db2.t1'     Only the table 't2' in database
     (or '--include-tables=db1.t2'        'db1' and the table 't1' in
     '--include-tables=db2.t1')           database 'db2' are restored; no
                                          other tables in 'db1', 'db2', or
                                          any other database are restored

     You can also use these two options together.  For example, the
     following causes all tables in databases 'db1' and 'db2', together
     with the tables 't1' and 't2' in database 'db3', to be restored
     (and no other databases or tables):

          shell> ndb_restore [...] --include-databases=db1,db2 --include-tables=db3.t1,db3.t2

     (Again we have omitted other, possibly required, options in the
     example just shown.)

     It also possible to restore only selected databases, or selected
     tables from a single database, without any '--include-*' (or
     '--exclude-*') options, using the syntax shown here:

          ndb_restore OTHER_OPTIONS DB_NAME,[DB_NAME[,...] | TBL_NAME[,TBL_NAME][,...]]

     In other words, you can specify either of the following to be
     restored:

        * All tables from one or more databases

        * One or more tables from a single database

   * 
     '--lines-terminated-by'=CHAR

     Property               Value
                            
     *Command-Line          '--lines-terminated-by=char'
     Format*                

     *Type*                 String
                            
     *Default Value*        '\n (linebreak)'

     Specifies the string used to end each line of output.  The default
     is a linefeed character ('\n').

   * 
     '--lossy-conversions', '-L'

     Property               Value
                            
     *Command-Line          '--lossy-conversions'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE' (If option is not used)

     This option is intended to complement the '--promote-attributes'
     option.  Using '--lossy-conversions' allows lossy conversions of
     column values (type demotions or changes in sign) when restoring
     data from backup.  With some exceptions, the rules governing
     demotion are the same as for MySQL replication; see *note
     replication-features-different-data-types::, for information about
     specific type conversions currently supported by attribute
     demotion.

     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. reports
     any truncation of data that it performs during lossy conversions
     once per attribute and column.

   * 
     '--no-binlog'

     Property               Value
                            
     *Command-Line          '--no-binlog'
     Format*

     This option prevents any connected SQL nodes from writing data
     restored by *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. to their binary logs.

   * 
     '--no-restore-disk-objects', '-d'

     Property               Value
                            
     *Command-Line          '--no-restore-disk-objects'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     This option stops *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. from restoring any NDB Cluster
     Disk Data objects, such as tablespaces and log file groups; see
     *note mysql-cluster-disk-data::, for more information about these.

   * 
     '--no-upgrade', '-u'

     Property               Value
                            
     *Command-Line          '--no-upgrade'
     Format*

     When using *note 'ndb_restore': mysql-cluster-programs-ndb-restore.
     to restore a backup, *note 'VARCHAR': char. columns created using
     the old fixed format are resized and recreated using the
     variable-width format now employed.  This behavior can be
     overridden by specifying '--no-upgrade'.

   * 
     '--ndb-nodegroup-map'=MAP, '-z'

     Property               Value
                            
     *Command-Line          '--ndb-nodegroup-map=map'
     Format*

     This option can be used to restore a backup taken from one node
     group to a different node group.  Its argument is a list of the
     form 'SOURCE_NODE_GROUP, TARGET_NODE_GROUP'.

   * 
     '--nodeid'=#, '-n'

     Property               Value
                            
     *Command-Line          '--nodeid=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        'none'

     Specify the node ID of the data node on which the backup was taken.

     When restoring to a cluster with different number of data nodes
     from that where the backup was taken, this information helps
     identify the correct set or sets of files to be restored to a given
     node.  (In such cases, multiple files usually need to be restored
     to a single data node.)  See *note
     ndb-restore-different-number-nodes::, for additional information
     and examples.

   * 
     '--parallelism'=#, '-p'

     Property               Value
                            
     *Command-Line          '--parallelism=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '128'
                            
     *Minimum Value*        '1'
                            
     *Maximum Value*        '1024'

     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. uses
     single-row transactions to apply many rows concurrently.  This
     parameter determines the number of parallel transactions
     (concurrent rows) that an instance of *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. tries to use.  By default, this
     is 128; the minimum is 1, and the maximum is 1024.

     The work of performing the inserts is parallelized across the
     threads in the data nodes involved.  This mechanism is employed for
     restoring bulk data from the '.Data' file--that is, the fuzzy
     snapshot of the data; it is not used for building or rebuilding
     indexes.  The change log is applied serially; index drops and
     builds are DDL operations and handled separately.  There is no
     thread-level parallelism on the client side of the restore.

   * 
     '--preserve-trailing-spaces', '-P'

     Property               Value
                            
     *Command-Line          '--preserve-trailing-spaces'
     Format*

     Cause trailing spaces to be preserved when promoting a fixed-width
     character data type to its variable-width equivalent--that is, when
     promoting a *note 'CHAR': char. column value to *note 'VARCHAR':
     char, or a 'BINARY' column value to *note 'VARBINARY':
     binary-varbinary.  Otherwise, any trailing spaces are dropped from
     such column values when they are inserted into the new columns.

     *Note*:

     Although you can promote *note 'CHAR': char. columns to *note
     'VARCHAR': char. and 'BINARY' columns to *note 'VARBINARY':
     binary-varbinary, you cannot promote *note 'VARCHAR': char. columns
     to *note 'CHAR': char. or *note 'VARBINARY': binary-varbinary.
     columns to 'BINARY'.

   * 
     '--print'

     Property               Value
                            
     *Command-Line          '--print'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Causes *note 'ndb_restore': mysql-cluster-programs-ndb-restore. to
     print all data, metadata, and logs to 'stdout'.  Equivalent to
     using the '--print-data', '--print-meta', and '--print-log' options
     together.

     *Note*:

     Use of '--print' or any of the '--print_*' options is in effect
     performing a dry run.  Including one or more of these options
     causes any output to be redirected to 'stdout'; in such cases,
     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. makes no
     attempt to restore data or metadata to an NDB Cluster.

   * 
     '--print-data'

     Property               Value
                            
     *Command-Line          '--print-data'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Cause *note 'ndb_restore': mysql-cluster-programs-ndb-restore. to
     direct its output to 'stdout'.  Often used together with one or
     more of '--tab', '--fields-enclosed-by',
     '--fields-optionally-enclosed-by', '--fields-terminated-by',
     '--hex', and '--append'.

     *note 'TEXT': blob. and *note 'BLOB': blob. column values are
     always truncated.  In NDB 7.2.18 and earlier, such values are
     truncated to the first 240 bytes in the output; in NDB 7.2.19 and
     later, they are truncated to 256 bytes.  (Bug #14571512, Bug
     #65467) This cannot currently be overridden when using
     '--print-data'.

   * 
     '--print-log'

     Property               Value
                            
     *Command-Line          '--print-log'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Cause *note 'ndb_restore': mysql-cluster-programs-ndb-restore. to
     output its log to 'stdout'.

   * 
     '--print-meta'

     Property               Value
                            
     *Command-Line          '--print-meta'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Print all metadata to 'stdout'.

   * 
     '--progress-frequency'=N

     Property               Value
                            
     *Command-Line          '--progress-frequency=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '0'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        '65535'

     Print a status report each N seconds while the restore is in
     progress.  0 (the default) causes no status reports to be printed.
     The maximum is 65535.

   * 
     '--promote-attributes', '-A'

     Property               Value
                            
     *Command-Line          '--promote-attributes'
     Format*

     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. supports
     limited _attribute promotion_ in much the same way that it is
     supported by MySQL replication; that is, data backed up from a
     column of a given type can generally be restored to a column using
     a 'larger, similar' type.  For example, data from a 'CHAR(20)'
     column can be restored to a column declared as 'VARCHAR(20)',
     'VARCHAR(30)', or 'CHAR(30)'; data from a *note 'MEDIUMINT':
     integer-types. column can be restored to a column of type *note
     'INT': integer-types. or *note 'BIGINT': integer-types.  See *note
     replication-features-different-data-types::, for a table of type
     conversions currently supported by attribute promotion.

     Attribute promotion by *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. must be enabled explicitly, as
     follows:

       1. Prepare the table to which the backup is to be restored.
          *note 'ndb_restore': mysql-cluster-programs-ndb-restore.
          cannot be used to re-create the table with a different
          definition from the original; this means that you must either
          create the table manually, or alter the columns which you wish
          to promote using *note 'ALTER TABLE': alter-table. after
          restoring the table metadata but before restoring the data.

       2. Invoke *note 'ndb_restore':
          mysql-cluster-programs-ndb-restore. with the
          '--promote-attributes' option (short form '-A') when restoring
          the table data.  Attribute promotion does not occur if this
          option is not used; instead, the restore operation fails with
          an error.

     Prior to NDB 7.2.14, conversions between character data types and
     'TEXT' or 'BLOB' were not handled correctly.

     Prior to NDB 7.2.18, demotion of *note 'TEXT': blob. to *note
     'TINYTEXT': blob. was not handled correctly (Bug #18875137).

     When converting between character data types and 'TEXT' or 'BLOB',
     only conversions between character types (*note 'CHAR': char. and
     *note 'VARCHAR': char.) and binary types (*note 'BINARY':
     binary-varbinary. and *note 'VARBINARY': binary-varbinary.) can be
     performed at the same time.  For example, you cannot promote an
     *note 'INT': integer-types. column to *note 'BIGINT':
     integer-types. while promoting a 'VARCHAR' column to 'TEXT' in the
     same invocation of *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore.

     Converting between *note 'TEXT': blob. columns using different
     character sets is not supported.  Beginning with NDB 7.2.18, it is
     expressly disallowed (Bug #18875137).

     When performing conversions of character or binary types to 'TEXT'
     or 'BLOB' with *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore, you may notice that it creates
     and uses one or more staging tables named 'TABLE_NAME$STNODE_ID'.
     These tables are not needed afterwards, and are normally deleted by
     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. following
     a successful restoration.

   * 
     '--rebuild-indexes'

     Property               Value
                            
     *Command-Line          '--rebuild-indexes'
     Format*

     Enable multithreaded rebuilding of the ordered indexes while
     restoring a native 'NDB' backup.  The number of threads used for
     building ordered indexes by *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. with this option is controlled
     by the 'BuildIndexThreads' data node configuration parameter and
     the number of LDMs.

     It is necessary to use this option only for the first run of *note
     'ndb_restore': mysql-cluster-programs-ndb-restore.; this causes all
     ordered indexes to be rebuilt without using '--rebuild-indexes'
     again when restoring subsequent nodes.  You should use this option
     prior to inserting new rows into the database; otherwise, it is
     possible for a row to be inserted that later causes a unique
     constraint violation when trying to rebuild the indexes.

     Building of ordered indices is parallelized with the number of LDMs
     by default.  Offline index builds performed during node and system
     restarts can be made faster using the 'BuildIndexThreads' data node
     configuration parameter; this parameter has no effect on dropping
     and rebuilding of indexes by *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore, which is performed online.

     Rebuilding of unique indexes uses disk write bandwidth for redo
     logging and local checkpointing.  An insufficient amount of this
     bandwith can lead to redo buffer overload or log overload errors.
     In such cases you can run *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. '--rebuild-indexes' again; the
     process resumes at the point where the error occurred.  You can
     also do this when you have encountered temporary errors.  You can
     repeat execution of *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. '--rebuild-indexes'
     indefinitely; you may be able to stop such errors by reducing the
     value of '--parallelism'.  If the problem is insufficient space,
     you can increase the size of the redo log ('FragmentLogFileSize'
     node configuration parameter), or you can increase the speed at
     which LCPs are performed ('MaxDiskWriteSpeed'
     (https://dev.mysql.com/doc/refman/5.6/en/mysql-cluster-ndbd-definition.html#ndbparam-ndbd-maxdiskwritespeed)
     and related parameters), in order to free space more quickly.

   * 
     '--restore-data', '-r'

     Property               Value
                            
     *Command-Line          '--restore-data'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Output *note 'NDB': mysql-cluster. table data and logs.

   * 
     '--restore-epoch', '-e'

     Property               Value
                            
     *Command-Line          '--restore-epoch'
     Format*

     Add (or restore) epoch information to the cluster replication
     status table.  This is useful for starting replication on an NDB
     Cluster replication slave.  When this option is used, the row in
     the 'mysql.ndb_apply_status' having '0' in the 'id' column is
     updated if it already exists; such a row is inserted if it does not
     already exist.  (See *note mysql-cluster-replication-backups::.)

   * 
     '--restore-meta', '-m'

     Property               Value
                            
     *Command-Line          '--restore-meta'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     This option causes *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. to print *note 'NDB':
     mysql-cluster. table metadata.

     The first time you run the *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. restoration program, you also
     need to restore the metadata.  In other words, you must re-create
     the database tables--this can be done by running it with the
     '--restore-meta' ('-m') option.  Restoring the metadata need be
     done only on a single data node; this is sufficient to restore it
     to the entire cluster.

     *Note*:

     The cluster should have an empty database when starting to restore
     a backup.  (In other words, you should start the data nodes with
     '--initial' prior to performing the restore.)

   * 
     '--restore-privilege-tables'

     Property               Value
                            
     *Command-Line          '--restore-privilege-tables'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE' (If option is not used)

     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. does not
     by default restore distributed MySQL privilege tables.  This option
     causes *note 'ndb_restore': mysql-cluster-programs-ndb-restore. to
     restore the privilege tables.

     This works only if the privilege tables were converted to *note
     'NDB': mysql-cluster. before the backup was taken.  For more
     information, see *note mysql-cluster-privilege-distribution::.

     This option was added in NDB 7.2.0.

   * 
     '--rewrite-database'=OLDDB,NEWDB

     Property               Value
                            
     *Command-Line          '--rewrite-database=olddb,newdb'
     Format*                

     *Type*                 String
                            
     *Default Value*        'none'

     This option makes it possible to restore to a database having a
     different name from that used in the backup.  For example, if a
     backup is made of a database named 'products', you can restore the
     data it contains to a database named 'inventory', use this option
     as shown here (omitting any other options that might be required):

          shell> ndb_restore --rewrite-database=product,inventory

     The option can be employed multiple times in a single invocation of
     *note 'ndb_restore': mysql-cluster-programs-ndb-restore.  Thus it
     is possible to restore simultaneously from a database named 'db1'
     to a database named 'db2' and from a database named 'db3' to one
     named 'db4' using '--rewrite-database=db1,db2
     --rewrite-database=db3,db4'.  Other *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. options may be used between
     multiple occurrences of '--rewrite-database'.

     In the event of conflicts between multiple '--rewrite-database'
     options, the last '--rewrite-database' option used, reading from
     left to right, is the one that takes effect.  For example, if
     '--rewrite-database=db1,db2 --rewrite-database=db1,db3' is used,
     only '--rewrite-database=db1,db3' is honored, and
     '--rewrite-database=db1,db2' is ignored.  It is also possible to
     restore from multiple databases to a single database, so that
     '--rewrite-database=db1,db3 --rewrite-database=db2,db3' restores
     all tables and data from databases 'db1' and 'db2' into database
     'db3'.

     *Important*:

     When restoring from multiple backup databases into a single target
     database using '--rewrite-database', no check is made for
     collisions between table or other object names, and the order in
     which rows are restored is not guaranteed.  This means that it is
     possible in such cases for rows to be overwritten and updates to be
     lost.

   * 
     '--skip-broken-objects'

     Property               Value
                            
     *Command-Line          '--skip-broken-objects'
     Format*

     This option causes *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. to ignore corrupt tables while
     reading a native *note 'NDB': mysql-cluster. backup, and to
     continue restoring any remaining tables (that are not also
     corrupted).  Currently, the '--skip-broken-objects' option works
     only in the case of missing blob parts tables.

   * 
     '--skip-table-check', '-s'

     Property               Value
                            
     *Command-Line          '--skip-table-check'
     Format*

     It is possible to restore data without restoring table metadata.
     By default when doing this, *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. fails with an error if a
     mismatch is found between the table data and the table schema; this
     option overrides that behavior.

     Some of the restrictions on mismatches in column definitions when
     restoring data using *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. are relaxed; when one of these
     types of mismatches is encountered, *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. does not stop with an error as
     it did previously, but rather accepts the data and inserts it into
     the target table while issuing a warning to the user that this is
     being done.  This behavior occurs whether or not either of the
     options '--skip-table-check' or '--promote-attributes' is in use.
     These differences in column definitions are of the following types:

        * Different 'COLUMN_FORMAT' settings ('FIXED', 'DYNAMIC',
          'DEFAULT')

        * Different 'STORAGE' settings ('MEMORY', 'DISK')

        * Different default values

        * Different distribution key settings

   * 
     '--skip-unknown-objects'

     Property               Value
                            
     *Command-Line          '--skip-unknown-objects'
     Format*

     This option causes *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. to ignore any schema objects it
     does not recognize while reading a native *note 'NDB':
     mysql-cluster. backup.  This can be used for restoring a backup
     made from a cluster running NDB 7.5 to a cluster running NDB
     Cluster 7.4.

   * 
     '--tab'=DIR_NAME, '-T' DIR_NAME

     Property               Value
                            
     *Command-Line          '--tab=dir_name'
     Format*                

     *Type*                 Directory name

     Causes '--print-data' to create dump files, one per table, each
     named 'TBL_NAME.txt'.  It requires as its argument the path to the
     directory where the files should be saved; use '.' for the current
     directory.

   * 
     '--verbose'=#

     Property               Value
                            
     *Command-Line          '--verbose=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '1'
                            
     *Minimum Value*        '0'
                            
     *Maximum Value*        '255'

     Sets the level for the verbosity of the output.  The minimum is 0;
     the maximum is 255.  The default value is 1.

Error reporting

*note 'ndb_restore': mysql-cluster-programs-ndb-restore. reports both
temporary and permanent errors.  In the case of temporary errors, it may
able to recover from them, and reports 'Restore successful, but
encountered temporary error, please look at configuration' in such
cases.

*Important*:

After using *note 'ndb_restore': mysql-cluster-programs-ndb-restore. to
initialize an NDB Cluster for use in circular replication, binary logs
on the SQL node acting as the replication slave are not automatically
created, and you must cause them to be created manually.  To cause the
binary logs to be created, issue a *note 'SHOW TABLES': show-tables.
statement on that SQL node before running *note 'START SLAVE':
start-slave.  This is a known issue in NDB Cluster.


File: manual.info.tmp,  Node: ndb-restore-different-number-nodes,  Prev: mysql-cluster-programs-ndb-restore,  Up: mysql-cluster-programs-ndb-restore

18.4.21.1 Restoring to a different number of data nodes
.......................................................

* Menu:

* ndb-restore-to-fewer-nodes::   Restoring to Fewer Nodes Than the Original
* ndb-restore-to-more-nodes::    Restoring to More Nodes Than the Original

It is possible to restore from an NDB backup to a cluster having a
different number of data nodes than the original from which the backup
was taken.  The following two sections discuss, respectively, the cases
where the target cluster has a lesser or greater number of data nodes
than the source of the backup.


File: manual.info.tmp,  Node: ndb-restore-to-fewer-nodes,  Next: ndb-restore-to-more-nodes,  Prev: ndb-restore-different-number-nodes,  Up: ndb-restore-different-number-nodes

18.4.21.2 Restoring to Fewer Nodes Than the Original
....................................................

You can restore to a cluster having fewer data nodes than the original
provided that the larger number of nodes is an even multiple of the
smaller number.  In the following example, we use a backup taken on a
cluster having four data nodes to a cluster having two data nodes.

  1. The management server for the original cluster is on host 'host10'.
     The original cluster has four data nodes, with the node IDs and
     host names shown in the following extract from the management
     server's 'config.ini' file:

          [ndbd]NodeId=2
          HostName=host2

          [ndbd]
          NodeId=4
          HostName=host4

          [ndbd]
          NodeId=6
          HostName=host6

          [ndbd]
          NodeId=8
          HostName=host8

     We assume that each data node was originally started with *note
     'ndbmtd': mysql-cluster-programs-ndbmtd.
     '--ndb-connectstring=host10' or the equivalent.

  2. Perform a backup in the normal manner.  See *note
     mysql-cluster-backup-using-management-client::, for information
     about how to do this.

  3. The files created by the backup on each data node are listed here,
     where N is the node ID and B is the backup ID.

        * 'BACKUP-B-0.N.Data'

        * 'BACKUP-B.N.ctl'

        * 'BACKUP-B.N.log'

     These files are found under 'BackupDataDir''/BACKUP/BACKUP-B', on
     each data node.  For the rest of this example, we assume that the
     backup ID is 1.

     Have all of these files available for later copying to the new data
     nodes (where they can be accessed on the data node's local file
     system by *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore.).  It is simplest to copy them
     all to a single location; we assume that this is what you have
     done.

  4. The management server for the target cluster is on host 'host20',
     and the target has two data nodes, with the node IDs and host names
     shown, from the management server 'config.ini' file on 'host20':

          [ndbd]
          NodeId=3
          hostname=host3

          [ndbd]
          NodeId=5
          hostname=host5

     Each of the data node processes on 'host3' and 'host5' should be
     started with *note 'ndbmtd': mysql-cluster-programs-ndbmtd. '-c
     host20' '--initial' or the equivalent, so that the new (target)
     cluster starts with clean data node file systems.

  5. Copy two different sets of two backup files to each of the target
     data nodes.  For this example, copy the backup files from nodes 2
     and 4 from the original cluster to node 3 in the target cluster.
     These files are listed here:

        * 'BACKUP-1-0.2.Data'

        * 'BACKUP-1.2.ctl'

        * 'BACKUP-1.2.log'

        * 'BACKUP-1-0.6.Data'

        * 'BACKUP-1.6.ctl'

        * 'BACKUP-1.6.log'

     Then copy the backup files from nodes 6 and 8 to node 5; these
     files are shown in the following list:

        * 'BACKUP-1-0.4.Data'

        * 'BACKUP-1.4.ctl'

        * 'BACKUP-1.4.log'

        * 'BACKUP-1-0.8.Data'

        * 'BACKUP-1.8.ctl'

        * 'BACKUP-1.8.log'

     For the remainder of this example, we assume that the respective
     backup files have been saved to the directory '/BACKUP-1' on each
     of nodes 3 and 5.

  6. On each of the two target data nodes, you must restore from both
     sets of backups.  First, restore the backups from nodes 2 and 4 to
     node 3 by invoking *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. on 'host3' as shown here:

          shell> ndb_restore -c host20 --nodeid=2 --backupid=1 --restore-data --backup_path=/BACKUP-1

          shell> ndb_restore -c host20 --nodeid=4 --backupid=1 --restore-data --backup_path=/BACKUP-1

     Then restore the backups from nodes 6 and 8 to node 5 by invoking
     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. on
     'host5', like this:

          shell> ndb_restore -c host20 --nodeid=6 --backupid=1 --restore-data --backup_path=/BACKUP-1

          shell> ndb_restore -c host20 --nodeid=8 --backupid=1 --restore-data --backup_path=/BACKUP-1


File: manual.info.tmp,  Node: ndb-restore-to-more-nodes,  Prev: ndb-restore-to-fewer-nodes,  Up: ndb-restore-different-number-nodes

18.4.21.3 Restoring to More Nodes Than the Original
...................................................

The node ID specified for a given *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. command is that of the node in the
original backup and not that of the data node to restore it to.  When
performing a backup using the method described in this section, *note
'ndb_restore': mysql-cluster-programs-ndb-restore. connects to the
management server and obtains a list of data nodes in the cluster the
backup is being restored to.  The restored data is distributed
accordingly, so that the number of nodes in the target cluster does not
need to be to be known or calculated when performing the backup.

*Note*:

When changing the total number of LCP threads or LQH threads per node
group, you should recreate the schema from backup created using *note
'mysqldump': mysqldump.

  1. _Create the backup of the data_.  You can do this by invoking the
     *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. client 'START
     BACKUP' command from the system shell, like this:

          shell> ndb_mgm -e "START BACKUP 1"

     This assumes that the desired backup ID is 1.

  2. Create a backup of the schema (see also below):


          shell> mysqldump --no-data --routines --events --triggers --databases > myschema.sql

     *Important*:

     You must not make any schema changes between the first and second
     steps.

  3. Copy the backup directories from above to the new cluster.  For
     example if the backup you want to restore is has ID 1 and
     'BackupDataDir' = '/backups/node_NODEID', then the path to the
     backup on this node is '/backups/node_1/BACKUP/BACKUP-1'.  Inside
     this directory there are three files, listed here:

        * 'BACKUP-1-0.1.Data'

        * 'BACKUP-1.1.ctl'

        * 'BACKUP-1.1.log'

     You should copy the entire directory to the new node.

There is no requirement for the backup to be restored from a specific
node or nodes.

To restore from the backup just created, perform the following steps:

  1. _Restore the schema_.  Import the schema file using the *note
     'mysql': mysql. client, as shown here:

          shell> mysql < myschema.sql

  2. _Restore the data_.  The following commands can be run in parallel:

          ndb_restore --nodeid=1 --backupid=1 --restore-data --backup_path=/backups/node_1/BACKUP/BACKUP-1 --disable-indexes
          ndb_restore --nodeid=2 --backupid=1 --restore-data --backup_path=/backups/node_2/BACKUP/BACKUP-1 --disable-indexes
          ndb_restore --nodeid=3 --backupid=1 --restore-data --backup_path=/backups/node_3/BACKUP/BACKUP-1 --disable-indexes
          ndb_restore --nodeid=4 --backupid=1 --restore-data --backup_path=/backups/node_4/BACKUP/BACKUP-1 --disable-indexes
          ndb_restore --nodeid=5 --backupid=1 --restore-data --backup_path=/backups/node_5/BACKUP/BACKUP-1 --disable-indexes
          ndb_restore --nodeid=6 --backupid=1 --restore-data --backup_path=/backups/node_6/BACKUP/BACKUP-1 --disable-indexes
          ndb_restore --nodeid=7 --backupid=1 --restore-data --backup_path=/backups/node_7/BACKUP/BACKUP-1 --disable-indexes
          ndb_restore --nodeid=8 --backupid=1 --restore-data --backup_path=/backups/node_8/BACKUP/BACKUP-1 --disable-indexes

     Add the '--ndb-connectstring' option as needed.

     If you in 3.  for example copied the backups from the 'old' nodes
     having node IDs 1 and 2 to a 'new' node whose node ID is 1, you
     should perform the two invocations of *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. with '--nodeid=1' and
     '--nodeid=2' on the new node that has 1 as its node ID.

  3. _Rebuild the indexes_.  These were disabled by the
     '--disable-indexes' option used in the commands just shown.
     Recreating the indexes avoids errors due to the restore not being
     consistent at all points.  Rebuilding the indexes can also improve
     performance in some cases.  To rebuild the indexes, execute the
     following command once, on a single node:

          shell> ndb_restore --nodeid=1 --backupid=1 --backup_path=/backups/node_1/BACKUP/BACKUP-1 --rebuild-indexes

*Important*:

You should be aware that the supported number of partitions in each
table depends on the number of data nodes, node groups, and LDM threads
in the cluster.  Other conditions (such as the values of
'MaxNoOfExecutionThreads', 'ThreadConfig', 'NoOfReplicas', and so on)
being the same, a cluster with (for example) two data nodes supports
fewer partitions than a cluster with eight data nodes supports.  This
means that using *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. '--restore-meta' to restore the
schema does not always work since this restores a given table with the
same number of partitions as in the original; it is safer to restore the
schema from a backup written by *note 'mysqldump': mysqldump.--as in the
example shown previously--when restoring to a cluster having fewer data
nodes, LDM threads, or both, than were used in the original cluster.

The support for fewer partitions when restoring to a smaller cluster
also means the maximum number of rows per table is lower.  However, with
the larger hash maps available in MySQL Cluster 7.2.9 and later (used by
default for new tables), this is not likely to be an issue.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-select-all,  Next: mysql-cluster-programs-ndb-select-count,  Prev: mysql-cluster-programs-ndb-restore,  Up: mysql-cluster-programs

18.4.22 'ndb_select_all' -- Print Rows from an NDB Table
--------------------------------------------------------

*note 'ndb_select_all': mysql-cluster-programs-ndb-select-all. prints
all rows from an *note 'NDB': mysql-cluster. table to 'stdout'.

*Usage*

     ndb_select_all -c CONNECTION_STRING TBL_NAME -d DB_NAME [> FILE_NAME]

The following table includes options that are specific to the NDB
Cluster native backup restoration program *note 'ndb_select_all':
mysql-cluster-programs-ndb-select-all.  Additional descriptions follow
the table.  For options common to most NDB Cluster programs (including
*note 'ndb_select_all': mysql-cluster-programs-ndb-select-all.), see
*note mysql-cluster-program-options-common::.

*Command-line options for the ndb_select_all program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Name of the database     
'--database=dbname',     in which the table is    All MySQL 5.5 based
                         found                    releases
' -d '                                            

'--parallelism=#',       Degree of parallelism    All MySQL 5.5 based
                                                  releases
' -p '                                            

'--lock=#',              Lock type                All MySQL 5.5 based
                                                  releases
' -l '                                            

'--order=index',         Sort resultset           All MySQL 5.5 based
                         according to index       releases
' -o '                   whose name is supplied   
                         
                         Sort resultset in        
'--descending',          descending order         All MySQL 5.5 based
                         (requires order flag)    releases
' -z '                                            

'--header',              Print header (set to     All MySQL 5.5 based
                         0|FALSE to disable       releases
' -h '                   headers in output)       
                         
                         Output numbers in        
'--useHexFormat',        hexadecimal format       All MySQL 5.5 based
                                                  releases
' -x '                                            

'--delimiter=char',      Set a column delimiter   All MySQL 5.5 based
                                                  releases
' -D '                                            

' --disk '               Print disk references    All MySQL 5.5 based
                         (useful only for Disk    releases
                         Data tables having       
                         nonindexed columns)
                         
                         Print rowid              
' --rowid '                                       All MySQL 5.5 based
                                                  releases
                                                  
                         Include GCI in output    
' --gci '                                         All MySQL 5.5 based
                                                  releases
                                                  
                         Include GCI and row      
' --gci64 '              epoch in output          All MySQL 5.5 based
                                                  releases
                                                  
                         Scan in tup order        
'--tupscan',                                      All MySQL 5.5 based
                                                  releases
' -t '                                            

' --nodata '             Do not print table       All MySQL 5.5 based
                         column data              releases
                         

   * 
     '--database=DBNAME', '-d' DBNAME

     Name of the database in which the table is found.  The default
     value is 'TEST_DB'.

   * 
     'parallelism=#', '-p' #

     Specifies the degree of parallelism.

   * 
     '--lock=LOCK_TYPE', '-l LOCK_TYPE'

     Employs a lock when reading the table.  Possible values for
     LOCK_TYPE are:

        * '0': Read lock

        * '1': Read lock with hold

        * '2': Exclusive read lock

     There is no default value for this option.

   * 
     '--order=INDEX_NAME', '-o INDEX_NAME'

     Orders the output according to the index named INDEX_NAME.  Note
     that this is the name of an index, not of a column, and that the
     index must have been explicitly named when created.

   * 
     '--descending', '-z'

     Sorts the output in descending order.  This option can be used only
     in conjunction with the '-o' ('--order') option.

   * 
     '--header=FALSE'

     Excludes column headers from the output.

   * 
     '--useHexFormat' '-x'

     Causes all numeric values to be displayed in hexadecimal format.
     This does not affect the output of numerals contained in strings or
     datetime values.

   * 
     '--delimiter=CHARACTER', '-D CHARACTER'

     Causes the CHARACTER to be used as a column delimiter.  Only table
     data columns are separated by this delimiter.

     The default delimiter is the tab character.

   * 
     '--disk'

     Adds a disk reference column to the output.  The column is nonempty
     only for Disk Data tables having nonindexed columns.

   * 
     '--rowid'

     Adds a 'ROWID' column providing information about the fragments in
     which rows are stored.

   * 
     '--gci'

     Adds a 'GCI' column to the output showing the global checkpoint at
     which each row was last updated.  See *note
     mysql-cluster-overview::, and *note mysql-cluster-log-events::, for
     more information about checkpoints.

   * 
     '--gci64'

     Adds a 'ROW$GCI64' column to the output showing the global
     checkpoint at which each row was last updated, as well as the
     number of the epoch in which this update occurred.

   * 
     '--tupscan', '-t'

     Scan the table in the order of the tuples.

   * 
     '--nodata'

     Causes any table data to be omitted.

*Sample Output*

Output from a MySQL *note 'SELECT': select. statement:

     mysql> SELECT * FROM ctest1.fish;
     +----+-----------+
     | id | name      |
     +----+-----------+
     |  3 | shark     |
     |  6 | puffer    |
     |  2 | tuna      |
     |  4 | manta ray |
     |  5 | grouper   |
     |  1 | guppy     |
     +----+-----------+
     6 rows in set (0.04 sec)

Output from the equivalent invocation of *note 'ndb_select_all':
mysql-cluster-programs-ndb-select-all.:

     shell> ./ndb_select_all -c localhost fish -d ctest1
     id      name
     3       [shark]
     6       [puffer]
     2       [tuna]
     4       [manta ray]
     5       [grouper]
     1       [guppy]
     6 rows returned

     NDBT_ProgramExit: 0 - OK

All string values are enclosed by square brackets ('['...']')  in the
output of *note 'ndb_select_all': mysql-cluster-programs-ndb-select-all.
Now consider the table created and populated as shown here:

     CREATE TABLE dogs (
         id INT(11) NOT NULL AUTO_INCREMENT,
         name VARCHAR(25) NOT NULL,
         breed VARCHAR(50) NOT NULL,
         PRIMARY KEY pk (id),
         KEY ix (name)
     )
     TABLESPACE ts STORAGE DISK
     ENGINE=NDBCLUSTER;

     INSERT INTO dogs VALUES
         ('', 'Lassie', 'collie'),
         ('', 'Scooby-Doo', 'Great Dane'),
         ('', 'Rin-Tin-Tin', 'Alsatian'),
         ('', 'Rosscoe', 'Mutt');

This demonstrates the use of several additional *note 'ndb_select_all':
mysql-cluster-programs-ndb-select-all. options:

     shell> ./ndb_select_all -d ctest1 dogs -o ix -z --gci --disk
     GCI     id name          breed        DISK_REF
     834461  2  [Scooby-Doo]  [Great Dane] [ m_file_no: 0 m_page: 98 m_page_idx: 0 ]
     834878  4  [Rosscoe]     [Mutt]       [ m_file_no: 0 m_page: 98 m_page_idx: 16 ]
     834463  3  [Rin-Tin-Tin] [Alsatian]   [ m_file_no: 0 m_page: 34 m_page_idx: 0 ]
     835657  1  [Lassie]      [Collie]     [ m_file_no: 0 m_page: 66 m_page_idx: 0 ]
     4 rows returned

     NDBT_ProgramExit: 0 - OK


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-select-count,  Next: mysql-cluster-programs-ndb-show-tables,  Prev: mysql-cluster-programs-ndb-select-all,  Up: mysql-cluster-programs

18.4.23 'ndb_select_count' -- Print Row Counts for NDB Tables
-------------------------------------------------------------

*note 'ndb_select_count': mysql-cluster-programs-ndb-select-count.
prints the number of rows in one or more *note 'NDB': mysql-cluster.
tables.  With a single table, the result is equivalent to that obtained
by using the MySQL statement 'SELECT COUNT(*) FROM TBL_NAME'.

*Usage*

     ndb_select_count [-c CONNECTION_STRING] -dDB_NAME TBL_NAME[, TBL_NAME2[, ...]]

The following table includes options that are specific to the NDB
Cluster native backup restoration program *note 'ndb_select_count':
mysql-cluster-programs-ndb-select-count.  Additional descriptions follow
the table.  For options common to most NDB Cluster programs (including
*note 'ndb_select_count': mysql-cluster-programs-ndb-select-count.), see
*note mysql-cluster-program-options-common::.

*Command-line options for the ndb_select_count program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Name of the database     
'--database=dbname',     in which the table is    All MySQL 5.5 based
                         found                    releases
'-d'                                              

'--parallelism=#',       Degree of parallelism    All MySQL 5.5 based
                                                  releases
'-p'                                              

'--lock=#',              Lock type                All MySQL 5.5 based
                                                  releases
'-l'

You can obtain row counts from multiple tables in the same database by
listing the table names separated by spaces when invoking this command,
as shown under *Sample Output*.

*Sample Output*

     shell> ./ndb_select_count -c localhost -d ctest1 fish dogs
     6 records in table fish
     4 records in table dogs

     NDBT_ProgramExit: 0 - OK


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-show-tables,  Next: mysql-cluster-programs-ndb-size-pl,  Prev: mysql-cluster-programs-ndb-select-count,  Up: mysql-cluster-programs

18.4.24 'ndb_show_tables' -- Display List of NDB Tables
-------------------------------------------------------

*note 'ndb_show_tables': mysql-cluster-programs-ndb-show-tables.
displays a list of all *note 'NDB': mysql-cluster. database objects in
the cluster.  By default, this includes not only both user-created
tables and *note 'NDB': mysql-cluster. system tables, but *note 'NDB':
mysql-cluster.-specific indexes, internal triggers, and NDB Cluster Disk
Data objects as well.

The following table includes options that are specific to the NDB
Cluster native backup restoration program *note 'ndb_show_tables':
mysql-cluster-programs-ndb-show-tables.  Additional descriptions follow
the table.  For options common to most NDB Cluster programs (including
*note 'ndb_show_tables': mysql-cluster-programs-ndb-show-tables.), see
*note mysql-cluster-program-options-common::.

*Command-line options for the ndb_show_tables program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Specifies the database   
'--database=string',     in which the table is    All MySQL 5.5 based
                         found                    releases
' -d '                                            

'--loops=#',             Number of times to       All MySQL 5.5 based
                         repeat output            releases
' -l '                                            

'--parsable',            Return output suitable   All MySQL 5.5 based
                         for MySQL LOAD DATA      releases
' -p '                   INFILE statement         
                         
                         Show table temporary     
' --show-temp-status '   flag                     All MySQL 5.5 based
                                                  releases
                                                  
                         Limit output to          
'--type=#',              objects of this type     All MySQL 5.5 based
                                                  releases
' -t '                                            

'--unqualified',         Do not qualify table     All MySQL 5.5 based
                         names                    releases
' -u '                   

*Usage*

     ndb_show_tables [-c CONNECTION_STRING]

   * 
     '--database', '-d'

     Specifies the name of the database in which the tables are found.

   * 
     '--loops', '-l'

     Specifies the number of times the utility should execute.  This is
     1 when this option is not specified, but if you do use the option,
     you must supply an integer argument for it.

   * 
     '--parsable', '-p'

     Using this option causes the output to be in a format suitable for
     use with *note 'LOAD DATA': load-data.

   * 
     '--show-temp-status'

     If specified, this causes temporary tables to be displayed.

   * 
     '--type', '-t'

     Can be used to restrict the output to one type of object, specified
     by an integer type code as shown here:

        * '1': System table

        * '2': User-created table

        * '3': Unique hash index

     Any other value causes all *note 'NDB': mysql-cluster. database
     objects to be listed (the default).

   * 
     '--unqualified', '-u'

     If specified, this causes unqualified object names to be displayed.

*Note*:

Only user-created NDB Cluster tables may be accessed from MySQL; system
tables such as 'SYSTAB_0' are not visible to *note 'mysqld': mysqld.
However, you can examine the contents of system tables using *note
'NDB': mysql-cluster. API applications such as *note 'ndb_select_all':
mysql-cluster-programs-ndb-select-all. (see *note
mysql-cluster-programs-ndb-select-all::).


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-size-pl,  Next: mysql-cluster-programs-ndb-waiter,  Prev: mysql-cluster-programs-ndb-show-tables,  Up: mysql-cluster-programs

18.4.25 'ndb_size.pl' -- NDBCLUSTER Size Requirement Estimator
--------------------------------------------------------------

This is a Perl script that can be used to estimate the amount of space
that would be required by a MySQL database if it were converted to use
the *note 'NDBCLUSTER': mysql-cluster. storage engine.  Unlike the other
utilities discussed in this section, it does not require access to an
NDB Cluster (in fact, there is no reason for it to do so).  However, it
does need to access the MySQL server on which the database to be tested
resides.

*Requirements*

   * A running MySQL server.  The server instance does not have to
     provide support for NDB Cluster.

   * A working installation of Perl.

   * The 'DBI' module, which can be obtained from CPAN if it is not
     already part of your Perl installation.  (Many Linux and other
     operating system distributions provide their own packages for this
     library.)

   * A MySQL user account having the necessary privileges.  If you do
     not wish to use an existing account, then creating one using 'GRANT
     USAGE ON DB_NAME.*'--where DB_NAME is the name of the database to
     be examined--is sufficient for this purpose.

'ndb_size.pl' can also be found in the MySQL sources in
'storage/ndb/tools'.

The following table includes options that are specific to the NDB
Cluster program *note 'ndb_size.pl': mysql-cluster-programs-ndb-size-pl.
Additional descriptions follow the table.  For options common to most
NDB Cluster programs (including *note 'ndb_size.pl':
mysql-cluster-programs-ndb-size-pl.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_size.pl program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         The database or          
' --database=dbname '    databases to examine;    All MySQL 5.5 based
                         accepts a                releases
                         comma-delimited list;    
                         the default is ALL
                         (use all databases
                         found on the server)
                         
                         Specify host and         
' --hostname[:port] '    optional port as         All MySQL 5.5 based
                         host[:port]              releases
                                                  
                         Specify a socket to      
' --socket=file_name '   connect to               All MySQL 5.5 based
                                                  releases
                                                  
                         Specify a MySQL user     
' --user=string '        name                     All MySQL 5.5 based
                                                  releases
                                                  
                         Specify a MySQL user     
' --password=string '    password                 All MySQL 5.5 based
                                                  releases
                                                  
                         Set output format        
' --format=string '      (text or HTML)           All MySQL 5.5 based
                                                  releases
                                                  
                         Skip any tables in a     
'                        comma-separated list     All MySQL 5.5 based
--excludetables=tbl_list of tables                releases
'                                                 

' --excludedbs=db_list   Skip any databases in    All MySQL 5.5 based
'                        a comma-separated list   releases
                         of databases             
                         
                         Saves all queries to     
' --savequeries=file '   the database into the    All MySQL 5.5 based
                         file specified           releases
                                                  
                         Loads all queries from   
' --loadqueries=file '   the file specified;      All MySQL 5.5 based
                         does not connect to a    releases
                         database                 
                         
                         Designates a table to    
'                        handle unique index      All MySQL 5.5 based
--real_table_name=table  size calculations        releases
'                        

*Usage*

     perl ndb_size.pl [--database={DB_NAME|ALL}] [--hostname=HOST[:PORT]] [--socket=SOCKET] \
           [--user=USER] [--password=PASSWORD]  \
           [--help|-h] [--format={html|text}] \
           [--loadqueries=FILE_NAME] [--savequeries=FILE_NAME]

By default, this utility attempts to analyze all databases on the
server.  You can specify a single database using the '--database'
option; the default behavior can be made explicit by using 'ALL' for the
name of the database.  You can also exclude one or more databases by
using the '--excludedbs' option with a comma-separated list of the names
of the databases to be skipped.  Similarly, you can cause specific
tables to be skipped by listing their names, separated by commas,
following the optional '--excludetables' option.  A host name can be
specified using '--hostname'; the default is 'localhost'.  In NDB 7.2.6
and later, you can specify a port in addition to the host using
HOST:PORT format for the value of '--hostname'.  The default port number
is 3306.  If necessary, you can also specify a socket; the default is
'/var/lib/mysql.sock'.  A MySQL user name and password can be specified
the corresponding options shown.  It also possible to control the format
of the output using the '--format' option; this can take either of the
values 'html' or 'text', with 'text' being the default.  An example of
the text output is shown here:

     shell> ndb_size.pl --database=test --socket=/tmp/mysql.sock
     ndb_size.pl report for database: 'test' (1 tables)
     --------------------------------------------------
     Connected to: DBI:mysql:host=localhost;mysql_socket=/tmp/mysql.sock

     Including information for versions: 4.1, 5.0, 5.1

     test.t1
     -------

     DataMemory for Columns (* means varsized DataMemory):
              Column Name            Type  Varsized   Key  4.1  5.0   5.1
          HIDDEN_NDB_PKEY          bigint             PRI    8    8     8
                       c2     varchar(50)         Y         52   52    4*
                       c1         int(11)                    4    4     4
                                                            --   --    --
     Fixed Size Columns DM/Row                              64   64    12
        Varsize Columns DM/Row                               0    0     4

     DataMemory for Indexes:
        Index Name                 Type        4.1        5.0        5.1
           PRIMARY                BTREE         16         16         16
                                                --         --         --
            Total Index DM/Row                  16         16         16

     IndexMemory for Indexes:
                    Index Name        4.1        5.0        5.1
                       PRIMARY         33         16         16
                                       --         --         --
                Indexes IM/Row         33         16         16

     Summary (for THIS table):
                                      4.1        5.0        5.1
         Fixed Overhead DM/Row         12         12         16
                NULL Bytes/Row          4          4          4
                DataMemory/Row         96         96         48
                         (Includes overhead, bitmap and indexes)

       Varsize Overhead DM/Row          0          0          8
        Varsize NULL Bytes/Row          0          0          4
            Avg Varside DM/Row          0          0         16

                      No. Rows          0          0          0

             Rows/32kb DM Page        340        340        680
     Fixedsize DataMemory (KB)          0          0          0

     Rows/32kb Varsize DM Page          0          0       2040
       Varsize DataMemory (KB)          0          0          0

              Rows/8kb IM Page        248        512        512
              IndexMemory (KB)          0          0          0

     Parameter Minimum Requirements
     ------------------------------
     * indicates greater than default

                     Parameter     Default        4.1         5.0         5.1
               DataMemory (KB)       81920          0           0           0
            NoOfOrderedIndexes         128          1           1           1
                    NoOfTables         128          1           1           1
              IndexMemory (KB)       18432          0           0           0
         NoOfUniqueHashIndexes          64          0           0           0
                NoOfAttributes        1000          3           3           3
                  NoOfTriggers         768          5           5           5

For debugging purposes, the Perl arrays containing the queries run by
this script can be read from the file specified using can be saved to a
file using '--savequeries'; a file containing such arrays to be read
during script execution can be specified using '--loadqueries'.  Neither
of these options has a default value.

To produce output in HTML format, use the '--format' option and redirect
the output to a file, as shown here:

     shell> ndb_size.pl --database=test --socket=/tmp/mysql.sock --format=html > ndb_size.html

(Without the redirection, the output is sent to 'stdout'.)

The output from this script includes the following information:

   * Minimum values for the 'DataMemory', 'IndexMemory',
     'MaxNoOfTables', 'MaxNoOfAttributes', 'MaxNoOfOrderedIndexes',
     'MaxNoOfUniqueHashIndexes', and 'MaxNoOfTriggers' configuration
     parameters required to accommodate the tables analyzed.

   * Memory requirements for all of the tables, attributes, ordered
     indexes, and unique hash indexes defined in the database.

   * The 'IndexMemory' and 'DataMemory' required per table and table
     row.


File: manual.info.tmp,  Node: mysql-cluster-programs-ndb-waiter,  Next: mysql-cluster-program-options-common,  Prev: mysql-cluster-programs-ndb-size-pl,  Up: mysql-cluster-programs

18.4.26 'ndb_waiter' -- Wait for NDB Cluster to Reach a Given Status
--------------------------------------------------------------------

*note 'ndb_waiter': mysql-cluster-programs-ndb-waiter. repeatedly (each
100 milliseconds) prints out the status of all cluster data nodes until
either the cluster reaches a given status or the '--timeout' limit is
exceeded, then exits.  By default, it waits for the cluster to achieve
'STARTED' status, in which all nodes have started and connected to the
cluster.  This can be overridden using the '--no-contact' and
'--not-started' options.

The node states reported by this utility are as follows:

   * 'NO_CONTACT': The node cannot be contacted.

   * 'UNKNOWN': The node can be contacted, but its status is not yet
     known.  Usually, this means that the node has received a 'START' or
     'RESTART' command from the management server, but has not yet acted
     on it.

   * 'NOT_STARTED': The node has stopped, but remains in contact with
     the cluster.  This is seen when restarting the node using the
     management client's 'RESTART' command.

   * 'STARTING': The node's *note 'ndbd': mysql-cluster-programs-ndbd.
     process has started, but the node has not yet joined the cluster.

   * 'STARTED': The node is operational, and has joined the cluster.

   * 'SHUTTING_DOWN': The node is shutting down.

   * 'SINGLE USER MODE': This is shown for all cluster data nodes when
     the cluster is in single user mode.

The following table includes options that are specific to the NDB
Cluster native backup restoration program *note 'ndb_waiter':
mysql-cluster-programs-ndb-waiter.  Additional descriptions follow the
table.  For options common to most NDB Cluster programs (including *note
'ndb_waiter': mysql-cluster-programs-ndb-waiter.), see *note
mysql-cluster-program-options-common::.

*Command-line options for the ndb_waiter program*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Wait for cluster to      
'--no-contact',          reach NO CONTACT state   All MySQL 5.5 based
                                                  releases
' -n '                                            

' --not-started '        Wait for cluster to      All MySQL 5.5 based
                         reach NOT STARTED        releases
                         state                    
                         
                         Wait for cluster to      
' --single-user '        enter single user mode   All MySQL 5.5 based
                                                  releases
                                                  
                         Wait this many           
'--timeout=#',           seconds, then exit       All MySQL 5.5 based
                         whether or not cluster   releases
' -t '                   has reached desired      
                         state; default is 2
                         minutes (120 seconds)
                         
                         List of nodes not to     
' --nowait-nodes=list    be waited for.           All MySQL 5.5 based
'                                                 releases
                                                  
                         List of nodes to be      
'--wait-nodes=list',     waited for.              All MySQL 5.5 based
                                                  releases
' -w '

*Usage*

     ndb_waiter [-c CONNECTION_STRING]

*Additional Options*

   * 
     '--no-contact', '-n'

     Instead of waiting for the 'STARTED' state, *note 'ndb_waiter':
     mysql-cluster-programs-ndb-waiter. continues running until the
     cluster reaches 'NO_CONTACT' status before exiting.

   * 
     '--not-started'

     Instead of waiting for the 'STARTED' state, *note 'ndb_waiter':
     mysql-cluster-programs-ndb-waiter. continues running until the
     cluster reaches 'NOT_STARTED' status before exiting.

   * 
     '--timeout=SECONDS', '-t SECONDS'

     Time to wait.  The program exits if the desired state is not
     achieved within this number of seconds.  The default is 120 seconds
     (1200 reporting cycles).

   * 
     '--single-user'

     The program waits for the cluster to enter single user mode.

   * 
     '--nowait-nodes=LIST'

     When this option is used, ndb_waiter does not wait for the nodes
     whose IDs are listed.  The list is comma-delimited; ranges can be
     indicated by dashes, as shown here:

          shell> ndb_waiter --nowait-nodes=1,3,7-9

     *Important*:

     Do _not_ use this option together with the '--wait-nodes' option.

   * 
     '--wait-nodes=LIST', '-w LIST'

     When this option is used, *note 'ndb_waiter':
     mysql-cluster-programs-ndb-waiter. waits only for the nodes whose
     IDs are listed.  The list is comma-delimited; ranges can be
     indicated by dashes, as shown here:

          shell> ndb_waiter --wait-nodes=2,4-6,10

     *Important*:

     Do _not_ use this option together with the '--nowait-nodes' option.

Sample Output

Shown here is the output from *note 'ndb_waiter':
mysql-cluster-programs-ndb-waiter. when run against a 4-node cluster in
which two nodes have been shut down and then started again manually.
Duplicate reports (indicated by '...') are omitted.

     shell> ./ndb_waiter -c localhost

     Connecting to mgmsrv at (localhost)
     State node 1 STARTED
     State node 2 NO_CONTACT
     State node 3 STARTED
     State node 4 NO_CONTACT
     Waiting for cluster enter state STARTED

     ...

     State node 1 STARTED
     State node 2 UNKNOWN
     State node 3 STARTED
     State node 4 NO_CONTACT
     Waiting for cluster enter state STARTED

     ...

     State node 1 STARTED
     State node 2 STARTING
     State node 3 STARTED
     State node 4 NO_CONTACT
     Waiting for cluster enter state STARTED

     ...

     State node 1 STARTED
     State node 2 STARTING
     State node 3 STARTED
     State node 4 UNKNOWN
     Waiting for cluster enter state STARTED

     ...

     State node 1 STARTED
     State node 2 STARTING
     State node 3 STARTED
     State node 4 STARTING
     Waiting for cluster enter state STARTED

     ...

     State node 1 STARTED
     State node 2 STARTED
     State node 3 STARTED
     State node 4 STARTING
     Waiting for cluster enter state STARTED

     ...

     State node 1 STARTED
     State node 2 STARTED
     State node 3 STARTED
     State node 4 STARTED
     Waiting for cluster enter state STARTED

     NDBT_ProgramExit: 0 - OK

*Note*:

If no connection string is specified, then *note 'ndb_waiter':
mysql-cluster-programs-ndb-waiter. tries to connect to a management on
'localhost', and reports 'Connecting to mgmsrv at (null)'.


File: manual.info.tmp,  Node: mysql-cluster-program-options-common,  Prev: mysql-cluster-programs-ndb-waiter,  Up: mysql-cluster-programs

18.4.27 Options Common to NDB Cluster Programs -- Options Common to NDB Cluster Programs
----------------------------------------------------------------------------------------

All NDB Cluster programs accept the options described in this section,
with the following exceptions:

   * *note 'mysqld': mysqld.

   * *note 'ndb_print_backup_file':
     mysql-cluster-programs-ndb-print-backup-file.

   * *note 'ndb_print_schema_file':
     mysql-cluster-programs-ndb-print-schema-file.

   * *note 'ndb_print_sys_file':
     mysql-cluster-programs-ndb-print-sys-file.

Users of earlier NDB Cluster versions should note that some of these
options have been changed to make them consistent with one another as
well as with *note 'mysqld': mysqld.  You can use the '--help' option
with any NDB Cluster program--with the exception of *note
'ndb_print_backup_file': mysql-cluster-programs-ndb-print-backup-file,
*note 'ndb_print_schema_file':
mysql-cluster-programs-ndb-print-schema-file, and *note
'ndb_print_sys_file': mysql-cluster-programs-ndb-print-sys-file.--to
view a list of the options which the program supports.

The options in the following table are common to all NDB Cluster
executables (except those noted previously in this section).

*Command-line options common to all MySQL NDB Cluster programs*

Format                   Description              Added, Deprecated, or
                                                  Removed
                                                  
                         Directory where          
'                        character sets are       All MySQL 5.5 based
--character-sets-dir=dir_nameinstalled            releases
'                                                 

' --core-file '          Write core on errors     All MySQL 5.5 based
                         (defaults to TRUE in     releases
                         debug builds)            
                         
                         Enable output from       
' --debug=options '      debug calls.  Can be     All MySQL 5.5 based
                         used only for versions   releases
                         compiled with            
                         debugging enabled
                         
                         Read this file after     
'                        global option files      All MySQL 5.5 based
--defaults-extra-file=filenameare read            releases
'                                                 

'                        Read default options     All MySQL 5.5 based
--defaults-file=filename from this file           releases
'                                                 

'--help',                Display help message     All MySQL 5.5 based
                         and exit                 releases
'--usage',                                        

' -? '

'--ndb-connectstring=connectstring',Set connection stringAll MySQL 5.5 based
                         for connecting to        releases
'--connect-string=connectstring',ndb_mgmd.  Syntax:
                         [nodeid=<id>;][host=]<hostname>[:<port>].
' -c '                   Overrides entries
                         specified in
                         NDB_CONNECTSTRING or
                         my.cnf.
                         
                         Set the host (and        
'                        port, if desired) for    All MySQL 5.5 based
--ndb-mgmd-host=host[:port]connecting to          releases
'                        management server        
                         
                         Set node id for this     
' --ndb-nodeid=# '       node                     All MySQL 5.5 based
                                                  releases
                                                  
                         Select nodes for         
'                        transactions in a more   All MySQL 5.5 based
--ndb-optimized-node-selectionoptimal way         releases
'                                                 

' --no-defaults '        Do not read default      All MySQL 5.5 based
                         options from any         releases
                         option file other than   
                         login file
                         
                         Print the program        
' --print-defaults '     argument list and exit   All MySQL 5.5 based
                                                  releases
                                                  
                         Output version           
'--version',             information and exit     All MySQL 5.5 based
                                                  releases
' -V '

For options specific to individual NDB Cluster programs, see *note
mysql-cluster-programs::.

See *note mysql-cluster-program-options-mysqld::, for *note 'mysqld':
mysqld. options relating to NDB Cluster.

   * 
     '--character-sets-dir=NAME'

     Property               Value
                            
     *Command-Line          '--character-sets-dir=dir_name'
     Format*                

     *Type*                 Directory name
                            
     *Default Value*        ''

     Tells the program where to find character set information.

   * 
     '--core-file'

     Property               Value
                            
     *Command-Line          '--core-file'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'FALSE'

     Write a core file if the program dies.  The name and location of
     the core file are system-dependent.  (For NDB Cluster programs
     nodes running on Linux, the default location is the program's
     working directory--for a data node, this is the node's 'DataDir'.)
     For some systems, there may be restrictions or limitations.  For
     example, it might be necessary to execute 'ulimit -c unlimited'
     before starting the server.  Consult your system documentation for
     detailed information.

     If NDB Cluster was built using the '--debug' option for
     'configure', then '--core-file' is enabled by default.  For regular
     builds, '--core-file' is disabled by default.

   * 
     '--debug[=OPTIONS]'

     Property               Value
                            
     *Command-Line          '--debug=options'
     Format*                

     *Type*                 String
                            
     *Default Value*        'd:t:O,/tmp/ndb_restore.trace'

     This option can be used only for versions compiled with debugging
     enabled.  It is used to enable output from debug calls in the same
     manner as for the *note 'mysqld': mysqld. process.

   * 
     '--defaults-extra-file'=FILENAME

     Property               Value
                            
     *Command-Line          '--defaults-extra-file=filename'
     Format*                

     *Type*                 String
                            
     *Default Value*        '[none]'

     Read this file after global option files are read.

     For additional information about this and other option-file
     options, see *note option-file-options::.

   * 
     '--defaults-file'=FILENAME

     Property               Value
                            
     *Command-Line          '--defaults-file=filename'
     Format*                

     *Type*                 String
                            
     *Default Value*        '[none]'

     Read default options from this file.

     For additional information about this and other option-file
     options, see *note option-file-options::.

   * 
     '--help', '--usage', '-?'

     Property               Value
                            
     *Command-Line          '--help' '--usage'
     Format*

     Prints a short list with descriptions of the available command
     options.

   * 
     '--ndb-connectstring=CONNECTION_STRING',
     '--connect-string=CONNECTION_STRING', '-c CONNECTION_STRING'

     Property               Value
                            
     *Command-Line          '--ndb-connectstring=connectstring'
     Format*                '--connect-string=connectstring'
                            
     *Type*                 String
                            
     *Default Value*        'localhost:1186'

     This option takes an NDB Cluster connection string that specifies
     the management server for the application to connect to, as shown
     here:

          shell> ndbd --ndb-connectstring="nodeid=2;host=ndb_mgmd.mysql.com:1186"

     For more information, see *note mysql-cluster-connection-strings::.

   * 
     '--ndb-mgmd-host=HOST[:PORT]'

     Property               Value
                            
     *Command-Line          '--ndb-mgmd-host=host[:port]'
     Format*                

     *Type*                 String
                            
     *Default Value*        'localhost:1186'

     Can be used to set the host and port number of a single management
     server for the program to connect to.  If the program requires node
     IDs or references to multiple management servers (or both) in its
     connection information, use the '--ndb-connectstring' option
     instead.

   * 
     '--ndb-nodeid=#'

     Property               Value
                            
     *Command-Line          '--ndb-nodeid=#'
     Format*                

     *Type*                 Numeric
                            
     *Default Value*        '0'

     Sets this node's NDB Cluster node ID. _The range of permitted
     values depends on the node's type (data, management, or API) and
     the NDB Cluster software version_.  See *note
     mysql-cluster-limitations-limits::, for more information.

   * 
     '--no-defaults'

     Property               Value
                            
     *Command-Line          '--no-defaults'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'TRUE'

     Do not read default options from any option file other than login
     file.

     For additional information about this and other option-file
     options, see *note option-file-options::.

   * 
     '--ndb-optimized-node-selection'

     Property               Value
                            
     *Command-Line          '--ndb-optimized-node-selection'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'TRUE'

     Optimize selection of nodes for transactions.  Enabled by default.

   * 
     '--print-defaults'

     Property               Value
                            
     *Command-Line          '--print-defaults'
     Format*                

     *Type*                 Boolean
                            
     *Default Value*        'TRUE'

     Print the program argument list and exit.

     For additional information about this and other option-file
     options, see *note option-file-options::.

   * 
     '--version', '-V'

     Property               Value
                            
     *Command-Line          '--version'
     Format*

     Prints the NDB Cluster version number of the executable.  The
     version number is relevant because not all versions can be used
     together, and the NDB Cluster startup process verifies that the
     versions of the binaries being used can co-exist in the same
     cluster.  This is also important when performing an online
     (rolling) software upgrade or downgrade of NDB Cluster.

     See *note mysql-cluster-rolling-restart::), for more information.


File: manual.info.tmp,  Node: mysql-cluster-management,  Next: mysql-cluster-replication,  Prev: mysql-cluster-programs,  Up: mysql-cluster

18.5 Management of NDB Cluster
==============================

* Menu:

* mysql-cluster-start-phases::   Summary of NDB Cluster Start Phases
* mysql-cluster-mgm-client-commands::  Commands in the NDB Cluster Management Client
* mysql-cluster-backup::         Online Backup of NDB Cluster
* mysql-cluster-mysqld::         MySQL Server Usage for NDB Cluster
* mysql-cluster-rolling-restart::  Performing a Rolling Restart of an NDB Cluster
* mysql-cluster-event-reports::  Event Reports Generated in NDB Cluster
* mysql-cluster-logs-ndb-messages::  NDB Cluster Log Messages
* mysql-cluster-single-user-mode::  NDB Cluster Single User Mode
* mysql-cluster-sql-statements::  Quick Reference: NDB Cluster SQL Statements
* mysql-cluster-ndbinfo::        ndbinfo: The NDB Cluster Information Database
* mysql-cluster-security::       NDB Cluster Security Issues
* mysql-cluster-disk-data::      NDB Cluster Disk Data Tables
* mysql-cluster-online-operations::  Online Operations with ALTER TABLE in NDB Cluster
* mysql-cluster-online-add-node::  Adding NDB Cluster Data Nodes Online
* mysql-cluster-privilege-distribution::  Distributed Privileges Using Shared Grant Tables
* mysql-cluster-ndb-api-statistics::  NDB API Statistics Counters and Variables

Managing an NDB Cluster involves a number of tasks, the first of which
is to configure and start NDB Cluster.  This is covered in *note
mysql-cluster-configuration::, and *note mysql-cluster-programs::.

The next few sections cover the management of a running NDB Cluster.

For information about security issues relating to management and
deployment of an NDB Cluster, see *note mysql-cluster-security::.

There are essentially two methods of actively managing a running NDB
Cluster.  The first of these is through the use of commands entered into
the management client whereby cluster status can be checked, log levels
changed, backups started and stopped, and nodes stopped and started.
The second method involves studying the contents of the cluster log
'ndb_NODE_ID_cluster.log'; this is usually found in the management
server's 'DataDir' directory, but this location can be overridden using
the 'LogDestination' option.  (Recall that NODE_ID represents the unique
identifier of the node whose activity is being logged.)  The cluster log
contains event reports generated by *note 'ndbd':
mysql-cluster-programs-ndbd.  It is also possible to send cluster log
entries to a Unix system log.

Some aspects of the cluster's operation can be also be monitored from an
SQL node using the *note 'SHOW ENGINE NDB STATUS': show-engine.
statement.

More detailed information about NDB Cluster operations is available in
real time through an SQL interface using the *note 'ndbinfo':
mysql-cluster-ndbinfo. database.  For more information, see *note
mysql-cluster-ndbinfo::.

NDB statistics counters provide improved monitoring using the *note
'mysql': mysql. client.  These counters, implemented in the NDB kernel,
relate to operations performed by or affecting 'Ndb'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) objects, such as
starting, closing, and aborting transactions; primary key and unique key
operations; table, range, and pruned scans; blocked threads waiting for
various operations to complete; and data and events sent and received by
NDB Cluster.  The counters are incremented by the NDB kernel whenever
NDB API calls are made or data is sent to or received by the data nodes.

*note 'mysqld': mysqld. exposes the NDB API statistics counters as
system status variables, which can be identified from the prefix common
to all of their names ('Ndb_api_').  The values of these variables can
be read in the *note 'mysql': mysql. client from the output of a *note
'SHOW STATUS': show-status. statement, or by querying either the *note
'SESSION_STATUS': status-table. table or the *note 'GLOBAL_STATUS':
status-table. table (in the 'INFORMATION_SCHEMA' database).  By
comparing the values of the status variables before and after the
execution of an SQL statement that acts on *note 'NDB': mysql-cluster.
tables, you can observe the actions taken on the NDB API level that
correspond to this statement, which can be beneficial for monitoring and
performance tuning of NDB Cluster.

MySQL Cluster Manager provides an advanced command-line interface that
simplifies many otherwise complex NDB Cluster management tasks, such as
starting, stopping, or restarting an NDB Cluster with a large number of
nodes.  The MySQL Cluster Manager client also supports commands for
getting and setting the values of most node configuration parameters as
well as *note 'mysqld': mysqld. server options and variables relating to
NDB Cluster.  See MySQL(tm) Cluster Manager 1.3.6 User Manual
(https://dev.mysql.com/doc/mysql-cluster-manager/1.3/en/), for more
information.


File: manual.info.tmp,  Node: mysql-cluster-start-phases,  Next: mysql-cluster-mgm-client-commands,  Prev: mysql-cluster-management,  Up: mysql-cluster-management

18.5.1 Summary of NDB Cluster Start Phases
------------------------------------------

This section provides a simplified outline of the steps involved when
NDB Cluster data nodes are started.  More complete information can be
found in NDB Cluster Start Phases
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-start-phases.html),
in the ''NDB' Internals Guide'.

These phases are the same as those reported in the output from the
'NODE_ID STATUS' command in the management client (see *note
mysql-cluster-mgm-client-commands::).  These start phases are also
reported in the 'start_phase' column of the *note 'ndbinfo.nodes':
mysql-cluster-ndbinfo-nodes. table.

Start types

There are several different startup types and modes, as shown in the
following list:

   * Initial start

     The cluster starts with a clean file system on all data nodes.
     This occurs either when the cluster started for the very first
     time, or when all data nodes are restarted using the '--initial'
     option.

     *Note*:

     Disk Data files are not removed when restarting a node using
     '--initial'.

   * System restart

     The cluster starts and reads data stored in the data nodes.  This
     occurs when the cluster has been shut down after having been in
     use, when it is desired for the cluster to resume operations from
     the point where it left off.

   * Node restart

     This is the online restart of a cluster node while the cluster
     itself is running.

   * Initial node restart

     This is the same as a node restart, except that the node is
     reinitialized and started with a clean file system.

Setup and initialization (phase -1)

Prior to startup, each data node (*note 'ndbd':
mysql-cluster-programs-ndbd. process) must be initialized.
Initialization consists of the following steps:

  1. Obtain a node ID

  2. Fetch configuration data

  3. Allocate ports to be used for inter-node communications

  4. Allocate memory according to settings obtained from the
     configuration file

When a data node or SQL node first connects to the management node, it
reserves a cluster node ID. To make sure that no other node allocates
the same node ID, this ID is retained until the node has managed to
connect to the cluster and at least one *note 'ndbd':
mysql-cluster-programs-ndbd. reports that this node is connected.  This
retention of the node ID is guarded by the connection between the node
in question and *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd.

After each data node has been initialized, the cluster startup process
can proceed.  The stages which the cluster goes through during this
process are listed here:

   * Phase 0

     The 'NDBFS' and 'NDBCNTR' blocks start (see NDB Kernel Blocks
     (https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks.html)).
     Data node file systems are cleared on those data nodes that were
     started with '--initial' option.

   * Phase 1

     In this stage, all remaining *note 'NDB': mysql-cluster. kernel
     blocks are started.  NDB Cluster connections are set up,
     inter-block communications are established, and heartbeats are
     started.  In the case of a node restart, API node connections are
     also checked.

     *Note*:

     When one or more nodes hang in Phase 1 while the remaining node or
     nodes hang in Phase 2, this often indicates network problems.  One
     possible cause of such issues is one or more cluster hosts having
     multiple network interfaces.  Another common source of problems
     causing this condition is the blocking of TCP/IP ports needed for
     communications between cluster nodes.  In the latter case, this is
     often due to a misconfigured firewall.

   * Phase 2

     The 'NDBCNTR' kernel block checks the states of all existing nodes.
     The master node is chosen, and the cluster schema file is
     initialized.

   * Phase 3

     The 'DBLQH' and 'DBTC' kernel blocks set up communications between
     them.  The startup type is determined; if this is a restart, the
     'DBDIH' block obtains permission to perform the restart.

   * Phase 4

     For an initial start or initial node restart, the redo log files
     are created.  The number of these files is equal to
     'NoOfFragmentLogFiles'.

     For a system restart:

        * Read schema or schemas.

        * Read data from the local checkpoint.

        * Apply all redo information until the latest restorable global
          checkpoint has been reached.

     For a node restart, find the tail of the redo log.

   * Phase 5

     Most of the database-related portion of a data node start is
     performed during this phase.  For an initial start or system
     restart, a local checkpoint is executed, followed by a global
     checkpoint.  Periodic checks of memory usage begin during this
     phase, and any required node takeovers are performed.

   * Phase 6

     In this phase, node groups are defined and set up.

   * Phase 7

     The arbitrator node is selected and begins to function.  The next
     backup ID is set, as is the backup disk write speed.  Nodes
     reaching this start phase are marked as 'Started'.  It is now
     possible for API nodes (including SQL nodes) to connect to the
     cluster.

   * Phase 8

     If this is a system restart, all indexes are rebuilt (by 'DBDIH').

   * Phase 9

     The node internal startup variables are reset.

   * Phase 100 (OBSOLETE)

     Formerly, it was at this point during a node restart or initial
     node restart that API nodes could connect to the node and begin to
     receive events.  Currently, this phase is empty.

   * Phase 101

     At this point in a node restart or initial node restart, event
     delivery is handed over to the node joining the cluster.  The
     newly-joined node takes over responsibility for delivering its
     primary data to subscribers.  This phase is also referred to as
     _'SUMA' handover phase_.

After this process is completed for an initial start or system restart,
transaction handling is enabled.  For a node restart or initial node
restart, completion of the startup process means that the node may now
act as a transaction coordinator.


File: manual.info.tmp,  Node: mysql-cluster-mgm-client-commands,  Next: mysql-cluster-backup,  Prev: mysql-cluster-start-phases,  Up: mysql-cluster-management

18.5.2 Commands in the NDB Cluster Management Client
----------------------------------------------------

In addition to the central configuration file, a cluster may also be
controlled through a command-line interface available through the
management client *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm.  This
is the primary administrative interface to a running cluster.

Commands for the event logs are given in *note
mysql-cluster-event-reports::; commands for creating backups and
restoring from them are provided in *note mysql-cluster-backup::.

Using ndb_mgm with MySQL Cluster Manager

MySQL Cluster Manager handles starting and stopping processes and tracks
their states internally, so it is not necessary to use *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. for these tasks for an NDB Cluster that
is under MySQL Cluster Manager control.  it is recommended _not_ to use
the *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. command-line client
that comes with the NDB Cluster distribution to perform operations that
involve starting or stopping nodes.  These include but are not limited
to the 'START', 'STOP', 'RESTART', and 'SHUTDOWN' commands.  For more
information, see MySQL Cluster Manager Process Commands
(https://dev.mysql.com/doc/mysql-cluster-manager/1.4/en/mcm-process-commands.html).

The management client has the following basic commands.  In the listing
that follows, NODE_ID denotes either a storage node ID or the keyword
'ALL', which indicates that the command should be applied to all of the
cluster's data nodes.

   * 
     'HELP'

     Displays information on all available commands.

   * 
     'CONNECT CONNECTION-STRING'

     Connects to the management server indicated by the connection
     string.  If the client is already connected to this server, the
     client reconnects.

   * 
     'SHOW'

     Displays information on the cluster's status.  Possible node status
     values include 'UNKNOWN', 'NO_CONTACT', 'NOT_STARTED', 'STARTING',
     'STARTED', 'SHUTTING_DOWN', and 'RESTARTING'.  The output from this
     command also indicates when the cluster is in single user mode
     (status 'SINGLE USER MODE').

   * 
     'NODE_ID START'

     Brings online the data node identified by NODE_ID (or all data
     nodes).

     'ALL START' works on all data nodes only, and does not affect
     management nodes.

     *Important*:

     To use this command to bring a data node online, the data node must
     have been started using '--nostart' or '-n'.

   * 
     'NODE_ID STOP [-a] [-f]'

     Stops the data or management node identified by NODE_ID.

     *Note*:

     'ALL STOP' works to stop all data nodes only, and does not affect
     management nodes.

     A node affected by this command disconnects from the cluster, and
     its associated *note 'ndbd': mysql-cluster-programs-ndbd. or *note
     'ndb_mgmd': mysql-cluster-programs-ndb-mgmd. process terminates.

     The '-a' option causes the node to be stopped immediately, without
     waiting for the completion of any pending transactions.

     Normally, 'STOP' fails if the result would cause an incomplete
     cluster.  The '-f' option forces the node to shut down without
     checking for this.  If this option is used and the result is an
     incomplete cluster, the cluster immediately shuts down.

     *Warning*:

     Use of the '-a' option also disables the safety check otherwise
     performed when 'STOP' is invoked to insure that stopping the node
     does not cause an incomplete cluster.  In other words, you should
     exercise extreme care when using the '-a' option with the 'STOP'
     command, due to the fact that this option makes it possible for the
     cluster to undergo a forced shutdown because it no longer has a
     complete copy of all data stored in *note 'NDB': mysql-cluster.

   * 
     'NODE_ID RESTART [-n] [-i] [-a] [-f]'

     Restarts the data node identified by NODE_ID (or all data nodes).

     Using the '-i' option with 'RESTART' causes the data node to
     perform an initial restart; that is, the node's file system is
     deleted and recreated.  The effect is the same as that obtained
     from stopping the data node process and then starting it again
     using *note 'ndbd': mysql-cluster-programs-ndbd. '--initial' from
     the system shell.

     *Note*:

     Backup files and Disk Data files are not removed when this option
     is used.

     Using the '-n' option causes the data node process to be restarted,
     but the data node is not actually brought online until the
     appropriate 'START' command is issued.  The effect of this option
     is the same as that obtained from stopping the data node and then
     starting it again using *note 'ndbd': mysql-cluster-programs-ndbd.
     '--nostart' or *note 'ndbd': mysql-cluster-programs-ndbd. '-n' from
     the system shell.

     Using the '-a' causes all current transactions relying on this node
     to be aborted.  No GCP check is done when the node rejoins the
     cluster.

     Normally, 'RESTART' fails if taking the node offline would result
     in an incomplete cluster.  The '-f' option forces the node to
     restart without checking for this.  If this option is used and the
     result is an incomplete cluster, the entire cluster is restarted.

   * 
     'NODE_ID STATUS'

     Displays status information for the data node identified by NODE_ID
     (or for all data nodes).

     The output from this command also indicates when the cluster is in
     single user mode.

   * 
     'NODE_ID REPORT REPORT-TYPE'

     Displays a report of type REPORT-TYPE for the data node identified
     by NODE_ID, or for all data nodes using 'ALL'.

     Currently, there are three accepted values for REPORT-TYPE:

        * 'BackupStatus' provides a status report on a cluster backup in
          progress

        * 'MemoryUsage' displays how much data memory and index memory
          is being used by each data node as shown in this example:

               ndb_mgm> ALL REPORT MEMORY

               Node 1: Data usage is 5%(177 32K pages of total 3200)
               Node 1: Index usage is 0%(108 8K pages of total 12832)
               Node 2: Data usage is 5%(177 32K pages of total 3200)
               Node 2: Index usage is 0%(108 8K pages of total 12832)

          This information is also available from the *note
          'ndbinfo.memoryusage': mysql-cluster-ndbinfo-memoryusage.
          table.

        * 'EventLog' reports events from the event log buffers of one or
          more data nodes.

     REPORT-TYPE is case-insensitive and 'fuzzy'; for 'MemoryUsage', you
     can use 'MEMORY' (as shown in the prior example), 'memory', or even
     simply 'MEM' (or 'mem').  You can abbreviate 'BackupStatus' in a
     similar fashion.

     Prior to NDB 7.2.10, 'ALL REPORT BackupStatus' did not work
     correctly with multithreaded data nodes.  (Bug #15908907)

   * 
     'ENTER SINGLE USER MODE NODE_ID'

     Enters single user mode, whereby only the MySQL server identified
     by the node ID NODE_ID is permitted to access the database.

   * 
     'EXIT SINGLE USER MODE'

     Exits single user mode, enabling all SQL nodes (that is, all
     running *note 'mysqld': mysqld. processes) to access the database.

     *Note*:

     It is possible to use 'EXIT SINGLE USER MODE' even when not in
     single user mode, although the command has no effect in this case.

   * 
     'QUIT', 'EXIT'

     Terminates the management client.

     This command does not affect any nodes connected to the cluster.

   * 
     'SHUTDOWN'

     Shuts down all cluster data nodes and management nodes.  To exit
     the management client after this has been done, use 'EXIT' or
     'QUIT'.

     This command does _not_ shut down any SQL nodes or API nodes that
     are connected to the cluster.

   * 
     'CREATE NODEGROUP NODEID[, NODEID, ...]'

     Creates a new NDB Cluster node group and causes data nodes to join
     it.

     This command is used after adding new data nodes online to an NDB
     Cluster, and causes them to join a new node group and thus to begin
     participating fully in the cluster.  The command takes as its sole
     parameter a comma-separated list of node IDs--these are the IDs of
     the nodes just added and started that are to join the new node
     group.  The number of nodes must be the same as the number of nodes
     in each node group that is already part of the cluster (each NDB
     Cluster node group must have the same number of nodes).  In other
     words, if the NDB Cluster has 2 node groups of 2 data nodes each,
     then the new node group must also have 2 data nodes.

     The node group ID of the new node group created by this command is
     determined automatically, and always the next highest unused node
     group ID in the cluster; it is not possible to set it manually.

     For more information, see *note mysql-cluster-online-add-node::.

   * 
     'DROP NODEGROUP NODEGROUP_ID'

     Drops the NDB Cluster node group with the given NODEGROUP_ID.

     This command can be used to drop a node group from an NDB Cluster.
     'DROP NODEGROUP' takes as its sole argument the node group ID of
     the node group to be dropped.

     'DROP NODEGROUP' acts only to remove the data nodes in the effected
     node group from that node group.  It does not stop data nodes,
     assign them to a different node group, or remove them from the
     cluster's configuration.  A data node that does not belong to a
     node group is indicated in the output of the management client
     'SHOW' command with 'no nodegroup' in place of the node group ID,
     like this (indicated using bold text):

          id=3    @10.100.2.67  (5.5.65-ndb-7.2.39, *no nodegroup*)

     Prior to NDB 7.0.4, the 'SHOW' output was not updated correctly
     following 'DROP NODEGROUP'.  (Bug #43413)

     'DROP NODEGROUP' works only when all data nodes in the node group
     to be dropped are completely empty of any table data and table
     definitions.  Since there is currently no way using *note
     'ndb_mgm': mysql-cluster-programs-ndb-mgm. or the *note 'mysql':
     mysql. client to remove all data from a specific data node or node
     group, this means that the command succeeds only in the two
     following cases:

       1. After issuing 'CREATE NODEGROUP' in the *note 'ndb_mgm':
          mysql-cluster-programs-ndb-mgm. client, but before issuing any
          *note 'ALTER ONLINE TABLE ... REORGANIZE PARTITION':
          alter-table. statements in the *note 'mysql': mysql. client.

       2. After dropping all *note 'NDBCLUSTER': mysql-cluster. tables
          using *note 'DROP TABLE': drop-table.

          *note 'TRUNCATE TABLE': truncate-table. does not work for this
          purpose because this removes only the table data; the data
          nodes continue to store an *note 'NDBCLUSTER': mysql-cluster.
          table's definition until a *note 'DROP TABLE': drop-table.
          statement is issued that causes the table metadata to be
          dropped.

     For more information about 'DROP NODEGROUP', see *note
     mysql-cluster-online-add-node::.

Additional commands

A number of other commands available in the *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. client are described elsewhere, as shown
in the following list:

   * *note 'START BACKUP': mysql-cluster-backup-using-management-client.
     is used to perform an online backup in the *note 'ndb_mgm':
     mysql-cluster-programs-ndb-mgm. client; the 'ABORT BACKUP' command
     is used to cancel a backup already in progress.  For more
     information, see *note mysql-cluster-backup::.

   * The *note 'CLUSTERLOG': mysql-cluster-logging-management-commands.
     command is used to perform various logging functions.  See *note
     mysql-cluster-event-reports::, for more information and examples.

   * For testing and diagnostics work, the client also supports a 'DUMP'
     (https://dev.mysql.com/doc/ndb-internals/en/dump-commands.html)
     command which can be used to execute internal commands on the
     cluster.  It should never be used in a production setting unless
     directed to do so by MySQL Support.  For more information, see
     MySQL NDB Cluster Internals Manual
     (https://dev.mysql.com/doc/ndb-internals/en/).


File: manual.info.tmp,  Node: mysql-cluster-backup,  Next: mysql-cluster-mysqld,  Prev: mysql-cluster-mgm-client-commands,  Up: mysql-cluster-management

18.5.3 Online Backup of NDB Cluster
-----------------------------------

* Menu:

* mysql-cluster-backup-concepts::  NDB Cluster Backup Concepts
* mysql-cluster-backup-using-management-client::  Using The NDB Cluster Management Client to Create a Backup
* mysql-cluster-backup-configuration::  Configuration for NDB Cluster Backups
* mysql-cluster-backup-troubleshooting::  NDB Cluster Backup Troubleshooting

The next few sections describe how to prepare for and then to create an
NDB Cluster backup using the functionality for this purpose found in the
*note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. management client.  To
distinguish this type of backup from a backup made using *note
'mysqldump': mysqldump, we sometimes refer to it as a 'native' NDB
Cluster backup.  (For information about the creation of backups with
*note 'mysqldump': mysqldump, see *note mysqldump::.)  Restoration of
NDB Cluster backups is done using the *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. utility provided with the NDB
Cluster distribution; for information about *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. and its use in restoring NDB Cluster
backups, see *note mysql-cluster-programs-ndb-restore::.


File: manual.info.tmp,  Node: mysql-cluster-backup-concepts,  Next: mysql-cluster-backup-using-management-client,  Prev: mysql-cluster-backup,  Up: mysql-cluster-backup

18.5.3.1 NDB Cluster Backup Concepts
....................................

A backup is a snapshot of the database at a given time.  The backup
consists of three main parts:

   * Metadata

     The names and definitions of all database tables

   * Table records

     The data actually stored in the database tables at the time that
     the backup was made

   * Transaction log

     A sequential record telling how and when data was stored in the
     database

Each of these parts is saved on all nodes participating in the backup.
During backup, each node saves these three parts into three files on
disk:

   * 'BACKUP-BACKUP_ID.NODE_ID.ctl'

     A control file containing control information and metadata.  Each
     node saves the same table definitions (for all tables in the
     cluster) to its own version of this file.

   * 'BACKUP-BACKUP_ID-0.NODE_ID.data'

     A data file containing the table records, which are saved on a
     per-fragment basis.  That is, different nodes save different
     fragments during the backup.  The file saved by each node starts
     with a header that states the tables to which the records belong.
     Following the list of records there is a footer containing a
     checksum for all records.

   * 'BACKUP-BACKUP_ID.NODE_ID.log'

     A log file containing records of committed transactions.  Only
     transactions on tables stored in the backup are stored in the log.
     Nodes involved in the backup save different records because
     different nodes host different database fragments.

In the listing just shown, BACKUP_ID stands for the backup identifier
and NODE_ID is the unique identifier for the node creating the file.

The location of the backup files is determined by the 'BackupDataDir'
parameter.


File: manual.info.tmp,  Node: mysql-cluster-backup-using-management-client,  Next: mysql-cluster-backup-configuration,  Prev: mysql-cluster-backup-concepts,  Up: mysql-cluster-backup

18.5.3.2 Using The NDB Cluster Management Client to Create a Backup
...................................................................

Before starting a backup, make sure that the cluster is properly
configured for performing one.  (See *note
mysql-cluster-backup-configuration::.)

The 'START BACKUP' command is used to create a backup:

     START BACKUP [BACKUP_ID] [WAIT_OPTION] [SNAPSHOT_OPTION]

     WAIT_OPTION:
     WAIT {STARTED | COMPLETED} | NOWAIT

     SNAPSHOT_OPTION:
     SNAPSHOTSTART | SNAPSHOTEND

Successive backups are automatically identified sequentially, so the
BACKUP_ID, an integer greater than or equal to 1, is optional; if it is
omitted, the next available value is used.  If an existing BACKUP_ID
value is used, the backup fails with the error 'Backup failed: file
already exists'.  If used, the BACKUP_ID must follow 'START BACKUP'
immediately, before any other options are used.

The WAIT_OPTION can be used to determine when control is returned to the
management client after a 'START BACKUP' command is issued, as shown in
the following list:

   * 
     If 'NOWAIT' is specified, the management client displays a prompt
     immediately, as seen here:

          ndb_mgm> START BACKUP NOWAIT
          ndb_mgm>

     In this case, the management client can be used even while it
     prints progress information from the backup process.

   * 
     With 'WAIT STARTED' the management client waits until the backup
     has started before returning control to the user, as shown here:

          ndb_mgm> START BACKUP WAIT STARTED
          Waiting for started, this may take several minutes
          Node 2: Backup 3 started from node 1
          ndb_mgm>

   * 
     WAIT COMPLETED causes the management client to wait until the
     backup process is complete before returning control to the user.

'WAIT COMPLETED' is the default.

A SNAPSHOT_OPTION can be used to determine whether the backup matches
the state of the cluster when 'START BACKUP' was issued, or when it was
completed.  'SNAPSHOTSTART' causes the backup to match the state of the
cluster when the backup began; 'SNAPSHOTEND' causes the backup to
reflect the state of the cluster when the backup was finished.
'SNAPSHOTEND' is the default, and matches the behavior found in previous
NDB Cluster releases.

*Note*:

If you use the 'SNAPSHOTSTART' option with 'START BACKUP', and the
'CompressedBackup' parameter is enabled, only the data and control files
are compressed--the log file is not compressed.

If both a WAIT_OPTION and a SNAPSHOT_OPTION are used, they may be
specified in either order.  For example, all of the following commands
are valid, assuming that there is no existing backup having 4 as its ID:

     START BACKUP WAIT STARTED SNAPSHOTSTART
     START BACKUP SNAPSHOTSTART WAIT STARTED
     START BACKUP 4 WAIT COMPLETED SNAPSHOTSTART
     START BACKUP SNAPSHOTEND WAIT COMPLETED
     START BACKUP 4 NOWAIT SNAPSHOTSTART

The procedure for creating a backup consists of the following steps:

  1. Start the management client (*note 'ndb_mgm':
     mysql-cluster-programs-ndb-mgm.), if it not running already.

  2. Execute the START BACKUP command.  This produces several lines of
     output indicating the progress of the backup, as shown here:

          ndb_mgm> START BACKUP
          Waiting for completed, this may take several minutes
          Node 2: Backup 1 started from node 1
          Node 2: Backup 1 started from node 1 completed
           StartGCP: 177 StopGCP: 180
           #Records: 7362 #LogRecords: 0
           Data: 453648 bytes Log: 0 bytes
          ndb_mgm>

  3. 
     When the backup has started the management client displays this
     message:

          Backup BACKUP_ID started from node NODE_ID

     BACKUP_ID is the unique identifier for this particular backup.
     This identifier is saved in the cluster log, if it has not been
     configured otherwise.  NODE_ID is the identifier of the management
     server that is coordinating the backup with the data nodes.  At
     this point in the backup process the cluster has received and
     processed the backup request.  It does not mean that the backup has
     finished.  An example of this statement is shown here:

          Node 2: Backup 1 started from node 1

  4. The management client indicates with a message like this one that
     the backup has started:

          Backup BACKUP_ID started from node NODE_ID completed

     As is the case for the notification that the backup has started,
     BACKUP_ID is the unique identifier for this particular backup, and
     NODE_ID is the node ID of the management server that is
     coordinating the backup with the data nodes.  This output is
     accompanied by additional information including relevant global
     checkpoints, the number of records backed up, and the size of the
     data, as shown here:

          Node 2: Backup 1 started from node 1 completed
           StartGCP: 177 StopGCP: 180
           #Records: 7362 #LogRecords: 0
           Data: 453648 bytes Log: 0 bytes

It is also possible to perform a backup from the system shell by
invoking *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. with the '-e'
or '--execute' option, as shown in this example:

     shell> ndb_mgm -e "START BACKUP 6 WAIT COMPLETED SNAPSHOTSTART"

When using 'START BACKUP' in this way, you must specify the backup ID.

Cluster backups are created by default in the 'BACKUP' subdirectory of
the 'DataDir' on each data node.  This can be overridden for one or more
data nodes individually, or for all cluster data nodes in the
'config.ini' file using the 'BackupDataDir' configuration parameter.
The backup files created for a backup with a given BACKUP_ID are stored
in a subdirectory named 'BACKUP-BACKUP_ID' in the backup directory.

Cancelling backups

To cancel or abort a backup that is already in progress, perform the
following steps:

  1. Start the management client.

  2. Execute this command:

          ndb_mgm> ABORT BACKUP BACKUP_ID

     The number BACKUP_ID is the identifier of the backup that was
     included in the response of the management client when the backup
     was started (in the message 'Backup BACKUP_ID started from node
     MANAGEMENT_NODE_ID').

  3. The management client will acknowledge the abort request with
     'Abort of backup BACKUP_ID ordered'.

     *Note*:

     At this point, the management client has not yet received a
     response from the cluster data nodes to this request, and the
     backup has not yet actually been aborted.

  4. After the backup has been aborted, the management client will
     report this fact in a manner similar to what is shown here:

          Node 1: Backup 3 started from 5 has been aborted.
            Error: 1321 - Backup aborted by user request: Permanent error: User defined error
          Node 3: Backup 3 started from 5 has been aborted.
            Error: 1323 - 1323: Permanent error: Internal error
          Node 2: Backup 3 started from 5 has been aborted.
            Error: 1323 - 1323: Permanent error: Internal error
          Node 4: Backup 3 started from 5 has been aborted.
            Error: 1323 - 1323: Permanent error: Internal error

     In this example, we have shown sample output for a cluster with 4
     data nodes, where the sequence number of the backup to be aborted
     is '3', and the management node to which the cluster management
     client is connected has the node ID '5'.  The first node to
     complete its part in aborting the backup reports that the reason
     for the abort was due to a request by the user.  (The remaining
     nodes report that the backup was aborted due to an unspecified
     internal error.)

     *Note*:

     There is no guarantee that the cluster nodes respond to an 'ABORT
     BACKUP' command in any particular order.

     The 'Backup BACKUP_ID started from node MANAGEMENT_NODE_ID has been
     aborted' messages mean that the backup has been terminated and that
     all files relating to this backup have been removed from the
     cluster file system.

It is also possible to abort a backup in progress from a system shell
using this command:

     shell> ndb_mgm -e "ABORT BACKUP BACKUP_ID"

*Note*:

If there is no backup having the ID BACKUP_ID running when an 'ABORT
BACKUP' is issued, the management client makes no response, nor is it
indicated in the cluster log that an invalid abort command was sent.


File: manual.info.tmp,  Node: mysql-cluster-backup-configuration,  Next: mysql-cluster-backup-troubleshooting,  Prev: mysql-cluster-backup-using-management-client,  Up: mysql-cluster-backup

18.5.3.3 Configuration for NDB Cluster Backups
..............................................

Five configuration parameters are essential for backup:

   * 
     'BackupDataBufferSize'

     The amount of memory used to buffer data before it is written to
     disk.

   * 
     'BackupLogBufferSize'

     The amount of memory used to buffer log records before these are
     written to disk.

   * 
     'BackupMemory'

     The total memory allocated in a data node for backups.  This should
     be the sum of the memory allocated for the backup data buffer and
     the backup log buffer.

   * 
     'BackupWriteSize'

     The default size of blocks written to disk.  This applies for both
     the backup data buffer and the backup log buffer.

   * 
     'BackupMaxWriteSize'

     The maximum size of blocks written to disk.  This applies for both
     the backup data buffer and the backup log buffer.

More detailed information about these parameters can be found in Backup
Parameters.

You can also set a location for the backup files using the
'BackupDataDir' configuration parameter.  The default is
'FileSystemPath''/BACKUP/BACKUP-BACKUP_ID'.


File: manual.info.tmp,  Node: mysql-cluster-backup-troubleshooting,  Prev: mysql-cluster-backup-configuration,  Up: mysql-cluster-backup

18.5.3.4 NDB Cluster Backup Troubleshooting
...........................................

If an error code is returned when issuing a backup request, the most
likely cause is insufficient memory or disk space.  You should check
that there is enough memory allocated for the backup.

*Important*:

If you have set 'BackupDataBufferSize' and 'BackupLogBufferSize' and
their sum is greater than 4MB, then you must also set 'BackupMemory' as
well.

You should also make sure that there is sufficient space on the hard
drive partition of the backup target.

*note 'NDB': mysql-cluster. does not support repeatable reads, which can
cause problems with the restoration process.  Although the backup
process is 'hot', restoring an NDB Cluster from backup is not a 100%
'hot' process.  This is due to the fact that, for the duration of the
restore process, running transactions get nonrepeatable reads from the
restored data.  This means that the state of the data is inconsistent
while the restore is in progress.


File: manual.info.tmp,  Node: mysql-cluster-mysqld,  Next: mysql-cluster-rolling-restart,  Prev: mysql-cluster-backup,  Up: mysql-cluster-management

18.5.4 MySQL Server Usage for NDB Cluster
-----------------------------------------

*note 'mysqld': mysqld. is the traditional MySQL server process.  To be
used with NDB Cluster, *note 'mysqld': mysqld. needs to be built with
support for the *note 'NDB': mysql-cluster. storage engine, as it is in
the precompiled binaries available from
<https://dev.mysql.com/downloads/>.  If you build MySQL from source, you
must invoke 'CMake' with the '-DWITH_NDBCLUSTER=1' option to include
support for 'NDB'.

For more information about compiling NDB Cluster from source, see *note
mysql-cluster-install-linux-source::, and *note
mysql-cluster-install-windows-source::.

(For information about *note 'mysqld': mysqld. options and variables, in
addition to those discussed in this section, which are relevant to NDB
Cluster, see *note mysql-cluster-options-variables::.)

If the *note 'mysqld': mysqld. binary has been built with Cluster
support, the *note 'NDBCLUSTER': mysql-cluster. storage engine is still
disabled by default.  You can use either of two possible options to
enable this engine:

   * Use '--ndbcluster' as a startup option on the command line when
     starting *note 'mysqld': mysqld.

   * Insert a line containing 'ndbcluster' in the '[mysqld]' section of
     your 'my.cnf' file.

An easy way to verify that your server is running with the *note
'NDBCLUSTER': mysql-cluster. storage engine enabled is to issue the
*note 'SHOW ENGINES': show-engines. statement in the MySQL Monitor
(*note 'mysql': mysql.).  You should see the value 'YES' as the
'Support' value in the row for *note 'NDBCLUSTER': mysql-cluster.  If
you see 'NO' in this row or if there is no such row displayed in the
output, you are not running an *note 'NDB': mysql-cluster.-enabled
version of MySQL. If you see 'DISABLED' in this row, you need to enable
it in either one of the two ways just described.

To read cluster configuration data, the MySQL server requires at a
minimum three pieces of information:

   * The MySQL server's own cluster node ID

   * The host name or IP address for the management server (MGM node)

   * The number of the TCP/IP port on which it can connect to the
     management server

Node IDs can be allocated dynamically, so it is not strictly necessary
to specify them explicitly.

The *note 'mysqld': mysqld. parameter 'ndb-connectstring' is used to
specify the connection string either on the command line when starting
*note 'mysqld': mysqld. or in 'my.cnf'.  The connection string contains
the host name or IP address where the management server can be found, as
well as the TCP/IP port it uses.

In the following example, 'ndb_mgmd.mysql.com' is the host where the
management server resides, and the management server listens for cluster
messages on port 1186:

     shell> mysqld --ndbcluster --ndb-connectstring=ndb_mgmd.mysql.com:1186

See *note mysql-cluster-connection-strings::, for more information on
connection strings.

Given this information, the MySQL server will be a full participant in
the cluster.  (We often refer to a *note 'mysqld': mysqld. process
running in this manner as an SQL node.)  It will be fully aware of all
cluster data nodes as well as their status, and will establish
connections to all data nodes.  In this case, it is able to use any data
node as a transaction coordinator and to read and update node data.

You can see in the *note 'mysql': mysql. client whether a MySQL server
is connected to the cluster using *note 'SHOW PROCESSLIST':
show-processlist.  If the MySQL server is connected to the cluster, and
you have the 'PROCESS' privilege, then the first row of the output is as
shown here:

     mysql> SHOW PROCESSLIST \G
     *************************** 1. row ***************************
          Id: 1
        User: system user
        Host:
          db:
     Command: Daemon
        Time: 1
       State: Waiting for event from ndbcluster
        Info: NULL

*Important*:

To participate in an NDB Cluster, the *note 'mysqld': mysqld. process
must be started with _both_ the options '--ndbcluster' and
'--ndb-connectstring' (or their equivalents in 'my.cnf').  If *note
'mysqld': mysqld. is started with only the '--ndbcluster' option, or if
it is unable to contact the cluster, it is not possible to work with
*note 'NDB': mysql-cluster. tables, _nor is it possible to create any
new tables regardless of storage engine_.  The latter restriction is a
safety measure intended to prevent the creation of tables having the
same names as *note 'NDB': mysql-cluster. tables while the SQL node is
not connected to the cluster.  If you wish to create tables using a
different storage engine while the *note 'mysqld': mysqld. process is
not participating in an NDB Cluster, you must restart the server
_without_ the '--ndbcluster' option.


File: manual.info.tmp,  Node: mysql-cluster-rolling-restart,  Next: mysql-cluster-event-reports,  Prev: mysql-cluster-mysqld,  Up: mysql-cluster-management

18.5.5 Performing a Rolling Restart of an NDB Cluster
-----------------------------------------------------

This section discusses how to perform a _rolling restart_ of an NDB
Cluster installation, so called because it involves stopping and
starting (or restarting) each node in turn, so that the cluster itself
remains operational.  This is often done as part of a _rolling upgrade_
or _rolling downgrade_, where high availability of the cluster is
mandatory and no downtime of the cluster as a whole is permissible.
Where we refer to upgrades, the information provided here also generally
applies to downgrades as well.

There are a number of reasons why a rolling restart might be desirable.
These are described in the next few paragraphs.

Configuration change

To make a change in the cluster's configuration, such as adding an SQL
node to the cluster, or setting a configuration parameter to a new
value.

NDB Cluster software upgrade or downgrade

To upgrade the cluster to a newer version of the NDB Cluster software
(or to downgrade it to an older version).  This is usually referred to
as a 'rolling upgrade' (or 'rolling downgrade', when reverting to an
older version of NDB Cluster).

Change on node host

To make changes in the hardware or operating system on which one or more
NDB Cluster node processes are running.

System reset (cluster reset)

To reset the cluster because it has reached an undesirable state.  In
such cases it is often desirable to reload the data and metadata of one
or more data nodes.  This can be done in any of three ways:

   * Start each data node process (*note 'ndbd':
     mysql-cluster-programs-ndbd. or possibly *note 'ndbmtd':
     mysql-cluster-programs-ndbmtd.) with the '--initial' option, which
     forces the data node to clear its file system and to reload all NDB
     Cluster data and metadata from the other data nodes.

   * Create a backup using the *note 'ndb_mgm':
     mysql-cluster-programs-ndb-mgm. client *note 'START BACKUP':
     mysql-cluster-backup-using-management-client. command prior to
     performing the restart.  Following the upgrade, restore the node or
     nodes using *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore.

     See *note mysql-cluster-backup::, and *note
     mysql-cluster-programs-ndb-restore::, for more information.

   * Use *note 'mysqldump': mysqldump. to create a backup prior to the
     upgrade; afterward, restore the dump using *note 'LOAD DATA':
     load-data.

Resource Recovery

To free memory previously allocated to a table by successive *note
'INSERT': insert. and *note 'DELETE': delete. operations, for re-use by
other NDB Cluster tables.

The process for performing a rolling restart may be generalized as
follows:

  1. Stop all cluster management nodes (*note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. processes), reconfigure them, then
     restart them.  (See *note
     mysql-cluster-rolling-restart-multiple-ndb-mgmd::.)

  2. Stop, reconfigure, then restart each cluster data node (*note
     'ndbd': mysql-cluster-programs-ndbd. process) in turn.

     Some node configuration parameters can be updated by issuing
     'RESTART' for each of the data nodes in the *note 'ndb_mgm':
     mysql-cluster-programs-ndb-mgm. client following the previous step;
     others require that the data node be stopped completely using a
     shell command (such as *note 'kill': kill. on most Unix systems) or
     the management client 'STOP' command, then started again from a
     system shell by invoking the *note 'ndbd':
     mysql-cluster-programs-ndbd. or *note 'ndbmtd':
     mysql-cluster-programs-ndbmtd. executable as appropriate.

     *Note*:

     On Windows, you can also use 'SC STOP' and 'SC START' commands,
     'NET STOP' and 'NET START' commands, or the Windows Service Manager
     to stop and start nodes which have been installed as Windows
     services (see *note mysql-cluster-install-windows-service::).

     The type of restart required is indicated in the documentation for
     each node configuration parameter.  See *note
     mysql-cluster-config-file::.

  3. Stop, reconfigure, then restart each cluster SQL node (*note
     'mysqld': mysqld. process) in turn.

NDB Cluster supports a somewhat flexible order for upgrading nodes.
When upgrading an NDB Cluster, you may upgrade API nodes (including SQL
nodes) before upgrading the management nodes, data nodes, or both.  In
other words, you are permitted to upgrade the API and SQL nodes in any
order.  This is subject to the following provisions:

   * This functionality is intended for use as part of an online upgrade
     only.  A mix of node binaries from different NDB Cluster releases
     is neither intended nor supported for continuous, long-term use in
     a production setting.

   * All management nodes must be upgraded before any data nodes are
     upgraded.  This remains true regardless of the order in which you
     upgrade the cluster's API and SQL nodes.

   * Features specific to the 'new' version must not be used until all
     management nodes and data nodes have been upgraded.

     This also applies to any MySQL Server version change that may
     apply, in addition to the NDB engine version change, so do not
     forget to take this into account when planning the upgrade.  (This
     is true for online upgrades of NDB Cluster in general.)

It is not possible for any API node to perform schema operations (such
as data definition statements) during a node restart.  Due in part to
this limitation, schema operations are also not supported during an
online upgrade or downgrade.

Rolling restarts with multiple management servers

When performing a rolling restart of an NDB Cluster with multiple
management nodes, you should keep in mind that *note 'ndb_mgmd':
mysql-cluster-programs-ndb-mgmd. checks to see if any other management
node is running, and, if so, tries to use that node's configuration
data.  To keep this from occurring, and to force *note 'ndb_mgmd':
mysql-cluster-programs-ndb-mgmd. to reread its configuration file,
perform the following steps:

  1. Stop all NDB Cluster *note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. processes.

  2. Update all 'config.ini' files.

  3. Start a single *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd.
     with '--reload', '--initial', or both options as desired.

  4. If you started the first *note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. with the '--initial' option, you
     must also start any remaining *note 'ndb_mgmd':
     mysql-cluster-programs-ndb-mgmd. processes using '--initial'.

     Regardless of any other options used when starting the first *note
     'ndb_mgmd': mysql-cluster-programs-ndb-mgmd, you should not start
     any remaining *note 'ndb_mgmd': mysql-cluster-programs-ndb-mgmd.
     processes after the first one using '--reload'.

  5. Complete the rolling restarts of the data nodes and API nodes as
     normal.

When performing a rolling restart to update the cluster's configuration,
you can use the 'config_generation' column of the *note 'ndbinfo.nodes':
mysql-cluster-ndbinfo-nodes. table to keep track of which data nodes
have been successfully restarted with the new configuration.  See *note
mysql-cluster-ndbinfo-nodes::.


File: manual.info.tmp,  Node: mysql-cluster-event-reports,  Next: mysql-cluster-logs-ndb-messages,  Prev: mysql-cluster-rolling-restart,  Up: mysql-cluster-management

18.5.6 Event Reports Generated in NDB Cluster
---------------------------------------------

* Menu:

* mysql-cluster-logging-management-commands::  NDB Cluster Logging Management Commands
* mysql-cluster-log-events::     NDB Cluster Log Events
* mysql-cluster-log-statistics::  Using CLUSTERLOG STATISTICS in the NDB Cluster Management Client

In this section, we discuss the types of event logs provided by NDB
Cluster, and the types of events that are logged.

NDB Cluster provides two types of event log:

   * The _cluster log_, which includes events generated by all cluster
     nodes.  The cluster log is the log recommended for most uses
     because it provides logging information for an entire cluster in a
     single location.

     By default, the cluster log is saved to a file named
     'ndb_NODE_ID_cluster.log', (where NODE_ID is the node ID of the
     management server) in the management server's 'DataDir'.

     Cluster logging information can also be sent to 'stdout' or a
     'syslog' facility in addition to or instead of being saved to a
     file, as determined by the values set for the 'DataDir' and
     'LogDestination' configuration parameters.  See *note
     mysql-cluster-mgm-definition::, for more information about these
     parameters.

   * _Node logs_ are local to each node.

     Output generated by node event logging is written to the file
     'ndb_NODE_ID_out.log' (where NODE_ID is the node's node ID) in the
     node's 'DataDir'.  Node event logs are generated for both
     management nodes and data nodes.

     Node logs are intended to be used only during application
     development, or for debugging application code.

Both types of event logs can be set to log different subsets of events.

Each reportable event can be distinguished according to three different
criteria:

   * _Category_: This can be any one of the following values: 'STARTUP',
     'SHUTDOWN', 'STATISTICS', 'CHECKPOINT', 'NODERESTART',
     'CONNECTION', 'ERROR', or 'INFO'.

   * _Priority_: This is represented by one of the numbers from 0 to 15
     inclusive, where 0 indicates 'most important' and 15 'least
     important.'

   * _Severity Level_: This can be any one of the following values:
     'ALERT', 'CRITICAL', 'ERROR', 'WARNING', 'INFO', or 'DEBUG'.

Both the cluster log and the node log can be filtered on these
properties.

The format used in the cluster log is as shown here:

     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 1: Data usage is 2%(60 32K pages of total 2560)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 1: Index usage is 1%(24 8K pages of total 2336)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 1: Resource 0 min: 0 max: 639 curr: 0
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 2: Data usage is 2%(76 32K pages of total 2560)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 2: Index usage is 1%(24 8K pages of total 2336)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 2: Resource 0 min: 0 max: 639 curr: 0
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 3: Data usage is 2%(58 32K pages of total 2560)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 3: Index usage is 1%(25 8K pages of total 2336)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 3: Resource 0 min: 0 max: 639 curr: 0
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 4: Data usage is 2%(74 32K pages of total 2560)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 4: Index usage is 1%(25 8K pages of total 2336)
     2007-01-26 19:35:55 [MgmSrvr] INFO     -- Node 4: Resource 0 min: 0 max: 639 curr: 0
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 4: Node 9 Connected
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 1: Node 9 Connected
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 1: Node 9: API 5.5.65-ndb-7.2.39
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 2: Node 9 Connected
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 2: Node 9: API 5.5.65-ndb-7.2.39
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 3: Node 9 Connected
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 3: Node 9: API 5.5.65-ndb-7.2.39
     2007-01-26 19:39:42 [MgmSrvr] INFO     -- Node 4: Node 9: API 5.5.65-ndb-7.2.39
     2007-01-26 19:59:22 [MgmSrvr] ALERT    -- Node 2: Node 7 Disconnected
     2007-01-26 19:59:22 [MgmSrvr] ALERT    -- Node 2: Node 7 Disconnected

Each line in the cluster log contains the following information:

   * A timestamp in 'YYYY-MM-DD HH:MM:SS' format.

   * The type of node which is performing the logging.  In the cluster
     log, this is always '[MgmSrvr]'.

   * The severity of the event.

   * The ID of the node reporting the event.

   * A description of the event.  The most common types of events to
     appear in the log are connections and disconnections between
     different nodes in the cluster, and when checkpoints occur.  In
     some cases, the description may contain status information.


File: manual.info.tmp,  Node: mysql-cluster-logging-management-commands,  Next: mysql-cluster-log-events,  Prev: mysql-cluster-event-reports,  Up: mysql-cluster-event-reports

18.5.6.1 NDB Cluster Logging Management Commands
................................................

*note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. supports a number of
management commands related to the cluster log.  In the listing that
follows, NODE_ID denotes either a storage node ID or the keyword 'ALL',
which indicates that the command should be applied to all of the
cluster's data nodes.

   * 'CLUSTERLOG ON'

     Turns the cluster log on.

   * 'CLUSTERLOG OFF'

     Turns the cluster log off.

   * 'CLUSTERLOG INFO'

     Provides information about cluster log settings.

   * 'NODE_ID CLUSTERLOG CATEGORY=THRESHOLD'

     Logs CATEGORY events with priority less than or equal to THRESHOLD
     in the cluster log.

   * 'CLUSTERLOG FILTER SEVERITY_LEVEL'

     Toggles cluster logging of events of the specified SEVERITY_LEVEL.

The following table describes the default setting (for all data nodes)
of the cluster log category threshold.  If an event has a priority with
a value lower than or equal to the priority threshold, it is reported in
the cluster log.

*Note*:

Events are reported per data node, and that the threshold can be set to
different values on different nodes.

*Cluster log categories, with default threshold setting*

Category               Default threshold (All data nodes)
                       
'STARTUP'              *7*
                       
'SHUTDOWN'             *7*
                       
'STATISTICS'           *7*
                       
'CHECKPOINT'           *7*
                       
'NODERESTART'          *7*
                       
'CONNECTION'           *7*
                       
'ERROR'                *15*
                       
'INFO'                 *7*

The 'STATISTICS' category can provide a great deal of useful data.  See
*note mysql-cluster-log-statistics::, for more information.

Thresholds are used to filter events within each category.  For example,
a 'STARTUP' event with a priority of 3 is not logged unless the
threshold for 'STARTUP' is set to 3 or higher.  Only events with
priority 3 or lower are sent if the threshold is 3.

The following table shows the event severity levels.

*Note*:

These correspond to Unix 'syslog' levels, except for 'LOG_EMERG' and
'LOG_NOTICE', which are not used or mapped.

*Event severity levels*

Severity       Severity       Description
Level Value                   

*1*            'ALERT'        A condition that should be corrected
                              immediately, such as a corrupted system
                              database
                              
*2*            'CRITICAL'     Critical conditions, such as device
                              errors or insufficient resources
                              
*3*            'ERROR'        Conditions that should be corrected, such
                              as configuration errors
                              
*4*            'WARNING'      Conditions that are not errors, but that
                              might require special handling
                              
*5*            'INFO'         Informational messages
                              
*6*            'DEBUG'        Debugging messages used for
                              *note 'NDBCLUSTER': mysql-cluster.
                              development

Event severity levels can be turned on or off (using 'CLUSTERLOG
FILTER'--see above).  If a severity level is turned on, then all events
with a priority less than or equal to the category thresholds are
logged.  If the severity level is turned off then no events belonging to
that severity level are logged.

*Important*:

Cluster log levels are set on a per *note 'ndb_mgmd':
mysql-cluster-programs-ndb-mgmd, per subscriber basis.  This means that,
in an NDB Cluster with multiple management servers, using a 'CLUSTERLOG'
command in an instance of *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. connected to one management server
affects only logs generated by that management server but not by any of
the others.  This also means that, should one of the management servers
be restarted, only logs generated by that management server are affected
by the resetting of log levels caused by the restart.


File: manual.info.tmp,  Node: mysql-cluster-log-events,  Next: mysql-cluster-log-statistics,  Prev: mysql-cluster-logging-management-commands,  Up: mysql-cluster-event-reports

18.5.6.2 NDB Cluster Log Events
...............................

An event report reported in the event logs has the following format:

     DATETIME [STRING] SEVERITY -- MESSAGE

For example:

     09:19:30 2005-07-24 [NDB] INFO -- Node 4 Start phase 4 completed

This section discusses all reportable events, ordered by category and
severity level within each category.

In the event descriptions, GCP and LCP mean 'Global Checkpoint' and
'Local Checkpoint', respectively.

*CONNECTION Events*

These events are associated with connections between Cluster nodes.

*Events associated with connections between cluster nodes*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'Connected'               8       'INFO'  Data nodes connected
                                          
'Disconnected'            8       'ALERT' Data nodes disconnected
                                          
'CommunicationClosed'     8       'INFO'  SQL node or data node
                                          connection closed
                                          
'CommunicationOpened'     8       'INFO'  SQL node or data node
                                          connection open
                                          
'ConnectedApiVersion'     8       'INFO'  Connection using API version
                                  

*CHECKPOINT Events*

The logging messages shown here are associated with checkpoints.

*Events associated with checkpoints*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'GlobalCheckpointStarted' 9       'INFO'  Start of GCP: REDO log is
                                          written to disk
                                          
'GlobalCheckpointCompleted'10     'INFO'  GCP finished
                                          
'LocalCheckpointStarted'  7       'INFO'  Start of LCP: data written to
                                          disk
                                          
'LocalCheckpointCompleted'7       'INFO'  LCP completed normally
                                          
'LCPStoppedInCalcKeepGci' 0       'ALERT' LCP stopped
                                          
'LCPFragmentCompleted'    11      'INFO'  LCP on a fragment has been
                                          completed
                                          
'UndoLogBlocked'          7       'INFO'  UNDO logging blocked; buffer
                                          near overflow
                                          
'RedoStatus'              7       'INFO'  Redo status
                                  

*STARTUP Events*

The following events are generated in response to the startup of a node
or of the cluster and of its success or failure.  They also provide
information relating to the progress of the startup process, including
information concerning logging activities.

*Events relating to the startup of a node or cluster*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'NDBStartStarted'         1       'INFO'  Data node start phases
                                          initiated (all nodes starting)
                                          
'NDBStartCompleted'       1       'INFO'  Start phases completed, all
                                          data nodes
                                          
'STTORRYRecieved'         15      'INFO'  Blocks received after
                                          completion of restart
                                          
'StartPhaseCompleted'     4       'INFO'  Data node start phase X
                                          completed
                                          
'CM_REGCONF'              3       'INFO'  Node has been successfully
                                          included into the cluster;
                                          shows the node, managing node,
                                          and dynamic ID
                                          
'CM_REGREF'               8       'INFO'  Node has been refused for
                                          inclusion in the cluster;
                                          cannot be included in cluster
                                          due to misconfiguration,
                                          inability to establish
                                          communication, or other
                                          problem
                                          
'FIND_NEIGHBOURS'         8       'INFO'  Shows neighboring data nodes
                                          
'NDBStopStarted'          1       'INFO'  Data node shutdown initiated
                                          
'NDBStopCompleted'        1       'INFO'  Data node shutdown complete
                                          
'NDBStopForced'           1       'ALERT' Forced shutdown of data node
                                          
'NDBStopAborted'          1       'INFO'  Unable to shut down data node
                                          normally
                                          
'StartREDOLog'            4       'INFO'  New redo log started; GCI keep
                                          X, newest restorable GCI Y
                                          
'StartLog'                10      'INFO'  New log started; log part X,
                                          start MB Y, stop MB Z
                                          
'UNDORecordsExecuted'     15      'INFO'  Undo records executed
                                          
'StartReport'             4       'INFO'  Report started
                                          
'LogFileInitStatus'       7       'INFO'  Log file initialization status
                                          
'LogFileInitCompStatus'   7       'INFO'  Log file completion status
                                          
'StartReadLCP'            10      'INFO'  Start read for local
                                          checkpoint
                                          
'ReadLCPComplete'         10      'INFO'  Read for local checkpoint
                                          completed
                                          
'RunRedo'                 8       'INFO'  Running the redo log
                                          
'RebuildIndex'            10      'INFO'  Rebuilding indexes
                                  

*NODERESTART Events*

The following events are generated when restarting a node and relate to
the success or failure of the node restart process.

*Events relating to restarting a node*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'NR_CopyDict'             7       'INFO'  Completed copying of
                                          dictionary information
                                          
'NR_CopyDistr'            7       'INFO'  Completed copying distribution
                                          information
                                          
'NR_CopyFragsStarted'     7       'INFO'  Starting to copy fragments
                                          
'NR_CopyFragDone'         10      'INFO'  Completed copying a fragment
                                          
'NR_CopyFragsCompleted'   7       'INFO'  Completed copying all
                                          fragments
                                          
'NodeFailCompleted'       8       'ALERT' Node failure phase completed
                                          
'NODE_FAILREP'            8       'ALERT' Reports that a node has failed
                                          
'ArbitState'              6       'INFO'  Report whether an arbitrator
                                          is found or not; there are
                                          seven different possible
                                          outcomes when seeking an
                                          arbitrator, listed here:
                                          
                                             * Management server
                                               restarts arbitration
                                               thread [state=X]
                                          
                                             * Prepare arbitrator node X
                                               [ticket=Y]
                                          
                                             * Receive arbitrator node X
                                               [ticket=Y]
                                          
                                             * Started arbitrator node X
                                               [ticket=Y]
                                          
                                             * Lost arbitrator node X -
                                               process failure [state=Y]
                                          
                                             * Lost arbitrator node X -
                                               process exit [state=Y]
                                          
                                             * Lost arbitrator node X
                                               <error msg> [state=Y]
                                          
'ArbitResult'             2       'ALERT' Report arbitrator results;
                                          there are eight different
                                          possible results for
                                          arbitration attempts, listed
                                          here:
                                          
                                             * Arbitration check failed:
                                               less than 1/2 nodes left
                                          
                                             * Arbitration check
                                               succeeded: node group
                                               majority
                                          
                                             * Arbitration check failed:
                                               missing node group
                                          
                                             * Network partitioning:
                                               arbitration required
                                          
                                             * Arbitration succeeded:
                                               affirmative response from
                                               node X
                                          
                                             * Arbitration failed:
                                               negative response from
                                               node X
                                          
                                             * Network partitioning: no
                                               arbitrator available
                                          
                                             * Network partitioning: no
                                               arbitrator configured
                                          
'GCP_TakeoverStarted'     7       'INFO'  GCP takeover started
                                          
'GCP_TakeoverCompleted'   7       'INFO'  GCP takeover complete
                                          
'LCP_TakeoverStarted'     7       'INFO'  LCP takeover started
                                          
'LCP_TakeoverCompleted'   7       'INFO'  LCP takeover complete (state =
                                          X)
                                          
'ConnectCheckStarted'     6       'INFO'  Connection check started
                                          
'ConnectCheckCompleted'   6       'INFO'  Connection check completed
                                          
'NodeFailRejected'        6       'ALERT' Node failure phase failed
                                  

*STATISTICS Events*

The following events are of a statistical nature.  They provide
information such as numbers of transactions and other operations, amount
of data sent or received by individual nodes, and memory usage.

*Events of a statistical nature*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'TransReportCounters'     8       'INFO'  Report transaction statistics,
                                          including numbers of
                                          transactions, commits, reads,
                                          simple reads, writes,
                                          concurrent operations,
                                          attribute information, and
                                          aborts
                                          
'OperationReportCounters' 8       'INFO'  Number of operations
                                          
'TableCreated'            7       'INFO'  Report number of tables
                                          created
                                          
'JobStatistic'            9       'INFO'  Mean internal job scheduling
                                          statistics
                                          
'ThreadConfigLoop'        9       'INFO'  Number of thread configuration
                                          loops
                                          
'SendBytesStatistic'      9       'INFO'  Mean number of bytes sent to
                                          node X
                                          
'ReceiveBytesStatistic'   9       'INFO'  Mean number of bytes received
                                          from node X
                                          
'MemoryUsage'             5       'INFO'  Data and index memory usage
                                          (80%, 90%, and 100%)
                                          
'MTSignalStatistics'      9       'INFO'  Multithreaded signals
                                  

*SCHEMA Events*

These events relate to NDB Cluster schema operations.

*Events relating to NDB Cluster schema operations*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'CreateSchemaObject'      8       'INFO'  Schema objected created
                                          
'AlterSchemaObject'       8       'INFO'  Schema object updated
                                          
'DropSchemaObject'        8       'INFO'  Schema object dropped
                                  

*ERROR Events*

These events relate to Cluster errors and warnings.  The presence of one
or more of these generally indicates that a major malfunction or failure
has occurred.

*Events relating to cluster errors and warnings*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'TransporterError'        2       'ERROR' Transporter error
                                          
'TransporterWarning'      8       'WARNING'Transporter warning
                                          
'MissedHeartbeat'         8       'WARNING'Node X missed heartbeat number
                                          Y
                                          
'DeadDueToHeartbeat'      8       'ALERT' Node X declared 'dead' due to
                                          missed heartbeat
                                          
'WarningEvent'            2       'WARNING'General warning event
                                          
'SubscriptionStatus'      4       'WARNING'Change in subscription status
                                  

*INFO Events*

These events provide general information about the state of the cluster
and activities associated with Cluster maintenance, such as logging and
heartbeat transmission.

*Information events*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'SentHeartbeat'           12      'INFO'  Sent heartbeat
                                          
'CreateLogBytes'          11      'INFO'  Create log: Log part, log
                                          file, size in MB
                                          
'InfoEvent'               2       'INFO'  General informational event
                                          
'EventBufferStatus'       7       'INFO'  Event buffer status
                                  

*Note*:

'SentHeartbeat' events are available only if NDB Cluster was compiled
with 'VM_TRACE' enabled.

*SINGLEUSER Events*

These events are associated with entering and exiting single user mode.

*Events relating to single user mode*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'SingleUser'              7       'INFO'  Entering or exiting single
                                          user mode

*BACKUP Events*

These events provide information about backups being created or
restored.

*Backup events*

Event                     PrioritySeverityDescription
                                  Level   
                                  
'BackupStarted'           7       'INFO'  Backup started
                                          
'BackupStatus'            7       'INFO'  Backup status
                                          
'BackupCompleted'         7       'INFO'  Backup completed
                                          
'BackupFailedToStart'     7       'ALERT' Backup failed to start
                                          
'BackupAborted'           7       'ALERT' Backup aborted by user
                                          
'RestoreStarted'          7       'INFO'  Started restoring from backup
                                          
'RestoreMetaData'         7       'INFO'  Restoring metadata
                                          
'RestoreData'             7       'INFO'  Restoring data
                                          
'RestoreLog'              7       'INFO'  Restoring log files
                                          
'RestoreCompleted'        7       'INFO'  Completed restoring from
                                          backup
                                          
'SavedEvent'              7       'INFO'  Event saved
                                  


File: manual.info.tmp,  Node: mysql-cluster-log-statistics,  Prev: mysql-cluster-log-events,  Up: mysql-cluster-event-reports

18.5.6.3 Using CLUSTERLOG STATISTICS in the NDB Cluster Management Client
.........................................................................

The *note 'NDB': mysql-cluster. management client's *note 'CLUSTERLOG
STATISTICS': mysql-cluster-logging-management-commands. command can
provide a number of useful statistics in its output.  Counters providing
information about the state of the cluster are updated at 5-second
reporting intervals by the transaction coordinator (TC) and the local
query handler (LQH), and written to the cluster log.

Transaction coordinator statistics

Each transaction has one transaction coordinator, which is chosen by one
of the following methods:

   * In a round-robin fashion

   * By communication proximity

   * By supplying a data placement hint when the transaction is started

*Note*:

You can determine which TC selection method is used for transactions
started from a given SQL node using the 'ndb_optimized_node_selection'
system variable.

All operations within the same transaction use the same transaction
coordinator, which reports the following statistics:

   * Trans count

     This is the number transactions started in the last interval using
     this TC as the transaction coordinator.  Any of these transactions
     may have committed, have been aborted, or remain uncommitted at the
     end of the reporting interval.

     *Note*:

     Transactions do not migrate between TCs.

   * Commit count

     This is the number of transactions using this TC as the transaction
     coordinator that were committed in the last reporting interval.
     Because some transactions committed in this reporting interval may
     have started in a previous reporting interval, it is possible for
     'Commit count' to be greater than 'Trans count'.

   * Read count

     This is the number of primary key read operations using this TC as
     the transaction coordinator that were started in the last reporting
     interval, including simple reads.  This count also includes reads
     performed as part of unique index operations.  A unique index read
     operation generates 2 primary key read operations--1 for the hidden
     unique index table, and 1 for the table on which the read takes
     place.

   * Simple read count

     This is the number of simple read operations using this TC as the
     transaction coordinator that were started in the last reporting
     interval.

   * Write count

     This is the number of primary key write operations using this TC as
     the transaction coordinator that were started in the last reporting
     interval.  This includes all inserts, updates, writes and deletes,
     as well as writes performed as part of unique index operations.

     *Note*:

     A unique index update operation can generate multiple PK read and
     write operations on the index table and on the base table.

   * AttrInfoCount

     This is the number of 32-bit data words received in the last
     reporting interval for primary key operations using this TC as the
     transaction coordinator.  For reads, this is proportional to the
     number of columns requested.  For inserts and updates, this is
     proportional to the number of columns written, and the size of
     their data.  For delete operations, this is usually zero.

     Unique index operations generate multiple PK operations and so
     increase this count.  However, data words sent to describe the PK
     operation itself, and the key information sent, are _not_ counted
     here.  Attribute information sent to describe columns to read for
     scans, or to describe ScanFilters, is also not counted in
     'AttrInfoCount'.

   * Concurrent Operations

     This is the number of primary key or scan operations using this TC
     as the transaction coordinator that were started during the last
     reporting interval but that were not completed.  Operations
     increment this counter when they are started and decrement it when
     they are completed; this occurs after the transaction commits.
     Dirty reads and writes--as well as failed operations--decrement
     this counter.

     The maximum value that 'Concurrent Operations' can have is the
     maximum number of operations that a TC block can support;
     currently, this is '(2 * MaxNoOfConcurrentOperations) + 16 +
     MaxNoOfConcurrentTransactions'.  (For more information about these
     configuration parameters, see the 'Transaction Parameters' section
     of *note mysql-cluster-ndbd-definition::.)

   * Abort count

     This is the number of transactions using this TC as the transaction
     coordinator that were aborted during the last reporting interval.
     Because some transactions that were aborted in the last reporting
     interval may have started in a previous reporting interval, 'Abort
     count' can sometimes be greater than 'Trans count'.

   * Scans

     This is the number of table scans using this TC as the transaction
     coordinator that were started during the last reporting interval.
     This does not include range scans (that is, ordered index scans).

   * Range scans

     This is the number of ordered index scans using this TC as the
     transaction coordinator that were started in the last reporting
     interval.

   * Local reads

     This is the number of primary-key read operations performed using a
     transaction coordinator on a node that also holds the primary
     replica of the record.  This count can also be obtained from the
     'LOCAL_READS' counter in the *note 'ndbinfo.counters':
     mysql-cluster-ndbinfo-counters. table.

   * Local writes

     This contains the number of primary-key read operations that were
     performed using a transaction coordinator on a node that also holds
     the primary replica of the record.  This count can also be obtained
     from the 'LOCAL_WRITES' counter in the *note 'ndbinfo.counters':
     mysql-cluster-ndbinfo-counters. table.

Local query handler statistics (Operations)

There is 1 cluster event per local query handler block (that is, 1 per
data node process).  Operations are recorded in the LQH where the data
they are operating on resides.

*Note*:

A single transaction may operate on data stored in multiple LQH blocks.

The 'Operations' statistic provides the number of local operations
performed by this LQH block in the last reporting interval, and includes
all types of read and write operations (insert, update, write, and
delete operations).  This also includes operations used to replicate
writes.  For example, in a 2-replica cluster, the write to the primary
replica is recorded in the primary LQH, and the write to the backup will
be recorded in the backup LQH. Unique key operations may result in
multiple local operations; however, this does _not_ include local
operations generated as a result of a table scan or ordered index scan,
which are not counted.

Process scheduler statistics

In addition to the statistics reported by the transaction coordinator
and local query handler, each *note 'ndbd': mysql-cluster-programs-ndbd.
process has a scheduler which also provides useful metrics relating to
the performance of an NDB Cluster.  This scheduler runs in an infinite
loop; during each loop the scheduler performs the following tasks:

  1. Read any incoming messages from sockets into a job buffer.

  2. Check whether there are any timed messages to be executed; if so,
     put these into the job buffer as well.

  3. Execute (in a loop) any messages in the job buffer.

  4. Send any distributed messages that were generated by executing the
     messages in the job buffer.

  5. Wait for any new incoming messages.

Process scheduler statistics include the following:

   * Mean Loop Counter

     This is the number of loops executed in the third step from the
     preceding list.  This statistic increases in size as the
     utilization of the TCP/IP buffer improves.  You can use this to
     monitor changes in performance as you add new data node processes.

   * Mean send size and Mean receive size

     These statistics enable you to gauge the efficiency of,
     respectively writes and reads between nodes.  The values are given
     in bytes.  Higher values mean a lower cost per byte sent or
     received; the maximum value is 64K.

To cause all cluster log statistics to be logged, you can use the
following command in the *note 'NDB': mysql-cluster. management client:

     ndb_mgm> ALL CLUSTERLOG STATISTICS=15

*Note*:

Setting the threshold for 'STATISTICS' to 15 causes the cluster log to
become very verbose, and to grow quite rapidly in size, in direct
proportion to the number of cluster nodes and the amount of activity in
the NDB Cluster.

For more information about NDB Cluster management client commands
relating to logging and reporting, see *note
mysql-cluster-logging-management-commands::.


File: manual.info.tmp,  Node: mysql-cluster-logs-ndb-messages,  Next: mysql-cluster-single-user-mode,  Prev: mysql-cluster-event-reports,  Up: mysql-cluster-management

18.5.7 NDB Cluster Log Messages
-------------------------------

* Menu:

* mysql-cluster-logs-cluster-log::  NDB Cluster: Messages in the Cluster Log
* mysql-cluster-log-startup-messages::  NDB Cluster Log Startup Messages
* mysql-cluster-ndb-transporter-errors::  NDB Cluster: NDB Transporter Errors

This section contains information about the messages written to the
cluster log in response to different cluster log events.  It provides
additional, more specific information on *note 'NDB': mysql-cluster.
transporter errors.


File: manual.info.tmp,  Node: mysql-cluster-logs-cluster-log,  Next: mysql-cluster-log-startup-messages,  Prev: mysql-cluster-logs-ndb-messages,  Up: mysql-cluster-logs-ndb-messages

18.5.7.1 NDB Cluster: Messages in the Cluster Log
.................................................

The following table lists the most common *note 'NDB': mysql-cluster.
cluster log messages.  For information about the cluster log, log
events, and event types, see *note mysql-cluster-event-reports::.  These
log messages also correspond to log event types in the MGM API; see The
Ndb_logevent_type Type
(https://dev.mysql.com/doc/ndbapi/en/mgm-ndb-logevent-type.html), for
related information of interest to Cluster API developers.

*Common NDB cluster log messages*

Log Message    Description    Event Name         Event       PrioritySeverity
                                                 Type                
                                                 
'Node          The data       'Connected'        'Connection'8       'INFO'
MGM_NODE_ID:   node having                                           
Node           node ID
DATA_NODE_ID   NODE_ID has
Connected'     connected to
               the
               management
               server (node
               MGM_NODE_ID).
               
'Node          The data       'Disconnected'     'Connection'8       'ALERT'
MGM_NODE_ID:   node having                                           
Node           node ID
DATA_NODE_ID   DATA_NODE_ID
Disconnected'  has
               disconnected
               from the
               management
               server (node
               MGM_NODE_ID).
               
'Node          The API node   'CommunicationClosed''Connection'8     'INFO'
DATA_NODE_ID:  or SQL node                                           
Communication  having node
to Node        ID
API_NODE_ID    API_NODE_ID
closed'        is no longer
               communicating
               with data
               node
               DATA_NODE_ID.
               
'Node          The API node   'CommunicationOpened''Connection'8     'INFO'
DATA_NODE_ID:  or SQL node                                           
Communication  having node
to Node        ID
API_NODE_ID    API_NODE_ID
opened'        is now
               communicating
               with data
               node
               DATA_NODE_ID.
               
'Node          The API node   'ConnectedApiVersion''Connection'8     'INFO'
MGM_NODE_ID:   having node                                           
Node           ID
API_NODE_ID:   API_NODE_ID
API VERSION'   has
               connected to
               management
               node
               MGM_NODE_ID
               using
               *note 'NDB': mysql-cluster.
               API version
               VERSION
               (generally
               the same as
               the MySQL
               version
               number).
               
'Node          A global       'GlobalCheckpointStarted''Checkpoint'9 'INFO'
NODE_ID:       checkpoint                                            
Global         with the ID
checkpoint     GCI has been
GCI started'   started;
               node NODE_ID
               is the
               master
               responsible
               for this
               global
               checkpoint.
               
'Node          The global     'GlobalCheckpointCompleted''Checkpoint'10'INFO'
NODE_ID:       checkpoint                                            
Global         having the
checkpoint     ID GCI has
GCI            been
completed'     completed;
               node NODE_ID
               was the
               master
               responsible
               for this
               global
               checkpoint.
               
'Node          The local      'LocalCheckpointStarted''Checkpoint'7  'INFO'
NODE_ID:       checkpoint                                            
Local          having
checkpoint     sequence ID
LCP started.   LCP has been
Keep GCI =     started on
CURRENT_GCI    node
oldest         NODE_ID.
restorable     The most
GCI =          recent GCI
OLD_GCI'       that can be
               used has the
               index
               CURRENT_GCI,
               and the
               oldest GCI
               from which
               the cluster
               can be
               restored has
               the index
               OLD_GCI.
               
'Node          The local      'LocalCheckpointCompleted''Checkpoint'8'INFO'
NODE_ID:       checkpoint                                            
Local          having
checkpoint     sequence ID
LCP            LCP on node
completed'     NODE_ID has
               been
               completed.
               
'Node          The node was   'LCPStoppedInCalcKeepGci''Checkpoint'0 'ALERT'
NODE_ID:       unable to                                             
Local          determine
Checkpoint     the most
stopped in     recent
CALCULATED_KEEP_GCI'usable GCI.
               
'Node          A table        'LCPFragmentCompleted''Checkpoint'11   'INFO'
NODE_ID:       fragment has                                          
Table ID =     been
TABLE_ID,      checkpointed
fragment ID    to disk on
=              node
FRAGMENT_ID    NODE_ID.
has            The GCI in
completed      progress has
LCP on Node    the index
NODE_ID        STARTED_GCI,
maxGciStarted: and the most
STARTED_GCI    recent GCI
maxGciCompleted:to have been
COMPLETED_GCI' completed
               has the
               index
               COMPLETED_GCI.
               
'Node          Undo logging   'UndoLogBlocked'   'Checkpoint'7       'INFO'
NODE_ID: ACC   is blocked                                            
Blocked        because the
NUM_1 and      log buffer
TUP Blocked    is close to
NUM_2 times    overflowing.
last second'   

'Node          Data node      'NDBStartStarted'  'StartUp'   1       'INFO'
NODE_ID:       NODE_ID,                                              
Start          running
initiated      *note 'NDB': mysql-cluster.
VERSION'       version
               VERSION, is
               beginning
               its startup
               process.
               
'Node          Data node      'NDBStartCompleted''StartUp'   1       'INFO'
NODE_ID:       NODE_ID,                                              
Started        running
VERSION'       *note 'NDB': mysql-cluster.
               version
               VERSION, has
               started
               successfully.
               
'Node          The node has   'STTORRYRecieved'  'StartUp'   15      'INFO'
NODE_ID:       received a                                            
STTORRY        signal
received       indicating
after          that a
restart        cluster
finished'      restart has
               completed.
               
'Node          The node has   'StartPhaseCompleted''StartUp' 4       'INFO'
NODE_ID:       completed                                             
Start phase    start phase
PHASE          PHASE of a
completed      TYPE start.
(TYPE)'        For a
               listing of
               start
               phases, see
               *note mysql-cluster-start-phases::.
               (TYPE is one
               of
               'initial',
               'system',
               'node',
               'initial
               node', or
               '<Unknown>'.)
               
'Node          Node           'CM_REGCONF'       'StartUp'   3       'INFO'
NODE_ID:       PRESIDENT_ID                                          
CM_REGCONF     has been
president =    selected as
PRESIDENT_ID,  'president'.
own Node =     OWN_ID and
OWN_ID, our    DYNAMIC_ID
dynamic id =   should
DYNAMIC_ID'    always be
               the same as
               the ID
               (NODE_ID) of
               the
               reporting
               node.
               
'Node          The            'CM_REGREF'        'StartUp'   8       'INFO'
NODE_ID:       reporting                                             
CM_REGREF      node (ID
from Node      NODE_ID) was
PRESIDENT_ID   unable to
to our Node    accept node
NODE_ID.       PRESIDENT_ID
Cause =        as
CAUSE'         president.
               The CAUSE of
               the problem
               is given as
               one of
               'Busy',
               'Election
               with wait =
               false', 'Not
               president',
               'Election
               without
               selecting
               new
               candidate',
               or 'No such
               cause'.
               
'Node          The node has   'FIND_NEIGHBOURS'  'StartUp'   8       'INFO'
NODE_ID: We    discovered                                            
are Node       its
OWN_ID with    neighboring
dynamic ID     nodes in the
DYNAMIC_ID,    cluster
our left       (node ID_1
neighbor is    and node
Node ID_1,     ID_2).
our right is   NODE_ID,
Node ID_2'     OWN_ID, and
               DYNAMIC_ID
               should
               always be
               the same; if
               they are
               not, this
               indicates a
               serious
               misconfiguration
               of the
               cluster
               nodes.
               
'Node          The node has   'NDBStopStarted'   'StartUp'   1       'INFO'
NODE_ID:       received a                                            
TYPE           shutdown
shutdown       signal.  The
initiated'     TYPE of
               shutdown is
               either
               'Cluster' or
               'Node'.
               
'Node          The node has   'NDBStopCompleted' 'StartUp'   1       'INFO'
NODE_ID:       been shut                                             
Node           down.  This
shutdown       report may
completed      include an
'[',           ACTION,
ACTION']       which if
['Initiated    present is
by signal      one of
SIGNAL.']      'restarting',
               'no start',
               or
               'initial'.
               The report
               may also
               include a
               reference to
               an
               *note 'NDB': mysql-cluster.
               Protocol
               SIGNAL; for
               possible
               signals,
               refer to
               Operations
               and Signals
               (https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-ndb-protocol-operations-signals.html).
               
'Node          The node has   'NDBStopForced'    'StartUp'   1       'ALERT'
NODE_ID:       been                                                  
Forced node    forcibly
shutdown       shut down.
completed      The ACTION
'[',           (one of
action']'.'    'restarting',
['Occurred     'no start',
during         or
startphase     'initial')
START_PHASE.'] subsequently
[' Initiated   being taken,
by SIGNAL.']   if any, is
['Caused by    also
error          reported.
ERROR_CODE:    If the
'ERROR_MESSAGE(ERROR_CLASSIFICATION).shutdown
ERROR_STATUS'.'occurred
['(extra       while the
info           node was
EXTRA_CODE)']] starting,
               the report
               includes the
               START_PHASE
               during which
               the node
               failed.  If
               this was a
               result of a
               SIGNAL sent
               to the node,
               this
               information
               is also
               provided
               (see
               Operations
               and Signals
               (https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-ndb-protocol-operations-signals.html),
               for more
               information).
               If the error
               causing the
               failure is
               known, this
               is also
               included;
               for more
               information
               about
               *note 'NDB': mysql-cluster.
               error
               messages and
               classifications,
               see NDB
               Cluster API
               Errors
               (https://dev.mysql.com/doc/ndb-internals/en/ndb-errors.html).
               
'Node          The node       'NDBStopAborted'   'StartUp'   1       'INFO'
NODE_ID:       shutdown                                              
Node           process was
shutdown       aborted by
aborted'       the user.
               
'Node          This reports   'StartREDOLog'     'StartUp'   4       'INFO'
NODE_ID:       global                                                
StartLog:      checkpoints
[GCI Keep:     referenced
KEEP_POS       during a
LastCompleted: node start.
LAST_POS       The redo log
NewestRestorable:prior to
RESTORE_POS]'  KEEP_POS is
               dropped.
               LAST_POS is
               the last
               global
               checkpoint
               in which
               data node
               the
               participated;
               RESTORE_POS
               is the
               global
               checkpoint
               which is
               actually
               used to
               restore all
               data nodes.
               
STARTUP_MESSAGEThere are a    'StartReport'      'StartUp'   4       'INFO'
[_Listed       number of                                             
separately;    possible
see below._]   startup
               messages
               that can be
               logged under
               different
               circumstances.
               These are
               listed
               separately;
               see
               *note mysql-cluster-log-startup-messages::.
               
'Node          Copying of     'NR_CopyDict'      'NodeRestart'8      'INFO'
NODE_ID:       data                                                  
Node restart   dictionary
completed      information
copy of        to the
dictionary     restarted
information'   node has
               been
               completed.
               
'Node          Copying of     'NR_CopyDistr'     'NodeRestart'8      'INFO'
NODE_ID:       data                                                  
Node restart   distribution
completed      information
copy of        to the
distribution   restarted
information'   node has
               been
               completed.
               
'Node          Copy of        'NR_CopyFragsStarted''NodeRestart'8    'INFO'
NODE_ID:       fragments to                                          
Node restart   starting
starting to    data node
copy the       NODE_ID has
fragments to   begun
Node           
NODE_ID'

'Node          Fragment       'NR_CopyFragDone'  'NodeRestart'10     'INFO'
NODE_ID:       FRAGMENT_ID                                           
Table ID =     from table
TABLE_ID,      TABLE_ID has
fragment ID    been copied
=              to data node
FRAGMENT_ID    NODE_ID
have been      
copied to
Node
NODE_ID'

'Node          Copying of     'NR_CopyFragsCompleted''NodeRestart'8  'INFO'
NODE_ID:       all table                                             
Node restart   fragments to
completed      restarting
copying the    data node
fragments to   NODE_ID has
Node           been
NODE_ID'       completed
               
'Node          Data node      'NodeFailCompleted''NodeRestart'8      'ALERT'
NODE_ID:       NODE1_ID has                                          
Node           detected the
NODE1_ID       failure of
completed      data node
failure of     NODE2_ID
Node           
NODE2_ID'

'All nodes     All            'NodeFailCompleted''NodeRestart'8      'ALERT'
completed      (remaining)                                           
failure of     data nodes
Node           have
NODE_ID'       detected the
               failure of
               data node
               NODE_ID
               
'Node          The failure    'NodeFailCompleted''NodeRestart'8      'ALERT'
failure of     of data node                                          
NODE_IDBLOCK   NODE_ID has
completed'     been
               detected in
               the
               BLOCK*note 'NDB': mysql-cluster.
               kernel
               block, where
               block is 1
               of 'DBTC',
               'DBDICT',
               'DBDIH', or
               'DBLQH'; for
               more
               information,
               see NDB
               Kernel
               Blocks
               (https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks.html)
               
'Node          A data node    'NODE_FAILREP'     'NodeRestart'8      'ALERT'
MGM_NODE_ID:   has failed.                                           
Node           Its state at
DATA_NODE_ID   the time of
has failed.    failure is
The Node       described by
state at       an
failure was    arbitration
STATE_CODE'    state code
               STATE_CODE:
               possible
               state code
               values can
               be found in
               the file
               'include/kernel/signaldata/ArbitSignalData.hpp'.
               
'President     This is a      'ArbitState'       'NodeRestart'6      'INFO'
restarts       report on                                             
arbitration    the current
thread         state and
[state=STATE_CODE]'progress of
or 'Prepare    arbitration
arbitrator     in the
node NODE_ID   cluster.
[ticket=TICKET_ID]'NODE_ID is
or 'Receive    the node ID
arbitrator     of the
node NODE_ID   management
[ticket=TICKET_ID]'node or SQL
or 'Started    node
arbitrator     selected as
node NODE_ID   the
[ticket=TICKET_ID]'arbitrator.
or 'Lost       STATE_CODE
arbitrator     is an
node NODE_ID   arbitration
- process      state code,
failure        as found in
[state=STATE_CODE]''include/kernel/signaldata/ArbitSignalData.hpp'.
or 'Lost       When an
arbitrator     error has
node NODE_ID   occurred, an
- process      ERROR_MESSAGE,
exit           also defined
[state=STATE_CODE]'in
or 'Lost       'ArbitSignalData.hpp',
arbitrator     is provided.
node NODE_ID   TICKET_ID is
-              a unique
ERROR_MESSAGE  identifier
[state=STATE_CODE]'handed out
               by the
               arbitrator
               when it is
               selected to
               all the
               nodes that
               participated
               in its
               selection;
               this is used
               to ensure
               that each
               node
               requesting
               arbitration
               was one of
               the nodes
               that took
               part in the
               selection
               process.
               
'Arbitration   This message   'ArbitResult'      'NodeRestart'2      'ALERT'
check lost -   reports on                                            
less than      the result
1/2 nodes      of
left' or       arbitration.
'Arbitration   In the event
check won -    of
all node       arbitration
groups and     failure, an
more than      ERROR_MESSAGE
1/2 nodes      and an
left' or       arbitration
'Arbitration   STATE_CODE
check won -    are
node group     provided;
majority' or   definitions
'Arbitration   for both of
check lost -   these are
missing node   found in
group' or      'include/kernel/signaldata/ArbitSignalData.hpp'.
'Network       
partitioning
-
arbitration
required' or
'Arbitration
won -
positive
reply from
node
NODE_ID' or
'Arbitration
lost -
negative
reply from
node
NODE_ID' or
'Network
partitioning
- no
arbitrator
available'
or 'Network
partitioning
- no
arbitrator
configured'
or
'Arbitration
failure -
ERROR_MESSAGE
[state=STATE_CODE]'

'Node          This node is   'GCP_TakeoverStarted''NodeRestart'7    'INFO'
NODE_ID: GCP   attempting                                            
Take over      to assume
started'       responsibility
               for the next
               global
               checkpoint
               (that is, it
               is becoming
               the master
               node)
               
'Node          This node      'GCP_TakeoverCompleted''NodeRestart'7  'INFO'
NODE_ID: GCP   has become                                            
Take over      the master,
completed'     and has
               assumed
               responsibility
               for the next
               global
               checkpoint
               
'Node          This node is   'LCP_TakeoverStarted''NodeRestart'7    'INFO'
NODE_ID: LCP   attempting                                            
Take over      to assume
started'       responsibility
               for the next
               set of local
               checkpoints
               (that is, it
               is becoming
               the master
               node)
               
'Node          This node      'LCP_TakeoverCompleted''NodeRestart'7  'INFO'
NODE_ID: LCP   has become                                            
Take over      the master,
completed'     and has
               assumed
               responsibility
               for the next
               set of local
               checkpoints
               
'Node          This report    'TransReportCounters''Statistic'8      'INFO'
NODE_ID:       of                                                    
Trans. Count   transaction
=              activity is
TRANSACTIONS,  given
Commit Count   approximately
= COMMITS,     once every
Read Count =   10 seconds
READS,         
Simple Read
Count =
SIMPLE_READS,
Write Count
= WRITES,
AttrInfo
Count =
ATTRINFO_OBJECTS,
Concurrent
Operations =
CONCURRENT_OPERATIONS,
Abort Count
= ABORTS,
Scans =
SCANS, Range
scans =
RANGE_SCANS'

'Node          Number of      'OperationReportCounters''Statistic'8  'INFO'
NODE_ID:       operations                                            
Operations=OPERATIONS'performed by
               this node,
               provided
               approximately
               once every
               10 seconds
               
'Node          A table        'TableCreated'     'Statistic' 7       'INFO'
NODE_ID:       having the                                            
Table with     table ID
ID =           shown has
TABLE_ID       been created
created'       

'Node                         'JobStatistic'     'Statistic' 9       'INFO'
NODE_ID:                                                             
Mean loop
Counter in
doJob last
8192 times =
COUNT'

'Mean send     This node is   'SendBytesStatistic''Statistic'9       'INFO'
size to Node   sending an                                            
= NODE_ID      average of
last 4096      BYTES bytes
sends =        per send to
BYTES bytes'   node NODE_ID
               
'Mean          This node is   'ReceiveBytesStatistic''Statistic'9    'INFO'
receive size   receiving an                                          
to Node =      average of
NODE_ID last   BYTES of
4096 sends =   data each
BYTES bytes'   time it
               receives
               data from
               node NODE_ID
               
'Node          This report    'MemoryUsage'      'Statistic' 5       'INFO'
NODE_ID:       is generated                                          
Data usage     when a 'DUMP
is             1000'
DATA_MEMORY_PERCENTAGE%(https://dev.mysql.com/doc/ndb-internals/en/dump-command-1000.html)
(DATA_PAGES_USEDcommand is
32K pages of   issued in
total          the cluster
DATA_PAGES_TOTAL)'management
/ 'Node        client; for
NODE_ID:       more
Index usage    information,
is             see DUMP
INDEX_MEMORY_PERCENTAGE%1000
(INDEX_PAGES_USED(https://dev.mysql.com/doc/ndb-internals/en/dump-command-1000.html),
8K pages of    in MySQL NDB
total          Cluster
INDEX_PAGES_TOTAL)Internals
'              Manual
               (https://dev.mysql.com/doc/ndb-internals/en/)
               
'Node          A              'TransporterError' 'Error'     2       'ERROR'
NODE1_ID:      transporter                                           
Transporter    error
to node        occurred
NODE2_ID       while
reported       communicating
error          with node
ERROR_CODE:    NODE2_ID;
ERROR_MESSAGE' for a
               listing of
               transporter
               error codes
               and
               messages,
               see NDB
               Transporter
               Errors
               (https://dev.mysql.com/doc/ndb-internals/en/ndb-transporter-errors.html),
               in MySQL NDB
               Cluster
               Internals
               Manual
               (https://dev.mysql.com/doc/ndb-internals/en/)
               
'Node          A warning of   'TransporterWarning''Error'    8       'WARNING'
NODE1_ID:      a potential                                           
Transporter    transporter
to node        problem
NODE2_ID       while
reported       communicating
error          with node
ERROR_CODE:    NODE2_ID;
ERROR_MESSAGE' for a
               listing of
               transporter
               error codes
               and
               messages,
               see NDB
               Transporter
               Errors
               (https://dev.mysql.com/doc/ndb-internals/en/ndb-transporter-errors.html),
               for more
               information
               
'Node          This node      'MissedHeartbeat'  'Error'     8       'WARNING'
NODE1_ID:      missed a                                              
Node           heartbeat
NODE2_ID       from node
missed         NODE2_ID
heartbeat      
HEARTBEAT_ID'

'Node          This node      'DeadDueToHeartbeat''Error'    8       'ALERT'
NODE1_ID:      has missed                                            
Node           at least 3
NODE2_ID       heartbeats
declared       from node
dead due to    NODE2_ID,
missed         and so has
heartbeat'     declared
               that node
               'dead'
               
'Node          This node      'SentHeartbeat'    'Info'      12      'INFO'
NODE1_ID:      has sent a                                            
Node Sent      heartbeat to
Heartbeat to   node
node =         NODE2_ID
NODE2_ID'      

(_NDB 7.5.0    This report    'EventBufferStatus''Info'      7       'INFO'
and            is seen                                               
earlier_:)     during heavy
'Node          event buffer
NODE_ID:       usage, for
Event buffer   example,
status:        when many
used=BYTES_USEDupdates are
(PERCENT_USED%)being
alloc=BYTES_ALLOCATEDapplied in a
(PERCENT_AVAILABLE%)relatively
max=BYTES_AVAILABLEshort period
apply_epoch=LATEST_RESTORABLE_EPOCHof time; the
latest_epoch=LATEST_EPOCH'report shows
               the number
               of bytes and
               the
               percentage
               of event
               buffer
               memory used,
               the bytes
               allocated
               and
               percentage
               still
               available,
               and the
               latest and
               latest
               restorable
               epochs
               
'Node          These          'SingleUser'       'Info'      7       'INFO'
NODE_ID:       reports are                                           
Entering       written to
single user    the cluster
mode', 'Node   log when
NODE_ID:       entering and
Entered        exiting
single user    single user
mode Node      mode;
API_NODE_ID    API_NODE_ID
has            is the node
exclusive      ID of the
access',       API or SQL
'Node          having
NODE_ID:       exclusive
Entering       access to
single user    the cluster
mode'          (for more
               information,
               see
               *note mysql-cluster-single-user-mode::);
               the message
               'Unknown
               single user
               report
               API_NODE_ID'
               indicates an
               error has
               taken place
               and should
               never be
               seen in
               normal
               operation
               
'Node          A backup has   'BackupStarted'    'Backup'    7       'INFO'
NODE_ID:       been started                                          
Backup         using the
BACKUP_ID      management
started from   node having
node           MGM_NODE_ID;
MGM_NODE_ID'   this message
               is also
               displayed in
               the cluster
               management
               client when
               the
               *note 'START BACKUP': mysql-cluster-backup-using-management-client.
               command is
               issued; for
               more
               information,
               see
               *note mysql-cluster-backup-using-management-client::
               
'Node          The backup     'BackupCompleted'  'Backup'    7       'INFO'
NODE_ID:       having the                                            
Backup         ID BACKUP_ID
BACKUP_ID      has been
started from   completed;
node           for more
MGM_NODE_ID    information,
completed.     see
StartGCP:      *note mysql-cluster-backup-using-management-client::
START_GCP      
StopGCP:
STOP_GCP
#Records:
RECORDS
#LogRecords:
LOG_RECORDS
Data:
DATA_BYTES
bytes Log:
LOG_BYTES
bytes'

'Node          The backup     'BackupFailedToStart''Backup'  7       'ALERT'
NODE_ID:       failed to                                             
Backup         start; for
request from   error codes,
MGM_NODE_ID    see MGM API
failed to      Errors
start.         (https://dev.mysql.com/doc/ndbapi/en/mgm-errors.html)
Error:         
ERROR_CODE'

'Node          The backup     'BackupAborted'    'Backup'    7       'ALERT'
NODE_ID:       was                                           
Backup         terminated
BACKUP_ID      after
started from   starting,
MGM_NODE_ID    possibly due
has been       to user
aborted.       intervention
Error:         
ERROR_CODE'


File: manual.info.tmp,  Node: mysql-cluster-log-startup-messages,  Next: mysql-cluster-ndb-transporter-errors,  Prev: mysql-cluster-logs-cluster-log,  Up: mysql-cluster-logs-ndb-messages

18.5.7.2 NDB Cluster Log Startup Messages
.........................................

Possible startup messages with descriptions are provided in the
following list:

   * 'Initial start, waiting for %s to connect, nodes [ all: %s
     connected: %s no-wait: %s ]'

   * 'Waiting until nodes: %s connects, nodes [ all: %s connected: %s
     no-wait: %s ]'

   * 'Waiting %u sec for nodes %s to connect, nodes [ all: %s connected:
     %s no-wait: %s ]'

   * 'Waiting for non partitioned start, nodes [ all: %s connected: %s
     missing: %s no-wait: %s ]'

   * 'Waiting %u sec for non partitioned start, nodes [ all: %s
     connected: %s missing: %s no-wait: %s ]'

   * 'Initial start with nodes %s [ missing: %s no-wait: %s ]'

   * 'Start with all nodes %s'

   * 'Start with nodes %s [ missing: %s no-wait: %s ]'

   * 'Start potentially partitioned with nodes %s [ missing: %s no-wait:
     %s ]'

   * 'Unknown startreport: 0x%x [ %s %s %s %s ]'


File: manual.info.tmp,  Node: mysql-cluster-ndb-transporter-errors,  Prev: mysql-cluster-log-startup-messages,  Up: mysql-cluster-logs-ndb-messages

18.5.7.3 NDB Cluster: NDB Transporter Errors
............................................

This section lists error codes, names, and messages that are written to
the cluster log in the event of transporter errors.

  1. 0x00

     TE_NO_ERROR

     'No error'

  2. 0x01

     TE_ERROR_CLOSING_SOCKET

     'Error found during closing of socket'

  3. 0x02

     TE_ERROR_IN_SELECT_BEFORE_ACCEPT

     'Error found before accept. The transporter will retry'

  4. 0x03

     TE_INVALID_MESSAGE_LENGTH

     'Error found in message (invalid message length)'

  5. 0x04

     TE_INVALID_CHECKSUM

     'Error found in message (checksum)'

  6. 0x05

     TE_COULD_NOT_CREATE_SOCKET

     'Error found while creating socket(can't create socket)'

  7. 0x06

     TE_COULD_NOT_BIND_SOCKET

     'Error found while binding server socket'

  8. 0x07

     TE_LISTEN_FAILED

     'Error found while listening to server socket'

  9. 0x08

     TE_ACCEPT_RETURN_ERROR

     'Error found during accept(accept return error)'

  10. 0x0b

     TE_SHM_DISCONNECT

     'The remote node has disconnected'

  11. 0x0c

     TE_SHM_IPC_STAT

     'Unable to check shm segment'

  12. 0x0d

     TE_SHM_UNABLE_TO_CREATE_SEGMENT

     'Unable to create shm segment'

  13. 0x0e

     TE_SHM_UNABLE_TO_ATTACH_SEGMENT

     'Unable to attach shm segment'

  14. 0x0f

     TE_SHM_UNABLE_TO_REMOVE_SEGMENT

     'Unable to remove shm segment'

  15. 0x10

     TE_TOO_SMALL_SIGID

     'Sig ID too small'

  16. 0x11

     TE_TOO_LARGE_SIGID

     'Sig ID too large'

  17. 0x12

     TE_WAIT_STACK_FULL

     'Wait stack was full'

  18. 0x13

     TE_RECEIVE_BUFFER_FULL

     'Receive buffer was full'

  19. 0x14

     TE_SIGNAL_LOST_SEND_BUFFER_FULL

     'Send buffer was full,and trying to force send fails'

  20. 0x15

     TE_SIGNAL_LOST

     'Send failed for unknown reason(signal lost)'

  21. 0x16

     TE_SEND_BUFFER_FULL

     'The send buffer was full, but sleeping for a while solved'

  22. 0x17

     TE_SCI_LINK_ERROR

     'There is no link from this node to the switch'

  23. 0x18

     TE_SCI_UNABLE_TO_START_SEQUENCE

     'Could not start a sequence, because system resources are exumed or
     no sequence has been created'

  24. 0x19

     TE_SCI_UNABLE_TO_REMOVE_SEQUENCE

     'Could not remove a sequence'

  25. 0x1a

     TE_SCI_UNABLE_TO_CREATE_SEQUENCE

     'Could not create a sequence, because system resources are
     exempted. Must reboot'

  26. 0x1b

     TE_SCI_UNRECOVERABLE_DATA_TFX_ERROR

     'Tried to send data on redundant link but failed'

  27. 0x1c

     TE_SCI_CANNOT_INIT_LOCALSEGMENT

     'Cannot initialize local segment'

  28. 0x1d

     TE_SCI_CANNOT_MAP_REMOTESEGMENT

     'Cannot map remote segment'

  29. 0x1e

     TE_SCI_UNABLE_TO_UNMAP_SEGMENT

     'Cannot free the resources used by this segment (step 1)'

  30. 0x1f

     TE_SCI_UNABLE_TO_REMOVE_SEGMENT

     'Cannot free the resources used by this segment (step 2)'

  31. 0x20

     TE_SCI_UNABLE_TO_DISCONNECT_SEGMENT

     'Cannot disconnect from a remote segment'

  32. 0x21

     TE_SHM_IPC_PERMANENT

     'Shm ipc Permanent error'

  33. 0x22

     TE_SCI_UNABLE_TO_CLOSE_CHANNEL

     'Unable to close the sci channel and the resources allocated'


File: manual.info.tmp,  Node: mysql-cluster-single-user-mode,  Next: mysql-cluster-sql-statements,  Prev: mysql-cluster-logs-ndb-messages,  Up: mysql-cluster-management

18.5.8 NDB Cluster Single User Mode
-----------------------------------

_Single user mode_ enables the database administrator to restrict access
to the database system to a single API node, such as a MySQL server (SQL
node) or an instance of *note 'ndb_restore':
mysql-cluster-programs-ndb-restore.  When entering single user mode,
connections to all other API nodes are closed gracefully and all running
transactions are aborted.  No new transactions are permitted to start.

Once the cluster has entered single user mode, only the designated API
node is granted access to the database.

You can use the 'ALL STATUS' command in the *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. client to see when the cluster has
entered single user mode.  You can also check the 'status' column of the
*note 'ndbinfo.nodes': mysql-cluster-ndbinfo-nodes. table (see *note
mysql-cluster-ndbinfo-nodes::, for more information).

Example:

     ndb_mgm> ENTER SINGLE USER MODE 5

After this command has executed and the cluster has entered single user
mode, the API node whose node ID is '5' becomes the cluster's only
permitted user.

The node specified in the preceding command must be an API node;
attempting to specify any other type of node will be rejected.

*Note*:

When the preceding command is invoked, all transactions running on the
designated node are aborted, the connection is closed, and the server
must be restarted.

The command 'EXIT SINGLE USER MODE' changes the state of the cluster's
data nodes from single user mode to normal mode.  API nodes--such as
MySQL Servers--waiting for a connection (that is, waiting for the
cluster to become ready and available), are again permitted to connect.
The API node denoted as the single-user node continues to run (if still
connected) during and after the state change.

Example:

     ndb_mgm> EXIT SINGLE USER MODE

There are two recommended ways to handle a node failure when running in
single user mode:

   * Method 1:

       1. Finish all single user mode transactions

       2. Issue the 'EXIT SINGLE USER MODE' command

       3. Restart the cluster's data nodes

   * Method 2:

     Restart storage nodes prior to entering single user mode.


File: manual.info.tmp,  Node: mysql-cluster-sql-statements,  Next: mysql-cluster-ndbinfo,  Prev: mysql-cluster-single-user-mode,  Up: mysql-cluster-management

18.5.9 Quick Reference: NDB Cluster SQL Statements
--------------------------------------------------

This section discusses several SQL statements that can prove useful in
managing and monitoring a MySQL server that is connected to an NDB
Cluster, and in some cases provide information about the cluster itself.

   * *note 'SHOW ENGINE NDB STATUS': show-engine, *note 'SHOW ENGINE
     NDBCLUSTER STATUS': show-engine.

     The output of this statement contains information about the
     server's connection to the cluster, creation and usage of NDB
     Cluster objects, and binary logging for NDB Cluster replication.

     See *note show-engine::, for a usage example and more detailed
     information.

   * 
     *note 'SHOW ENGINES': show-engines.

     This statement can be used to determine whether or not clustering
     support is enabled in the MySQL server, and if so, whether it is
     active.

     See *note show-engines::, for more detailed information.

     *Note*:

     In MySQL 5.1 and later, this statement does not support a 'LIKE'
     clause.  However, you can use 'LIKE' to filter queries against the
     *note 'INFORMATION_SCHEMA.ENGINES': engines-table. table, as
     discussed in the next item.

   * 
     'SELECT * FROM INFORMATION_SCHEMA.ENGINES [WHERE ENGINE LIKE
     'NDB%']'

     This is the equivalent of *note 'SHOW ENGINES': show-engines, but
     uses the *note 'ENGINES': engines-table. table of the
     'INFORMATION_SCHEMA' database.  Unlike the case with the *note
     'SHOW ENGINES': show-engines. statement, it is possible to filter
     the results using a 'LIKE' clause, and to select specific columns
     to obtain information that may be of use in scripts.  For example,
     the following query shows whether the server was built with *note
     'NDB': mysql-cluster. support and, if so, whether it is enabled:

          mysql> SELECT SUPPORT FROM INFORMATION_SCHEMA.ENGINES
              ->   WHERE ENGINE LIKE 'NDB%';
          +---------+
          | support |
          +---------+
          | ENABLED |
          +---------+

     See *note engines-table::, for more information.

   * 
     'SHOW VARIABLES LIKE 'NDB%''

     This statement provides a list of most server system variables
     relating to the *note 'NDB': mysql-cluster. storage engine, and
     their values, as shown here:

          mysql> SHOW VARIABLES LIKE 'NDB%';
          +-------------------------------------+-------+
          | Variable_name                       | Value |
          +-------------------------------------+-------+
          | ndb_autoincrement_prefetch_sz       | 32    |
          | ndb_cache_check_time                | 0     |
          | ndb_extra_logging                   | 0     |
          | ndb_force_send                      | ON    |
          | ndb_index_stat_cache_entries        | 32    |
          | ndb_index_stat_enable               | OFF   |
          | ndb_index_stat_update_freq          | 20    |
          | ndb_report_thresh_binlog_epoch_slip | 3     |
          | ndb_report_thresh_binlog_mem_usage  | 10    |
          | ndb_use_copying_alter_table         | OFF   |
          | ndb_use_exact_count                 | ON    |
          | ndb_use_transactions                | ON    |
          +-------------------------------------+-------+

     See *note server-system-variables::, for more information.

   * 
     'SELECT * FROM INFORMATION_SCHEMA.GLOBAL_VARIABLES WHERE
     VARIABLE_NAME LIKE 'NDB%';'

     This statement is the equivalent of the *note 'SHOW VARIABLES':
     show-variables. statement described in the previous item, and
     provides almost identical output, as shown here:

          mysql> SELECT * FROM INFORMATION_SCHEMA.GLOBAL_VARIABLES
              ->   WHERE VARIABLE_NAME LIKE 'NDB%';
          +-------------------------------------+----------------+
          | VARIABLE_NAME                       | VARIABLE_VALUE |
          +-------------------------------------+----------------+
          | NDB_AUTOINCREMENT_PREFETCH_SZ       | 32             |
          | NDB_CACHE_CHECK_TIME                | 0              |
          | NDB_EXTRA_LOGGING                   | 0              |
          | NDB_FORCE_SEND                      | ON             |
          | NDB_INDEX_STAT_CACHE_ENTRIES        | 32             |
          | NDB_INDEX_STAT_ENABLE               | OFF            |
          | NDB_INDEX_STAT_UPDATE_FREQ          | 20             |
          | NDB_REPORT_THRESH_BINLOG_EPOCH_SLIP | 3              |
          | NDB_REPORT_THRESH_BINLOG_MEM_USAGE  | 10             |
          | NDB_USE_COPYING_ALTER_TABLE         | OFF            |
          | NDB_USE_EXACT_COUNT                 | ON             |
          | NDB_USE_TRANSACTIONS                | ON             |
          +-------------------------------------+----------------+

     Unlike the case with the *note 'SHOW VARIABLES': show-variables.
     statement, it is possible to select individual columns.  For
     example:

          mysql> SELECT VARIABLE_VALUE
              ->   FROM INFORMATION_SCHEMA.GLOBAL_VARIABLES
              ->   WHERE VARIABLE_NAME = 'ndb_force_send';
          +----------------+
          | VARIABLE_VALUE |
          +----------------+
          | ON             |
          +----------------+

     See *note variables-table::, and *note server-system-variables::,
     for more information.

   * 
     'SHOW STATUS LIKE 'NDB%''

     This statement shows at a glance whether or not the MySQL server is
     acting as a cluster SQL node, and if so, it provides the MySQL
     server's cluster node ID, the host name and port for the cluster
     management server to which it is connected, and the number of data
     nodes in the cluster, as shown here:

          mysql> SHOW STATUS LIKE 'NDB%';
          +--------------------------+----------------+
          | Variable_name            | Value          |
          +--------------------------+----------------+
          | Ndb_cluster_node_id      | 10             |
          | Ndb_config_from_host     | 198.51.100.103 |
          | Ndb_config_from_port     | 1186           |
          | Ndb_number_of_data_nodes | 4              |
          +--------------------------+----------------+

     If the MySQL server was built with clustering support, but it is
     not connected to a cluster, all rows in the output of this
     statement contain a zero or an empty string:

          mysql> SHOW STATUS LIKE 'NDB%';
          +--------------------------+-------+
          | Variable_name            | Value |
          +--------------------------+-------+
          | Ndb_cluster_node_id      | 0     |
          | Ndb_config_from_host     |       |
          | Ndb_config_from_port     | 0     |
          | Ndb_number_of_data_nodes | 0     |
          +--------------------------+-------+

     See also *note show-status::.

   * 
     'SELECT * FROM INFORMATION_SCHEMA.GLOBAL_STATUS WHERE VARIABLE_NAME
     LIKE 'NDB%';'

     This statement provides similar output to the *note 'SHOW STATUS':
     show-status. statement discussed in the previous item.  However,
     unlike the case with *note 'SHOW STATUS': show-status, it is
     possible using the *note 'SELECT': select. to extract values in SQL
     for use in scripts for monitoring and automation purposes.

     See *note status-table::, for more information.

You can also query the tables in the *note 'ndbinfo':
mysql-cluster-ndbinfo. information database for real-time data about
many NDB Cluster operations.  See *note mysql-cluster-ndbinfo::.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo,  Next: mysql-cluster-security,  Prev: mysql-cluster-sql-statements,  Up: mysql-cluster-management

18.5.10 ndbinfo: The NDB Cluster Information Database
-----------------------------------------------------

* Menu:

* mysql-cluster-ndbinfo-arbitrator-validity-detail::  The ndbinfo arbitrator_validity_detail Table
* mysql-cluster-ndbinfo-arbitrator-validity-summary::  The ndbinfo arbitrator_validity_summary Table
* mysql-cluster-ndbinfo-blocks::  The ndbinfo blocks Table
* mysql-cluster-ndbinfo-cluster-operations::  The ndbinfo cluster_operations Table
* mysql-cluster-ndbinfo-cluster-transactions::  The ndbinfo cluster_transactions Table
* mysql-cluster-ndbinfo-config-params::  The ndbinfo config_params Table
* mysql-cluster-ndbinfo-counters::  The ndbinfo counters Table
* mysql-cluster-ndbinfo-diskpagebuffer::  The ndbinfo diskpagebuffer Table
* mysql-cluster-ndbinfo-logbuffers::  The ndbinfo logbuffers Table
* mysql-cluster-ndbinfo-logspaces::  The ndbinfo logspaces Table
* mysql-cluster-ndbinfo-membership::  The ndbinfo membership Table
* mysql-cluster-ndbinfo-memoryusage::  The ndbinfo memoryusage Table
* mysql-cluster-ndbinfo-nodes::  The ndbinfo nodes Table
* mysql-cluster-ndbinfo-resources::  The ndbinfo resources Table
* mysql-cluster-ndbinfo-server-operations::  The ndbinfo server_operations Table
* mysql-cluster-ndbinfo-server-transactions::  The ndbinfo server_transactions Table
* mysql-cluster-ndbinfo-threadblocks::  The ndbinfo threadblocks Table
* mysql-cluster-ndbinfo-threadstat::  The ndbinfo threadstat Table
* mysql-cluster-ndbinfo-transporters::  The ndbinfo transporters Table

'ndbinfo' is a database containing information specific to NDB Cluster.

This database contains a number of tables, each providing a different
sort of data about NDB Cluster node status, resource usage, and
operations.  You can find more detailed information about each of these
tables in the next several sections.

'ndbinfo' is included with NDB Cluster support in the MySQL Server; no
special compilation or configuration steps are required; the tables are
created by the MySQL Server when it connects to the cluster.  You can
verify that 'ndbinfo' support is active in a given MySQL Server instance
using *note 'SHOW PLUGINS': show-plugins.; if 'ndbinfo' support is
enabled, you should see a row containing 'ndbinfo' in the 'Name' column
and 'ACTIVE' in the 'Status' column, as shown here (emphasized text):

     mysql> SHOW PLUGINS;
     +----------------------------------+--------+--------------------+---------+---------+
     | Name                             | Status | Type               | Library | License |
     +----------------------------------+--------+--------------------+---------+---------+
     | binlog                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | mysql_native_password            | ACTIVE | AUTHENTICATION     | NULL    | GPL     |
     | mysql_old_password               | ACTIVE | AUTHENTICATION     | NULL    | GPL     |
     | CSV                              | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | MEMORY                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | MRG_MYISAM                       | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | MyISAM                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | PERFORMANCE_SCHEMA               | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | BLACKHOLE                        | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | ARCHIVE                          | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | ndbcluster                       | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     _| ndbinfo                          | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |_
     | ndb_transid_mysql_connection_map | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | InnoDB                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | INNODB_TRX                       | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_LOCKS                     | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_LOCK_WAITS                | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMP                       | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMP_RESET                 | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMPMEM                    | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMPMEM_RESET              | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | partition                        | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     +----------------------------------+--------+--------------------+---------+---------+
     22 rows in set (0.00 sec)

You can also do this by checking the output of *note 'SHOW ENGINES':
show-engines. for a line including 'ndbinfo' in the 'Engine' column and
'YES' in the 'Support' column, as shown here (emphasized text):

     mysql> SHOW ENGINES\G
     *************************** 1. row ***************************
           Engine: ndbcluster
          Support: YES
          Comment: Clustered, fault-tolerant tables
     Transactions: YES
               XA: NO
       Savepoints: NO
     *************************** 2. row ***************************
           Engine: MRG_MYISAM
          Support: YES
          Comment: Collection of identical MyISAM tables
     Transactions: NO
               XA: NO
       Savepoints: NO
     _*************************** 3. row ***************************
           Engine: ndbinfo
          Support: YES
          Comment: NDB Cluster system information storage engine
     Transactions: NO
               XA: NO
       Savepoints: NO_
     *************************** 4. row ***************************
           Engine: CSV
          Support: YES
          Comment: CSV storage engine
     Transactions: NO
               XA: NO
       Savepoints: NO
     *************************** 5. row ***************************
           Engine: MEMORY
          Support: YES
          Comment: Hash based, stored in memory, useful for temporary tables
     Transactions: NO
               XA: NO
       Savepoints: NO
     *************************** 6. row ***************************
           Engine: FEDERATED
          Support: NO
          Comment: Federated MySQL storage engine
     Transactions: NULL
               XA: NULL
       Savepoints: NULL
     *************************** 7. row ***************************
           Engine: ARCHIVE
          Support: YES
          Comment: Archive storage engine
     Transactions: NO
               XA: NO
       Savepoints: NO
     *************************** 8. row ***************************
           Engine: InnoDB
          Support: YES
          Comment: Supports transactions, row-level locking, and foreign keys
     Transactions: YES
               XA: YES
       Savepoints: YES
     *************************** 9. row ***************************
           Engine: MyISAM
          Support: DEFAULT
          Comment: Default engine as of MySQL 3.23 with great performance
     Transactions: NO
               XA: NO
       Savepoints: NO
     *************************** 10. row ***************************
           Engine: BLACKHOLE
          Support: YES
          Comment: /dev/null storage engine (anything you write to it disappears)
     Transactions: NO
               XA: NO
       Savepoints: NO
     10 rows in set (0.00 sec)

If 'ndbinfo' support is enabled, then you can access 'ndbinfo' using SQL
statements in *note 'mysql': mysql. or another MySQL client.  For
example, you can see 'ndbinfo' listed in the output of *note 'SHOW
DATABASES': show-databases, as shown here (emphasized text):

     mysql> SHOW DATABASES;
     +--------------------+
     | Database           |
     +--------------------+
     | information_schema |
     | mysql              |
     _| ndbinfo            |_
     | test               |
     +--------------------+
     4 rows in set (0.00 sec)

If the *note 'mysqld': mysqld. process was not started with the
'--ndbcluster' option, 'ndbinfo' is not available and is not displayed
by *note 'SHOW DATABASES': show-databases.  If *note 'mysqld': mysqld.
was formerly connected to an NDB Cluster but the cluster becomes
unavailable (due to events such as cluster shutdown, loss of network
connectivity, and so forth), 'ndbinfo' and its tables remain visible,
but an attempt to access any tables (other than 'blocks' or
'config_params') fails with 'Got error 157 'Connection to NDB failed'
from NDBINFO'.

With the exception of the 'blocks' and 'config_params' tables, what we
refer to as 'ndbinfo' 'tables' are actually views generated from
internal *note 'NDB': mysql-cluster. tables not normally visible to the
MySQL Server.

All 'ndbinfo' tables are read-only, and are generated on demand when
queried.  Because many of them are generated in parallel by the data
nodes while other are specific to a given SQL node, they are not
guaranteed to provide a consistent snapshot.

In addition, pushing down of joins is not supported on 'ndbinfo' tables;
so joining large 'ndbinfo' tables can require transfer of a large amount
of data to the requesting API node, even when the query makes use of a
'WHERE' clause.

'ndbinfo' tables are not included in the query cache.  (Bug #59831)

You can select the 'ndbinfo' database with a *note 'USE': use.
statement, and then issue a *note 'SHOW TABLES': show-tables. statement
to obtain a list of tables, just as for any other database, like this:

     mysql> USE ndbinfo;
     Database changed

     mysql> SHOW TABLES;
     +-----------------------------+
     | Tables_in_ndbinfo           |
     +-----------------------------+
     | arbitrator_validity_detail  |
     | arbitrator_validity_summary |
     | blocks                      |
     | cluster_operations          |
     | cluster_transactions        |
     | config_params               |
     | counters                    |
     | diskpagebuffer              |
     | logbuffers                  |
     | logspaces                   |
     | membership                  |
     | memoryusage                 |
     | nodes                       |
     | resources                   |
     | server_operations           |
     | server_transactions         |
     | threadblocks                |
     | threadstat                  |
     | transporters                |
     +-----------------------------+
     19 rows in set (0.03 sec)

The *note 'cluster_operations':
mysql-cluster-ndbinfo-cluster-operations, *note 'cluster_transactions':
mysql-cluster-ndbinfo-cluster-transactions, *note 'server_operations':
mysql-cluster-ndbinfo-server-operations, *note 'server_transactions':
mysql-cluster-ndbinfo-server-transactions, *note 'threadblocks':
mysql-cluster-ndbinfo-threadblocks, and *note 'threadstat':
mysql-cluster-ndbinfo-threadstat. tables were added in NDB 7.2.2.  The
*note 'arbitrator_validity_detail':
mysql-cluster-ndbinfo-arbitrator-validity-detail, *note
'arbitrator_validity_summary':
mysql-cluster-ndbinfo-arbitrator-validity-summary, and *note
'membership': mysql-cluster-ndbinfo-membership. tables were added in NDB
7.2.10.

You can execute *note 'SELECT': select. statements against these tables,
just as you would normally expect:

     mysql> SELECT * FROM memoryusage;
     +---------+---------------------+--------+------------+------------+-------------+
     | node_id | memory_type         | used   | used_pages | total      | total_pages |
     +---------+---------------------+--------+------------+------------+-------------+
     |       5 | Data memory         | 753664 |         23 | 1073741824 |       32768 |
     |       5 | Index memory        | 163840 |         20 | 1074003968 |      131104 |
     |       5 | Long message buffer |   2304 |          9 |   67108864 |      262144 |
     |       6 | Data memory         | 753664 |         23 | 1073741824 |       32768 |
     |       6 | Index memory        | 163840 |         20 | 1074003968 |      131104 |
     |       6 | Long message buffer |   2304 |          9 |   67108864 |      262144 |
     +---------+---------------------+--------+------------+------------+-------------+
     6 rows in set (0.02 sec)

More complex queries, such as the two following *note 'SELECT': select.
statements using the *note 'memoryusage':
mysql-cluster-ndbinfo-memoryusage. table, are possible:

     mysql> SELECT SUM(used) as 'Data Memory Used, All Nodes'
          >     FROM memoryusage
          >     WHERE memory_type = 'Data memory';
     +-----------------------------+
     | Data Memory Used, All Nodes |
     +-----------------------------+
     |                        6460 |
     +-----------------------------+
     1 row in set (0.37 sec)

     mysql> SELECT SUM(max) as 'Total IndexMemory Available'
          >     FROM memoryusage
          >     WHERE memory_type = 'Index memory';
     +-----------------------------+
     | Total IndexMemory Available |
     +-----------------------------+
     |                       25664 |
     +-----------------------------+
     1 row in set (0.33 sec)

'ndbinfo' table and column names are case-sensitive (as is the name of
the 'ndbinfo' database itself).  These identifiers are in lowercase.
Trying to use the wrong lettercase results in an error, as shown in this
example:

     mysql> SELECT * FROM nodes;
     +---------+--------+---------+-------------+
     | node_id | uptime | status  | start_phase |
     +---------+--------+---------+-------------+
     |       1 |  13602 | STARTED |           0 |
     |       2 |     16 | STARTED |           0 |
     +---------+--------+---------+-------------+
     2 rows in set (0.04 sec)

     mysql> SELECT * FROM Nodes;
     ERROR 1146 (42S02): Table 'ndbinfo.Nodes' doesn't exist

*note 'mysqldump': mysqldump. ignores the 'ndbinfo' database entirely,
and excludes it from any output.  This is true even when using the
'--databases' or '--all-databases' option.

NDB Cluster also maintains tables in the 'INFORMATION_SCHEMA'
information database, including the *note 'FILES': files-table. table
which contains information about files used for NDB Cluster Disk Data
storage.  For more information, see *note mysql-cluster-i_s-tables::.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-arbitrator-validity-detail,  Next: mysql-cluster-ndbinfo-arbitrator-validity-summary,  Prev: mysql-cluster-ndbinfo,  Up: mysql-cluster-ndbinfo

18.5.10.1 The ndbinfo arbitrator_validity_detail Table
......................................................

The 'arbitrator_validity_detail' table shows the view that each data
node in the cluster has of the arbitrator.  It is a subset of the *note
'membership': mysql-cluster-ndbinfo-membership. table.

The following table provides information about the columns in the
'arbitrator_validity_detail' table.  For each column, the table shows
the name, data type, and a brief description.  Additional information
can be found in the notes following the table.

*Columns of the arbitrator_validity_detail table*

Column Name            Type               Description
                                          
'node_id'              integer            This node's node ID
                                          
'arbitrator'           integer            Node ID of arbitrator
                                          
'arb_ticket'           string             Internal identifier used to
                                          track arbitration
                                          
'arb_connected'        'Yes' or 'No'      Whether this node is connected
                                          to the arbitrator
                                          
'arb_state'            Enumeration (see   Arbitration state
                       text)
                       

The node ID is the same as that reported by *note 'ndb_mgm -e "SHOW"':
mysql-cluster-programs-ndb-mgm.

All nodes should show the same 'arbitrator' and 'arb_ticket' values as
well as the same 'arb_state' value.  Possible 'arb_state' values are
'ARBIT_NULL', 'ARBIT_INIT', 'ARBIT_FIND', 'ARBIT_PREP1', 'ARBIT_PREP2',
'ARBIT_START', 'ARBIT_RUN', 'ARBIT_CHOOSE', 'ARBIT_CRASH', and
'UNKNOWN'.

'arb_connected' shows whether the current node is connected to the
'arbitrator'.

Like the *note 'membership': mysql-cluster-ndbinfo-membership. and *note
'arbitrator_validity_summary':
mysql-cluster-ndbinfo-arbitrator-validity-summary. tables, this table
was added in NDB 7.2.10.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-arbitrator-validity-summary,  Next: mysql-cluster-ndbinfo-blocks,  Prev: mysql-cluster-ndbinfo-arbitrator-validity-detail,  Up: mysql-cluster-ndbinfo

18.5.10.2 The ndbinfo arbitrator_validity_summary Table
.......................................................

The 'arbitrator_validity_summary' table provides a composite view of the
arbitrator with regard to the cluster's data nodes.

The following table provides information about the columns in the
'arbitrator_validity_summary' table.  For each column, the table shows
the name, data type, and a brief description.  Additional information
can be found in the notes following the table.

*Columns of the arbitrator_validity_summary table*

Column Name            Type               Description
                                          
'arbitrator'           integer            Node ID of arbitrator
                                          
'arb_ticket'           string             Internal identifier used to
                                          track arbitration
                                          
'arb_connected'        'Yes' or 'No'      Whether this arbitrator is
                                          connected to the cluster
                                          
'consensus_count'      integer            Number of data nodes that see
                                          this node as arbitrator

In normal operations, this table should have only 1 row for any
appreciable length of time.  If it has more than 1 row for longer than a
few moments, then either not all nodes are connected to the arbitrator,
or all nodes are connected, but do not agree on the same arbitrator.

The 'arbitrator' column shows the arbitrator's node ID.

'arb_ticket' is the internal identifier used by this arbitrator.

'arb_connected' shows whether this node is connected to the cluster as
an arbitrator.

Like the *note 'membership': mysql-cluster-ndbinfo-membership. and *note
'arbitrator_validity_detail':
mysql-cluster-ndbinfo-arbitrator-validity-detail. tables, this table was
added in NDB 7.2.10.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-blocks,  Next: mysql-cluster-ndbinfo-cluster-operations,  Prev: mysql-cluster-ndbinfo-arbitrator-validity-summary,  Up: mysql-cluster-ndbinfo

18.5.10.3 The ndbinfo blocks Table
..................................

The 'blocks' table is a static table which simply contains the names and
internal IDs of all NDB kernel blocks (see NDB Kernel Blocks
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks.html)).
It is for use by the other *note 'ndbinfo': mysql-cluster-ndbinfo.
tables (most of which are actually views) in mapping block numbers to
block names for producing human-readable output.

The following table provides information about the columns in the
'blocks' table.  For each column, the table shows the name, data type,
and a brief description.  Additional information can be found in the
notes following the table.

*Columns of the blocks table*

Column Name            Type               Description
                                          
'block_number'         integer            Block number
                                          
'block_name'           string             Block name
                       

To obtain a list of all block names, simply execute 'SELECT block_name
FROM ndbinfo.blocks'.  Although this is a static table, its content can
vary between different NDB Cluster releases.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-cluster-operations,  Next: mysql-cluster-ndbinfo-cluster-transactions,  Prev: mysql-cluster-ndbinfo-blocks,  Up: mysql-cluster-ndbinfo

18.5.10.4 The ndbinfo cluster_operations Table
..............................................

The 'cluster_operations' table provides a per-operation (stateful
primary key op) view of all activity in the NDB Cluster from the point
of view of the local data management (LQH) blocks (see The DBLQH Block
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks-dblqh.html)).

The following table provides information about the columns in the
'cluster_operations' table.  For each column, the table shows the name,
data type, and a brief description.  Additional information can be found
in the notes following the table.

*Columns of the cluster_operations table*

Column Name            Type               Description
                                          
'node_id'              integer            Node ID of reporting LQH block
                                          
'block_instance'       integer            LQH block instance
                                          
'transid'              integer            Transaction ID
                                          
'operation_type'       string             Operation type (see text for
                                          possible values)
                                          
'state'                string             Operation state (see text for
                                          possible values)
                                          
'tableid'              integer            Table ID
                                          
'fragmentid'           integer            Fragment ID
                                          
'client_node_id'       integer            Client node ID
                                          
'client_block_ref'     integer            Client block reference
                                          
'tc_node_id'           integer            Transaction coordinator node
                                          ID
                                          
'tc_block_no'          integer            Transaction coordinator block
                                          number
                                          
'tc_block_instance'    integer            Transaction coordinator block
                                          instance

The transaction ID is a unique 64-bit number which can be obtained using
the NDB API's 'getTransactionId()'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndbtransaction-gettransactionid.html)
method.  (Currently, the MySQL Server does not expose the NDB API
transaction ID of an ongoing transaction.)

The 'operation_type' column can take any one of the values 'READ',
'READ-SH', 'READ-EX', 'INSERT', 'UPDATE', 'DELETE', 'WRITE', 'UNLOCK',
'REFRESH', 'SCAN', 'SCAN-SH', 'SCAN-EX', or '<unknown>'.

The 'state' column can have any one of the values 'ABORT_QUEUED',
'ABORT_STOPPED', 'COMMITTED', 'COMMIT_QUEUED', 'COMMIT_STOPPED',
'COPY_CLOSE_STOPPED', 'COPY_FIRST_STOPPED', 'COPY_STOPPED',
'COPY_TUPKEY', 'IDLE', 'LOG_ABORT_QUEUED', 'LOG_COMMIT_QUEUED',
'LOG_COMMIT_QUEUED_WAIT_SIGNAL', 'LOG_COMMIT_WRITTEN',
'LOG_COMMIT_WRITTEN_WAIT_SIGNAL', 'LOG_QUEUED', 'PREPARED',
'PREPARED_RECEIVED_COMMIT', 'SCAN_CHECK_STOPPED', 'SCAN_CLOSE_STOPPED',
'SCAN_FIRST_STOPPED', 'SCAN_RELEASE_STOPPED', 'SCAN_STATE_USED',
'SCAN_STOPPED', 'SCAN_TUPKEY', 'STOPPED', 'TC_NOT_CONNECTED',
'WAIT_ACC', 'WAIT_ACC_ABORT', 'WAIT_AI_AFTER_ABORT', 'WAIT_ATTR',
'WAIT_SCAN_AI', 'WAIT_TUP', 'WAIT_TUPKEYINFO', 'WAIT_TUP_COMMIT', or
'WAIT_TUP_TO_ABORT'.  (If the MySQL Server is running with
'ndbinfo_show_hidden' enabled, you can view this list of states by
selecting from the 'ndb$dblqh_tcconnect_state' table, which is normally
hidden.)

You can obtain the name of an 'NDB' table from its table ID by checking
the output of *note 'ndb_show_tables':
mysql-cluster-programs-ndb-show-tables.

The 'fragid' is the same as the partition number seen in the output of
*note 'ndb_desc': mysql-cluster-programs-ndb-desc.
'--extra-partition-info' (short form '-p').

In 'client_node_id' and 'client_block_ref', 'client' refers to an NDB
Cluster API or SQL node (that is, an NDB API client or a MySQL Server
attached to the cluster).

The 'block_instance' and 'tc_block_instance' column provide,
respectively, the 'DBLQH' and 'DBTC' block instance numbers.  You can
use these along with the block names to obtain information about
specific threads from the *note 'threadblocks':
mysql-cluster-ndbinfo-threadblocks. table.

This table was added in NDB 7.2.2.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-cluster-transactions,  Next: mysql-cluster-ndbinfo-config-params,  Prev: mysql-cluster-ndbinfo-cluster-operations,  Up: mysql-cluster-ndbinfo

18.5.10.5 The ndbinfo cluster_transactions Table
................................................

The 'cluster_transactions' table shows information about all ongoing
transactions in an NDB Cluster.

The following table provides information about the columns in the
'cluster_transactions' table.  For each column, the table shows the
name, data type, and a brief description.  Additional information can be
found in the notes following the table.

*Columns of the cluster_transactions table*

Column Name            Type               Description
                                          
'node_id'              integer            Node ID of transaction
                                          coordinator
                                          
'block_instance'       integer            TC block instance
                                          
'transid'              integer            Transaction ID
                                          
'state'                string             Operation state (see text for
                                          possible values)
                                          
'count_operations'     integer            Number of stateful primary key
                                          operations in transaction
                                          (includes reads with locks, as
                                          well as DML operations)
                                          
'outstanding_operations'integer           Operations still being
                                          executed in local data
                                          management blocks
                                          
'inactive_seconds'     integer            Time spent waiting for API
                                          
'client_node_id'       integer            Client node ID
                                          
'client_block_ref'     integer            Client block reference
                       

The transaction ID is a unique 64-bit number which can be obtained using
the NDB API's 'getTransactionId()'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndbtransaction-gettransactionid.html)
method.  (Currently, the MySQL Server does not expose the NDB API
transaction ID of an ongoing transaction.)

'block_instance' refers to an instance of a kernel block.  Together with
the block name, this number can be used to look up a given instance in
the *note 'threadblocks': mysql-cluster-ndbinfo-threadblocks. table.

The 'state' column can have any one of the values 'CS_ABORTING',
'CS_COMMITTING', 'CS_COMMIT_SENT', 'CS_COMPLETE_SENT', 'CS_COMPLETING',
'CS_CONNECTED', 'CS_DISCONNECTED', 'CS_FAIL_ABORTED',
'CS_FAIL_ABORTING', 'CS_FAIL_COMMITTED', 'CS_FAIL_COMMITTING',
'CS_FAIL_COMPLETED', 'CS_FAIL_PREPARED', 'CS_PREPARE_TO_COMMIT',
'CS_RECEIVING', 'CS_REC_COMMITTING', 'CS_RESTART',
'CS_SEND_FIRE_TRIG_REQ', 'CS_STARTED', 'CS_START_COMMITTING',
'CS_START_SCAN', 'CS_WAIT_ABORT_CONF', 'CS_WAIT_COMMIT_CONF',
'CS_WAIT_COMPLETE_CONF', 'CS_WAIT_FIRE_TRIG_REQ'.  (If the MySQL Server
is running with 'ndbinfo_show_hidden' enabled, you can view this list of
states by selecting from the 'ndb$dbtc_apiconnect_state' table, which is
normally hidden.)

In 'client_node_id' and 'client_block_ref', 'client' refers to an NDB
Cluster API or SQL node (that is, an NDB API client or a MySQL Server
attached to the cluster).

The 'tc_block_instance' column provides the 'DBTC' block instance
number.  You can use this along with the block name to obtain
information about specific threads from the *note 'threadblocks':
mysql-cluster-ndbinfo-threadblocks. table.

This table was added in NDB 7.2.2.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-config-params,  Next: mysql-cluster-ndbinfo-counters,  Prev: mysql-cluster-ndbinfo-cluster-transactions,  Up: mysql-cluster-ndbinfo

18.5.10.6 The ndbinfo config_params Table
.........................................

The 'config_params' table is a static table which provides the names and
internal ID numbers of and other information about NDB Cluster
configuration parameters.

The following table provides information about the columns in the
'config_params' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the config_params table*

Column Name            Type               Description
                                          
'param_number'         integer            The parameter's internal ID
                                          number
                                          
'param_name'           string             The name of the parameter
                       

Although this is a static table, its content can vary between NDB
Cluster installations, since supported parameters can vary due to
differences between software releases, cluster hardware configurations,
and other factors.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-counters,  Next: mysql-cluster-ndbinfo-diskpagebuffer,  Prev: mysql-cluster-ndbinfo-config-params,  Up: mysql-cluster-ndbinfo

18.5.10.7 The ndbinfo counters Table
....................................

The 'counters' table provides running totals of events such as reads and
writes for specific kernel blocks and data nodes.  Counts are kept from
the most recent node start or restart; a node start or restart resets
all counters on that node.  Not all kernel blocks have all types of
counters.

The following table provides information about the columns in the
'counters' table.  For each column, the table shows the name, data type,
and a brief description.  Additional information can be found in the
notes following the table.

*Columns of the counters table*

Column Name            Type               Description
                                          
'node_id'              integer            The data node ID
                                          
'block_name'           string             Name of the associated NDB
                                          kernel block (see NDB Kernel
                                          Blocks
                                          (https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks.html)).
                                          
'block_instance'       integer            Block instance
                                          
'counter_id'           integer            The counter's internal ID
                                          number; normally an integer
                                          between 1 and 10, inclusive.
                                          
'counter_name'         string             The name of the counter.  See
                                          text for names of individual
                                          counters and the NDB kernel
                                          block with which each counter
                                          is associated.
                                          
'val'                  integer            The counter's value
                       

Each counter is associated with a particular 'NDB' kernel block.  Prior
to NDB 7.2.0, this was limited to either the 'DBLQH' kernel block or the
'DBTC' kernel block.  In NDB 7.2.0 and later, a number of counters
relating to the 'DBSPJ' kernel block are also available; these counters
are described later in this section.

The 'OPERATIONS' counter is associated with the 'DBLQH' (local query
handler) kernel block (see The DBLQH Block
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks-dblqh.html)).
A primary-key read counts as one operation, as does a primary-key
update.  For reads, there is one operation in 'DBLQH' per operation in
'DBTC'.  For writes, there is one operation counted per replica.

The 'ATTRINFO', 'TRANSACTIONS', 'COMMITS', 'READS', 'LOCAL_READS',
'SIMPLE_READS', 'WRITES', 'LOCAL_WRITES', 'ABORTS', 'TABLE_SCANS', and
'RANGE_SCANS' counters are associated with the DBTC (transaction
co-ordinator) kernel block (see The DBTC Block
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks-dbtc.html)).

'LOCAL_WRITES' and 'LOCAL_READS' are primary-key operations using a
transaction coordinator in a node that also holds the primary replica of
the record.

The 'READS' counter includes all reads.  'LOCAL_READS' includes only
those reads of the primary replica on the same node as this transaction
coordinator.  'SIMPLE_READS' includes only those reads in which the read
operation is the beginning and ending operation for a given transaction.
Simple reads do not hold locks but are part of a transaction, in that
they observe uncommitted changes made by the transaction containing them
but not of any other uncommitted transactions.  Such reads are 'simple'
from the point of view of the TC block; since they hold no locks they
are not durable, and once 'DBTC' has routed them to the relevant LQH
block, it holds no state for them.

'ATTRINFO' keeps a count of the number of times an interpreted program
is sent to the data node.  See NDB Protocol Messages
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-ndb-protocol-messages.html),
for more information about 'ATTRINFO' messages in the 'NDB' kernel.

NDB 7.2.0, as part of its implementation of distributed pushed-down
joins, adds the 'LOCAL_TABLE_SCANS_SENT', 'READS_RECEIVED',
'PRUNED_RANGE_SCANS_RECEIVED', 'RANGE_SCANS_RECEIVED',
'LOCAL_READS_SENT', 'CONST_PRUNED_RANGE_SCANS_RECEIVED',
'LOCAL_RANGE_SCANS_SENT', 'REMOTE_READS_SENT',
'REMOTE_RANGE_SCANS_SENT', 'READS_NOT_FOUND', 'SCAN_BATCHES_RETURNED',
'TABLE_SCANS_RECEIVED', and 'SCAN_ROWS_RETURNED' counters.  These
counters are associated with the 'DBSPJ' (select push-down join) kernel
block (see The DBSPJ Block
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-kernel-blocks-dbspj.html)).

The 'block_name' and 'block_instance' columns provide, respectively, the
applicable NDB kernel block name and instance number.  You can use these
to obtain information about specific threads from the *note
'threadblocks': mysql-cluster-ndbinfo-threadblocks. table.

A number of counters increasing the visibility of transporter overload
and send buffer sizing when troubleshooting such issues were added in
NDB 7.2.10.  (Bug #15935206) For each LQH instance, there is one
instance of each counter in the following list:

   * 'LQHKEY_OVERLOAD': Number of primary key requests rejected at the
     LQH block instance due to transporter overload

   * 'LQHKEY_OVERLOAD_TC': Count of instances of 'LQHKEY_OVERLOAD' where
     the TC node transporter was overloaded

   * 'LQHKEY_OVERLOAD_READER': Count of instances of 'LQHKEY_OVERLOAD'
     where the API reader (reads only) node was overloaded.

   * 'LQHKEY_OVERLOAD_NODE_PEER': Count of instances of
     'LQHKEY_OVERLOAD' where the next backup data node (writes only) was
     overloaded

   * 'LQHKEY_OVERLOAD_SUBSCRIBER': Count of instances of
     'LQHKEY_OVERLOAD' where a event subscriber (writes only) was
     overloaded.

   * 'LQHSCAN_SLOWDOWNS': Count of instances where a fragment scan batch
     size was reduced due to scanning API transporter overload.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-diskpagebuffer,  Next: mysql-cluster-ndbinfo-logbuffers,  Prev: mysql-cluster-ndbinfo-counters,  Up: mysql-cluster-ndbinfo

18.5.10.8 The ndbinfo diskpagebuffer Table
..........................................

The 'diskpagebuffer' table provides statistics about disk page buffer
usage by NDB Cluster Disk Data tables.

The following table provides information about the columns in the
'diskpagebuffer' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the diskpagebuffer table*

Column Name            Type               Description
                                          
'node_id'              integer            The data node ID
                                          
'block_instance'       integer            Block instance
                                          
'pages_written'        integer            Number of pages written to
                                          disk.
                                          
'pages_written_lcp'    integer            Number of pages written by
                                          local checkpoints.
                                          
'pages_read'           integer            Number of pages read from disk
                                          
'log_waits'            integer            Number of page writes waiting
                                          for log to be written to disk
                                          
'page_requests_direct_return'integer      Number of requests for pages
                                          that were available in buffer
                                          
'page_requests_wait_queue'integer         Number of requests that had to
                                          wait for pages to become
                                          available in buffer
                                          
'page_requests_wait_io'integer            Number of requests that had to
                                          be read from pages on disk
                                          (pages were unavailable in
                                          buffer)

You can use this table with NDB Cluster Disk Data tables to determine
whether 'DiskPageBufferMemory' is sufficiently large to allow data to be
read from the buffer rather from disk; minimizing disk seeks can help
improve performance of such tables.

You can determine the proportion of reads from 'DiskPageBufferMemory' to
the total number of reads using a query such as this one, which obtains
this ratio as a percentage:

     SELECT
       node_id,
       100 * page_requests_direct_return /
         (page_requests_direct_return + page_requests_wait_io)
           AS hit_ratio
     FROM ndbinfo.diskpagebuffer;

The result from this query should be similar to what is shown here, with
one row for each data node in the cluster (in this example, the cluster
has 4 data nodes):

     +---------+-----------+
     | node_id | hit_ratio |
     +---------+-----------+
     |       5 |   97.6744 |
     |       6 |   97.6879 |
     |       7 |   98.1776 |
     |       8 |   98.1343 |
     +---------+-----------+
     4 rows in set (0.00 sec)

'hit_ratio' values approaching 100% indicate that only a very small
number of reads are being made from disk rather than from the buffer,
which means that Disk Data read performance is approaching an optimum
level.  If any of these values are less than 95%, this is a strong
indicator that the setting for 'DiskPageBufferMemory' needs to be
increased in the 'config.ini' file.

*Note*:

A change in 'DiskPageBufferMemory' requires a rolling restart of all of
the cluster's data nodes before it takes effect.

The 'block_instance' column provides the NDB kernel block instance
number.  You can use this to obtain information about specific threads
from the *note 'threadblocks': mysql-cluster-ndbinfo-threadblocks.
table.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-logbuffers,  Next: mysql-cluster-ndbinfo-logspaces,  Prev: mysql-cluster-ndbinfo-diskpagebuffer,  Up: mysql-cluster-ndbinfo

18.5.10.9 The ndbinfo logbuffers Table
......................................

The 'logbuffer' table provides information on NDB Cluster log buffer
usage.

The following table provides information about the columns in the
'logbuffers' table.  For each column, the table shows the name, data
type, and a brief description.

*Columns in the logbuffers table*

Column Name            Type               Description
                                          
'node_id'              integer            The ID of this data node.
                                          
'log_type'             string             Type of log, one of: 'REDO' or
                                          'DD-UNDO'.
                                          
'log_id'               integer            The log ID.
                                          
'log_part'             integer            The log part number.
                                          
'total'                integer            Total space available for this
                                          log.
                                          
'used'                 integer            Space used by this log.
                       


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-logspaces,  Next: mysql-cluster-ndbinfo-membership,  Prev: mysql-cluster-ndbinfo-logbuffers,  Up: mysql-cluster-ndbinfo

18.5.10.10 The ndbinfo logspaces Table
......................................

This table provides information about NDB Cluster log space usage.

The following table provides information about the columns in the
'logspaces' table.  For each column, the table shows the name, data
type, and a brief description.

*Columns in the logspaces table*

Column Name            Type               Description
                                          
'node_id'              integer            The ID of this data node.
                                          
'log_type'             string             Type of log; one of: 'REDO' or
                                          'DD-UNDO'.
                                          
'log_id'               integer            The log ID.
                                          
'log_part'             integer            The log part number.
                                          
'total'                integer            Total space available for this
                                          log.
                                          
'used'                 integer            Space used by this log.
                       


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-membership,  Next: mysql-cluster-ndbinfo-memoryusage,  Prev: mysql-cluster-ndbinfo-logspaces,  Up: mysql-cluster-ndbinfo

18.5.10.11 The ndbinfo membership Table
.......................................

The 'membership' table describes the view that each data node has of all
the others in the cluster, including node group membership, president
node, arbitrator, arbitrator successor, arbitrator connection states,
and other information.

The following table provides information about the columns in the
'membership' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the membership table*

Column Name            Type               Description
                                          
'node_id'              integer            This node's node ID
                                          
'group_id'             integer            Node group to which this node
                                          belongs
                                          
'left node'            integer            Node ID of the previous node
                                          
'right_node'           integer            Node ID of the next node
                                          
'president'            integer            President's node ID
                                          
'successor'            integer            Node ID of successor to
                                          president
                                          
'succession_order'     integer            Order in which this node
                                          succeeds to presidency
                                          
'Conf_HB_order'        integer            -
                                          
'arbitrator'           integer            Node ID of arbitrator
                                          
'arb_ticket'           string             Internal identifier used to
                                          track arbitration
                                          
'arb_state'            Enumeration (see   Arbitration state
                       text)              
                       
'arb_connected'        'Yes' or 'No'      Whether this node is connected
                                          to the arbitrator
                                          
'connected_rank1_arbs' List of node IDs   Connected arbitrators of rank
                                          1
                                          
'connected_rank2_arbs' List of node IDs   Connected arbitrators of rank
                                          1

The node ID and node group ID are the same as reported by *note 'ndb_mgm
-e "SHOW"': mysql-cluster-programs-ndb-mgm.

'left_node' and 'right_node' are defined in terms of a model that
connects all data nodes in a circle, in order of their node IDs, similar
to the ordering of the numbers on a clock dial, as shown here:

FIGURE GOES HERE: Circular Arrangement of NDB Cluster Nodes

In this example, we have 8 data nodes, numbered 5, 6, 7, 8, 12, 13, 14,
and 15, ordered clockwise in a circle.  We determine 'left' and 'right'
from the interior of the circle.  The node to the left of node 5 is node
15, and the node to the right of node 5 is node 6.  You can see all
these relationships by running the following query and observing the
output:

     mysql> SELECT node_id,left_node,right_node
         -> FROM ndbinfo.membership;
     +---------+-----------+------------+
     | node_id | left_node | right_node |
     +---------+-----------+------------+
     |       5 |        15 |          6 |
     |       6 |         5 |          7 |
     |       7 |         6 |          8 |
     |       8 |         7 |         12 |
     |      12 |         8 |         13 |
     |      13 |        12 |         14 |
     |      14 |        13 |         15 |
     |      15 |        14 |          5 |
     +---------+-----------+------------+
     8 rows in set (0.00 sec)

The designations 'left' and 'right' are used in the event log in the
same way.

The 'president' node is the node viewed by the current node as
responsible for setting an arbitrator (see NDB Cluster Start Phases
(https://dev.mysql.com/doc/ndb-internals/en/ndb-internals-start-phases.html)).
If the president fails or becomes disconnected, the current node expects
the node whose ID is shown in the 'successor' column to become the new
president.  The 'succession_order' column shows the place in the
succession queue that the current node views itself as having.

In a normal NDB Cluster, all data nodes should see the same node as
'president', and the same node (other than the president) as its
'successor'.  In addition, the current president should see itself as
'1' in the order of succession, the 'successor' node should see itself
as '2', and so on.

All nodes should show the same 'arb_ticket' values as well as the same
'arb_state' values.  Possible 'arb_state' values are 'ARBIT_NULL',
'ARBIT_INIT', 'ARBIT_FIND', 'ARBIT_PREP1', 'ARBIT_PREP2', 'ARBIT_START',
'ARBIT_RUN', 'ARBIT_CHOOSE', 'ARBIT_CRASH', and 'UNKNOWN'.

'arb_connected' shows whether this node is connected to the node shown
as this node's 'arbitrator'.

The 'connected_rank1_arbs' and 'connected_rank2_arbs' columns each
display a list of 0 or more arbitrators having an 'ArbitrationRank'
equal to 1, or to 2, respectively.

*Note*:

Both management nodes and API nodes are eligible to become arbitrators.

Like the *note 'arbitrator_validity_detail':
mysql-cluster-ndbinfo-arbitrator-validity-detail. and *note
'arbitrator_validity_summary':
mysql-cluster-ndbinfo-arbitrator-validity-summary. tables, this table
was added in NDB 7.2.10.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-memoryusage,  Next: mysql-cluster-ndbinfo-nodes,  Prev: mysql-cluster-ndbinfo-membership,  Up: mysql-cluster-ndbinfo

18.5.10.12 The ndbinfo memoryusage Table
........................................

Querying this table provides information similar to that provided by the
'ALL REPORT MemoryUsage' command in the *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. client, or logged by 'ALL DUMP 1000'
(https://dev.mysql.com/doc/ndb-internals/en/dump-command-1000.html).

The following table provides information about the columns in the
'memoryusage' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the memoryusage table*

Column Name            Type               Description
                                          
'node_id'              integer            The node ID of this data node.
                                          
'memory_type'          string             One of 'Data memory', 'Index
                                          memory', or 'Long message
                                          buffer'.
                                          
'used'                 integer            Number of bytes currently used
                                          for data memory or index
                                          memory by this data node.
                                          
'used_pages'           integer            Number of pages currently used
                                          for data memory or index
                                          memory by this data node; see
                                          text.
                                          
'total'                integer            Total number of bytes of data
                                          memory or index memory
                                          available for this data node;
                                          see text.
                                          
'total_pages'          integer            Total number of memory pages
                                          available for data memory or
                                          index memory on this data
                                          node; see text.

The 'total' column represents the total amount of memory in bytes
available for the given resource (data memory or index memory) on a
particular data node.  This number should be approximately equal to the
setting of the corresponding configuration parameter in the 'config.ini'
file.

Suppose that the cluster has 2 data nodes having node IDs '5' and '6',
and the 'config.ini' file contains the following:

     [ndbd default]
     DataMemory = 1G
     IndexMemory = 1G

Suppose also that the value of the 'LongMessageBuffer' configuration
parameter is allowed to assume its default (64 MB in NDB 7.2.16 and
later).

The following query shows approximately the same values:

     mysql> SELECT node_id, memory_type, total
          > FROM ndbinfo.memoryusage;
     +---------+---------------------+------------+
     | node_id | memory_type         | total      |
     +---------+---------------------+------------+
     |       5 | Data memory         | 1073741824 |
     |       5 | Index memory        | 1074003968 |
     |       5 | Long message buffer |   67108864 |
     |       6 | Data memory         | 1073741824 |
     |       6 | Index memory        | 1074003968 |
     |       6 | Long message buffer |   67108864 |
     +---------+---------------------+------------+
     6 rows in set (0.00 sec)

In this case, the 'total' column values for index memory are slightly
higher than the value set of 'IndexMemory' due to internal rounding.

For the 'used_pages' and 'total_pages' columns, resources are measured
in pages, which are 32K in size for 'DataMemory' and 8K for
'IndexMemory'.  For long message buffer memory, the page size is 256
bytes.

Long message buffer information can be found in this table beginning
with NDB 7.2.16; in earlier versions of NDB Cluster 7.2, only data
memory and index memory were included.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-nodes,  Next: mysql-cluster-ndbinfo-resources,  Prev: mysql-cluster-ndbinfo-memoryusage,  Up: mysql-cluster-ndbinfo

18.5.10.13 The ndbinfo nodes Table
..................................

This table contains information on the status of data nodes.  For each
data node that is running in the cluster, a corresponding row in this
table provides the node's node ID, status, and uptime.  For nodes that
are starting, it also shows the current start phase.

The following table provides information about the columns in the
'nodes' table.  For each column, the table shows the name, data type,
and a brief description.  Additional information can be found in the
notes following the table.

*Columns of the nodes table*

Column Name            Type               Description
                                          
'node_id'              integer            The data node's unique node ID
                                          in the cluster.
                                          
'uptime'               integer            Time since the node was last
                                          started, in seconds.
                                          
'status'               string             Current status of the data
                                          node; see text for possible
                                          values.
                                          
'start_phase'          integer            If the data node is starting,
                                          the current start phase.
                                          
'config_generation'    integer            The version of the cluster
                                          configuration file in use on
                                          this data node.

The 'uptime' column shows the time in seconds that this node has been
running since it was last started or restarted.  This is a *note
'BIGINT': integer-types. value.  This figure includes the time actually
needed to start the node; in other words, this counter starts running
the moment that *note 'ndbd': mysql-cluster-programs-ndbd. or *note
'ndbmtd': mysql-cluster-programs-ndbmtd. is first invoked; thus, even
for a node that has not yet finished starting, 'uptime' may show a
nonzero value.

The 'status' column shows the node's current status.  This is one of:
'NOTHING', 'CMVMI', 'STARTING', 'STARTED', 'SINGLEUSER', 'STOPPING_1',
'STOPPING_2', 'STOPPING_3', or 'STOPPING_4'.  When the status is
'STARTING', you can see the current start phase in the 'start_phase'
column (see later in this section).  'SINGLEUSER' is displayed in the
'status' column for all data nodes when the cluster is in single user
mode (see *note mysql-cluster-single-user-mode::).  Seeing one of the
'STOPPING' states does not necessarily mean that the node is shutting
down but can mean rather that it is entering a new state.  For example,
if you put the cluster in single user mode, you can sometimes see data
nodes report their state briefly as 'STOPPING_2' before the status
changes to 'SINGLEUSER'.

The 'start_phase' column uses the same range of values as those used in
the output of the *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm.
client 'NODE_ID STATUS' command (see *note
mysql-cluster-mgm-client-commands::).  If the node is not currently
starting, then this column shows '0'.  For a listing of NDB Cluster
start phases with descriptions, see *note mysql-cluster-start-phases::.

The 'config_generation' column shows which version of the cluster
configuration is in effect on each data node.  This can be useful when
performing a rolling restart of the cluster in order to make changes in
configuration parameters.  For example, from the output of the following
*note 'SELECT': select. statement, you can see that node 3 is not yet
using the latest version of the cluster configuration ('6') although
nodes 1, 2, and 4 are doing so:

     mysql> USE ndbinfo;
     Database changed
     mysql> SELECT * FROM nodes;
     +---------+--------+---------+-------------+-------------------+
     | node_id | uptime | status  | start_phase | config_generation |
     +---------+--------+---------+-------------+-------------------+
     |       1 |  10462 | STARTED |           0 |                 6 |
     |       2 |  10460 | STARTED |           0 |                 6 |
     |       3 |  10457 | STARTED |           0 |                 5 |
     |       4 |  10455 | STARTED |           0 |                 6 |
     +---------+--------+---------+-------------+-------------------+
     2 rows in set (0.04 sec)

Therefore, for the case just shown, you should restart node 3 to
complete the rolling restart of the cluster.

Nodes that are stopped are not accounted for in this table.  Suppose
that you have an NDB Cluster with 4 data nodes (node IDs 1, 2, 3 and 4),
and all nodes are running normally, then this table contains 4 rows, 1
for each data node:

     mysql> USE ndbinfo;
     Database changed
     mysql> SELECT * FROM nodes;
     +---------+--------+---------+-------------+-------------------+
     | node_id | uptime | status  | start_phase | config_generation |
     +---------+--------+---------+-------------+-------------------+
     |       1 |  11776 | STARTED |           0 |                 6 |
     |       2 |  11774 | STARTED |           0 |                 6 |
     |       3 |  11771 | STARTED |           0 |                 6 |
     |       4 |  11769 | STARTED |           0 |                 6 |
     +---------+--------+---------+-------------+-------------------+
     4 rows in set (0.04 sec)

If you shut down one of the nodes, only the nodes that are still running
are represented in the output of this *note 'SELECT': select. statement,
as shown here:

     ndb_mgm> 2 STOP
     Node 2: Node shutdown initiated
     Node 2: Node shutdown completed.
     Node 2 has shutdown.

     mysql> SELECT * FROM nodes;
     +---------+--------+---------+-------------+-------------------+
     | node_id | uptime | status  | start_phase | config_generation |
     +---------+--------+---------+-------------+-------------------+
     |       1 |  11807 | STARTED |           0 |                 6 |
     |       3 |  11802 | STARTED |           0 |                 6 |
     |       4 |  11800 | STARTED |           0 |                 6 |
     +---------+--------+---------+-------------+-------------------+
     3 rows in set (0.02 sec)


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-resources,  Next: mysql-cluster-ndbinfo-server-operations,  Prev: mysql-cluster-ndbinfo-nodes,  Up: mysql-cluster-ndbinfo

18.5.10.14 The ndbinfo resources Table
......................................

This table provides information about data node resource availability
and usage.

These resources are sometimes known as _super-pools_.

The following table provides information about the columns in the
'resources' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the resources table*

Column Name            Type               Description
                                          
'node_id'              integer            The unique node ID of this
                                          data node.
                                          
'resource_name'        string             Name of the resource; see
                                          text.
                                          
'reserved'             integer            The amount reserved for this
                                          resource.
                                          
'used'                 integer            The amount actually used by
                                          this resource.
                                          
'max'                  integer            The maximum amount of this
                                          resource used, since the node
                                          was last started.

The 'resource_name' can be one of the names shown in the following
table:

*ndbinfo.resources table resource names and descriptions*

Resource name      Description
                   
'RESERVED'         Reserved by the system; cannot be overridden.
                   
'DISK_OPERATIONS'  If a log file group is allocated, the size of the
                   undo log buffer is used to set the size of this
                   resource.  This resource is used only to allocate
                   the undo log buffer for an undo log file group;
                   there can only be one such group.  Overallocation
                   occurs as needed by
                   *note 'CREATE LOGFILE GROUP': create-logfile-group.
                   
'DISK_RECORDS'     Records allocated for Disk Data operations.
                   
'DATA_MEMORY'      Used for main memory tuples, indexes, and hash
                   indexes.  Sum of DataMemory and IndexMemory, plus 8
                   pages of 32 KB each if IndexMemory has been set.
                   Cannot be overallocated.
                   
'JOBBUFFER'        Used for allocating job buffers by the NDB
                   scheduler; cannot be overallocated.  This is
                   approximately 2 MB per thread plus a 1 MB buffer in
                   both directions for all threads that can
                   communicate.  For large configurations this consume
                   several GB.
                   
'FILE_BUFFERS'     Used by the redo log handler in the 'DBLQH' kernel
                   block; cannot be overallocated.  Size is
                   'NoOfFragmentLogParts' * 'RedoBuffer', plus 1 MB per
                   log file part.
                   
'TRANSPORTER_BUFFERS'Used for send buffers by
                   *note 'ndbmtd': mysql-cluster-programs-ndbmtd.; the
                   sum of 'TotalSendBufferMemory' and
                   'ExtraSendBufferMemory'.  This resource that can be
                   overallocated by up to 25 percent.
                   'TotalSendBufferMemory' is calculated by summing the
                   send buffer memory per node, the default value of
                   which is 2 MB. Thus, in a system having four data
                   nodes and eight API nodes, the data nodes have 12 *
                   2 MB send buffer memory.  'ExtraSendBufferMemory' is
                   used by
                   *note 'ndbmtd': mysql-cluster-programs-ndbmtd. and
                   amounts to 2 MB extra memory per thread.  Thus, with
                   4 LDM threads, 2 TC threads, 1 main thread, 1
                   replication thread, and 2 receive threads,
                   'ExtraSendBufferMemory' is 10 * 2 MB. Overallocation
                   of this resource can be performed by setting the
                   'SharedGlobalMemory' data node configuration
                   parameter.
                   
'DISK_PAGE_BUFFER' Used for the disk page buffer; determined by the
                   'DiskPageBufferMemory' configuration parameter.
                   Cannot be overallocated.
                   
'QUERY_MEMORY'     Used by the 'DBSPJ' kernel block.
                   
'SCHEMA_TRANS_MEMORY'Minimum is 2 MB; can be overallocated to use any
                   remaining available memory.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-server-operations,  Next: mysql-cluster-ndbinfo-server-transactions,  Prev: mysql-cluster-ndbinfo-resources,  Up: mysql-cluster-ndbinfo

18.5.10.15 The ndbinfo server_operations Table
..............................................

The 'server_operations' table contains entries for all ongoing *note
'NDB': mysql-cluster. operations that the current SQL node (MySQL
Server) is currently involved in.  It effectively is a subset of the
*note 'cluster_operations': mysql-cluster-ndbinfo-cluster-operations.
table, in which operations for other SQL and API nodes are not shown.

The following table provides information about the columns in the
'server_operations' table.  For each column, the table shows the name,
data type, and a brief description.  Additional information can be found
in the notes following the table.

*Columns of the server_operations table*

Column Name            Type               Description
                                          
'mysql_connection_id'  integer            MySQL Server connection ID
                                          
'node_id'              integer            Node ID
                                          
'block_instance'       integer            Block instance
                                          
'transid'              integer            Transaction ID
                                          
'operation_type'       string             Operation type (see text for
                                          possible values)
                                          
'state'                string             Operation state (see text for
                                          possible values)
                                          
'tableid'              integer            Table ID
                                          
'fragmentid'           integer            Fragment ID
                                          
'client_node_id'       integer            Client node ID
                                          
'client_block_ref'     integer            Client block reference
                                          
'tc_node_id'           integer            Transaction coordinator node
                                          ID
                                          
'tc_block_no'          integer            Transaction coordinator block
                                          number
                                          
'tc_block_instance'    integer            Transaction coordinator block
                                          instance

The 'mysql_connection_id' is the same as the connection or session ID
shown in the output of *note 'SHOW PROCESSLIST': show-processlist.  It
is obtained from the 'INFORMATION_SCHEMA' table *note
'NDB_TRANSID_MYSQL_CONNECTION_MAP':
ndb-transid-mysql-connection-map-table.

'block_instance' refers to an instance of a kernel block.  Together with
the block name, this number can be used to look up a given instance in
the *note 'threadblocks': mysql-cluster-ndbinfo-threadblocks. table.

The transaction ID ('transid') is a unique 64-bit number which can be
obtained using the NDB API's 'getTransactionId()'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndbtransaction-gettransactionid.html)
method.  (Currently, the MySQL Server does not expose the NDB API
transaction ID of an ongoing transaction.)

The 'operation_type' column can take any one of the values 'READ',
'READ-SH', 'READ-EX', 'INSERT', 'UPDATE', 'DELETE', 'WRITE', 'UNLOCK',
'REFRESH', 'SCAN', 'SCAN-SH', 'SCAN-EX', or '<unknown>'.

The 'state' column can have any one of the values 'ABORT_QUEUED',
'ABORT_STOPPED', 'COMMITTED', 'COMMIT_QUEUED', 'COMMIT_STOPPED',
'COPY_CLOSE_STOPPED', 'COPY_FIRST_STOPPED', 'COPY_STOPPED',
'COPY_TUPKEY', 'IDLE', 'LOG_ABORT_QUEUED', 'LOG_COMMIT_QUEUED',
'LOG_COMMIT_QUEUED_WAIT_SIGNAL', 'LOG_COMMIT_WRITTEN',
'LOG_COMMIT_WRITTEN_WAIT_SIGNAL', 'LOG_QUEUED', 'PREPARED',
'PREPARED_RECEIVED_COMMIT', 'SCAN_CHECK_STOPPED', 'SCAN_CLOSE_STOPPED',
'SCAN_FIRST_STOPPED', 'SCAN_RELEASE_STOPPED', 'SCAN_STATE_USED',
'SCAN_STOPPED', 'SCAN_TUPKEY', 'STOPPED', 'TC_NOT_CONNECTED',
'WAIT_ACC', 'WAIT_ACC_ABORT', 'WAIT_AI_AFTER_ABORT', 'WAIT_ATTR',
'WAIT_SCAN_AI', 'WAIT_TUP', 'WAIT_TUPKEYINFO', 'WAIT_TUP_COMMIT', or
'WAIT_TUP_TO_ABORT'.  (If the MySQL Server is running with
'ndbinfo_show_hidden' enabled, you can view this list of states by
selecting from the 'ndb$dblqh_tcconnect_state' table, which is normally
hidden.)

You can obtain the name of an 'NDB' table from its table ID by checking
the output of *note 'ndb_show_tables':
mysql-cluster-programs-ndb-show-tables.

The 'fragid' is the same as the partition number seen in the output of
*note 'ndb_desc': mysql-cluster-programs-ndb-desc.
'--extra-partition-info' (short form '-p').

In 'client_node_id' and 'client_block_ref', 'client' refers to an NDB
Cluster API or SQL node (that is, an NDB API client or a MySQL Server
attached to the cluster).

The 'block_instance' and 'tc_block_instance' column provide NDB kernel
block instance numbers.  You can use these to obtain information about
specific threads from the *note 'threadblocks':
mysql-cluster-ndbinfo-threadblocks. table.

This table was added in NDB 7.2.2.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-server-transactions,  Next: mysql-cluster-ndbinfo-threadblocks,  Prev: mysql-cluster-ndbinfo-server-operations,  Up: mysql-cluster-ndbinfo

18.5.10.16 The ndbinfo server_transactions Table
................................................

The 'server_transactions' table is subset of the *note
'cluster_transactions': mysql-cluster-ndbinfo-cluster-transactions.
table, but includes only those transactions in which the current SQL
node (MySQL Server) is a participant, while including the relevant
connection IDs.

The following table provides information about the columns in the
'server_transactions' table.  For each column, the table shows the name,
data type, and a brief description.  Additional information can be found
in the notes following the table.

*Columns of the server_transactions table*

Column Name            Type               Description
                                          
'mysql_connection_id'  integer            MySQL Server connection ID
                                          
'node_id'              integer            Transaction coordinator node
                                          ID
                                          
'block_instance'       integer            Transaction coordinator block
                                          instance
                                          
'transid'              integer            Transaction ID
                                          
'state'                string             Operation state (see text for
                                          possible values)
                                          
'count_operations'     integer            Number of stateful operations
                                          in the transaction
                                          
'outstanding_operations'integer           Operations still being
                                          executed by local data
                                          management layer (LQH blocks)
                                          
'inactive_seconds'     integer            Time spent waiting for API
                                          
'client_node_id'       integer            Client node ID
                                          
'client_block_ref'     integer            Client block reference
                       

The 'mysql_connection_id' is the same as the connection or session ID
shown in the output of *note 'SHOW PROCESSLIST': show-processlist.  It
is obtained from the 'INFORMATION_SCHEMA' table *note
'NDB_TRANSID_MYSQL_CONNECTION_MAP':
ndb-transid-mysql-connection-map-table.

'block_instance' refers to an instance of a kernel block.  Together with
the block name, this number can be used to look up a given instance in
the *note 'threadblocks': mysql-cluster-ndbinfo-threadblocks. table.

The transaction ID ('transid') is a unique 64-bit number which can be
obtained using the NDB API's 'getTransactionId()'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndbtransaction-gettransactionid.html)
method.  (Currently, the MySQL Server does not expose the NDB API
transaction ID of an ongoing transaction.)

The 'state' column can have any one of the values 'CS_ABORTING',
'CS_COMMITTING', 'CS_COMMIT_SENT', 'CS_COMPLETE_SENT', 'CS_COMPLETING',
'CS_CONNECTED', 'CS_DISCONNECTED', 'CS_FAIL_ABORTED',
'CS_FAIL_ABORTING', 'CS_FAIL_COMMITTED', 'CS_FAIL_COMMITTING',
'CS_FAIL_COMPLETED', 'CS_FAIL_PREPARED', 'CS_PREPARE_TO_COMMIT',
'CS_RECEIVING', 'CS_REC_COMMITTING', 'CS_RESTART',
'CS_SEND_FIRE_TRIG_REQ', 'CS_STARTED', 'CS_START_COMMITTING',
'CS_START_SCAN', 'CS_WAIT_ABORT_CONF', 'CS_WAIT_COMMIT_CONF',
'CS_WAIT_COMPLETE_CONF', 'CS_WAIT_FIRE_TRIG_REQ'.  (If the MySQL Server
is running with 'ndbinfo_show_hidden' enabled, you can view this list of
states by selecting from the 'ndb$dbtc_apiconnect_state' table, which is
normally hidden.)

In 'client_node_id' and 'client_block_ref', 'client' refers to an NDB
Cluster API or SQL node (that is, an NDB API client or a MySQL Server
attached to the cluster).

The 'block_instance' column provides the 'DBTC' kernel block instance
number.  You can use this to obtain information about specific threads
from the *note 'threadblocks': mysql-cluster-ndbinfo-threadblocks.
table.

This table was added in NDB 7.2.2.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-threadblocks,  Next: mysql-cluster-ndbinfo-threadstat,  Prev: mysql-cluster-ndbinfo-server-transactions,  Up: mysql-cluster-ndbinfo

18.5.10.17 The ndbinfo threadblocks Table
.........................................

The 'threadblocks' table associates data nodes, threads, and instances
of 'NDB' kernel blocks.

The following table provides information about the columns in the
'threadblocks' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the threadblocks table*

Column Name            Type               Description
                                          
'node_id'              integer            Node ID
                                          
'thr_no'               integer            Thread ID
                                          
'block_name'           string             Block name
                                          
'block_instance'       integer            Block instance number
                       

The value of the 'block_name' in this table is one of the values found
in the 'block_name' column when selecting from the *note
'ndbinfo.blocks': mysql-cluster-ndbinfo-blocks. table.  Although the
list of possible values is static for a given NDB Cluster release, the
list may vary between releases.

The 'block_instance' column provides the kernel block instance number.

This table was added in NDB 7.2.2.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-threadstat,  Next: mysql-cluster-ndbinfo-transporters,  Prev: mysql-cluster-ndbinfo-threadblocks,  Up: mysql-cluster-ndbinfo

18.5.10.18 The ndbinfo threadstat Table
.......................................

The 'threadstat' table provides a rough snapshot of statistics for
threads running in the 'NDB' kernel.

The following table provides information about the columns in the
'threadstat' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the threadstat table*

Column Name            Type               Description
                                          
'node_id'              integer            Node ID
                                          
'thr_no'               integer            Thread ID
                                          
'thr_nm'               string             Thread name
                                          
'c_loop'               string             Number of loops in main loop
                                          
'c_exec'               string             Number of signals executed
                                          
'c_wait'               string             Number of times waiting for
                                          additional input
                                          
'c_l_sent_prioa'       integer            Number of priority A signals
                                          sent to own node
                                          
'c_l_sent_priob'       integer            Number of priority B signals
                                          sent to own node
                                          
'c_r_sent_prioa'       integer            Number of priority A signals
                                          sent to remote node
                                          
'c_r_sent_priob'       integer            Number of priority B signals
                                          sent to remote node
                                          
'os_tid'               integer            OS thread ID
                                          
'os_now'               integer            OS time (ms)
                                          
'os_ru_utime'          integer            OS user CPU time (s)
                                          
'os_ru_stime'          integer            OS system CPU time (s)
                                          
'os_ru_minflt'         integer            OS page reclaims (soft page
                                          faults)
                                          
'os_ru_majflt'         integer            OS page faults (hard page
                                          faults)
                                          
'os_ru_nvcsw'          integer            OS voluntary context switches
                                          
'os_ru_nivcsw'         integer            OS involuntary context
                                          switches

'os_time' uses the system 'gettimeofday()' call.

The values of the 'os_ru_utime', 'os_ru_stime', 'os_ru_minflt',
'os_ru_majflt', 'os_ru_nvcsw', and 'os_ru_nivcsw' columns are obtained
using the system 'getrusage()' call, or the equivalent.

Since this table contains counts taken at a given point in time, for
best results it is necessary to query this table periodically and store
the results in an intermediate table or tables.  The MySQL Server's
Event Scheduler can be employed to automate such monitoring.  For more
information, see *note event-scheduler::.

This table was added in NDB 7.2.2.


File: manual.info.tmp,  Node: mysql-cluster-ndbinfo-transporters,  Prev: mysql-cluster-ndbinfo-threadstat,  Up: mysql-cluster-ndbinfo

18.5.10.19 The ndbinfo transporters Table
.........................................

This table contains information about NDB transporters.

The following table provides information about the columns in the
'transporters' table.  For each column, the table shows the name, data
type, and a brief description.  Additional information can be found in
the notes following the table.

*Columns of the transporters table*

Column Name            Type               Description
                                          
'node_id'              integer            This data node's unique node
                                          ID in the cluster
                                          
'remote_node_id'       integer            The remote data node's node ID
                                          
'status'               string             Status of the connection
                                          
'remote_address'       string             Name or IP address of the
                                          remote host
                                          
'bytes_sent'           integer            Number of bytes sent using
                                          this connection
                                          
'bytes_received'       integer            Number of bytes received using
                                          this connection
                                          
'connect_count'        integer            Number of times connection
                                          established on this
                                          transporter
                                          
'overloaded'           boolean (0 or 1)   1 if this transporter is
                                          currently overloaded,
                                          otherwise 0
                                          
'overload_count'       integer            Number of times this
                                          transporter has entered
                                          overload state since
                                          connecting
                                          
'slowdown'             boolean (0 or 1)   1 if this transporter is in
                                          slowdown state, otherwise 0
                                          
'slowdown_count'       integer            Number of times this
                                          transporter has entered
                                          slowdown state since
                                          connecting

For each running data node in the cluster, the 'transporters' table
displays a row showing the status of each of that node's connections
with all nodes in the cluster, _including itself_.  This information is
shown in the table's _status_ column, which can have any one of the
following values: 'CONNECTING', 'CONNECTED', 'DISCONNECTING', or
'DISCONNECTED'.

Connections to API and management nodes which are configured but not
currently connected to the cluster are shown with status 'DISCONNECTED'.
Rows where the 'node_id' is that of a data node which is not currently
connected are not shown in this table.  (This is similar omission of
disconnected nodes in the *note 'ndbinfo.nodes':
mysql-cluster-ndbinfo-nodes. table.

The 'remote_address', 'bytes_sent', and 'bytes_received' columns were
added in NDB 7.2.9.  The 'remote_address' is the host name or address
for the node whose ID is shown in the 'remote_node_id' column.  The
'bytes_sent' from this node and 'bytes_received' by this node are the
numbers, respectively, of bytes sent and received by the node using this
connection since it was established.  For nodes whose status is
'CONNECTING' or 'DISCONNECTED', these columns always display '0'.

Assume you have a 5-node cluster consisting of 2 data nodes, 2 SQL
nodes, and 1 management node, as shown in the output of the 'SHOW'
command in the *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. client:

     ndb_mgm> SHOW
     Connected to Management Server at: localhost:1186
     Cluster Configuration
     ---------------------
     [ndbd(NDB)]     2 node(s)
     id=1    @10.100.10.1  (5.5.65-ndb-7.2.39, Nodegroup: 0, *)
     id=2    @10.100.10.2  (5.5.65-ndb-7.2.39, Nodegroup: 0)

     [ndb_mgmd(MGM)] 1 node(s)
     id=10   @10.100.10.10  (5.5.65-ndb-7.2.39)

     [mysqld(API)]   2 node(s)
     id=20   @10.100.10.20  (5.5.65-ndb-7.2.39)
     id=21   @10.100.10.21  (5.5.65-ndb-7.2.39)

There are 10 rows in the 'transporters' table--5 for the first data
node, and 5 for the second--assuming that all data nodes are running, as
shown here:

     mysql> SELECT node_id, remote_node_id, status
         ->   FROM ndbinfo.transporters;
     +---------+----------------+---------------+
     | node_id | remote_node_id | status        |
     +---------+----------------+---------------+
     |       1 |              1 | DISCONNECTED  |
     |       1 |              2 | CONNECTED     |
     |       1 |             10 | CONNECTED     |
     |       1 |             20 | CONNECTED     |
     |       1 |             21 | CONNECTED     |
     |       2 |              1 | CONNECTED     |
     |       2 |              2 | DISCONNECTED  |
     |       2 |             10 | CONNECTED     |
     |       2 |             20 | CONNECTED     |
     |       2 |             21 | CONNECTED     |
     +---------+----------------+---------------+
     10 rows in set (0.04 sec)

If you shut down one of the data nodes in this cluster using the command
'2 STOP' in the *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. client,
then repeat the previous query (again using the *note 'mysql': mysql.
client), this table now shows only 5 rows--1 row for each connection
from the remaining management node to another node, including both
itself and the data node that is currently offline--and displays
'CONNECTING' for the status of each remaining connection to the data
node that is currently offline, as shown here:

     mysql> SELECT node_id, remote_node_id, status
         ->   FROM ndbinfo.transporters;
     +---------+----------------+---------------+
     | node_id | remote_node_id | status        |
     +---------+----------------+---------------+
     |       1 |              1 | DISCONNECTED  |
     |       1 |              2 | CONNECTING    |
     |       1 |             10 | CONNECTED     |
     |       1 |             20 | CONNECTED     |
     |       1 |             21 | CONNECTED     |
     +---------+----------------+---------------+
     5 rows in set (0.02 sec)

The 'connect_count', 'overloaded', 'overload_count' ,'slowdown', and
'slowdown_count' columns were added in NDB 7.2.10.  These counters are
reset on connection, and retain their values after the remote node
disconnects.  Also beginning with NDB 7.2.10, the 'bytes_send' and
'bytes_received' counters are reset on connection as well, and so retain
their values following disconnection.  (Previously, the values in these
columns were reset on disconnection.)  (Bug #15935206)

The _overload_ state referred to by the 'overloaded' and
'overload_count' columns occurs when this transporter's send buffer
contains more than 'OVerloadLimit' bytes (default is 80% of
'SendBufferMemory', that is, 0.8 * 2097152 = 1677721 bytes).  When a
given transporter is in a state of overload, any new transaction that
tries to use this transporter fails with Error 1218 ('Send Buffers
overloaded in NDB kernel').  This affects both scans and primary key
operations.

The _slowdown_ state referenced by the 'slowdown' and 'slowdown_count'
columns of this table occurs when the transporter's send buffer contains
more than 60% of the overload limit (equal to 0.6 * 2097152 = 1258291
bytes by default).  In this state, any new scan using this transporter
has its batch size reduced to minimize the load on the transporter.

Common causes of send buffer slowdown or overloading include the
following:

   * Data size, in particular the quantity of data stored in *note
     'TEXT': blob. columns or *note 'BLOB': blob. columns (or both types
     of columns)

   * Having a data node (ndbd or ndbmtd) on the same host as an SQL node
     that is engaged in binary logging

   * Large number of rows per transaction or transaction batch

   * Configuration issues such as insufficient 'SendBufferMemory'

   * Hardware issues such as insufficient RAM or poor network
     connectivity

See also *note mysql-cluster-config-send-buffers::.


File: manual.info.tmp,  Node: mysql-cluster-security,  Next: mysql-cluster-disk-data,  Prev: mysql-cluster-ndbinfo,  Up: mysql-cluster-management

18.5.11 NDB Cluster Security Issues
-----------------------------------

* Menu:

* mysql-cluster-security-networking-issues::  NDB Cluster Security and Networking Issues
* mysql-cluster-security-mysql-privileges::  NDB Cluster and MySQL Privileges
* mysql-cluster-security-mysql-security-procedures::  NDB Cluster and MySQL Security Procedures

This section discusses security considerations to take into account when
setting up and running NDB Cluster.

Topics covered in this section include the following:

   * NDB Cluster and network security issues

   * Configuration issues relating to running NDB Cluster securely

   * NDB Cluster and the MySQL privilege system

   * MySQL standard security procedures as applicable to NDB Cluster


File: manual.info.tmp,  Node: mysql-cluster-security-networking-issues,  Next: mysql-cluster-security-mysql-privileges,  Prev: mysql-cluster-security,  Up: mysql-cluster-security

18.5.11.1 NDB Cluster Security and Networking Issues
....................................................

In this section, we discuss basic network security issues as they relate
to NDB Cluster.  It is extremely important to remember that NDB Cluster
'out of the box' is not secure; you or your network administrator must
take the proper steps to ensure that your cluster cannot be compromised
over the network.

Cluster communication protocols are inherently insecure, and no
encryption or similar security measures are used in communications
between nodes in the cluster.  Because network speed and latency have a
direct impact on the cluster's efficiency, it is also not advisable to
employ SSL or other encryption to network connections between nodes, as
such schemes will effectively slow communications.

It is also true that no authentication is used for controlling API node
access to an NDB Cluster.  As with encryption, the overhead of imposing
authentication requirements would have an adverse impact on Cluster
performance.

In addition, there is no checking of the source IP address for either of
the following when accessing the cluster:

   * SQL or API nodes using 'free slots' created by empty '[mysqld]' or
     '[api]' sections in the 'config.ini' file

     This means that, if there are any empty '[mysqld]' or '[api]'
     sections in the 'config.ini' file, then any API nodes (including
     SQL nodes) that know the management server's host name (or IP
     address) and port can connect to the cluster and access its data
     without restriction.  (See *note
     mysql-cluster-security-mysql-privileges::, for more information
     about this and related issues.)

     *Note*:

     You can exercise some control over SQL and API node access to the
     cluster by specifying a 'HostName' parameter for all '[mysqld]' and
     '[api]' sections in the 'config.ini' file.  However, this also
     means that, should you wish to connect an API node to the cluster
     from a previously unused host, you need to add an '[api]' section
     containing its host name to the 'config.ini' file.

     More information is available elsewhere in this chapter about the
     'HostName' parameter.  Also see *note mysql-cluster-quick::, for
     configuration examples using 'HostName' with API nodes.

   * Any *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. client

     This means that any cluster management client that is given the
     management server's host name (or IP address) and port (if not the
     standard port) can connect to the cluster and execute any
     management client command.  This includes commands such as 'ALL
     STOP' and 'SHUTDOWN'.

For these reasons, it is necessary to protect the cluster on the network
level.  The safest network configuration for Cluster is one which
isolates connections between Cluster nodes from any other network
communications.  This can be accomplished by any of the following
methods:

  1. Keeping Cluster nodes on a network that is physically separate from
     any public networks.  This option is the most dependable; however,
     it is the most expensive to implement.

     We show an example of an NDB Cluster setup using such a physically
     segregated network here:

     FIGURE GOES HERE: NDB Cluster with Hardware Firewall

     This setup has two networks, one private (solid box) for the
     Cluster management servers and data nodes, and one public (dotted
     box) where the SQL nodes reside.  (We show the management and data
     nodes connected using a gigabit switch since this provides the best
     performance.)  Both networks are protected from the outside by a
     hardware firewall, sometimes also known as a _network-based
     firewall_.

     This network setup is safest because no packets can reach the
     cluster's management or data nodes from outside the network--and
     none of the cluster's internal communications can reach the
     outside--without going through the SQL nodes, as long as the SQL
     nodes do not permit any packets to be forwarded.  This means, of
     course, that all SQL nodes must be secured against hacking
     attempts.

     *Important*:

     With regard to potential security vulnerabilities, an SQL node is
     no different from any other MySQL server.  See *note
     security-against-attack::, for a description of techniques you can
     use to secure MySQL servers.

  2. 
     Using one or more software firewalls (also known as _host-based
     firewalls_) to control which packets pass through to the cluster
     from portions of the network that do not require access to it.  In
     this type of setup, a software firewall must be installed on every
     host in the cluster which might otherwise be accessible from
     outside the local network.

     The host-based option is the least expensive to implement, but
     relies purely on software to provide protection and so is the most
     difficult to keep secure.

     This type of network setup for NDB Cluster is illustrated here:

     FIGURE GOES HERE: NDB Cluster with Software Firewalls

     Using this type of network setup means that there are two zones of
     NDB Cluster hosts.  Each cluster host must be able to communicate
     with all of the other machines in the cluster, but only those
     hosting SQL nodes (dotted box) can be permitted to have any contact
     with the outside, while those in the zone containing the data nodes
     and management nodes (solid box) must be isolated from any machines
     that are not part of the cluster.  Applications using the cluster
     and user of those applications must _not_ be permitted to have
     direct access to the management and data node hosts.

     To accomplish this, you must set up software firewalls that limit
     the traffic to the type or types shown in the following table,
     according to the type of node that is running on each cluster host
     computer:

     *Node types in a host-based firewall cluster configuration*

     Node Type          Permitted Traffic
                        
     SQL or API node    
                           * It originates from the IP address of a
                             management or data node (using any TCP or UDP
                             port).
                        
                           * It originates from within the network in which
                             the cluster resides and is on the port that
                             your application is using.
                        
     Data node or       
     Management node       * It originates from the IP address of a
                             management or data node (using any TCP or UDP
                             port).
                        
                           * It originates from the IP address of an SQL or
                             API node.

     Any traffic other than that shown in the table for a given node
     type should be denied.

     The specifics of configuring a firewall vary from firewall
     application to firewall application, and are beyond the scope of
     this Manual.  'iptables' is a very common and reliable firewall
     application, which is often used with 'APF' as a front end to make
     configuration easier.  You can (and should) consult the
     documentation for the software firewall that you employ, should you
     choose to implement an NDB Cluster network setup of this type, or
     of a 'mixed' type as discussed under the next item.

  3. 
     It is also possible to employ a combination of the first two
     methods, using both hardware and software to secure the
     cluster--that is, using both network-based and host-based
     firewalls.  This is between the first two schemes in terms of both
     security level and cost.  This type of network setup keeps the
     cluster behind the hardware firewall, but permits incoming packets
     to travel beyond the router connecting all cluster hosts to reach
     the SQL nodes.

     One possible network deployment of an NDB Cluster using hardware
     and software firewalls in combination is shown here:

     FIGURE GOES HERE: NDB Cluster with a Combination of Hardware and
     Software Firewalls

     In this case, you can set the rules in the hardware firewall to
     deny any external traffic except to SQL nodes and API nodes, and
     then permit traffic to them only on the ports required by your
     application.

Whatever network configuration you use, remember that your objective
from the viewpoint of keeping the cluster secure remains the same--to
prevent any unessential traffic from reaching the cluster while ensuring
the most efficient communication between the nodes in the cluster.

Because NDB Cluster requires large numbers of ports to be open for
communications between nodes, the recommended option is to use a
segregated network.  This represents the simplest way to prevent
unwanted traffic from reaching the cluster.

*Note*:

If you wish to administer an NDB Cluster remotely (that is, from outside
the local network), the recommended way to do this is to use 'ssh' or
another secure login shell to access an SQL node host.  From this host,
you can then run the management client to access the management server
safely, from within the Cluster's own local network.

Even though it is possible to do so in theory, it is _not_ recommended
to use *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. to manage a
Cluster directly from outside the local network on which the Cluster is
running.  Since neither authentication nor encryption takes place
between the management client and the management server, this represents
an extremely insecure means of managing the cluster, and is almost
certain to be compromised sooner or later.


File: manual.info.tmp,  Node: mysql-cluster-security-mysql-privileges,  Next: mysql-cluster-security-mysql-security-procedures,  Prev: mysql-cluster-security-networking-issues,  Up: mysql-cluster-security

18.5.11.2 NDB Cluster and MySQL Privileges
..........................................

In this section, we discuss how the MySQL privilege system works in
relation to NDB Cluster and the implications of this for keeping an NDB
Cluster secure.

Standard MySQL privileges apply to NDB Cluster tables.  This includes
all MySQL privilege types ('SELECT' privilege, 'UPDATE' privilege,
'DELETE' privilege, and so on) granted on the database, table, and
column level.  As with any other MySQL Server, user and privilege
information is stored in the 'mysql' system database.  The SQL
statements used to grant and revoke privileges on *note 'NDB':
mysql-cluster. tables, databases containing such tables, and columns
within such tables are identical in all respects with the *note 'GRANT':
grant. and *note 'REVOKE': revoke. statements used in connection with
database objects involving any (other) MySQL storage engine.  The same
thing is true with respect to the *note 'CREATE USER': create-user. and
*note 'DROP USER': drop-user. statements.

It is important to keep in mind that, by default, the MySQL grant tables
use the *note 'MyISAM': myisam-storage-engine. storage engine.  Because
of this, those tables are not normally duplicated or shared among MySQL
servers acting as SQL nodes in an NDB Cluster.  In other words, changes
in users and their privileges do not automatically propagate between SQL
nodes by default.  In NDB Cluster 7.2 (and later), you can enable
automatic distribution of MySQL users and privileges across NDB Cluster
SQL nodes; see *note mysql-cluster-privilege-distribution::, for
details.

Conversely, because there is no way in MySQL to deny privileges
(privileges can either be revoked or not granted in the first place, but
not denied as such), there is no special protection for *note 'NDB':
mysql-cluster. tables on one SQL node from users that have privileges on
another SQL node; (This is true even if you are not using automatic
distribution of user privileges.  The definitive example of this is the
MySQL 'root' account, which can perform any action on any database
object.  In combination with empty '[mysqld]' or '[api]' sections of the
'config.ini' file, this account can be especially dangerous.  To
understand why, consider the following scenario:

   * The 'config.ini' file contains at least one empty '[mysqld]' or
     '[api]' section.  This means that the NDB Cluster management server
     performs no checking of the host from which a MySQL Server (or
     other API node) accesses the NDB Cluster.

   * There is no firewall, or the firewall fails to protect against
     access to the NDB Cluster from hosts external to the network.

   * The host name or IP address of the NDB Cluster management server is
     known or can be determined from outside the network.

If these conditions are true, then anyone, anywhere can start a MySQL
Server with '--ndbcluster' '--ndb-connectstring=MANAGEMENT_HOST' and
access this NDB Cluster.  Using the MySQL 'root' account, this person
can then perform the following actions:

   * Execute metadata statements such as *note 'SHOW DATABASES':
     show-databases. statement (to obtain a list of all *note 'NDB':
     mysql-cluster. databases on the server) or *note 'SHOW TABLES FROM
     SOME_NDB_DATABASE': show-tables. statement to obtain a list of all
     *note 'NDB': mysql-cluster. tables in a given database

   * 
     Run any legal MySQL statements on any of the discovered tables,
     such as:

        * 'SELECT * FROM SOME_TABLE' to read all the data from any table

        * 'DELETE FROM SOME_TABLE' to delete all the data from a table

        * 'DESCRIBE SOME_TABLE' or 'SHOW CREATE TABLE SOME_TABLE' to
          determine the table schema

        * 'UPDATE SOME_TABLE SET COLUMN1 = SOME_VALUE' to fill a table
          column with 'garbage' data; this could actually cause much
          greater damage than simply deleting all the data

          More insidious variations might include statements like these:

               UPDATE SOME_TABLE SET AN_INT_COLUMN = AN_INT_COLUMN + 1

          or

               UPDATE SOME_TABLE SET A_VARCHAR_COLUMN = REVERSE(A_VARCHAR_COLUMN)

          Such malicious statements are limited only by the imagination
          of the attacker.

     The only tables that would be safe from this sort of mayhem would
     be those tables that were created using storage engines other than
     *note 'NDB': mysql-cluster, and so not visible to a 'rogue' SQL
     node.

     A user who can log in as 'root' can also access the
     'INFORMATION_SCHEMA' database and its tables, and so obtain
     information about databases, tables, stored routines, scheduled
     events, and any other database objects for which metadata is stored
     in 'INFORMATION_SCHEMA'.

     It is also a very good idea to use different passwords for the
     'root' accounts on different NDB Cluster SQL nodes unless you are
     using distributed privileges.

In sum, you cannot have a safe NDB Cluster if it is directly accessible
from outside your local network.

*Important*:

_Never leave the MySQL root account password empty_.  This is just as
true when running MySQL as an NDB Cluster SQL node as it is when running
it as a standalone (non-Cluster) MySQL Server, and should be done as
part of the MySQL installation process before configuring the MySQL
Server as an SQL node in an NDB Cluster.

Prior to NDB Cluster 7.2, you should never convert the system tables in
the 'mysql' database to use the *note 'NDB': mysql-cluster. storage
engine.  There are a number of reasons why you should not do this, but
the most important reason is this: _Many of the SQL statements that
affect 'mysql' tables storing information about user privileges, stored
routines, scheduled events, and other database objects cease to function
if these tables are changed to use any storage engine other than
'MyISAM'_.  This is a consequence of various MySQL Server internals.
Beginning with NDB Cluster 7.2, you can use a stored procedure provided
for this purpose (see *note mysql-cluster-privilege-distribution::), but
you are strongly advised not to attempt convert the system tables
manually.

Otherwise, if you need to synchronize 'mysql' system tables between SQL
nodes, you can use standard MySQL replication to do so, or employ a
script to copy table entries between the MySQL servers.

Summary

The most important points to remember regarding the MySQL privilege
system with regard to NDB Cluster are listed here:

  1. Users and privileges established on one SQL node do not
     automatically exist or take effect on other SQL nodes in the
     cluster.  Conversely, removing a user or privilege on one SQL node
     in the cluster does not remove the user or privilege from any other
     SQL nodes.

  2. You can distribute MySQL users and privileges among SQL nodes using
     the SQL script, and the stored procedures it contains, that are
     supplied for this purpose in the NDB Cluster distribution.

  3. Once a MySQL user is granted privileges on an *note 'NDB':
     mysql-cluster. table from one SQL node in an NDB Cluster, that user
     can 'see' any data in that table regardless of the SQL node from
     which the data originated, even if you are not using privilege
     distribution.


File: manual.info.tmp,  Node: mysql-cluster-security-mysql-security-procedures,  Prev: mysql-cluster-security-mysql-privileges,  Up: mysql-cluster-security

18.5.11.3 NDB Cluster and MySQL Security Procedures
...................................................

In this section, we discuss MySQL standard security procedures as they
apply to running NDB Cluster.

In general, any standard procedure for running MySQL securely also
applies to running a MySQL Server as part of an NDB Cluster.  First and
foremost, you should always run a MySQL Server as the 'mysql' operating
system user; this is no different from running MySQL in a standard
(non-Cluster) environment.  The 'mysql' system account should be
uniquely and clearly defined.  Fortunately, this is the default behavior
for a new MySQL installation.  You can verify that the *note 'mysqld':
mysqld. process is running as the 'mysql' operating system user by using
the system command such as the one shown here:

     shell> ps aux | grep mysql
     root     10467  0.0  0.1   3616  1380 pts/3    S    11:53   0:00 \
       /bin/sh ./mysqld_safe --ndbcluster --ndb-connectstring=localhost:1186
     mysql    10512  0.2  2.5  58528 26636 pts/3    Sl   11:53   0:00 \
       /usr/local/mysql/libexec/mysqld --basedir=/usr/local/mysql \
       --datadir=/usr/local/mysql/var --user=mysql --ndbcluster \
       --ndb-connectstring=localhost:1186 --pid-file=/usr/local/mysql/var/mothra.pid \
       --log-error=/usr/local/mysql/var/mothra.err
     jon      10579  0.0  0.0   2736   688 pts/0    S+   11:54   0:00 grep mysql

If the *note 'mysqld': mysqld. process is running as any other user than
'mysql', you should immediately shut it down and restart it as the
'mysql' user.  If this user does not exist on the system, the 'mysql'
user account should be created, and this user should be part of the
'mysql' user group; in this case, you should also make sure that the
MySQL data directory on this system (as set using the '--datadir' option
for *note 'mysqld': mysqld.) is owned by the 'mysql' user, and that the
SQL node's 'my.cnf' file includes 'user=mysql' in the '[mysqld]'
section.  Alternatively, you can start the MySQL server process with
'--user=mysql' on the command line, but it is preferable to use the
'my.cnf' option, since you might forget to use the command-line option
and so have *note 'mysqld': mysqld. running as another user
unintentionally.  The *note 'mysqld_safe': mysqld-safe. startup script
forces MySQL to run as the 'mysql' user.

*Important*:

Never run *note 'mysqld': mysqld. as the system root user.  Doing so
means that potentially any file on the system can be read by MySQL, and
thus--should MySQL be compromised--by an attacker.

As mentioned in the previous section (see *note
mysql-cluster-security-mysql-privileges::), you should always set a root
password for the MySQL Server as soon as you have it running.  You
should also delete the anonymous user account that is installed by
default.  You can accomplish these tasks using the following statements:

     shell> mysql -u root

     mysql> UPDATE mysql.user
         ->     SET Password=PASSWORD('SECURE_PASSWORD')
         ->     WHERE User='root';

     mysql> DELETE FROM mysql.user
         ->     WHERE User='';

     mysql> FLUSH PRIVILEGES;

Be very careful when executing the *note 'DELETE': delete. statement not
to omit the 'WHERE' clause, or you risk deleting _all_ MySQL users.  Be
sure to run the 'FLUSH PRIVILEGES' statement as soon as you have
modified the 'mysql.user' table, so that the changes take immediate
effect.  Without 'FLUSH PRIVILEGES', the changes do not take effect
until the next time that the server is restarted.

*Note*:

Many of the NDB Cluster utilities such as *note 'ndb_show_tables':
mysql-cluster-programs-ndb-show-tables, *note 'ndb_desc':
mysql-cluster-programs-ndb-desc, and *note 'ndb_select_all':
mysql-cluster-programs-ndb-select-all. also work without authentication
and can reveal table names, schemas, and data.  By default these are
installed on Unix-style systems with the permissions 'wxr-xr-x' (755),
which means they can be executed by any user that can access the
'mysql/bin' directory.

See *note mysql-cluster-programs::, for more information about these
utilities.


File: manual.info.tmp,  Node: mysql-cluster-disk-data,  Next: mysql-cluster-online-operations,  Prev: mysql-cluster-security,  Up: mysql-cluster-management

18.5.12 NDB Cluster Disk Data Tables
------------------------------------

* Menu:

* mysql-cluster-disk-data-objects::  NDB Cluster Disk Data Objects
* mysql-cluster-disk-data-symlinks::  Using Symbolic Links with Disk Data Objects
* mysql-cluster-disk-data-storage-requirements::  NDB Cluster Disk Data Storage Requirements

It is possible to store the nonindexed columns of *note 'NDB':
mysql-cluster. tables on disk, rather than in RAM.

As part of implementing NDB Cluster Disk Data work, a number of
improvements were made in NDB Cluster for the efficient handling of very
large amounts (terabytes) of data during node recovery and restart.
These include a 'no-steal' algorithm for synchronizing a starting node
with very large data sets.  For more information, see the paper
'Recovery Principles of NDB Cluster 5.1
(http://www.vldb2005.org/program/paper/wed/p1108-ronstrom.pdf)', by NDB
Cluster developers Mikael Ronstro"m and Jonas Oreland.

NDB Cluster Disk Data performance can be influenced by a number of
configuration parameters.  For information about these parameters and
their effects, see 'NDB Cluster Disk Data configuration parameters' and
'NDB Cluster Disk Data storage and 'GCP Stop' errors'

The performance of an NDB Cluster that uses Disk Data storage can also
be greatly improved by separating data node file systems from undo log
files and tablespace data files, which can be done using symbolic links.
For more information, see *note mysql-cluster-disk-data-symlinks::.


File: manual.info.tmp,  Node: mysql-cluster-disk-data-objects,  Next: mysql-cluster-disk-data-symlinks,  Prev: mysql-cluster-disk-data,  Up: mysql-cluster-disk-data

18.5.12.1 NDB Cluster Disk Data Objects
.......................................

NDB Cluster Disk Data storage is implemented using a number of _Disk
Data objects_.  These include the following:

   * _Tablespaces_ act as containers for other Disk Data objects.

   * _Undo log files_ undo information required for rolling back
     transactions.

   * One or more undo log files are assigned to a _log file group_,
     which is then assigned to a tablespace.

   * _Data files_ store Disk Data table data.  A data file is assigned
     directly to a tablespace.

Undo log files and data files are actual files in the file system of
each data node; by default they are placed in 'ndb_NODE_ID_fs' in the
DATADIR specified in the NDB Cluster 'config.ini' file, and where
NODE_ID is the data node's node ID. It is possible to place these
elsewhere by specifying either an absolute or relative path as part of
the filename when creating the undo log or data file.  Statements that
create these files are shown later in this section.

NDB Cluster tablespaces and log file groups are not implemented as
files.

*Important*:

Although not all Disk Data objects are implemented as files, they all
share the same namespace.  This means that _each Disk Data object_ must
be uniquely named (and not merely each Disk Data object of a given
type).  For example, you cannot have a tablespace and a log file group
both named 'dd1'.

Assuming that you have already set up an NDB Cluster with all nodes
(including management and SQL nodes), the basic steps for creating an
NDB Cluster table on disk are as follows:

  1. Create a log file group, and assign one or more undo log files to
     it (an undo log file is also sometimes referred to as an
     _undofile_).

     *Note*:

     Undo log files are necessary only for Disk Data tables; they are
     not used for *note 'NDBCLUSTER': mysql-cluster. tables that are
     stored only in memory.

  2. Create a tablespace; assign the log file group, as well as one or
     more data files, to the tablespace.

  3. Create a Disk Data table that uses this tablespace for data
     storage.

Each of these tasks can be accomplished using SQL statements in the
*note 'mysql': mysql. client or other MySQL client application, as shown
in the example that follows.

  1. 
     We create a log file group named 'lg_1' using *note 'CREATE LOGFILE
     GROUP': create-logfile-group.  This log file group is to be made up
     of two undo log files, which we name 'undo_1.log' and 'undo_2.log',
     whose initial sizes are 16 MB and 12 MB, respectively.  (The
     default initial size for an undo log file is 128 MB.) Optionally,
     you can also specify a size for the log file group's undo buffer,
     or permit it to assume the default value of 8 MB. In this example,
     we set the UNDO buffer's size at 2 MB. A log file group must be
     created with an undo log file; so we add 'undo_1.log' to 'lg_1' in
     this *note 'CREATE LOGFILE GROUP': create-logfile-group. statement:

          CREATE LOGFILE GROUP lg_1
              ADD UNDOFILE 'undo_1.log'
              INITIAL_SIZE 16M
              UNDO_BUFFER_SIZE 2M
              ENGINE NDBCLUSTER;

     To add 'undo_2.log' to the log file group, use the following *note
     'ALTER LOGFILE GROUP': alter-logfile-group. statement:

          ALTER LOGFILE GROUP lg_1
              ADD UNDOFILE 'undo_2.log'
              INITIAL_SIZE 12M
              ENGINE NDBCLUSTER;

     Some items of note:

        * The '.log' file extension used here is not required.  We use
          it merely to make the log files easily recognisable.

        * Every *note 'CREATE LOGFILE GROUP': create-logfile-group. and
          *note 'ALTER LOGFILE GROUP': alter-logfile-group. statement
          must include an 'ENGINE' option.  The only permitted values
          for this option are *note 'NDBCLUSTER': mysql-cluster. and
          *note 'NDB': mysql-cluster.

          *Important*:

          There can exist at most one log file group in the same NDB
          Cluster at any given time.

        * When you add an undo log file to a log file group using 'ADD
          UNDOFILE 'FILENAME'', a file with the name FILENAME is created
          in the 'ndb_NODE_ID_fs' directory within the 'DataDir' of each
          data node in the cluster, where NODE_ID is the node ID of the
          data node.  Each undo log file is of the size specified in the
          SQL statement.  For example, if an NDB Cluster has 4 data
          nodes, then the *note 'ALTER LOGFILE GROUP':
          alter-logfile-group. statement just shown creates 4 undo log
          files, 1 each on in the data directory of each of the 4 data
          nodes; each of these files is named 'undo_2.log' and each file
          is 12 MB in size.

        * 'UNDO_BUFFER_SIZE' is limited by the amount of system memory
          available.

        * For more information about the *note 'CREATE LOGFILE GROUP':
          create-logfile-group. statement, see *note
          create-logfile-group::.  For more information about *note
          'ALTER LOGFILE GROUP': alter-logfile-group, see *note
          alter-logfile-group::.

  2. 
     Now we can create a tablespace, which contains files to be used by
     NDB Cluster Disk Data tables for storing their data.  A tablespace
     is also associated with a particular log file group.  When creating
     a new tablespace, you must specify the log file group which it is
     to use for undo logging; you must also specify a data file.  You
     can add more data files to the tablespace after the tablespace is
     created; it is also possible to drop data files from a tablespace
     (an example of dropping data files is provided later in this
     section).

     Assume that we wish to create a tablespace named 'ts_1' which uses
     'lg_1' as its log file group.  This tablespace is to contain two
     data files named 'data_1.dat' and 'data_2.dat', whose initial sizes
     are 32 MB and 48 MB, respectively.  (The default value for
     'INITIAL_SIZE' is 128 MB.) We can do this using two SQL statements,
     as shown here:

          CREATE TABLESPACE ts_1
              ADD DATAFILE 'data_1.dat'
              USE LOGFILE GROUP lg_1
              INITIAL_SIZE 32M
              ENGINE NDBCLUSTER;

          ALTER TABLESPACE ts_1
              ADD DATAFILE 'data_2.dat'
              INITIAL_SIZE 48M
              ENGINE NDBCLUSTER;

     The *note 'CREATE TABLESPACE': create-tablespace. statement creates
     a tablespace 'ts_1' with the data file 'data_1.dat', and associates
     'ts_1' with log file group 'lg_1'.  The *note 'ALTER TABLESPACE':
     alter-tablespace. adds the second data file ('data_2.dat').

     Some items of note:

        * As is the case with the '.log' file extension used in this
          example for undo log files, there is no special significance
          for the '.dat' file extension; it is used merely for easy
          recognition of data files.

        * When you add a data file to a tablespace using 'ADD DATAFILE
          'FILENAME'', a file with the name FILENAME is created in the
          'ndb_NODE_ID_fs' directory within the 'DataDir' of each data
          node in the cluster, where NODE_ID is the node ID of the data
          node.  Each data file is of the size specified in the SQL
          statement.  For example, if an NDB Cluster has 4 data nodes,
          then the *note 'ALTER TABLESPACE': alter-tablespace. statement
          just shown creates 4 data files, 1 each in the data directory
          of each of the 4 data nodes; each of these files is named
          'data_2.dat' and each file is 48 MB in size.

        * All *note 'CREATE TABLESPACE': create-tablespace. and *note
          'ALTER TABLESPACE': alter-tablespace. statements must contain
          an 'ENGINE' clause; only tables using the same storage engine
          as the tablespace can be created in the tablespace.  In MySQL
          NDB Cluster 7.2, the only permitted values for this clause are
          *note 'NDBCLUSTER': mysql-cluster. and *note 'NDB':
          mysql-cluster.

        * For more information about the *note 'CREATE TABLESPACE':
          create-tablespace. and *note 'ALTER TABLESPACE':
          alter-tablespace. statements, see *note create-tablespace::,
          and *note alter-tablespace::.

  3. 
     Now it is possible to create a table whose nonindexed columns are
     stored on disk in the tablespace 'ts_1':

          CREATE TABLE dt_1 (
              member_id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
              last_name VARCHAR(50) NOT NULL,
              first_name VARCHAR(50) NOT NULL,
              dob DATE NOT NULL,
              joined DATE NOT NULL,
              INDEX(last_name, first_name)
              )
              TABLESPACE ts_1 STORAGE DISK
              ENGINE NDBCLUSTER;

     The 'TABLESPACE ... STORAGE DISK' option tells the *note
     'NDBCLUSTER': mysql-cluster. storage engine to use tablespace
     'ts_1' for disk data storage.

     Once table 'ts_1' has been created as shown, you can perform *note
     'INSERT': insert, *note 'SELECT': select, *note 'UPDATE': update,
     and *note 'DELETE': delete. statements on it just as you would with
     any other MySQL table.

     It is also possible to specify whether an individual column is
     stored on disk or in memory by using a 'STORAGE' clause as part of
     the column's definition in a *note 'CREATE TABLE': create-table. or
     *note 'ALTER TABLE': alter-table. statement.  'STORAGE DISK' causes
     the column to be stored on disk, and 'STORAGE MEMORY' causes
     in-memory storage to be used.  See *note create-table::, for more
     information.

Indexing of columns implicitly stored on disk

For table 'dt_1' as defined in the example just shown, only the 'dob'
and 'joined' columns are stored on disk.  This is because there are
indexes on the 'id', 'last_name', and 'first_name' columns, and so data
belonging to these columns is stored in RAM. Only nonindexed columns can
be held on disk; indexes and indexed column data continue to be stored
in memory.  This tradeoff between the use of indexes and conservation of
RAM is something you must keep in mind as you design Disk Data tables.

You cannot add an index to a column that has been explicitly declared
'STORAGE DISK', without first changing its storage type to 'MEMORY'; any
attempt to do so fails with an error.  A column which _implicitly_ uses
disk storage can be indexed; when this is done, the column's storage
type is changed to 'MEMORY' automatically.  By 'implicitly', we mean a
column whose storage type is not declared, but which is which inherited
from the parent table.  In the following CREATE TABLE statement (using
the tablespace 'ts_1' defined previously), columns 'c2' and 'c3' use
disk storage implicitly:

     mysql> CREATE TABLE ti (
         ->     c1 INT PRIMARY KEY,
         ->     c2 INT,
         ->     c3 INT,
         ->     c4 INT
         -> )
         ->     STORAGE DISK
         ->     TABLESPACE ts_1
         ->     ENGINE NDBCLUSTER;
     Query OK, 0 rows affected (1.31 sec)

Because 'c2', 'c3', and 'c4' are themselves not declared with 'STORAGE
DISK', it is possible to index them.  Here, we add indexes to 'c2' and
'c3', using, respectively, 'CREATE INDEX' and 'ALTER TABLE':

     mysql> CREATE INDEX i1 ON ti(c2);
     Query OK, 0 rows affected (2.72 sec)
     Records: 0  Duplicates: 0  Warnings: 0

     mysql> ALTER TABLE ti ADD INDEX i2(c3);
     Query OK, 0 rows affected (0.92 sec)
     Records: 0  Duplicates: 0  Warnings: 0

*note 'SHOW CREATE TABLE': show-create-table. confirms that the indexes
were added.

     mysql> SHOW CREATE TABLE ti\G
     *************************** 1. row ***************************
            Table: ti
     Create Table: CREATE TABLE `ti` (
       `c1` int(11) NOT NULL,
       `c2` int(11) DEFAULT NULL,
       `c3` int(11) DEFAULT NULL,
       `c4` int(11) DEFAULT NULL,
       PRIMARY KEY (`c1`),
       KEY `i1` (`c2`),
       KEY `i2` (`c3`)
     ) /*!50100 TABLESPACE `ts_1` STORAGE DISK */ ENGINE=ndbcluster DEFAULT CHARSET=latin1
     1 row in set (0.00 sec)

You can see using *note 'ndb_desc': mysql-cluster-programs-ndb-desc.
that the indexed columns (emphasized text) now use in-memory rather than
on-disk storage:

     shell> ./ndb_desc -d test t1
     -- t1 --
     Version: 33554433
     Fragment type: HashMapPartition
     K Value: 6
     Min load factor: 78
     Max load factor: 80
     Temporary table: no
     Number of attributes: 4
     Number of primary keys: 1
     Length of frm data: 317
     Max Rows: 0
     Row Checksum: 1
     Row GCI: 1
     SingleUserMode: 0
     ForceVarPart: 1
     PartitionCount: 4
     FragmentCount: 4
     PartitionBalance: FOR_RP_BY_LDM
     ExtraRowGciBits: 0
     ExtraRowAuthorBits: 0
     TableStatus: Retrieved
     Table options:
     HashMap: DEFAULT-HASHMAP-3840-4
     -- Attributes --
     c1 Int PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY
     _c2 Int NULL AT=FIXED ST=MEMORY
     c3 Int NULL AT=FIXED ST=MEMORY_
     c4 Int NULL AT=FIXED ST=DISK
     -- Indexes --
     PRIMARY KEY(c1) - UniqueHashIndex
     i2(c3) - OrderedIndex
     PRIMARY(c1) - OrderedIndex
     i1(c2) - OrderedIndex

     NDBT_ProgramExit: 0 - OK

Performance note

The performance of a cluster using Disk Data storage is greatly improved
if Disk Data files are kept on a separate physical disk from the data
node file system.  This must be done for each data node in the cluster
to derive any noticeable benefit.

You may use absolute and relative file system paths with 'ADD UNDOFILE'
and 'ADD DATAFILE'.  Relative paths are calculated relative to the data
node's data directory.  You may also use symbolic links; see *note
mysql-cluster-disk-data-symlinks::, for more information and examples.

A log file group, a tablespace, and any Disk Data tables using these
must be created in a particular order.  The same is true for dropping
any of these objects:

   * A log file group cannot be dropped as long as any tablespaces are
     using it.

   * A tablespace cannot be dropped as long as it contains any data
     files.

   * You cannot drop any data files from a tablespace as long as there
     remain any tables which are using the tablespace.

   * It is not possible to drop files created in association with a
     different tablespace than the one with which the files were
     created.  (Bug #20053)

For example, to drop all the objects created so far in this section, you
would use the following statements:

     mysql> DROP TABLE dt_1;

     mysql> ALTER TABLESPACE ts_1
         -> DROP DATAFILE 'data_2.dat'
         -> ENGINE NDBCLUSTER;

     mysql> ALTER TABLESPACE ts_1
         -> DROP DATAFILE 'data_1.dat'
         -> ENGINE NDBCLUSTER;

     mysql> DROP TABLESPACE ts_1
         -> ENGINE NDBCLUSTER;

     mysql> DROP LOGFILE GROUP lg_1
         -> ENGINE NDBCLUSTER;

These statements must be performed in the order shown, except that the
two 'ALTER TABLESPACE ... DROP DATAFILE' statements may be executed in
either order.

You can obtain information about data files used by Disk Data tables by
querying the *note 'FILES': files-table. table in the
'INFORMATION_SCHEMA' database.  An extra ''NULL' row' provides
additional information about undo log files.  For more information and
examples, see *note files-table::.


File: manual.info.tmp,  Node: mysql-cluster-disk-data-symlinks,  Next: mysql-cluster-disk-data-storage-requirements,  Prev: mysql-cluster-disk-data-objects,  Up: mysql-cluster-disk-data

18.5.12.2 Using Symbolic Links with Disk Data Objects
.....................................................

The performance of an NDB Cluster that uses Disk Data storage can be
greatly improved by separating data node file systems from undo log
files and tablespace data files and placing these on different disks.
In early versions of NDB Cluster, there was no direct support for this
in NDB Cluster, but it was possible to achieve this separation using
symbolic links as described in this section.  NDB Cluster 7.2 supports
the data node configuration parameters 'FileSystemPathDD',
'FileSystemPathDataFiles', and 'FileSystemPathUndoFiles', which make the
use of symbolic links for this purpose unnecessary.  For more
information about these parameters, see *note
mysql-cluster-ndbd-disk-data-filesystem-parameters::.

Each data node in the cluster creates a file system in the directory
named 'ndb_NODE_ID_fs' under the data node's 'DataDir' as defined in the
'config.ini' file.  In this example, we assume that each data node host
has 3 disks, aliased as '/data0', '/data1', and '/data2', and that the
cluster's 'config.ini' includes the following:

     [ndbd default]
     DataDir= /data0

Our objective is to place all Disk Data log files in '/data1', and all
Disk Data data files in '/data2', on each data node host.

*Note*:

In this example, we assume that the cluster's data node hosts are all
using Linux operating systems.  For other platforms, you may need to
substitute you operating system's commands for those shown here.

To accomplish this, perform the following steps:

   * Under the data node file system create symbolic links pointing to
     the other drives:

          shell> cd /data0/ndb_2_fs
          shell> ls
          D1  D10  D11  D2  D8  D9  LCP
          shell> ln -s /data0 dnlogs
          shell> ln -s /data1 dndata

     You should now have two symbolic links:

          shell> ls -l --hide=D*
          lrwxrwxrwx 1 user group   30 2007-03-19 13:58 dndata -> /data1
          lrwxrwxrwx 1 user group   30 2007-03-19 13:59 dnlogs -> /data2

     We show this only for the data node with node ID 2; however, you
     must do this for _each_ data node.

   * Now, in the *note 'mysql': mysql. client, create a log file group
     and tablespace using the symbolic links, as shown here:

          mysql> CREATE LOGFILE GROUP lg1
              ->    ADD UNDOFILE 'dnlogs/undo1.log'
              ->    INITIAL_SIZE 150M
              ->    UNDO_BUFFER_SIZE = 1M
              ->    ENGINE=NDBCLUSTER;

          mysql> CREATE TABLESPACE ts1
              ->    ADD DATAFILE 'dndata/data1.log'
              ->    USE LOGFILE GROUP lg1
              ->    INITIAL_SIZE 1G
              ->    ENGINE=NDBCLUSTER;

     Verify that the files were created and placed correctly as shown
     here:

          shell> cd /data1
          shell> ls -l
          total 2099304
          -rw-rw-r--  1 user group 157286400 2007-03-19 14:02 undo1.dat

          shell> cd /data2
          shell> ls -l
          total 2099304
          -rw-rw-r--  1 user group 1073741824 2007-03-19 14:02 data1.dat

   * If you are running multiple data nodes on one host, you must take
     care to avoid having them try to use the same space for Disk Data
     files.  You can make this easier by creating a symbolic link in
     each data node file system.  Suppose you are using '/data0' for
     both data node file systems, but you wish to have the Disk Data
     files for both nodes on '/data1'.  In this case, you can do
     something similar to what is shown here:

          shell> cd /data0
          shell> ln -s /data1/dn2 ndb_2_fs/dd
          shell> ln -s /data1/dn3 ndb_3_fs/dd
          shell> ls -l --hide=D* ndb_2_fs
          lrwxrwxrwx 1 user group   30 2007-03-19 14:22 dd -> /data1/dn2
          shell> ls -l --hide=D* ndb_3_fs
          lrwxrwxrwx 1 user group   30 2007-03-19 14:22 dd -> /data1/dn3

   * Now you can create a logfile group and tablespace using the
     symbolic link, like this:

          mysql> CREATE LOGFILE GROUP lg1
              ->    ADD UNDOFILE 'dd/undo1.log'
              ->    INITIAL_SIZE 150M
              ->    UNDO_BUFFER_SIZE = 1M
              ->    ENGINE=NDBCLUSTER;

          mysql> CREATE TABLESPACE ts1
              ->    ADD DATAFILE 'dd/data1.log'
              ->    USE LOGFILE GROUP lg1
              ->    INITIAL_SIZE 1G
              ->    ENGINE=NDBCLUSTER;

     Verify that the files were created and placed correctly as shown
     here:

          shell> cd /data1
          shell> ls
          dn2        dn3
          shell> ls dn2
          undo1.log        data1.log
          shell> ls dn3
          undo1.log        data1.log


File: manual.info.tmp,  Node: mysql-cluster-disk-data-storage-requirements,  Prev: mysql-cluster-disk-data-symlinks,  Up: mysql-cluster-disk-data

18.5.12.3 NDB Cluster Disk Data Storage Requirements
....................................................

The following items apply to Disk Data storage requirements:

   * Variable-length columns of Disk Data tables take up a fixed amount
     of space.  For each row, this is equal to the space required to
     store the largest possible value for that column.

     For general information about calculating these values, see *note
     storage-requirements::.

     You can obtain an estimate the amount of space available in data
     files and undo log files by querying the *note
     'INFORMATION_SCHEMA.FILES': files-table. table.  For more
     information and examples, see *note files-table::.

     *Note*:

     The *note 'OPTIMIZE TABLE': optimize-table. statement does not have
     any effect on Disk Data tables.

   * In a Disk Data table, the first 256 bytes of a *note 'TEXT': blob.
     or *note 'BLOB': blob. column are stored in memory; only the
     remainder is stored on disk.

   * Each row in a Disk Data table uses 8 bytes in memory to point to
     the data stored on disk.  This means that, in some cases,
     converting an in-memory column to the disk-based format can
     actually result in greater memory usage.  For example, converting a
     'CHAR(4)' column from memory-based to disk-based format increases
     the amount of 'DataMemory' used per row from 4 to 8 bytes.

*Important*:

Starting the cluster with the '--initial' option does _not_ remove Disk
Data files.  You must remove these manually prior to performing an
initial restart of the cluster.

Performance of Disk Data tables can be improved by minimizing the number
of disk seeks by making sure that 'DiskPageBufferMemory' is of
sufficient size.  You can query the *note 'diskpagebuffer':
mysql-cluster-ndbinfo-diskpagebuffer. table to help determine whether
the value for this parameter needs to be increased.


File: manual.info.tmp,  Node: mysql-cluster-online-operations,  Next: mysql-cluster-online-add-node,  Prev: mysql-cluster-disk-data,  Up: mysql-cluster-management

18.5.13 Online Operations with ALTER TABLE in NDB Cluster
---------------------------------------------------------

Operations that add and drop indexes on variable-width columns of *note
'NDBCLUSTER': mysql-cluster. tables occur online.  Online operations are
noncopying; that is, they do not require that indexes be re-created.
They do not lock the table being altered from access by other API nodes
in an NDB Cluster (but see 'Limitations' later in this section).  Such
operations do not require single user mode for *note 'NDBCLUSTER':
mysql-cluster. table alterations made in a cluster with multiple API
nodes; transactions can continue uninterrupted during online DDL
operations.

The 'ONLINE' keyword can be used to perform online 'ADD COLUMN', 'ADD
INDEX' (including 'CREATE INDEX' statements), and 'DROP INDEX'
operations on *note 'NDBCLUSTER': mysql-cluster. tables.  Online
renaming of *note 'NDBCLUSTER': mysql-cluster. tables is also supported.

The 'ONLINE' and 'OFFLINE' keywords are supported only in NDB Cluster.
For standard MySQL Server 5.5 releases:

   * The server determines automatically whether an 'ADD INDEX' or 'DROP
     INDEX' operation can be (and is) performed online or offline; if
     the column is of a variable-width data type, the operation is
     performed online.  It is not possible to override the server
     behavior in this regard.

   * Attempting to use the 'ONLINE' or 'OFFLINE' keyword in an *note
     'ALTER TABLE': alter-table, *note 'CREATE INDEX': create-index, or
     *note 'DROP INDEX': drop-index. statement results in an error.

Currently you cannot add disk-based columns to *note 'NDBCLUSTER':
mysql-cluster. tables online.  This means that, if you wish to add an
in-memory column to an *note 'NDBCLUSTER': mysql-cluster. table that
uses a table-level 'STORAGE DISK' option, you must declare the new
column as using memory-based storage explicitly.  For example--assuming
that you have already created tablespace 'ts1'--suppose that you create
table 't1' as follows:

     mysql> CREATE TABLE t1 (
          >     c1 INT NOT NULL PRIMARY KEY,
          >     c2 VARCHAR(30)
          >     )
          >     TABLESPACE ts1 STORAGE DISK
          >     ENGINE NDBCLUSTER;
     Query OK, 0 rows affected (1.73 sec)
     Records: 0  Duplicates: 0  Warnings: 0

You can add a new in-memory column to this table online as shown here:

     mysql> ALTER ONLINE TABLE t1 ADD COLUMN c3 INT COLUMN_FORMAT DYNAMIC STORAGE MEMORY;
     Query OK, 0 rows affected (1.25 sec)
     Records: 0  Duplicates: 0  Warnings: 0

This statement fails if the 'STORAGE MEMORY' option is omitted:

     mysql> ALTER ONLINE TABLE t1 ADD COLUMN c3 INT COLUMN_FORMAT DYNAMIC;
     ERROR 1235 (42000): This version of MySQL doesn't yet support
     'ALTER ONLINE TABLE t1 ADD COLUMN c3 INT COLUMN_FORMAT DYNAMIC'

If you omit the 'COLUMN_FORMAT DYNAMIC' option, the dynamic column
format is employed automatically, but a warning is issued, as shown
here:

     mysql> ALTER ONLINE TABLE t1 ADD COLUMN c3 INT STORAGE MEMORY;
     Query OK, 0 rows affected, 1 warning (1.17 sec)
     Records: 0  Duplicates: 0  Warnings: 0

     mysql> SHOW WARNINGS;
     +---------+------+---------------------------------------------------------------+
     | Level   | Code | Message                                                       |
     +---------+------+---------------------------------------------------------------+
     | Warning | 1478 | Converted FIXED field to DYNAMIC to enable on-line ADD COLUMN |
     +---------+------+---------------------------------------------------------------+
     1 row in set (0.00 sec)

     mysql> SHOW CREATE TABLE t1\G
     *************************** 1. row ***************************
            Table: t1
     Create Table: CREATE TABLE `t1` (
       `c1` int(11) NOT NULL,
       `c2` varchar(30) DEFAULT NULL,
       `c3` int(11) /*!50120 STORAGE MEMORY */ /*!50120 COLUMN_FORMAT DYNAMIC */ DEFAULT NULL,
       `t4` int(11) /*!50120 STORAGE MEMORY */ DEFAULT NULL,
       PRIMARY KEY (`c1`)
     ) /*!50100 TABLESPACE ts_1 STORAGE DISK */ ENGINE=ndbcluster DEFAULT CHARSET=latin1
     1 row in set (0.03 sec)

*Note*:

The 'STORAGE' and 'COLUMN_FORMAT' keywords are supported only in NDB
Cluster; in any other version of MySQL, attempting to use either of
these keywords in a *note 'CREATE TABLE': create-table. or *note 'ALTER
TABLE': alter-table. statement results in an error.

It is also possible to use the statement 'ALTER ONLINE TABLE ...
REORGANIZE PARTITION' with no 'PARTITION_NAMES INTO
(PARTITION_DEFINITIONS)' option on *note 'NDB': mysql-cluster. tables.
This can be used to redistribute NDB Cluster data among new data nodes
that have been added to the cluster online.  This does _not_ perform any
defragmentation, which requires an *note 'OPTIMIZE TABLE':
optimize-table. or null *note 'ALTER TABLE': alter-table. statement.
For more information, see *note mysql-cluster-online-add-node::.

*Limitations of NDB online operations*

Online 'DROP COLUMN' operations are not supported.

Online *note 'ALTER TABLE': alter-table, *note 'CREATE INDEX':
create-index, or *note 'DROP INDEX': drop-index. statements that add
columns or add or drop indexes are subject to the following limitations:

   * A given online *note 'ALTER TABLE': alter-table. can use only one
     of 'ADD COLUMN', 'ADD INDEX', or 'DROP INDEX'.  One or more columns
     can be added online in a single statement; only one index may be
     created or dropped online in a single statement.

   * An 'ALTER TABLE' statement that performs a rename while using the
     'ONLINE' or 'OFFLINE' keyword cannot perform any other operations,
     including but not limited to 'ADD COLUMN', 'ADD INDEX', or 'DROP
     INDEX'.  Beginning with MySQL NDB Cluster 7.2.11, such statements
     are specifically disallowed, and fail with 'ER_NOT_SUPPORTED_YET'.
     (Bug #16021021)

   * The table being altered is not locked with respect to API nodes
     other than the one on which an online *note 'ALTER TABLE':
     alter-table. 'ADD COLUMN', 'ADD INDEX', or 'DROP INDEX' operation
     (or *note 'CREATE INDEX': create-index. or *note 'DROP INDEX':
     drop-index. statement) is run.  However, the table is locked
     against any other operations originating on the _same_ API node
     while the online operation is being executed.

   * The table to be altered must have an explicit primary key; the
     hidden primary key created by the *note 'NDB': mysql-cluster.
     storage engine is not sufficient for this purpose.

   * The storage engine used by the table cannot be changed online.

   * When used with NDB Cluster Disk Data tables, it is not possible to
     change the storage type ('DISK' or 'MEMORY') of a column online.
     This means, that when you add or drop an index in such a way that
     the operation would be performed online, and you want the storage
     type of the column or columns to be changed, you must use the
     'OFFLINE' keyword in the statement that adds or drops the index.

Columns to be added online cannot use the *note 'BLOB': blob. or *note
'TEXT': blob. type, and must meet the following criteria:

   * The columns must be dynamic; that is, it must be possible to create
     them using 'COLUMN_FORMAT DYNAMIC'.  If you omit the 'COLUMN_FORMAT
     DYNAMIC' option, the dynamic column format is employed
     automatically.

   * The columns must permit 'NULL' values and not have any explicit
     default value other than 'NULL'.  Columns added online are
     automatically created as 'DEFAULT NULL', as can be seen here:

          mysql> CREATE TABLE t1 (
               >     c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY
               >     ) ENGINE=NDB;
          Query OK, 0 rows affected (1.44 sec)

          mysql> ALTER ONLINE TABLE t1
               >     ADD COLUMN c2 INT,
               >     ADD COLUMN c3 INT;
          Query OK, 0 rows affected, 2 warnings (0.93 sec)

          mysql> SHOW CREATE TABLE t1\G
          *************************** 1. row ***************************
                 Table: t1
          Create Table: CREATE TABLE `t1` (
            `c1` int(11) NOT NULL AUTO_INCREMENT,
            `c2` int(11) DEFAULT NULL,
            `c3` int(11) DEFAULT NULL,
            PRIMARY KEY (`c1`)
          ) ENGINE=ndbcluster DEFAULT CHARSET=latin1
          1 row in set (0.00 sec)

   * The columns must be added following any existing columns.  If you
     attempt to add a column online before any existing columns or using
     the 'FIRST' keyword, the statement fails with an error.

   * Existing table columns cannot be reordered online.

For online *note 'ALTER TABLE': alter-table. operations on *note 'NDB':
mysql-cluster. tables, fixed-format columns are converted to dynamic
when they are added online, or when indexes are created or dropped
online, as shown here:

     mysql> CREATE TABLE t1 (
          >     c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY
          >     ) ENGINE=NDB;
     Query OK, 0 rows affected (1.44 sec)

     mysql> ALTER ONLINE TABLE t1 ADD COLUMN c2 INT, ADD COLUMN c3 INT;
     Query OK, 0 rows affected, 2 warnings (0.93 sec)
     Records: 0  Duplicates: 0  Warnings: 0

     mysql> SHOW WARNINGS;
     +---------+------+---------------------------------------------------------------+
     | Level   | Code | Message                                                       |
     +---------+------+---------------------------------------------------------------+
     | Warning | 1475 | Converted FIXED field to DYNAMIC to enable on-line ADD COLUMN |
     | Warning | 1475 | Converted FIXED field to DYNAMIC to enable on-line ADD COLUMN |
     +---------+------+---------------------------------------------------------------+
     2 rows in set (0.00 sec)

*Note*:

Existing columns, including the table's primary key, need not be
dynamic; only the column or columns to be added online must be dynamic.

     mysql> CREATE TABLE t2 (
          >     c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY COLUMN_FORMAT FIXED
          >     ) ENGINE=NDB;
     Query OK, 0 rows affected (2.10 sec)

     mysql> ALTER ONLINE TABLE t2 ADD COLUMN c2 INT;
     Query OK, 0 rows affected, 1 warning (0.78 sec)
     Records: 0  Duplicates: 0  Warnings: 0

     mysql> SHOW WARNINGS;
     +---------+------+---------------------------------------------------------------+
     | Level   | Code | Message                                                       |
     +---------+------+---------------------------------------------------------------+
     | Warning | 1475 | Converted FIXED field to DYNAMIC to enable on-line ADD COLUMN |
     +---------+------+---------------------------------------------------------------+
     1 row in set (0.00 sec)

Columns are not converted from 'FIXED' to 'DYNAMIC' column format by
renaming operations.  For more information about 'COLUMN_FORMAT', see
*note create-table::.

The 'KEY', 'CONSTRAINT', and 'IGNORE' keywords are supported in *note
'ALTER TABLE': alter-table. statements using the 'ONLINE' keyword.


File: manual.info.tmp,  Node: mysql-cluster-online-add-node,  Next: mysql-cluster-privilege-distribution,  Prev: mysql-cluster-online-operations,  Up: mysql-cluster-management

18.5.14 Adding NDB Cluster Data Nodes Online
--------------------------------------------

* Menu:

* mysql-cluster-online-add-node-remarks::  Adding NDB Cluster Data Nodes Online: General Issues
* mysql-cluster-online-add-node-basics::  Adding NDB Cluster Data Nodes Online: Basic procedure
* mysql-cluster-online-add-node-example::  Adding NDB Cluster Data Nodes Online: Detailed Example

This section describes how to add NDB Cluster data nodes 'online'--that
is, without needing to shut down the cluster completely and restart it
as part of the process.

*Important*:

Currently, you must add new data nodes to an NDB Cluster as part of a
new node group.  In addition, it is not possible to change the number of
replicas (or the number of nodes per node group) online.


File: manual.info.tmp,  Node: mysql-cluster-online-add-node-remarks,  Next: mysql-cluster-online-add-node-basics,  Prev: mysql-cluster-online-add-node,  Up: mysql-cluster-online-add-node

18.5.14.1 Adding NDB Cluster Data Nodes Online: General Issues
..............................................................

This section provides general information about the behavior of and
current limitations in adding NDB Cluster nodes online.

Redistribution of Data

The ability to add new nodes online includes a means to reorganize *note
'NDBCLUSTER': mysql-cluster. table data and indexes so that they are
distributed across all data nodes, including the new ones, by means of
the *note 'ALTER ONLINE TABLE ... REORGANIZE PARTITION':
alter-table-partition-operations. statement.  Table reorganization of
both in-memory and Disk Data tables is supported.  This redistribution
does not currently include unique indexes (only ordered indexes are
redistributed).  Prior to NDB 7.2.14, 'BLOB' table data is also not
redistributed using this method (Bug #13714148).

The redistribution for *note 'NDBCLUSTER': mysql-cluster. tables already
existing before the new data nodes were added is not automatic, but can
be accomplished using simple SQL statements in *note 'mysql': mysql. or
another MySQL client application.  However, all data and indexes added
to tables created after a new node group has been added are distributed
automatically among all cluster data nodes, including those added as
part of the new node group.

Partial starts

It is possible to add a new node group without all of the new data nodes
being started.  It is also possible to add a new node group to a
degraded cluster--that is, a cluster that is only partially started, or
where one or more data nodes are not running.  In the latter case, the
cluster must have enough nodes running to be viable before the new node
group can be added.

Effects on ongoing operations

Normal DML operations using NDB Cluster data are not prevented by the
creation or addition of a new node group, or by table reorganization.
However, it is not possible to perform DDL concurrently with table
reorganization--that is, no other DDL statements can be issued while an
*note 'ALTER TABLE ... REORGANIZE PARTITION': alter-table. statement is
executing.  In addition, during the execution of 'ALTER TABLE ...
REORGANIZE PARTITION' (or the execution of any other DDL statement), it
is not possible to restart cluster data nodes.

Failure handling

Failures of data nodes during node group creation and table
reorganization are handled as shown in the following table:

*Data node failure handling during node group creation and table
reorganization*

Failure during     Failure in 'Old'   Failure in 'New'   System Failure
                   data node          data node          
                                      
Node group                                               
creation              * If a node        * If a node        * If the
                        other than         other than         execution
                        the master         the master         of CREATE
                        fails:             fails:             NODEGROUP
                                                              has reached
                        The                The                the
                        creation of        creation of        internal
                        the node           the node           commit
                        group is           group is           point:
                        always             always        
                        rolled             rolled             When
                        forward.           forward.           restarted,
                                                              the cluster
                      * If the           * If the             includes
                        master             master             the new
                        fails:             fails:             node group.
                                                              Otherwise
                           * If the           * If the        it without.
                             internal           internal 
                             commit             commit      * If the
                             point              point         execution
                             has                has           of CREATE
                             been               been          NODEGROUP
                             reached:           reached:      has not yet
                                                              reached the
                             The                The           internal
                             creation           creation      commit
                             of the             of the        point:
                             node               node     
                             group              group         When
                             is                 is            restarted,
                             rolled             rolled        the cluster
                             forward.           forward.      does not
                                                              include the
                           * If the           * If the        new node
                             internal           internal      group.
                             commit             commit   
                             point              point
                             has                has
                             not                not
                             yet                yet
                             been               been
                             reached            reached
                                      
                             The                The
                             creation           creation
                             of the             of the
                             node               node
                             group              group
                             is                 is
                             rolled             rolled
                             back               back
                                      
Table                                                    
reorganization        * If a node        * If a node        * If the
                        other than         other than         execution
                        the master         the master         of an ALTER
                        fails:             fails:             TABLE ...
                                                              REORGANIZE
                        The table          The table          PARTITION
                        reorganization     reorganization     statement
                        is always          is always          has reached
                        rolled             rolled             the
                        forward.           forward.           internal
                                                              commit
                      * If the           * If the             point:
                        master             master        
                        fails:             fails:             When the
                                                              cluster is
                           * If the           * If the        restarted,
                             internal           internal      the data
                             commit             commit        and indexes
                             point              point         belonging
                             has                has           to TABLE
                             been               been          are
                             reached:           reached:      distributed
                                                              using the
                             The                The           'new' data
                             table              table         nodes.
                             reorganization          reorganization
                             is                 is          * If the
                             rolled             rolled        execution
                             forward.           forward.      of an ALTER
                                                              TABLE ...
                           * If the           * If the        REORGANIZE
                             internal           internal      PARTITION
                             commit             commit        statement
                             point              point         has not yet
                             has                has           reached the
                             not                not           internal
                             yet                yet           commit
                             been               been          point:
                             reached            reached  
                                                              When the
                             The                The           cluster is
                             table              table         restarted,
                             reorganization          reorganization     the data
                             is                 is            and indexes
                             rolled             rolled        belonging
                             back.              back.         to TABLE
                                                              are
                                                              distributed
                                                              using only
                                                              the 'old'
                                                              data nodes.

Dropping node groups

The *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. client supports a
'DROP NODEGROUP' command, but it is possible to drop a node group only
when no data nodes in the node group contain any data.  Since there is
currently no way to 'empty' a specific data node or node group, this
command works only the following two cases:

  1. After issuing 'CREATE NODEGROUP' in the *note 'ndb_mgm':
     mysql-cluster-programs-ndb-mgm. client, but before issuing any
     *note 'ALTER ONLINE TABLE ... REORGANIZE PARTITION': alter-table.
     statements in the *note 'mysql': mysql. client.

  2. After dropping all *note 'NDBCLUSTER': mysql-cluster. tables using
     *note 'DROP TABLE': drop-table.

     *note 'TRUNCATE TABLE': truncate-table. does not work for this
     purpose because the data nodes continue to store the table
     definitions.


File: manual.info.tmp,  Node: mysql-cluster-online-add-node-basics,  Next: mysql-cluster-online-add-node-example,  Prev: mysql-cluster-online-add-node-remarks,  Up: mysql-cluster-online-add-node

18.5.14.2 Adding NDB Cluster Data Nodes Online: Basic procedure
...............................................................

In this section, we list the basic steps required to add new data nodes
to an NDB Cluster.  This procedure applies whether you are using *note
'ndbd': mysql-cluster-programs-ndbd. or *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. binaries for the data node processes.
For a more detailed example, see *note
mysql-cluster-online-add-node-example::.

Assuming that you already have a running NDB Cluster, adding data nodes
online requires the following steps:

  1. Edit the cluster configuration 'config.ini' file, adding new
     '[ndbd]' sections corresponding to the nodes to be added.  In the
     case where the cluster uses multiple management servers, these
     changes need to be made to all 'config.ini' files used by the
     management servers.

     You must be careful that node IDs for any new data nodes added in
     the 'config.ini' file do not overlap node IDs used by existing
     nodes.  In the event that you have API nodes using dynamically
     allocated node IDs and these IDs match node IDs that you want to
     use for new data nodes, it is possible to force any such API nodes
     to 'migrate', as described later in this procedure.

  2. Perform a rolling restart of all NDB Cluster management servers.

     *Important*:

     All management servers must be restarted with the '--reload' or
     '--initial' option to force the reading of the new configuration.

  3. Perform a rolling restart of all existing NDB Cluster data nodes.
     It is not necessary (or usually even desirable) to use '--initial'
     when restarting the existing data nodes.

     If you are using API nodes with dynamically allocated IDs matching
     any node IDs that you wish to assign to new data nodes, you must
     restart all API nodes (including SQL nodes) before restarting any
     of the data nodes processes in this step.  This causes any API
     nodes with node IDs that were previously not explicitly assigned to
     relinquish those node IDs and acquire new ones.

  4. Perform a rolling restart of any SQL or API nodes connected to the
     NDB Cluster.

  5. Start the new data nodes.

     The new data nodes may be started in any order.  They can also be
     started concurrently, as long as they are started after the rolling
     restarts of all existing data nodes have been completed, and before
     proceeding to the next step.

  6. Execute one or more 'CREATE NODEGROUP' commands in the NDB Cluster
     management client to create the new node group or node groups to
     which the new data nodes will belong.

  7. Redistribute the cluster's data among all data nodes, including the
     new ones.  Normally this is done by issuing an *note 'ALTER ONLINE
     TABLE ... REORGANIZE PARTITION': alter-table. statement in the
     *note 'mysql': mysql. client for each *note 'NDBCLUSTER':
     mysql-cluster. table.

     _Exception_: For tables created using the 'MAX_ROWS' option, this
     statement does not work; instead, use 'ALTER ONLINE TABLE ...
     MAX_ROWS=...' to reorganize such tables.

     *Note*:

     This needs to be done only for tables already existing at the time
     the new node group is added.  Data in tables created after the new
     node group is added is distributed automatically; however, data
     added to any given table 'tbl' that existed before the new nodes
     were added is not distributed using the new nodes until that table
     has been reorganized.

  8. 'ALTER ONLINE TABLE ... REORGANIZE PARTITION' reorganizes
     partitions but does not reclaim the space freed on the 'old' nodes.
     You can do this by issuing, for each *note 'NDBCLUSTER':
     mysql-cluster. table, an *note 'OPTIMIZE TABLE': optimize-table.
     statement in the *note 'mysql': mysql. client.

     This works for space used by variable-width columns of in-memory
     'NDB' tables.  'OPTIMIZE TABLE' is not supported for fixed-width
     columns of in-memory tables; it is also not supported for Disk Data
     tables.

You can add all the nodes desired, then issue several 'CREATE NODEGROUP'
commands in succession to add the new node groups to the cluster.


File: manual.info.tmp,  Node: mysql-cluster-online-add-node-example,  Prev: mysql-cluster-online-add-node-basics,  Up: mysql-cluster-online-add-node

18.5.14.3 Adding NDB Cluster Data Nodes Online: Detailed Example
................................................................

In this section we provide a detailed example illustrating how to add
new NDB Cluster data nodes online, starting with an NDB Cluster having 2
data nodes in a single node group and concluding with a cluster having 4
data nodes in 2 node groups.

Starting configuration

For purposes of illustration, we assume a minimal configuration, and
that the cluster uses a 'config.ini' file containing only the following
information:

     [ndbd default]
     DataMemory = 100M
     IndexMemory = 100M
     NoOfReplicas = 2
     DataDir = /usr/local/mysql/var/mysql-cluster

     [ndbd]
     Id = 1
     HostName = 198.51.100.1

     [ndbd]
     Id = 2
     HostName = 198.51.100.2

     [mgm]
     HostName = 198.51.100.10
     Id = 10

     [api]
     Id=20
     HostName = 198.51.100.20

     [api]
     Id=21
     HostName = 198.51.100.21

*Note*:

We have left a gap in the sequence between data node IDs and other
nodes.  This make it easier later to assign node IDs that are not
already in use to data nodes which are newly added.

We also assume that you have already started the cluster using the
appropriate command line or 'my.cnf' options, and that running 'SHOW' in
the management client produces output similar to what is shown here:

     -- NDB Cluster -- Management Client --
     ndb_mgm> SHOW
     Connected to Management Server at: 198.51.100.10:1186
     Cluster Configuration
     ---------------------
     [ndbd(NDB)]     2 node(s)
     id=1    @198.51.100.1  (5.5.65-ndb-7.2.39, Nodegroup: 0, *)
     id=2    @198.51.100.2  (5.5.65-ndb-7.2.39, Nodegroup: 0)

     [ndb_mgmd(MGM)] 1 node(s)
     id=10   @198.51.100.10  (5.5.65-ndb-7.2.39)

     [mysqld(API)]   2 node(s)
     id=20   @198.51.100.20  (5.5.65-ndb-7.2.39)
     id=21   @198.51.100.21  (5.5.65-ndb-7.2.39)

Finally, we assume that the cluster contains a single *note
'NDBCLUSTER': mysql-cluster. table created as shown here:

     USE n;

     CREATE TABLE ips (
         id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY,
         country_code CHAR(2) NOT NULL,
         type CHAR(4) NOT NULL,
         ip_address VARCHAR(15) NOT NULL,
         addresses BIGINT UNSIGNED DEFAULT NULL,
         date BIGINT UNSIGNED DEFAULT NULL
     )   ENGINE NDBCLUSTER;

The memory usage and related information shown later in this section was
generated after inserting approximately 50000 rows into this table.

*Note*:

In this example, we show the single-threaded *note 'ndbd':
mysql-cluster-programs-ndbd. being used for the data node processes.
However--beginning with NDB 7.0.4--you can also apply this example, if
you are using the multithreaded *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. by substituting *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. for *note 'ndbd':
mysql-cluster-programs-ndbd. wherever it appears in the steps that
follow.  (Bug #43108)

Step 1: Update configuration file

Open the cluster global configuration file in a text editor and add
'[ndbd]' sections corresponding to the 2 new data nodes.  (We give these
data nodes IDs 3 and 4, and assume that they are to be run on host
machines at addresses 198.51.100.3 and 198.51.100.4, respectively.)
After you have added the new sections, the contents of the 'config.ini'
file should look like what is shown here, where the additions to the
file are shown in bold type:

     [ndbd default]
     DataMemory = 100M
     IndexMemory = 100M
     NoOfReplicas = 2
     DataDir = /usr/local/mysql/var/mysql-cluster

     [ndbd]
     Id = 1
     HostName = 198.51.100.1

     [ndbd]
     Id = 2
     HostName = 198.51.100.2
     *[ndbd]
     Id = 3
     HostName = 198.51.100.3

     [ndbd]
     Id = 4
     HostName = 198.51.100.4*

     [mgm]
     HostName = 198.51.100.10
     Id = 10

     [api]
     Id=20
     HostName = 198.51.100.20

     [api]
     Id=21
     HostName = 198.51.100.21

Once you have made the necessary changes, save the file.

Step 2: Restart the management server

Restarting the cluster management server requires that you issue
separate commands to stop the management server and then to start it
again, as follows:

  1. Stop the management server using the management client 'STOP'
     command, as shown here:

          ndb_mgm> 10 STOP
          Node 10 has shut down.
          Disconnecting to allow Management Server to shutdown

          shell>

  2. Because shutting down the management server causes the management
     client to terminate, you must start the management server from the
     system shell.  For simplicity, we assume that 'config.ini' is in
     the same directory as the management server binary, but in
     practice, you must supply the correct path to the configuration
     file.  You must also supply the '--reload' or '--initial' option so
     that the management server reads the new configuration from the
     file rather than its configuration cache.  If your shell's current
     directory is also the same as the directory where the management
     server binary is located, then you can invoke the management server
     as shown here:

          shell> ndb_mgmd -f config.ini --reload
          2008-12-08 17:29:23 [MgmSrvr] INFO     -- NDB Cluster Management Server. 5.5.65-ndb-7.2.39
          2008-12-08 17:29:23 [MgmSrvr] INFO     -- Reading cluster configuration from 'config.ini'

If you check the output of 'SHOW' in the management client after
restarting the *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. process,
you should now see something like this:

     -- NDB Cluster -- Management Client --
     ndb_mgm> SHOW
     Connected to Management Server at: 198.51.100.10:1186
     Cluster Configuration
     ---------------------
     [ndbd(NDB)]     2 node(s)
     id=1    @198.51.100.1  (5.5.65-ndb-7.2.39, Nodegroup: 0, *)
     id=2    @198.51.100.2  (5.5.65-ndb-7.2.39, Nodegroup: 0)
     id=3 (not connected, accepting connect from 198.51.100.3)
     id=4 (not connected, accepting connect from 198.51.100.4)

     [ndb_mgmd(MGM)] 1 node(s)
     id=10   @198.51.100.10  (5.5.65-ndb-7.2.39)

     [mysqld(API)]   2 node(s)
     id=20   @198.51.100.20  (5.5.65-ndb-7.2.39)
     id=21   @198.51.100.21  (5.5.65-ndb-7.2.39)

Step 3: Perform a rolling restart of the existing data nodes

This step can be accomplished entirely within the cluster management
client using the 'RESTART' command, as shown here:

     ndb_mgm> 1 RESTART
     Node 1: Node shutdown initiated
     Node 1: Node shutdown completed, restarting, no start.
     Node 1 is being restarted

     ndb_mgm> Node 1: Start initiated (version 7.2.39)
     Node 1: Started (version 7.2.39)

     ndb_mgm> 2 RESTART
     Node 2: Node shutdown initiated
     Node 2: Node shutdown completed, restarting, no start.
     Node 2 is being restarted

     ndb_mgm> Node 2: Start initiated (version 7.2.39)

     ndb_mgm> Node 2: Started (version 7.2.39)

*Important*:

After issuing each 'X RESTART' command, wait until the management client
reports 'Node X: Started (version ...)' _before_ proceeding any further.

You can verify that all existing data nodes were restarted using the
updated configuration by checking the *note 'ndbinfo.nodes':
mysql-cluster-ndbinfo-nodes. table in the *note 'mysql': mysql. client.

Step 4: Perform a rolling restart of all cluster API nodes

Shut down and restart each MySQL server acting as an SQL node in the
cluster using *note 'mysqladmin shutdown': mysqladmin. followed by *note
'mysqld_safe': mysqld-safe. (or another startup script).  This should be
similar to what is shown here, where PASSWORD is the MySQL 'root'
password for a given MySQL server instance:

     shell> mysqladmin -uroot -pPASSWORD shutdown
     081208 20:19:56 mysqld_safe mysqld from pid file
     /usr/local/mysql/var/tonfisk.pid ended
     shell> mysqld_safe --ndbcluster --ndb-connectstring=198.51.100.10 &
     081208 20:20:06 mysqld_safe Logging to '/usr/local/mysql/var/tonfisk.err'.
     081208 20:20:06 mysqld_safe Starting mysqld daemon with databases
     from /usr/local/mysql/var

Of course, the exact input and output depend on how and where MySQL is
installed on the system, as well as which options you choose to start it
(and whether or not some or all of these options are specified in a
'my.cnf' file).

Step 5: Perform an initial start of the new data nodes

From a system shell on each of the hosts for the new data nodes, start
the data nodes as shown here, using the '--initial' option:

     shell> ndbd -c 198.51.100.10 --initial

*Note*:

Unlike the case with restarting the existing data nodes, you can start
the new data nodes concurrently; you do not need to wait for one to
finish starting before starting the other.

_Wait until both of the new data nodes have started before proceeding
with the next step_.  Once the new data nodes have started, you can see
in the output of the management client 'SHOW' command that they do not
yet belong to any node group (as indicated with bold type here):

     ndb_mgm> SHOW
     Connected to Management Server at: 198.51.100.10:1186
     Cluster Configuration
     ---------------------
     [ndbd(NDB)]     2 node(s)
     id=1    @198.51.100.1  (5.5.65-ndb-7.2.39, Nodegroup: 0, *)
     id=2    @198.51.100.2  (5.5.65-ndb-7.2.39, Nodegroup: 0)
     id=3    @198.51.100.3  (5.5.65-ndb-7.2.39, *no nodegroup*)
     id=4    @198.51.100.4  (5.5.65-ndb-7.2.39, *no nodegroup*)

     [ndb_mgmd(MGM)] 1 node(s)
     id=10   @198.51.100.10  (5.5.65-ndb-7.2.39)

     [mysqld(API)]   2 node(s)
     id=20   @198.51.100.20  (5.5.65-ndb-7.2.39)
     id=21   @198.51.100.21  (5.5.65-ndb-7.2.39)

Step 6: Create a new node group

You can do this by issuing a 'CREATE NODEGROUP' command in the cluster
management client.  This command takes as its argument a comma-separated
list of the node IDs of the data nodes to be included in the new node
group, as shown here:

     ndb_mgm> CREATE NODEGROUP 3,4
     Nodegroup 1 created

By issuing 'SHOW' again, you can verify that data nodes 3 and 4 have
joined the new node group (again indicated in bold type):

     ndb_mgm> SHOW
     Connected to Management Server at: 198.51.100.10:1186
     Cluster Configuration
     ---------------------
     [ndbd(NDB)]     2 node(s)
     id=1    @198.51.100.1  (5.5.65-ndb-7.2.39, Nodegroup: 0, *)
     id=2    @198.51.100.2  (5.5.65-ndb-7.2.39, Nodegroup: 0)
     id=3    @198.51.100.3  (5.5.65-ndb-7.2.39, *Nodegroup: 1*)
     id=4    @198.51.100.4  (5.5.65-ndb-7.2.39, *Nodegroup: 1*)

     [ndb_mgmd(MGM)] 1 node(s)
     id=10   @198.51.100.10  (5.5.65-ndb-7.2.39)

     [mysqld(API)]   2 node(s)
     id=20   @198.51.100.20  (5.5.65-ndb-7.2.39)
     id=21   @198.51.100.21  (5.5.65-ndb-7.2.39)

Step 7: Redistribute cluster data

When a node group is created, existing data and indexes are not
automatically distributed to the new node group's data nodes, as you can
see by issuing the appropriate 'REPORT' command in the management
client:

     ndb_mgm> ALL REPORT MEMORY

     Node 1: Data usage is 5%(177 32K pages of total 3200)
     Node 1: Index usage is 0%(108 8K pages of total 12832)
     Node 2: Data usage is 5%(177 32K pages of total 3200)
     Node 2: Index usage is 0%(108 8K pages of total 12832)
     *Node 3: Data usage is 0%(0 32K pages of total 3200)
     Node 3: Index usage is 0%(0 8K pages of total 12832)
     Node 4: Data usage is 0%(0 32K pages of total 3200)
     Node 4: Index usage is 0%(0 8K pages of total 12832)*

By using *note 'ndb_desc': mysql-cluster-programs-ndb-desc. with the
'-p' option, which causes the output to include partitioning
information, you can see that the table still uses only 2 partitions (in
the 'Per partition info' section of the output, shown here in bold
text):

     shell> ndb_desc -c 198.51.100.10 -d n ips -p
     -- ips --
     Version: 1
     Fragment type: 9
     K Value: 6
     Min load factor: 78
     Max load factor: 80
     Temporary table: no
     Number of attributes: 6
     Number of primary keys: 1
     Length of frm data: 340
     Row Checksum: 1
     Row GCI: 1
     SingleUserMode: 0
     ForceVarPart: 1
     FragmentCount: 2
     TableStatus: Retrieved
     -- Attributes --
     id Bigint PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY AUTO_INCR
     country_code Char(2;latin1_swedish_ci) NOT NULL AT=FIXED ST=MEMORY
     type Char(4;latin1_swedish_ci) NOT NULL AT=FIXED ST=MEMORY
     ip_address Varchar(15;latin1_swedish_ci) NOT NULL AT=SHORT_VAR ST=MEMORY
     addresses Bigunsigned NULL AT=FIXED ST=MEMORY
     date Bigunsigned NULL AT=FIXED ST=MEMORY

     -- Indexes --
     PRIMARY KEY(id) - UniqueHashIndex
     PRIMARY(id) - OrderedIndex

     *-- Per partition info --
     Partition   Row count   Commit count  Frag fixed memory   Frag varsized memory
     0           26086       26086         1572864             557056
     1           26329       26329         1605632             557056*

     NDBT_ProgramExit: 0 - OK

You can cause the data to be redistributed among all of the data nodes
by performing, for each *note 'NDB': mysql-cluster. table, an *note
'ALTER ONLINE TABLE ... REORGANIZE PARTITION': alter-table. statement in
the *note 'mysql': mysql. client.

*Important*:

'ALTER ONLINE TABLE ... REORGANIZE PARTITION' does not work on tables
that were created with the 'MAX_ROWS' option.  Instead, use 'ALTER
ONLINE TABLE ... MAX_ROWS=...' to reorganize such tables.

After issuing the statement 'ALTER ONLINE TABLE ips REORGANIZE
PARTITION', you can see using *note 'ndb_desc':
mysql-cluster-programs-ndb-desc. that the data for this table is now
stored using 4 partitions, as shown here (with the relevant portions of
the output in bold type):

     shell> ndb_desc -c 198.51.100.10 -d n ips -p
     -- ips --
     Version: 16777217
     Fragment type: 9
     K Value: 6
     Min load factor: 78
     Max load factor: 80
     Temporary table: no
     Number of attributes: 6
     Number of primary keys: 1
     Length of frm data: 341
     Row Checksum: 1
     Row GCI: 1
     SingleUserMode: 0
     ForceVarPart: 1
     FragmentCount: 4
     TableStatus: Retrieved
     -- Attributes --
     id Bigint PRIMARY KEY DISTRIBUTION KEY AT=FIXED ST=MEMORY AUTO_INCR
     country_code Char(2;latin1_swedish_ci) NOT NULL AT=FIXED ST=MEMORY
     type Char(4;latin1_swedish_ci) NOT NULL AT=FIXED ST=MEMORY
     ip_address Varchar(15;latin1_swedish_ci) NOT NULL AT=SHORT_VAR ST=MEMORY
     addresses Bigunsigned NULL AT=FIXED ST=MEMORY
     date Bigunsigned NULL AT=FIXED ST=MEMORY

     -- Indexes --
     PRIMARY KEY(id) - UniqueHashIndex
     PRIMARY(id) - OrderedIndex

     *-- Per partition info --
     Partition   Row count   Commit count  Frag fixed memory   Frag varsized memory
     0           12981       52296         1572864             557056
     1           13236       52515         1605632             557056
     2           13105       13105         819200              294912
     3           13093       13093         819200              294912*

     NDBT_ProgramExit: 0 - OK

*Note*:

Normally, *note 'ALTER [ONLINE] TABLE TABLE_NAME REORGANIZE PARTITION':
alter-table. is used with a list of partition identifiers and a set of
partition definitions to create a new partitioning scheme for a table
that has already been explicitly partitioned.  Its use here to
redistribute data onto a new NDB Cluster node group is an exception in
this regard; when used in this way, only the name of the table is used
following the 'TABLE' keyword, and no other keywords or identifiers
follow 'REORGANIZE PARTITION'.

For more information, see *note alter-table::.

In addition, for each table, the *note 'ALTER ONLINE TABLE':
alter-table. statement should be followed by an *note 'OPTIMIZE TABLE':
optimize-table. to reclaim wasted space.  You can obtain a list of all
*note 'NDBCLUSTER': mysql-cluster. tables using the following query
against the *note 'INFORMATION_SCHEMA.TABLES': tables-table. table:

     SELECT TABLE_SCHEMA, TABLE_NAME
         FROM INFORMATION_SCHEMA.TABLES
         WHERE ENGINE = 'NDBCLUSTER';

*Note*:

The 'INFORMATION_SCHEMA.TABLES.ENGINE' value for an NDB Cluster table is
always *note 'NDBCLUSTER': mysql-cluster, regardless of whether the
'CREATE TABLE' statement used to create the table (or *note 'ALTER
TABLE': alter-table. statement used to convert an existing table from a
different storage engine) used *note 'NDB': mysql-cluster. or *note
'NDBCLUSTER': mysql-cluster. in its 'ENGINE' option.

You can see after performing these statements in the output of 'ALL
REPORT MEMORY' that the data and indexes are now redistributed between
all cluster data nodes, as shown here:

     ndb_mgm> ALL REPORT MEMORY

     Node 1: Data usage is 5%(176 32K pages of total 3200)
     Node 1: Index usage is 0%(76 8K pages of total 12832)
     Node 2: Data usage is 5%(176 32K pages of total 3200)
     Node 2: Index usage is 0%(76 8K pages of total 12832)
     Node 3: Data usage is 2%(80 32K pages of total 3200)
     Node 3: Index usage is 0%(51 8K pages of total 12832)
     Node 4: Data usage is 2%(80 32K pages of total 3200)
     Node 4: Index usage is 0%(50 8K pages of total 12832)

*Note*:

Since only one DDL operation on *note 'NDBCLUSTER': mysql-cluster.
tables can be executed at a time, you must wait for each *note 'ALTER
ONLINE TABLE ... REORGANIZE PARTITION': alter-table. statement to finish
before issuing the next one.

It is not necessary to issue *note 'ALTER ONLINE TABLE ... REORGANIZE
PARTITION': alter-table. statements for *note 'NDBCLUSTER':
mysql-cluster. tables created _after_ the new data nodes have been
added; data added to such tables is distributed among all data nodes
automatically.  However, in *note 'NDBCLUSTER': mysql-cluster. tables
that existed _prior to_ the addition of the new nodes, neither existing
nor new data is distributed using the new nodes until these tables have
been reorganized using *note 'ALTER ONLINE TABLE ... REORGANIZE
PARTITION': alter-table.

Alternative procedure, without rolling restart

It is possible to avoid the need for a rolling restart by configuring
the extra data nodes, but not starting them, when first starting the
cluster.  We assume, as before, that you wish to start with two data
nodes--nodes 1 and 2--in one node group and later to expand the cluster
to four data nodes, by adding a second node group consisting of nodes 3
and 4:

     [ndbd default]
     DataMemory = 100M
     IndexMemory = 100M
     NoOfReplicas = 2
     DataDir = /usr/local/mysql/var/mysql-cluster

     [ndbd]
     Id = 1
     HostName = 198.51.100.1

     [ndbd]
     Id = 2
     HostName = 198.51.100.2

     [ndbd]
     Id = 3
     HostName = 198.51.100.3
     Nodegroup = 65536

     [ndbd]
     Id = 4
     HostName = 198.51.100.4
     Nodegroup = 65536

     [mgm]
     HostName = 198.51.100.10
     Id = 10

     [api]
     Id=20
     HostName = 198.51.100.20

     [api]
     Id=21
     HostName = 198.51.100.21

*Note*:

In NDB Cluster 7.2, it is no longer necessary to perform the initial
start of the cluster using '--nowait-nodes' option with *note 'ndbd':
mysql-cluster-programs-ndbd. or *note 'ndbmtd':
mysql-cluster-programs-ndbmtd. as it was in some earlier versions of NDB
Cluster.

The data nodes to be brought online at a later time (nodes 3 and 4) can
be configured with 'NodeGroup = 65536', in which case nodes 1 and 2 can
each be started as shown here:

     shell> ndbd -c 198.51.100.10 --initial

The data nodes configured with 'NodeGroup = 65536' are treated by the
management server as though you had started nodes 1 and 2 using
'--nowait-nodes=3,4' after waiting for a period of time determined by
the setting for the 'StartNoNodeGroupTimeout' data node configuration
parameter.  By default, this is 15 seconds (15000 milliseconds).

*Note*:

'StartNoNodegroupTimeout' must be the same for all data nodes in the
cluster; for this reason, you should always set it in the '[ndbd
default]' section of the 'config.ini' file, rather than for individual
data nodes.

When you are ready to add the second node group, you need only perform
the following additional steps:

  1. Start data nodes 3 and 4, invoking the data node process once for
     each new node:

          shell> ndbd -c 198.51.100.10 --initial

  2. Issue the appropriate 'CREATE NODEGROUP' command in the management
     client:

          ndb_mgm> CREATE NODEGROUP 3,4

  3. In the *note 'mysql': mysql. client, issue *note 'ALTER ONLINE
     TABLE ... REORGANIZE PARTITION': alter-table. and *note 'OPTIMIZE
     TABLE': optimize-table. statements for each existing *note
     'NDBCLUSTER': mysql-cluster. table.  (As noted elsewhere in this
     section, existing NDB Cluster tables cannot use the new nodes for
     data distribution until this has been done.)


File: manual.info.tmp,  Node: mysql-cluster-privilege-distribution,  Next: mysql-cluster-ndb-api-statistics,  Prev: mysql-cluster-online-add-node,  Up: mysql-cluster-management

18.5.15 Distributed Privileges Using Shared Grant Tables
--------------------------------------------------------

NDB Cluster 7.2 introduces support for distributing MySQL users and
privileges across all SQL nodes in an NDB Cluster.  This support is not
enabled by default; you should follow the procedure outlined in this
section in order to do so.

Normally, each MySQL server's user privilege tables in the 'mysql'
database must use the *note 'MyISAM': myisam-storage-engine. storage
engine, which means that a user account and its associated privileges
created on one SQL node are not available on the cluster's other SQL
nodes.  In NDB Cluster 7.2 and later, an SQL file 'ndb_dist_priv.sql' is
provided with the NDB Cluster distribution.  This file can be found in
the 'share' directory in the MySQL installation directory.

The first step in enabling distributed privileges is to load this script
into a MySQL Server that functions as an SQL node (which we refer to
after this as the _target_ SQL node or MySQL Server).  You can do this
by executing the following command from the system shell on the target
SQL node after changing to its MySQL installation directory (where
OPTIONS stands for any additional options needed to connect to this SQL
node):

     shell> mysql OPTIONS -uroot < share/ndb_dist_priv.sql

Importing 'ndb_dist_priv.sql' creates a number of stored routines (six
stored procedures and one stored function) in the 'mysql' database on
the target SQL node.  After connecting to the SQL node in the *note
'mysql': mysql. client (as the MySQL 'root' user), you can verify that
these were created as shown here:

     mysql> SELECT ROUTINE_NAME, ROUTINE_SCHEMA, ROUTINE_TYPE
         ->     FROM INFORMATION_SCHEMA.ROUTINES
         ->     WHERE ROUTINE_NAME LIKE 'mysql_cluster%'
         ->     ORDER BY ROUTINE_TYPE;
     +---------------------------------------------+----------------+--------------+
     | ROUTINE_NAME                                | ROUTINE_SCHEMA | ROUTINE_TYPE |
     +---------------------------------------------+----------------+--------------+
     | mysql_cluster_privileges_are_distributed    | mysql          | FUNCTION     |
     | mysql_cluster_backup_privileges             | mysql          | PROCEDURE    |
     | mysql_cluster_move_grant_tables             | mysql          | PROCEDURE    |
     | mysql_cluster_move_privileges               | mysql          | PROCEDURE    |
     | mysql_cluster_restore_local_privileges      | mysql          | PROCEDURE    |
     | mysql_cluster_restore_privileges            | mysql          | PROCEDURE    |
     | mysql_cluster_restore_privileges_from_local | mysql          | PROCEDURE    |
     +---------------------------------------------+----------------+--------------+

     7 rows in set (0.01 sec)

The stored procedure named 'mysql_cluster_move_privileges' creates
backup copies of the existing privilege tables, then converts them to
*note 'NDB': mysql-cluster.

'mysql_cluster_move_privileges' performs the backup and conversion in
two steps.  The first step is to call 'mysql_cluster_backup_privileges',
which creates two sets of copies in the 'mysql' database:

   * A set of local copies that use the *note 'MyISAM':
     myisam-storage-engine. storage engine.  Their names are generated
     by adding the suffix '_backup' to the original privilege table
     names.

   * A set of distributed copies that use the *note 'NDBCLUSTER':
     mysql-cluster. storage engine.  These tables are named by prefixing
     'ndb_' and appending '_backup' to the names of the original tables.

After the copies are created, 'mysql_cluster_move_privileges' invokes
'mysql_cluster_move_grant_tables', which contains the *note 'ALTER TABLE
... ENGINE = NDB': alter-table. statements that convert the mysql system
tables to *note 'NDB': mysql-cluster.

Normally, you should not invoke either 'mysql_cluster_backup_privileges'
or 'mysql_cluster_move_grant_tables' manually; these stored procedures
are intended only for use by 'mysql_cluster_move_privileges'.

Although the original privilege tables are backed up automatically, it
is always a good idea to create backups manually of the existing
privilege tables on all affected SQL nodes before proceeding.  You can
do this using *note 'mysqldump': mysqldump. in a manner similar to what
is shown here:

     shell> mysqldump OPTIONS -uroot \
         mysql host user db tables_priv columns_priv procs_priv proxies_priv > BACKUP_FILE

To perform the conversion, you must be connected to the target SQL node
using the *note 'mysql': mysql. client (again, as the MySQL 'root'
user).  Invoke the stored procedure like this:

     mysql> CALL mysql.mysql_cluster_move_privileges();
     Query OK, 0 rows affected (22.32 sec)

Depending on the number of rows in the privilege tables, this procedure
may take some time to execute.  If some of the privilege tables are
empty, you may see one or more 'No data - zero rows fetched, selected,
or processed' warnings when 'mysql_cluster_move_privileges' returns.  In
such cases, the warnings may be safely ignored.  To verify that the
conversion was successful, you can use the stored function
'mysql_cluster_privileges_are_distributed' as shown here:

     mysql> SELECT CONCAT(
         ->    'Conversion ',
         ->    IF(mysql.mysql_cluster_privileges_are_distributed(), 'succeeded', 'failed'),
         ->    '.')
         ->    AS Result;
     +-----------------------+
     | Result                |
     +-----------------------+
     | Conversion succeeded. |
     +-----------------------+
     1 row in set (0.00 sec)

'mysql_cluster_privileges_are_distributed' checks for the existence of
the distributed privilege tables and returns '1' if all of the privilege
tables are distributed; otherwise, it returns '0'.

You can verify that the backups have been created using a query such as
this one:

     mysql> SELECT TABLE_NAME, ENGINE FROM INFORMATION_SCHEMA.TABLES
         ->     WHERE TABLE_SCHEMA = 'mysql' AND TABLE_NAME LIKE '%backup'
         ->     ORDER BY ENGINE;
     +-------------------------+------------+
     | TABLE_NAME              | ENGINE     |
     +-------------------------+------------+
     | columns_priv_backup     | MyISAM     |
     | user_backup             | MyISAM     |
     | tables_priv_backup      | MyISAM     |
     | proxies_priv_backup     | MyISAM     |
     | procs_priv_backup       | MyISAM     |
     | host_backup             | MyISAM     |
     | db_backup               | MyISAM     |
     | ndb_user_backup         | ndbcluster |
     | ndb_tables_priv_backup  | ndbcluster |
     | ndb_proxies_priv_backup | ndbcluster |
     | ndb_procs_priv_backup   | ndbcluster |
     | ndb_host_backup         | ndbcluster |
     | ndb_db_backup           | ndbcluster |
     | ndb_columns_priv_backup | ndbcluster |
     +-------------------------+------------+
     14 rows in set (0.02 sec)

Once the conversion to distributed privileges has been made, any time a
MySQL user account is created, dropped, or has its privileges updated on
any SQL node, the changes take effect immediately on all other MySQL
servers attached to the cluster.  Once privileges are distributed, any
new MySQL Servers that connect to the cluster automatically participate
in the distribution.

*Note*:

For clients connected to SQL nodes at the time that
'mysql_cluster_move_privileges' is executed, you may need to execute
'FLUSH PRIVILEGES' on those SQL nodes, or to disconnect and then
reconnect the clients, in order for those clients to be able to see the
changes in privileges.

All MySQL user privileges are distributed across all connected MySQL
Servers.  This includes any privileges associated with views and stored
routines, even though distribution of views and stored routines
themselves is not currently supported.

In the event that an SQL node becomes disconnected from the cluster
while 'mysql_cluster_move_privileges' is running, you must drop its
privilege tables after reconnecting to the cluster, using a statement
such as *note 'DROP TABLE IF EXISTS mysql.user mysql.db
mysql.tables_priv mysql.columns_priv mysql.procs_priv': drop-table.
This causes the SQL node to use the shared privilege tables rather than
its own local versions of them.  This is not needed when connecting a
new SQL node to the cluster for the first time.

In the event of an initial restart of the entire cluster (all data nodes
shut down, then started again with '--initial'), the shared privilege
tables are lost.  If this happens, you can restore them using the
original target SQL node either from the backups made by
'mysql_cluster_move_privileges' or from a dump file created with *note
'mysqldump': mysqldump.  If you need to use a new MySQL Server to
perform the restoration, you should start it with '--skip-grant-tables'
when connecting to the cluster for the first time; after this, you can
restore the privilege tables locally, then distribute them again using
'mysql_cluster_move_privileges'.  After restoring and distributing the
tables, you should restart this MySQL Server without the
'--skip-grant-tables' option.

You can also restore the distributed tables using *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. '--restore-privilege-tables' from a
backup made using *note 'START BACKUP':
mysql-cluster-backup-using-management-client. in the *note 'ndb_mgm':
mysql-cluster-programs-ndb-mgm. client.  (The *note 'MyISAM':
myisam-storage-engine. tables created by 'mysql_cluster_move_privileges'
are not backed up by the 'START BACKUP' command.)  *note 'ndb_restore':
mysql-cluster-programs-ndb-restore. does not restore the privilege
tables by default; the '--restore-privilege-tables' option causes it to
do so.

You can restore the SQL node's local privileges using either of two
procedures.  'mysql_cluster_restore_privileges' works as follows:

  1. If copies of the 'mysql.ndb_*_backup' tables are available, attempt
     to restore the system tables from these.

  2. Otherwise, attempt to restore the system tables from the local
     backups named '*_backup' (without the 'ndb_' prefix).

The other procedure, named 'mysql_cluster_restore_local_privileges',
restores the system tables from the local backups only, without checking
the 'ndb_*' backups.

The system tables re-created by 'mysql_cluster_restore_privileges' or
'mysql_cluster_restore_local_privileges' use the MySQL server default
storage engine; they are not shared or distributed in any way, and do
not use NDB Cluster's *note 'NDB': mysql-cluster. storage engine.

The additional stored procedure
'mysql_cluster_restore_privileges_from_local' is intended for the use of
'mysql_cluster_restore_privileges' and
'mysql_cluster_restore_local_privileges'.  It should not be invoked
directly.

*Important*:

Applications that access NDB Cluster data directly, including NDB API
and ClusterJ applications, are not subject to the MySQL privilege
system.  This means that, once you have distributed the grant tables,
they can be freely accessed by such applications, just as they can any
other *note 'NDB': mysql-cluster. tables.  In particular, you should
keep in mind that _NDB API and ClusterJ applications can read and write
user names, host names, password hashes, and any other contents of the
distributed grant tables without any restrictions_.


File: manual.info.tmp,  Node: mysql-cluster-ndb-api-statistics,  Prev: mysql-cluster-privilege-distribution,  Up: mysql-cluster-management

18.5.16 NDB API Statistics Counters and Variables
-------------------------------------------------

A number of types of statistical counters relating to actions performed
by or affecting 'Ndb' (https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html)
objects are available.  Such actions include starting and closing (or
aborting) transactions; primary key and unique key operations; table,
range, and pruned scans; threads blocked while waiting for the
completion of various operations; and data and events sent and received
by 'NDBCLUSTER'.  The counters are incremented inside the NDB kernel
whenever NDB API calls are made or data is sent to or received by the
data nodes.  *note 'mysqld': mysqld. exposes these counters as system
status variables; their values can be read in the output of *note 'SHOW
STATUS': show-status, or by querying the *note
'INFORMATION_SCHEMA.SESSION_STATUS': status-table. or *note
'INFORMATION_SCHEMA.GLOBAL_STATUS': status-table. table.  By comparing
the values before and after statements operating on *note 'NDB':
mysql-cluster. tables, you can observe the corresponding actions taken
on the API level, and thus the cost of performing the statement.

You can list all of these status variables using the following *note
'SHOW STATUS': show-status. statement:

     mysql> SHOW STATUS LIKE 'ndb_api%';
     +--------------------------------------------+----------+
     | Variable_name                              | Value    |
     +--------------------------------------------+----------+
     | Ndb_api_wait_exec_complete_count_session   | 0        |
     | Ndb_api_wait_scan_result_count_session     | 0        |
     | Ndb_api_wait_meta_request_count_session    | 0        |
     | Ndb_api_wait_nanos_count_session           | 0        |
     | Ndb_api_bytes_sent_count_session           | 0        |
     | Ndb_api_bytes_received_count_session       | 0        |
     | Ndb_api_trans_start_count_session          | 0        |
     | Ndb_api_trans_commit_count_session         | 0        |
     | Ndb_api_trans_abort_count_session          | 0        |
     | Ndb_api_trans_close_count_session          | 0        |
     | Ndb_api_pk_op_count_session                | 0        |
     | Ndb_api_uk_op_count_session                | 0        |
     | Ndb_api_table_scan_count_session           | 0        |
     | Ndb_api_range_scan_count_session           | 0        |
     | Ndb_api_pruned_scan_count_session          | 0        |
     | Ndb_api_scan_batch_count_session           | 0        |
     | Ndb_api_read_row_count_session             | 0        |
     | Ndb_api_trans_local_read_row_count_session | 0        |
     | Ndb_api_event_data_count_injector          | 0        |
     | Ndb_api_event_nondata_count_injector       | 0        |
     | Ndb_api_event_bytes_count_injector         | 0        |
     | Ndb_api_wait_exec_complete_count_slave     | 0        |
     | Ndb_api_wait_scan_result_count_slave       | 0        |
     | Ndb_api_wait_meta_request_count_slave      | 0        |
     | Ndb_api_wait_nanos_count_slave             | 0        |
     | Ndb_api_bytes_sent_count_slave             | 0        |
     | Ndb_api_bytes_received_count_slave         | 0        |
     | Ndb_api_trans_start_count_slave            | 0        |
     | Ndb_api_trans_commit_count_slave           | 0        |
     | Ndb_api_trans_abort_count_slave            | 0        |
     | Ndb_api_trans_close_count_slave            | 0        |
     | Ndb_api_pk_op_count_slave                  | 0        |
     | Ndb_api_uk_op_count_slave                  | 0        |
     | Ndb_api_table_scan_count_slave             | 0        |
     | Ndb_api_range_scan_count_slave             | 0        |
     | Ndb_api_pruned_scan_count_slave            | 0        |
     | Ndb_api_scan_batch_count_slave             | 0        |
     | Ndb_api_read_row_count_slave               | 0        |
     | Ndb_api_trans_local_read_row_count_slave   | 0        |
     | Ndb_api_wait_exec_complete_count           | 2        |
     | Ndb_api_wait_scan_result_count             | 3        |
     | Ndb_api_wait_meta_request_count            | 27       |
     | Ndb_api_wait_nanos_count                   | 45612023 |
     | Ndb_api_bytes_sent_count                   | 992      |
     | Ndb_api_bytes_received_count               | 9640     |
     | Ndb_api_trans_start_count                  | 2        |
     | Ndb_api_trans_commit_count                 | 1        |
     | Ndb_api_trans_abort_count                  | 0        |
     | Ndb_api_trans_close_count                  | 2        |
     | Ndb_api_pk_op_count                        | 1        |
     | Ndb_api_uk_op_count                        | 0        |
     | Ndb_api_table_scan_count                   | 1        |
     | Ndb_api_range_scan_count                   | 0        |
     | Ndb_api_pruned_scan_count                  | 0        |
     | Ndb_api_scan_batch_count                   | 0        |
     | Ndb_api_read_row_count                     | 1        |
     | Ndb_api_trans_local_read_row_count         | 1        |
     | Ndb_api_event_data_count                   | 0        |
     | Ndb_api_event_nondata_count                | 0        |
     | Ndb_api_event_bytes_count                  | 0        |
     +--------------------------------------------+----------+
     60 rows in set (0.02 sec)

These status variables are also available from the *note
'SESSION_STATUS': status-table. and *note 'GLOBAL_STATUS': status-table.
tables of the 'INFORMATION_SCHEMA' database, as shown here:

     mysql> SELECT * FROM INFORMATION_SCHEMA.SESSION_STATUS
         ->   WHERE VARIABLE_NAME LIKE 'ndb_api%';
     +--------------------------------------------+----------------+
     | VARIABLE_NAME                              | VARIABLE_VALUE |
     +--------------------------------------------+----------------+
     | NDB_API_WAIT_EXEC_COMPLETE_COUNT_SESSION   | 2              |
     | NDB_API_WAIT_SCAN_RESULT_COUNT_SESSION     | 0              |
     | NDB_API_WAIT_META_REQUEST_COUNT_SESSION    | 1              |
     | NDB_API_WAIT_NANOS_COUNT_SESSION           | 8144375        |
     | NDB_API_BYTES_SENT_COUNT_SESSION           | 68             |
     | NDB_API_BYTES_RECEIVED_COUNT_SESSION       | 84             |
     | NDB_API_TRANS_START_COUNT_SESSION          | 1              |
     | NDB_API_TRANS_COMMIT_COUNT_SESSION         | 1              |
     | NDB_API_TRANS_ABORT_COUNT_SESSION          | 0              |
     | NDB_API_TRANS_CLOSE_COUNT_SESSION          | 1              |
     | NDB_API_PK_OP_COUNT_SESSION                | 1              |
     | NDB_API_UK_OP_COUNT_SESSION                | 0              |
     | NDB_API_TABLE_SCAN_COUNT_SESSION           | 0              |
     | NDB_API_RANGE_SCAN_COUNT_SESSION           | 0              |
     | NDB_API_PRUNED_SCAN_COUNT_SESSION          | 0              |
     | NDB_API_SCAN_BATCH_COUNT_SESSION           | 0              |
     | NDB_API_READ_ROW_COUNT_SESSION             | 1              |
     | NDB_API_TRANS_LOCAL_READ_ROW_COUNT_SESSION | 1              |
     | NDB_API_EVENT_DATA_COUNT_INJECTOR          | 0              |
     | NDB_API_EVENT_NONDATA_COUNT_INJECTOR       | 0              |
     | NDB_API_EVENT_BYTES_COUNT_INJECTOR         | 0              |
     | NDB_API_WAIT_EXEC_COMPLETE_COUNT_SLAVE     | 0              |
     | NDB_API_WAIT_SCAN_RESULT_COUNT_SLAVE       | 0              |
     | NDB_API_WAIT_META_REQUEST_COUNT_SLAVE      | 0              |
     | NDB_API_WAIT_NANOS_COUNT_SLAVE             | 0              |
     | NDB_API_BYTES_SENT_COUNT_SLAVE             | 0              |
     | NDB_API_BYTES_RECEIVED_COUNT_SLAVE         | 0              |
     | NDB_API_TRANS_START_COUNT_SLAVE            | 0              |
     | NDB_API_TRANS_COMMIT_COUNT_SLAVE           | 0              |
     | NDB_API_TRANS_ABORT_COUNT_SLAVE            | 0              |
     | NDB_API_TRANS_CLOSE_COUNT_SLAVE            | 0              |
     | NDB_API_PK_OP_COUNT_SLAVE                  | 0              |
     | NDB_API_UK_OP_COUNT_SLAVE                  | 0              |
     | NDB_API_TABLE_SCAN_COUNT_SLAVE             | 0              |
     | NDB_API_RANGE_SCAN_COUNT_SLAVE             | 0              |
     | NDB_API_PRUNED_SCAN_COUNT_SLAVE            | 0              |
     | NDB_API_SCAN_BATCH_COUNT_SLAVE             | 0              |
     | NDB_API_READ_ROW_COUNT_SLAVE               | 0              |
     | NDB_API_TRANS_LOCAL_READ_ROW_COUNT_SLAVE   | 0              |
     | NDB_API_WAIT_EXEC_COMPLETE_COUNT           | 4              |
     | NDB_API_WAIT_SCAN_RESULT_COUNT             | 3              |
     | NDB_API_WAIT_META_REQUEST_COUNT            | 28             |
     | NDB_API_WAIT_NANOS_COUNT                   | 53756398       |
     | NDB_API_BYTES_SENT_COUNT                   | 1060           |
     | NDB_API_BYTES_RECEIVED_COUNT               | 9724           |
     | NDB_API_TRANS_START_COUNT                  | 3              |
     | NDB_API_TRANS_COMMIT_COUNT                 | 2              |
     | NDB_API_TRANS_ABORT_COUNT                  | 0              |
     | NDB_API_TRANS_CLOSE_COUNT                  | 3              |
     | NDB_API_PK_OP_COUNT                        | 2              |
     | NDB_API_UK_OP_COUNT                        | 0              |
     | NDB_API_TABLE_SCAN_COUNT                   | 1              |
     | NDB_API_RANGE_SCAN_COUNT                   | 0              |
     | NDB_API_PRUNED_SCAN_COUNT                  | 0              |
     | NDB_API_SCAN_BATCH_COUNT                   | 0              |
     | NDB_API_READ_ROW_COUNT                     | 2              |
     | NDB_API_TRANS_LOCAL_READ_ROW_COUNT         | 2              |
     | NDB_API_EVENT_DATA_COUNT                   | 0              |
     | NDB_API_EVENT_NONDATA_COUNT                | 0              |
     | NDB_API_EVENT_BYTES_COUNT                  | 0              |
     +--------------------------------------------+----------------+
     60 rows in set (0.00 sec)

     mysql> SELECT * FROM INFORMATION_SCHEMA.GLOBAL_STATUS
         ->     WHERE VARIABLE_NAME LIKE 'ndb_api%';
     +--------------------------------------------+----------------+
     | VARIABLE_NAME                              | VARIABLE_VALUE |
     +--------------------------------------------+----------------+
     | NDB_API_WAIT_EXEC_COMPLETE_COUNT_SESSION   | 2              |
     | NDB_API_WAIT_SCAN_RESULT_COUNT_SESSION     | 0              |
     | NDB_API_WAIT_META_REQUEST_COUNT_SESSION    | 1              |
     | NDB_API_WAIT_NANOS_COUNT_SESSION           | 8144375        |
     | NDB_API_BYTES_SENT_COUNT_SESSION           | 68             |
     | NDB_API_BYTES_RECEIVED_COUNT_SESSION       | 84             |
     | NDB_API_TRANS_START_COUNT_SESSION          | 1              |
     | NDB_API_TRANS_COMMIT_COUNT_SESSION         | 1              |
     | NDB_API_TRANS_ABORT_COUNT_SESSION          | 0              |
     | NDB_API_TRANS_CLOSE_COUNT_SESSION          | 1              |
     | NDB_API_PK_OP_COUNT_SESSION                | 1              |
     | NDB_API_UK_OP_COUNT_SESSION                | 0              |
     | NDB_API_TABLE_SCAN_COUNT_SESSION           | 0              |
     | NDB_API_RANGE_SCAN_COUNT_SESSION           | 0              |
     | NDB_API_PRUNED_SCAN_COUNT_SESSION          | 0              |
     | NDB_API_SCAN_BATCH_COUNT_SESSION           | 0              |
     | NDB_API_READ_ROW_COUNT_SESSION             | 1              |
     | NDB_API_TRANS_LOCAL_READ_ROW_COUNT_SESSION | 1              |
     | NDB_API_EVENT_DATA_COUNT_INJECTOR          | 0              |
     | NDB_API_EVENT_NONDATA_COUNT_INJECTOR       | 0              |
     | NDB_API_EVENT_BYTES_COUNT_INJECTOR         | 0              |
     | NDB_API_WAIT_EXEC_COMPLETE_COUNT_SLAVE     | 0              |
     | NDB_API_WAIT_SCAN_RESULT_COUNT_SLAVE       | 0              |
     | NDB_API_WAIT_META_REQUEST_COUNT_SLAVE      | 0              |
     | NDB_API_WAIT_NANOS_COUNT_SLAVE             | 0              |
     | NDB_API_BYTES_SENT_COUNT_SLAVE             | 0              |
     | NDB_API_BYTES_RECEIVED_COUNT_SLAVE         | 0              |
     | NDB_API_TRANS_START_COUNT_SLAVE            | 0              |
     | NDB_API_TRANS_COMMIT_COUNT_SLAVE           | 0              |
     | NDB_API_TRANS_ABORT_COUNT_SLAVE            | 0              |
     | NDB_API_TRANS_CLOSE_COUNT_SLAVE            | 0              |
     | NDB_API_PK_OP_COUNT_SLAVE                  | 0              |
     | NDB_API_UK_OP_COUNT_SLAVE                  | 0              |
     | NDB_API_TABLE_SCAN_COUNT_SLAVE             | 0              |
     | NDB_API_RANGE_SCAN_COUNT_SLAVE             | 0              |
     | NDB_API_PRUNED_SCAN_COUNT_SLAVE            | 0              |
     | NDB_API_SCAN_BATCH_COUNT_SLAVE             | 0              |
     | NDB_API_READ_ROW_COUNT_SLAVE               | 0              |
     | NDB_API_TRANS_LOCAL_READ_ROW_COUNT_SLAVE   | 0              |
     | NDB_API_WAIT_EXEC_COMPLETE_COUNT           | 4              |
     | NDB_API_WAIT_SCAN_RESULT_COUNT             | 3              |
     | NDB_API_WAIT_META_REQUEST_COUNT            | 28             |
     | NDB_API_WAIT_NANOS_COUNT                   | 53756398       |
     | NDB_API_BYTES_SENT_COUNT                   | 1060           |
     | NDB_API_BYTES_RECEIVED_COUNT               | 9724           |
     | NDB_API_TRANS_START_COUNT                  | 3              |
     | NDB_API_TRANS_COMMIT_COUNT                 | 2              |
     | NDB_API_TRANS_ABORT_COUNT                  | 0              |
     | NDB_API_TRANS_CLOSE_COUNT                  | 3              |
     | NDB_API_PK_OP_COUNT                        | 2              |
     | NDB_API_UK_OP_COUNT                        | 0              |
     | NDB_API_TABLE_SCAN_COUNT                   | 1              |
     | NDB_API_RANGE_SCAN_COUNT                   | 0              |
     | NDB_API_PRUNED_SCAN_COUNT                  | 0              |
     | NDB_API_SCAN_BATCH_COUNT                   | 0              |
     | NDB_API_READ_ROW_COUNT                     | 2              |
     | NDB_API_TRANS_LOCAL_READ_ROW_COUNT         | 2              |
     | NDB_API_EVENT_DATA_COUNT                   | 0              |
     | NDB_API_EVENT_NONDATA_COUNT                | 0              |
     | NDB_API_EVENT_BYTES_COUNT                  | 0              |
     +--------------------------------------------+----------------+
     60 rows in set (0.00 sec)

Each 'Ndb' (https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) object has
its own counters.  NDB API applications can read the values of the
counters for use in optimization or monitoring.  For multithreaded
clients which use more than one 'Ndb'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) object concurrently,
it is also possible to obtain a summed view of counters from all 'Ndb'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) objects belonging to
a given 'Ndb_cluster_connection'
(https://dev.mysql.com/doc/ndbapi/en/ndb-ndb-cluster-connection.html).

Four sets of these counters are exposed.  One set applies to the current
session only; the other 3 are global.  _This is in spite of the fact
that their values can be obtained as either session or global status
variables in the *note 'mysql': mysql. client_.  This means that
specifying the 'SESSION' or 'GLOBAL' keyword with *note 'SHOW STATUS':
show-status. has no effect on the values reported for NDB API statistics
status variables, and the value for each of these variables is the same
whether the value is obtained from the equivalent column of the *note
'SESSION_STATUS': status-table. or the *note 'GLOBAL_STATUS':
status-table. table.

   * _Session counters (session specific)_

     Session counters relate to the 'Ndb'
     (https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) objects in use
     by (only) the current session.  Use of such objects by other MySQL
     clients does not influence these counts.

     In order to minimize confusion with standard MySQL session
     variables, we refer to the variables that correspond to these NDB
     API session counters as ''_session' variables', with a leading
     underscore.

   * _Slave counters (global)_

     This set of counters relates to the 'Ndb'
     (https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) objects used by
     the replication slave SQL thread, if any.  If this *note 'mysqld':
     mysqld. does not act as a replication slave, or does not use *note
     'NDB': mysql-cluster. tables, then all of these counts are 0.

     We refer to the related status variables as ''_slave' variables'
     (with a leading underscore).

   * _Injector counters (global)_

     Injector counters relate to the 'Ndb'
     (https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) object used to
     listen to cluster events by the binary log injector thread.  Even
     when not writing a binary log, *note 'mysqld': mysqld. processes
     attached to an NDB Cluster continue to listen for some events, such
     as schema changes.

     We refer to the status variables that correspond to NDB API
     injector counters as ''_injector' variables' (with a leading
     underscore).

   * _Server (Global) counters (global)_

     This set of counters relates to all 'Ndb'
     (https://dev.mysql.com/doc/ndbapi/en/ndb-ndb.html) objects
     currently used by this *note 'mysqld': mysqld.  This includes all
     MySQL client applications, the slave SQL thread (if any), the
     binlog injector, and the *note 'NDB': mysql-cluster. utility
     thread.

     We refer to the status variables that correspond to these counters
     as 'global variables' or '*note 'mysqld': mysqld.-level variables'.

You can obtain values for a particular set of variables by additionally
filtering for the substring 'session', 'slave', or 'injector' in the
variable name (along with the common prefix 'Ndb_api').  For '_session'
variables, this can be done as shown here:

     mysql> SHOW STATUS LIKE 'ndb_api%session';
     +--------------------------------------------+---------+
     | Variable_name                              | Value   |
     +--------------------------------------------+---------+
     | Ndb_api_wait_exec_complete_count_session   | 2       |
     | Ndb_api_wait_scan_result_count_session     | 0       |
     | Ndb_api_wait_meta_request_count_session    | 1       |
     | Ndb_api_wait_nanos_count_session           | 8144375 |
     | Ndb_api_bytes_sent_count_session           | 68      |
     | Ndb_api_bytes_received_count_session       | 84      |
     | Ndb_api_trans_start_count_session          | 1       |
     | Ndb_api_trans_commit_count_session         | 1       |
     | Ndb_api_trans_abort_count_session          | 0       |
     | Ndb_api_trans_close_count_session          | 1       |
     | Ndb_api_pk_op_count_session                | 1       |
     | Ndb_api_uk_op_count_session                | 0       |
     | Ndb_api_table_scan_count_session           | 0       |
     | Ndb_api_range_scan_count_session           | 0       |
     | Ndb_api_pruned_scan_count_session          | 0       |
     | Ndb_api_scan_batch_count_session           | 0       |
     | Ndb_api_read_row_count_session             | 1       |
     | Ndb_api_trans_local_read_row_count_session | 1       |
     +--------------------------------------------+---------+
     18 rows in set (0.50 sec)

To obtain a listing of the NDB API *note 'mysqld': mysqld.-level status
variables, filter for variable names beginning with 'ndb_api' and ending
in '_count', like this:

     mysql> SELECT * FROM INFORMATION_SCHEMA.SESSION_STATUS
         ->     WHERE VARIABLE_NAME LIKE 'ndb_api%count';
     +------------------------------------+----------------+
     | VARIABLE_NAME                      | VARIABLE_VALUE |
     +------------------------------------+----------------+
     | NDB_API_WAIT_EXEC_COMPLETE_COUNT   | 4              |
     | NDB_API_WAIT_SCAN_RESULT_COUNT     | 3              |
     | NDB_API_WAIT_META_REQUEST_COUNT    | 28             |
     | NDB_API_WAIT_NANOS_COUNT           | 53756398       |
     | NDB_API_BYTES_SENT_COUNT           | 1060           |
     | NDB_API_BYTES_RECEIVED_COUNT       | 9724           |
     | NDB_API_TRANS_START_COUNT          | 3              |
     | NDB_API_TRANS_COMMIT_COUNT         | 2              |
     | NDB_API_TRANS_ABORT_COUNT          | 0              |
     | NDB_API_TRANS_CLOSE_COUNT          | 3              |
     | NDB_API_PK_OP_COUNT                | 2              |
     | NDB_API_UK_OP_COUNT                | 0              |
     | NDB_API_TABLE_SCAN_COUNT           | 1              |
     | NDB_API_RANGE_SCAN_COUNT           | 0              |
     | NDB_API_PRUNED_SCAN_COUNT          | 0              |
     | NDB_API_SCAN_BATCH_COUNT           | 0              |
     | NDB_API_READ_ROW_COUNT             | 2              |
     | NDB_API_TRANS_LOCAL_READ_ROW_COUNT | 2              |
     | NDB_API_EVENT_DATA_COUNT           | 0              |
     | NDB_API_EVENT_NONDATA_COUNT        | 0              |
     | NDB_API_EVENT_BYTES_COUNT          | 0              |
     +------------------------------------+----------------+
     21 rows in set (0.09 sec)

Not all counters are reflected in all 4 sets of status variables.  For
the event counters 'DataEventsRecvdCount', 'NondataEventsRecvdCount',
and 'EventBytesRecvdCount', only '_injector' and *note 'mysqld':
mysqld.-level NDB API status variables are available:

     mysql> SHOW STATUS LIKE 'ndb_api%event%';
     +--------------------------------------+-------+
     | Variable_name                        | Value |
     +--------------------------------------+-------+
     | Ndb_api_event_data_count_injector    | 0     |
     | Ndb_api_event_nondata_count_injector | 0     |
     | Ndb_api_event_bytes_count_injector   | 0     |
     | Ndb_api_event_data_count             | 0     |
     | Ndb_api_event_nondata_count          | 0     |
     | Ndb_api_event_bytes_count            | 0     |
     +--------------------------------------+-------+
     6 rows in set (0.00 sec)

'_injector' status variables are not implemented for any other NDB API
counters, as shown here:

     mysql> SHOW STATUS LIKE 'ndb_api%injector%';
     +--------------------------------------+-------+
     | Variable_name                        | Value |
     +--------------------------------------+-------+
     | Ndb_api_event_data_count_injector    | 0     |
     | Ndb_api_event_nondata_count_injector | 0     |
     | Ndb_api_event_bytes_count_injector   | 0     |
     +--------------------------------------+-------+
     3 rows in set (0.00 sec)

The names of the status variables can easily be associated with the
names of the corresponding counters.  Each NDB API statistics counter is
listed in the following table with a description as well as the names of
any MySQL server status variables corresponding to this counter.

*NDB API statistics counters*

Counter Name           Description               Status Variables (by
                                                 statistic type):
                                                 
                                                    * Session
                                                 
                                                    * Slave
                                                 
                                                    * Injector
                                                 
                                                    * Server
                                                 
'WaitExecCompleteCount'Number of times thread    
                       has been blocked while       * 
                       waiting for execution          'Ndb_api_wait_exec_complete_count_session'
                       of an operation to        
                       complete.  Includes all      * 
                       'execute()'                    'Ndb_api_wait_exec_complete_count_slave'
                       (https://dev.mysql.com/doc/ndbapi/en/ndb-ndbtransaction-execute.html)
                       calls as well as             * [none]
                       implicit executes for     
                       blob operations and          * 
                       auto-increment not             'Ndb_api_wait_exec_complete_count'
                       visible to clients.       
                       
'WaitScanResultCount'  Number of times thread    
                       has been blocked while       * 
                       waiting for a                  'Ndb_api_wait_scan_result_count_session'
                       scan-based signal, such   
                       waiting for additional       * 
                       results, or for a scan         'Ndb_api_wait_scan_result_count_slave'
                       to close.                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_wait_scan_result_count'
                                                 
'WaitMetaRequestCount' Number of times thread    
                       has been blocked             * 
                       waiting for a                  'Ndb_api_wait_meta_request_count_session'
                       metadata-based signal;    
                       this can occur when          * 
                       waiting for a DDL              'Ndb_api_wait_meta_request_count_slave'
                       operation or for an       
                       epoch to be started (or      * [none]
                       ended).                   
                                                    * 
                                                      'Ndb_api_wait_meta_request_count'
                                                 
'WaitNanosCount'       Total time (in            
                       nanoseconds) spent           * 
                       waiting for some type          'Ndb_api_wait_nanos_count_session'
                       of signal from the data   
                       nodes.                       * 
                                                      'Ndb_api_wait_nanos_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_wait_nanos_count'
                                                 
'BytesSentCount'       Amount of data (in        
                       bytes) sent to the data      * 
                       nodes                          'Ndb_api_bytes_sent_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_bytes_sent_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_bytes_sent_count'
                                                 
'BytesRecvdCount'      Amount of data (in        
                       bytes) received from         * 
                       the data nodes                 'Ndb_api_bytes_received_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_bytes_received_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_bytes_received_count'
                                                 
'TransStartCount'      Number of transactions    
                       started.                     * 
                                                      'Ndb_api_trans_start_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_trans_start_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_trans_start_count'
                                                 
'TransCommitCount'     Number of transactions    
                       committed.                   * 
                                                      'Ndb_api_trans_commit_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_trans_commit_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_trans_commit_count'
                                                 
'TransAbortCount'      Number of transactions    
                       aborted.                     * 
                                                      'Ndb_api_trans_abort_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_trans_abort_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_trans_abort_count'
                                                 
'TransCloseCount'      Number of transactions    
                       aborted.  (This value        * 
                       may be greater than the        'Ndb_api_trans_close_count_session'
                       sum of                    
                       'TransCommitCount' and       * 
                       'TransAbortCount'.)            'Ndb_api_trans_close_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_trans_close_count'
                                                 
'PkOpCount'            Number of operations      
                       based on or using            * 
                       primary keys.  This            'Ndb_api_pk_op_count_session'
                       count includes            
                       blob-part table              * 
                       operations, implicit           'Ndb_api_pk_op_count_slave'
                       unlocking operations,     
                       and auto-increment           * [none]
                       operations, as well as    
                       primary key operations       * 'Ndb_api_pk_op_count'
                       normally visible to       
                       MySQL clients.
                       
'UkOpCount'            Number of operations      
                       based on or using            * 
                       unique keys.                   'Ndb_api_uk_op_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_uk_op_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 'Ndb_api_uk_op_count'
                                                 
'TableScanCount'       Number of table scans     
                       that have been started.      * 
                       This includes scans of         'Ndb_api_table_scan_count_session'
                       internal tables.          
                                                    * 
                                                      'Ndb_api_table_scan_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_table_scan_count'
                                                 
'RangeScanCount'       Number of range scans     
                       that have been started.      * 
                                                      'Ndb_api_range_scan_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_range_scan_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_range_scan_count'
                                                 
'PrunedScanCount'      Number of scans that      
                       have been pruned to a        * 
                       single partition.              'Ndb_api_pruned_scan_count_session'
                                                 
                                                    * 
                                                      'Ndb_api_pruned_scan_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_pruned_scan_count'
                                                 
'ScanBatchCount'       Number of batches of      
                       rows received.  (A           * 
                       _batch_ in this context        'Ndb_api_scan_batch_count_session'
                       is a set of scan          
                       results from a single        * 
                       fragment.)                     'Ndb_api_scan_batch_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_scan_batch_count'
                                                 
'ReadRowCount'         Total number of rows      
                       that have been read.         * 
                       Includes rows read             'Ndb_api_read_row_count_session'
                       using primary key,        
                       unique key, and scan         * 
                       operations.                    'Ndb_api_read_row_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_read_row_count'
                                                 
'TransLocalReadRowCount'Number of rows read      
                       from the data same node      * 
                       on which the                   'Ndb_api_trans_local_read_row_count_session'
                       transaction was being     
                       run.                         * 
                                                      'Ndb_api_trans_local_read_row_count_slave'
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_trans_local_read_row_count'
                                                 
'DataEventsRecvdCount' Number of row change      
                       events received.             * [none]
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_event_data_count_injector'
                                                 
                                                    * 
                                                      'Ndb_api_event_data_count'
                                                 
'NondataEventsRecvdCount'Number of events        
                       received, other than         * [none]
                       row change events.        
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_event_nondata_count_injector'
                                                 
                                                    * 
                                                      'Ndb_api_event_nondata_count'
                                                 
'EventBytesRecvdCount' Number of bytes of        
                       events received.             * [none]
                                                 
                                                    * [none]
                                                 
                                                    * 
                                                      'Ndb_api_event_bytes_count_injector'
                                                 
                                                    * 
                                                      'Ndb_api_event_bytes_count'

To see all counts of committed transactions--that is, all
'TransCommitCount' counter status variables--you can filter the results
of *note 'SHOW STATUS': show-status. for the substring
'trans_commit_count', like this:

     mysql> SHOW STATUS LIKE '%trans_commit_count%';
     +------------------------------------+-------+
     | Variable_name                      | Value |
     +------------------------------------+-------+
     | Ndb_api_trans_commit_count_session | 1     |
     | Ndb_api_trans_commit_count_slave   | 0     |
     | Ndb_api_trans_commit_count         | 2     |
     +------------------------------------+-------+
     3 rows in set (0.00 sec)

From this you can determine that 1 transaction has been committed in the
current *note 'mysql': mysql. client session, and 2 transactions have
been committed on this *note 'mysqld': mysqld. since it was last
restarted.

You can see how various NDB API counters are incremented by a given SQL
statement by comparing the values of the corresponding '_session' status
variables immediately before and after performing the statement.  In
this example, after getting the initial values from *note 'SHOW STATUS':
show-status, we create in the 'test' database an *note 'NDB':
mysql-cluster. table, named 't', that has a single column:

     mysql> SHOW STATUS LIKE 'ndb_api%session%';
     +--------------------------------------------+--------+
     | Variable_name                              | Value  |
     +--------------------------------------------+--------+
     | Ndb_api_wait_exec_complete_count_session   | 2      |
     | Ndb_api_wait_scan_result_count_session     | 0      |
     | Ndb_api_wait_meta_request_count_session    | 3      |
     | Ndb_api_wait_nanos_count_session           | 820705 |
     | Ndb_api_bytes_sent_count_session           | 132    |
     | Ndb_api_bytes_received_count_session       | 372    |
     | Ndb_api_trans_start_count_session          | 1      |
     | Ndb_api_trans_commit_count_session         | 1      |
     | Ndb_api_trans_abort_count_session          | 0      |
     | Ndb_api_trans_close_count_session          | 1      |
     | Ndb_api_pk_op_count_session                | 1      |
     | Ndb_api_uk_op_count_session                | 0      |
     | Ndb_api_table_scan_count_session           | 0      |
     | Ndb_api_range_scan_count_session           | 0      |
     | Ndb_api_pruned_scan_count_session          | 0      |
     | Ndb_api_scan_batch_count_session           | 0      |
     | Ndb_api_read_row_count_session             | 1      |
     | Ndb_api_trans_local_read_row_count_session | 1      |
     +--------------------------------------------+--------+
     18 rows in set (0.00 sec)

     mysql> USE test;
     Database changed
     mysql> CREATE TABLE t (c INT) ENGINE NDBCLUSTER;
     Query OK, 0 rows affected (0.85 sec)

Now you can execute a new *note 'SHOW STATUS': show-status. statement
and observe the changes, as shown here (with the changed rows
highlighted in the output):

     mysql> SHOW STATUS LIKE 'ndb_api%session%';
     +--------------------------------------------+-----------+
     | Variable_name                              | Value     |
     +--------------------------------------------+-----------+_
     | Ndb_api_wait_exec_complete_count_session   | 8         |_
     | Ndb_api_wait_scan_result_count_session     | 0         |
     _| Ndb_api_wait_meta_request_count_session    | 17        |_
     _| Ndb_api_wait_nanos_count_session           | 706871709 |_
     _| Ndb_api_bytes_sent_count_session           | 2376      |_
     _| Ndb_api_bytes_received_count_session       | 3844      |_
     _| Ndb_api_trans_start_count_session          | 4         |_
     _| Ndb_api_trans_commit_count_session         | 4         |_
     | Ndb_api_trans_abort_count_session          | 0         |
     _| Ndb_api_trans_close_count_session          | 4         |_
     _| Ndb_api_pk_op_count_session                | 6         |_
     | Ndb_api_uk_op_count_session                | 0         |
     | Ndb_api_table_scan_count_session           | 0         |
     | Ndb_api_range_scan_count_session           | 0         |
     | Ndb_api_pruned_scan_count_session          | 0         |
     | Ndb_api_scan_batch_count_session           | 0         |
     _| Ndb_api_read_row_count_session             | 2         |_
     | Ndb_api_trans_local_read_row_count_session | 1         |
     +--------------------------------------------+-----------+
     18 rows in set (0.00 sec)

Similarly, you can see the changes in the NDB API statistics counters
caused by inserting a row into 't': Insert the row, then run the same
*note 'SHOW STATUS': show-status. statement used in the previous
example, as shown here:

     mysql> INSERT INTO t VALUES (100);
     Query OK, 1 row affected (0.00 sec)

     mysql> SHOW STATUS LIKE 'ndb_api%session%';
     +--------------------------------------------+-----------+
     | Variable_name                              | Value     |
     +--------------------------------------------+-----------+
     _| Ndb_api_wait_exec_complete_count_session   | 11        |_
     _| Ndb_api_wait_scan_result_count_session     | 6         |_
     _| Ndb_api_wait_meta_request_count_session    | 20        |_
     _| Ndb_api_wait_nanos_count_session           | 707370418 |_
     _| Ndb_api_bytes_sent_count_session           | 2724      |_
     _| Ndb_api_bytes_received_count_session       | 4116      |_
     _| Ndb_api_trans_start_count_session          | 7         |_
     _| Ndb_api_trans_commit_count_session         | 6         |_
     | Ndb_api_trans_abort_count_session          | 0         |
     _| Ndb_api_trans_close_count_session          | 7         |_
     _| Ndb_api_pk_op_count_session                | 8         |_
     | Ndb_api_uk_op_count_session                | 0         |
     _| Ndb_api_table_scan_count_session           | 1         |_
     | Ndb_api_range_scan_count_session           | 0         |
     | Ndb_api_pruned_scan_count_session          | 0         |
     | Ndb_api_scan_batch_count_session           | 0         |
     _| Ndb_api_read_row_count_session             | 3         |_
     _| Ndb_api_trans_local_read_row_count_session | 2         |_
     +--------------------------------------------+-----------+
     18 rows in set (0.00 sec)

We can make a number of observations from these results:

   * Although we created 't' with no explicit primary key, 5 primary key
     operations were performed in doing so (the difference in the
     'before' and 'after' values of 'Ndb_api_pk_op_count_session', or 6
     minus 1).  This reflects the creation of the hidden primary key
     that is a feature of all tables using the *note 'NDB':
     mysql-cluster. storage engine.

   * By comparing successive values for
     'Ndb_api_wait_nanos_count_session', we can see that the NDB API
     operations implementing the *note 'CREATE TABLE': create-table.
     statement waited much longer (706871709 - 820705 = 706051004
     nanoseconds, or approximately 0.7 second) for responses from the
     data nodes than those executed by the *note 'INSERT': insert.
     (707370418 - 706871709 = 498709 ns or roughly .0005 second).  The
     execution times reported for these statements in the *note 'mysql':
     mysql. client correlate roughly with these figures.

     On platforms without sufficient (nanosecond) time resolution, small
     changes in the value of the 'WaitNanosCount' NDB API counter due to
     SQL statements that execute very quickly may not always be visible
     in the values of 'Ndb_api_wait_nanos_count_session',
     'Ndb_api_wait_nanos_count_slave', or 'Ndb_api_wait_nanos_count'.

   * The *note 'INSERT': insert. statement incremented both the
     'ReadRowCount' and 'TransLocalReadRowCount' NDB API statistics
     counters, as reflected by the increased values of
     'Ndb_api_read_row_count_session' and
     'Ndb_api_trans_local_read_row_count_session'.


File: manual.info.tmp,  Node: mysql-cluster-replication,  Next: mysql-cluster-news,  Prev: mysql-cluster-management,  Up: mysql-cluster

18.6 NDB Cluster Replication
============================

* Menu:

* mysql-cluster-replication-abbreviations::  NDB Cluster Replication: Abbreviations and Symbols
* mysql-cluster-replication-general::  General Requirements for NDB Cluster Replication
* mysql-cluster-replication-issues::  Known Issues in NDB Cluster Replication
* mysql-cluster-replication-schema::  NDB Cluster Replication Schema and Tables
* mysql-cluster-replication-preparation::  Preparing the NDB Cluster for Replication
* mysql-cluster-replication-starting::  Starting NDB Cluster Replication (Single Replication Channel)
* mysql-cluster-replication-two-channels::  Using Two Replication Channels for NDB Cluster Replication
* mysql-cluster-replication-failover::  Implementing Failover with NDB Cluster Replication
* mysql-cluster-replication-backups::  NDB Cluster Backups With NDB Cluster Replication
* mysql-cluster-replication-multi-master::  NDB Cluster Replication: Multi-Master and Circular Replication
* mysql-cluster-replication-conflict-resolution::  NDB Cluster Replication Conflict Resolution

NDB Cluster supports _asynchronous replication_, more usually referred
to simply as 'replication'.  This section explains how to set up and
manage a configuration in which one group of computers operating as an
NDB Cluster replicates to a second computer or group of computers.  We
assume some familiarity on the part of the reader with standard MySQL
replication as discussed elsewhere in this Manual.  (See *note
replication::).

*Note*:

Semisynchronous replication is not supported by the 'NDB' storage
engine.

Normal (non-clustered) replication involves a 'master' server and a
'slave' server, the master being the source of the operations and data
to be replicated and the slave being the recipient of these.  In NDB
Cluster, replication is conceptually very similar but can be more
complex in practice, as it may be extended to cover a number of
different configurations including replicating between two complete
clusters.  Although an NDB Cluster itself depends on the *note 'NDB':
mysql-cluster. storage engine for clustering functionality, it is not
necessary to use *note 'NDB': mysql-cluster. as the storage engine for
the slave's copies of the replicated tables (see *note
mysql-cluster-replication-ndb-to-non-ndb::).  However, for maximum
availability, it is possible (and preferable) to replicate from one NDB
Cluster to another, and it is this scenario that we discuss, as shown in
the following figure:

FIGURE GOES HERE: NDB Cluster-to-Cluster Replication Layout

In this scenario, the replication process is one in which successive
states of a master cluster are logged and saved to a slave cluster.
This process is accomplished by a special thread known as the NDB binary
log injector thread, which runs on each MySQL server and produces a
binary log ('binlog').  This thread ensures that all changes in the
cluster producing the binary log--and not just those changes that are
effected through the MySQL Server--are inserted into the binary log with
the correct serialization order.  We refer to the MySQL replication
master and replication slave servers as replication servers or
replication nodes, and the data flow or line of communication between
them as a _replication channel_.

For information about performing point-in-time recovery with NDB Cluster
and NDB Cluster Replication, see *note mysql-cluster-replication-pitr::.

NDB API _slave status variables

NDB API counters can provide enhanced monitoring capabilities on NDB
Cluster replication slaves.  These are implemented as NDB statistics
'_slave' status variables, as seen in the output of *note 'SHOW STATUS':
show-status, or in the results of queries against the *note
'SESSION_STATUS': status-table. or *note 'GLOBAL_STATUS': status-table.
table in a *note 'mysql': mysql. client session connected to a MySQL
Server that is acting as a slave in NDB Cluster Replication.  By
comparing the values of these status variables before and after the
execution of statements affecting replicated *note 'NDB': mysql-cluster.
tables, you can observe the corresponding actions taken on the NDB API
level by the slave, which can be useful when monitoring or
troubleshooting NDB Cluster Replication.  *note
mysql-cluster-ndb-api-statistics::, provides additional information.

Replication from NDB to non-NDB tables

It is possible to replicate *note 'NDB': mysql-cluster. tables from an
NDB Cluster acting as the master to tables using other MySQL storage
engines such as *note 'InnoDB': innodb-storage-engine. or *note
'MyISAM': myisam-storage-engine. on a slave *note 'mysqld': mysqld.
This is subject to a number of conditions; see *note
mysql-cluster-replication-ndb-to-non-ndb::, and *note
mysql-cluster-replication-ndb-to-nontransactional::, for more
information.


File: manual.info.tmp,  Node: mysql-cluster-replication-abbreviations,  Next: mysql-cluster-replication-general,  Prev: mysql-cluster-replication,  Up: mysql-cluster-replication

18.6.1 NDB Cluster Replication: Abbreviations and Symbols
---------------------------------------------------------

Throughout this section, we use the following abbreviations or symbols
for referring to the master and slave clusters, and to processes and
commands run on the clusters or cluster nodes:

*Abbreviations used throughout this section referring to master and
slave clusters, and to processes and commands run on nodes*

Symbol or          Description (Refers to...)
Abbreviation       

M                  The cluster serving as the (primary) replication
                   master
                   
S                  The cluster acting as the (primary) replication
                   slave
                   
'shellM>'          Shell command to be issued on the master cluster
                   
'mysqlM>'          MySQL client command issued on a single MySQL server
                   running as an SQL node on the master cluster
                   
'mysqlM*>'         MySQL client command to be issued on all SQL nodes
                   participating in the replication master cluster
                   
'shellS>'          Shell command to be issued on the slave cluster
                   
'mysqlS>'          MySQL client command issued on a single MySQL server
                   running as an SQL node on the slave cluster
                   
'mysqlS*>'         MySQL client command to be issued on all SQL nodes
                   participating in the replication slave cluster
                   
C                  Primary replication channel
                   
C'                 Secondary replication channel
                   
M'                 Secondary replication master
                   
S'                 Secondary replication slave


File: manual.info.tmp,  Node: mysql-cluster-replication-general,  Next: mysql-cluster-replication-issues,  Prev: mysql-cluster-replication-abbreviations,  Up: mysql-cluster-replication

18.6.2 General Requirements for NDB Cluster Replication
-------------------------------------------------------

A replication channel requires two MySQL servers acting as replication
servers (one each for the master and slave).  For example, this means
that in the case of a replication setup with two replication channels
(to provide an extra channel for redundancy), there will be a total of
four replication nodes, two per cluster.

Replication of an NDB Cluster as described in this section and those
following is dependent on row-based replication.  This means that the
replication master MySQL server must be running with
'--binlog-format=ROW' or '--binlog-format=MIXED', as described in *note
mysql-cluster-replication-starting::.  For general information about
row-based replication, see *note replication-formats::.

*Important*:

If you attempt to use NDB Cluster Replication with
'--binlog-format=STATEMENT', replication fails to work properly because
the 'ndb_binlog_index' table on the master and the 'epoch' column of the
'ndb_apply_status' table on the slave are not updated (see *note
mysql-cluster-replication-schema::).  Instead, only updates on the MySQL
server acting as the replication master propagate to the slave, and no
updates from any other SQL nodes on the master cluster are replicated.

Beginning with NDB 7.2.13, the default value for the '--binlog-format'
option is 'MIXED'.  (Bug #16417224)

In NDB 7.2.12 and earlier NDB Cluster 7.2 releases, the default for
'--binlog-format' was 'STATEMENT'; this meant that you were required to
change the binary logging format to 'ROW' (or 'MIXED') manually on all
MySQL Servers on the master NDB Cluster, prior to starting NDB Cluster
replication.  If necessary, you can do this on startup using the
'--binlog-format' option, or at runtime by setting the global
'binlog_format' system variable.  Using the startup option is preferred
in such cases.

Each MySQL server used for replication in either cluster must be
uniquely identified among all the MySQL replication servers
participating in either cluster (you cannot have replication servers on
both the master and slave clusters sharing the same ID). This can be
done by starting each SQL node using the '--server-id=ID' option, where
ID is a unique integer.  Although it is not strictly necessary, we will
assume for purposes of this discussion that all NDB Cluster binaries are
of the same release version.

It is generally true in MySQL Replication that both MySQL servers (*note
'mysqld': mysqld. processes) involved must be compatible with one
another with respect to both the version of the replication protocol
used and the SQL feature sets which they support (see *note
replication-compatibility::).  It is due to such differences between the
binaries in the NDB Cluster and MySQL Server 5.5 distributions that NDB
Cluster Replication has the additional requirement that both *note
'mysqld': mysqld. binaries come from an NDB Cluster distribution.  The
simplest and easiest way to assure that the *note 'mysqld': mysqld.
servers are compatible is to use the same NDB Cluster distribution for
all master and slave *note 'mysqld': mysqld. binaries.

We assume that the slave server or cluster is dedicated to replication
of the master, and that no other data is being stored on it.

All 'NDB' tables being replicated must be created using a MySQL server
and client.  Tables and other database objects created using the NDB API
(with, for example, 'Dictionary::createTable()'
(https://dev.mysql.com/doc/ndbapi/en/ndb-dictionary-createtable.html))
are not visible to a MySQL server and so are not replicated.  Updates by
NDB API applications to existing tables that were created using a MySQL
server can be replicated.

*Note*:

It is possible to replicate an NDB Cluster using statement-based
replication.  However, in this case, the following restrictions apply:

   * All updates to data rows on the cluster acting as the master must
     be directed to a single MySQL server.

   * It is not possible to replicate a cluster using multiple
     simultaneous MySQL replication processes.

   * Only changes made at the SQL level are replicated.

These are in addition to the other limitations of statement-based
replication as opposed to row-based replication; see *note
replication-sbr-rbr::, for more specific information concerning the
differences between the two replication formats.


File: manual.info.tmp,  Node: mysql-cluster-replication-issues,  Next: mysql-cluster-replication-schema,  Prev: mysql-cluster-replication-general,  Up: mysql-cluster-replication

18.6.3 Known Issues in NDB Cluster Replication
----------------------------------------------

This section discusses known problems or issues when using replication
with NDB Cluster 7.2.

Loss of master-slave connection

A loss of connection can occur either between the replication master SQL
node and the replication slave SQL node, or between the replication
master SQL node and the data nodes in the master cluster.  In the latter
case, this can occur not only as a result of loss of physical connection
(for example, a broken network cable), but due to the overflow of data
node event buffers; if the SQL node is too slow to respond, it may be
dropped by the cluster (this is controllable to some degree by adjusting
the 'MaxBufferedEpochs' and 'TimeBetweenEpochs' configuration
parameters).  If this occurs, _it is entirely possible for new data to
be inserted into the master cluster without being recorded in the
replication master's binary log_.  For this reason, to guarantee high
availability, it is extremely important to maintain a backup replication
channel, to monitor the primary channel, and to fail over to the
secondary replication channel when necessary to keep the slave cluster
synchronized with the master.  NDB Cluster is not designed to perform
such monitoring on its own; for this, an external application is
required.

The replication master issues a 'gap' event when connecting or
reconnecting to the master cluster.  (A gap event is a type of 'incident
event,' which indicates an incident that occurs that affects the
contents of the database but that cannot easily be represented as a set
of changes.  Examples of incidents are server crashes, database
resynchronization, (some) software updates, and (some) hardware
changes.)  When the slave encounters a gap in the replication log, it
stops with an error message.  This message is available in the output of
*note 'SHOW SLAVE STATUS': show-slave-status, and indicates that the SQL
thread has stopped due to an incident registered in the replication
stream, and that manual intervention is required.  See *note
mysql-cluster-replication-failover::, for more information about what to
do in such circumstances.

*Important*:

Because NDB Cluster is not designed on its own to monitor replication
status or provide failover, if high availability is a requirement for
the slave server or cluster, then you must set up multiple replication
lines, monitor the master *note 'mysqld': mysqld. on the primary
replication line, and be prepared fail over to a secondary line if and
as necessary.  This must be done manually, or possibly by means of a
third-party application.  For information about implementing this type
of setup, see *note mysql-cluster-replication-two-channels::, and *note
mysql-cluster-replication-failover::.

However, if you are replicating from a standalone MySQL server to an NDB
Cluster, one channel is usually sufficient.

Circular replication

NDB Cluster Replication supports circular replication, as shown in the
next example.  The replication setup involves three NDB Clusters
numbered 1, 2, and 3, in which Cluster 1 acts as the replication master
for Cluster 2, Cluster 2 acts as the master for Cluster 3, and Cluster 3
acts as the master for Cluster 1, thus completing the circle.  Each NDB
Cluster has two SQL nodes, with SQL nodes A and B belonging to Cluster
1, SQL nodes C and D belonging to Cluster 2, and SQL nodes E and F
belonging to Cluster 3.

Circular replication using these clusters is supported as long as the
following conditions are met:

   * The SQL nodes on all masters and slaves are the same.

   * All SQL nodes acting as replication masters and slaves are started
     with the 'log_slave_updates' system variable enabled.

This type of circular replication setup is shown in the following
diagram:

FIGURE GOES HERE: NDB Cluster Circular Replication With All Masters As
Slaves

In this scenario, SQL node A in Cluster 1 replicates to SQL node C in
Cluster 2; SQL node C replicates to SQL node E in Cluster 3; SQL node E
replicates to SQL node A. In other words, the replication line
(indicated by the curved arrows in the diagram) directly connects all
SQL nodes used as replication masters and slaves.

It should also be possible to set up circular replication in which not
all master SQL nodes are also slaves, as shown here:

FIGURE GOES HERE: NDB Cluster Circular Replication Where Not All Masters
Are Slaves

In this case, different SQL nodes in each cluster are used as
replication masters and slaves.  However, you must _not_ start any of
the SQL nodes with the 'log_slave_updates' system variable enabled.
This type of circular replication scheme for NDB Cluster, in which the
line of replication (again indicated by the curved arrows in the
diagram) is discontinuous, should be possible, but it should be noted
that it has not yet been thoroughly tested and must therefore still be
considered experimental.

*Note*:

The *note 'NDB': mysql-cluster. storage engine uses _idempotent
execution mode_, which suppresses duplicate-key and other errors that
otherwise break circular replication of NDB Cluster.  This is equivalent
to setting the global 'slave_exec_mode' system variable to 'IDEMPOTENT',
although this is not necessary in NDB Cluster replication, since NDB
Cluster sets this variable automatically and ignores any attempts to set
it explicitly.

NDB Cluster replication and primary keys

In the event of a node failure, errors in replication of *note 'NDB':
mysql-cluster. tables without primary keys can still occur, due to the
possibility of duplicate rows being inserted in such cases.  For this
reason, it is highly recommended that all *note 'NDB': mysql-cluster.
tables being replicated have primary keys.

NDB Cluster Replication and Unique Keys

In older versions of NDB Cluster, operations that updated values of
unique key columns of *note 'NDB': mysql-cluster. tables could result in
duplicate-key errors when replicated.  This issue is solved for
replication between *note 'NDB': mysql-cluster. tables by deferring
unique key checks until after all table row updates have been performed.

Deferring constraints in this way is currently supported only by *note
'NDB': mysql-cluster.  Thus, updates of unique keys when replicating
from *note 'NDB': mysql-cluster. to a different storage engine such as
*note 'MyISAM': myisam-storage-engine. or *note 'InnoDB':
innodb-storage-engine. are still not supported.

The problem encountered when replicating without deferred checking of
unique key updates can be illustrated using *note 'NDB': mysql-cluster.
table such as 't', is created and populated on the master (and
replicated to a slave that does not support deferred unique key updates)
as shown here:

     CREATE TABLE t (
         p INT PRIMARY KEY,
         c INT,
         UNIQUE KEY u (c)
     )   ENGINE NDB;

     INSERT INTO t
         VALUES (1,1), (2,2), (3,3), (4,4), (5,5);

The following *note 'UPDATE': update. statement on 't' succeeded on the
master, since the rows affected are processed in the order determined by
the 'ORDER BY' option, performed over the entire table:

     UPDATE t SET c = c - 1 ORDER BY p;

However, the same statement failed with a duplicate key error or other
constraint violation on the slave, because the ordering of the row
updates was done for one partition at a time, rather than for the table
as a whole.

*Note*:

Every *note 'NDB': mysql-cluster. table is implicitly partitioned by key
when it is created.  See *note partitioning-key::, for more information.

Restarting with -initial

Restarting the cluster with the '--initial' option causes the sequence
of GCI and epoch numbers to start over from '0'.  (This is generally
true of NDB Cluster and not limited to replication scenarios using NDB.)
The MySQL servers involved in replication should in this case be
restarted.  After this, you should use the *note 'RESET MASTER':
reset-master. and *note 'RESET SLAVE': reset-slave. statements to clear
the invalid 'ndb_binlog_index' and 'ndb_apply_status' tables,
respectively.

Replication from NDB to other storage engines

It is possible to replicate an *note 'NDB': mysql-cluster. table on the
master to a table using a different storage engine on the slave, taking
into account the restrictions listed here:

   * Multi-master and circular replication are not supported (tables on
     both the master and the slave must use the *note 'NDB':
     mysql-cluster. storage engine for this to work).

   * Using a storage engine which does not perform binary logging for
     slave tables requires special handling.

   * Use of a nontransactional storage engine for slave tables also
     requires special handling.

   * The master *note 'mysqld': mysqld. must be started with
     '--ndb-log-update-as-write=0' or '--ndb-log-update-as-write=OFF'.

The next few paragraphs provide additional information about each of the
issues just described.

Multiple masters not supported when replicating NDB to other storage
engines

For replication from *note 'NDB': mysql-cluster. to a different storage
engine, the relationship between the two databases must be a simple
master-slave one.  This means that circular or master-master replication
is not supported between NDB Cluster and other storage engines.

In addition, it is not possible to configure more than one replication
channel when replicating between *note 'NDB': mysql-cluster. and a
different storage engine.  (However, an NDB Cluster database _can_
simultaneously replicate to multiple slave NDB Cluster databases.)  If
the master uses *note 'NDB': mysql-cluster. tables, it is still possible
to have more than one MySQL Server maintain a binary log of all changes;
however, for the slave to change masters (fail over), the new
master-slave relationship must be explicitly defined on the slave.

Replicating NDB to a slave storage engine that does not perform binary
logging

If you attempt to replicate from an NDB Cluster to a slave that uses a
storage engine that does not handle its own binary logging, the
replication process aborts with the error 'Binary logging not possible
... Statement cannot be written atomically since more than one engine
involved and at least one engine is self-logging' (Error 1595).  It is
possible to work around this issue in one of the following ways:

   * Turn off binary logging on the slave

     This can be accomplished by setting 'sql_log_bin = 0'.

   * Change the storage engine used for the mysql.ndb_apply_status table

     Causing this table to use an engine that does not handle its own
     binary logging can also eliminate the conflict.  This can be done
     by issuing a statement such as *note 'ALTER TABLE
     mysql.ndb_apply_status ENGINE=MyISAM': alter-table. on the slave.
     It is safe to do this when using a non-*note 'NDB': mysql-cluster.
     storage engine on the slave, since you do not then need to worry
     about keeping multiple slave SQL nodes synchronized.

   * Filter out changes to the mysql.ndb_apply_status table on the slave

     This can be done by starting the slave SQL node with
     '--replicate-ignore-table=mysql.ndb_apply_status'.  If you need for
     other tables to be ignored by replication, you might wish to use an
     appropriate '--replicate-wild-ignore-table' option instead.

*Important*:

You should _not_ disable replication or binary logging of
'mysql.ndb_apply_status' or change the storage engine used for this
table when replicating from one NDB Cluster to another.  See *note
mysql-cluster-replication-issues-filtering::, for details.

Replication from NDB to a nontransactional storage engine

When replicating from *note 'NDB': mysql-cluster. to a nontransactional
storage engine such as *note 'MyISAM': myisam-storage-engine, you may
encounter unnecessary duplicate key errors when replicating *note
'INSERT ... ON DUPLICATE KEY UPDATE': insert-on-duplicate. statements.
You can suppress these by using '--ndb-log-update-as-write=0', which
forces updates to be logged as writes (rather than as updates).

In addition, when replicating from *note 'NDB': mysql-cluster. to a
storage engine that does not implement transactions, if the slave fails
to apply any row changes from a given transaction, it does not roll back
the rest of the transaction.  (This is true when replicating tables
using any transactional storage engine--not only *note 'NDB':
mysql-cluster.--to a nontransactional storage engine.)  Because of this,
it cannot be guaranteed that transactional consistency will be
maintained on the slave in such cases.

Replication and binary log filtering rules with replication between NDB
Clusters

If you are using any of the options '--replicate-do-*',
'--replicate-ignore-*', '--binlog-do-db', or '--binlog-ignore-db' to
filter databases or tables being replicated, care must be taken not to
block replication or binary logging of the 'mysql.ndb_apply_status',
which is required for replication between NDB Clusters to operate
properly.  In particular, you must keep in mind the following:

  1. Using '--replicate-do-db=DB_NAME' (and no other '--replicate-do-*'
     or '--replicate-ignore-*' options) means that _only_ tables in
     database DB_NAME are replicated.  In this case, you should also use
     '--replicate-do-db=mysql', '--binlog-do-db=mysql', or
     '--replicate-do-table=mysql.ndb_apply_status' to ensure that
     'mysql.ndb_apply_status' is populated on slaves.

     Using '--binlog-do-db=DB_NAME' (and no other '--binlog-do-db'
     options) means that changes _only_ to tables in database DB_NAME
     are written to the binary log.  In this case, you should also use
     '--replicate-do-db=mysql', '--binlog-do-db=mysql', or
     '--replicate-do-table=mysql.ndb_apply_status' to ensure that
     'mysql.ndb_apply_status' is populated on slaves.

  2. Using '--replicate-ignore-db=mysql' means that no tables in the
     'mysql' database are replicated.  In this case, you should also use
     '--replicate-do-table=mysql.ndb_apply_status' to ensure that
     'mysql.ndb_apply_status' is replicated.

     Using '--binlog-ignore-db=mysql' means that no changes to tables in
     the 'mysql' database are written to the binary log.  In this case,
     you should also use '--replicate-do-table=mysql.ndb_apply_status'
     to ensure that 'mysql.ndb_apply_status' is replicated.

You should also remember that each replication rule requires the
following:

  1. Its own '--replicate-do-*' or '--replicate-ignore-*' option, and
     that multiple rules cannot be expressed in a single replication
     filtering option.  For information about these rules, see *note
     replication-options::.

  2. Its own '--binlog-do-db' or '--binlog-ignore-db' option, and that
     multiple rules cannot be expressed in a single binary log filtering
     option.  For information about these rules, see *note binary-log::.

If you are replicating an NDB Cluster to a slave that uses a storage
engine other than *note 'NDB': mysql-cluster, the considerations just
given previously may not apply, as discussed elsewhere in this section.

NDB Cluster Replication and IPv6

Currently, the NDB API and MGM API do not support IPv6.  However, MySQL
Servers--including those acting as SQL nodes in an NDB Cluster--can use
IPv6 to contact other MySQL Servers.  This means that you can replicate
between NDB Clusters using IPv6 to connect the master and slave SQL
nodes as shown by the dotted arrow in the following diagram:

FIGURE GOES HERE: Replication Between SQL Nodes Connected Using IPv6

However, all connections originating _within_ the NDB
Cluster--represented in the preceding diagram by solid arrows--must use
IPv4.  In other words, all NDB Cluster data nodes, management servers,
and management clients must be accessible from one another using IPv4.
In addition, SQL nodes must use IPv4 to communicate with the cluster.

Since there is currently no support in the NDB and MGM APIs for IPv6,
any applications written using these APIs must also make all connections
using IPv4.

Attribute promotion and demotion

NDB Cluster Replication includes support for attribute promotion and
demotion.  The implementation of the latter distinguishes between lossy
and non-lossy type conversions, and their use on the slave can be
controlled by setting the 'slave_type_conversions' global server system
variable.

For more information about attribute promotion and demotion in NDB
Cluster, see *note replication-features-attribute-promotion::.


File: manual.info.tmp,  Node: mysql-cluster-replication-schema,  Next: mysql-cluster-replication-preparation,  Prev: mysql-cluster-replication-issues,  Up: mysql-cluster-replication

18.6.4 NDB Cluster Replication Schema and Tables
------------------------------------------------

Replication in NDB Cluster makes use of a number of dedicated tables in
the 'mysql' database on each MySQL Server instance acting as an SQL node
in both the cluster being replicated and the replication slave (whether
the slave is a single server or a cluster).  These tables are created
during the MySQL installation process by the *note 'mysql_install_db':
mysql-install-db. script, and include a table for storing the binary
log's indexing data.  Since the 'ndb_binlog_index' table is local to
each MySQL server and does not participate in clustering, it uses the
'MyISAM' storage engine.  This means that it must be created separately
on each *note 'mysqld': mysqld. participating in the master cluster.
(However, the binary log itself contains updates from all MySQL servers
in the cluster to be replicated.)  This table is defined as follows:

     CREATE TABLE `ndb_binlog_index` (
         `Position` BIGINT(20) UNSIGNED NOT NULL,
         `File` VARCHAR(255) NOT NULL,
         `epoch` BIGINT(20) UNSIGNED NOT NULL,
         `inserts` INT(10) UNSIGNED NOT NULL,
         `updates` INT(10) UNSIGNED NOT NULL,
         `deletes` INT(10) UNSIGNED NOT NULL,
         `schemaops` INT(10) UNSIGNED NOT NULL,
         `orig_server_id` INT(10) UNSIGNED NOT NULL,
         `orig_epoch` BIGINT(20) UNSIGNED NOT NULL,
         `gci` INT(10) UNSIGNED NOT NULL,
         `next_position` bigint(20) unsigned NOT NULL,
         `next_file` varchar(255) NOT NULL,
         PRIMARY KEY (`epoch`,`orig_server_id`,`orig_epoch`)
     ) ENGINE=MyISAM DEFAULT CHARSET=latin1;

The size of this table is dependent on the number of epochs per binary
log file and the number of binary log files.  The number of epochs per
binary log file normally depends on the amount of binary log generated
per epoch and the size of the binary log file, with smaller epochs
resulting in more epochs per file.  You should be aware that empty
epochs produce inserts to the 'ndb_binlog_index' table, even when the
'--ndb-log-empty-epochs' option is 'OFF', meaning that the number of
entries per file depends on the length of time that the file is in use;
that is,

     [number of epochs per file] = [time spent per file] / TimeBetweenEpochs

A busy NDB Cluster writes to the binary log regularly and presumably
rotates binary log files more quickly than a quiet one.  This means that
a 'quiet' NDB Cluster with '--ndb-log-empty-epochs=ON' can actually have
a much higher number of 'ndb_binlog_index' rows per file than one with a
great deal of activity.

When *note 'mysqld': mysqld. is started with the '--ndb-log-orig'
option, the 'orig_server_id' and 'orig_epoch' columns store,
respectively, the ID of the server on which the event originated and the
epoch in which the event took place on the originating server, which is
useful in NDB Cluster replication setups employing multiple masters.
The *note 'SELECT': select. statement used to find the closest binary
log position to the highest applied epoch on the slave in a multi-master
setup (see *note mysql-cluster-replication-multi-master::) employs these
two columns, which are not indexed.  This can lead to performance issues
when trying to fail over, since the query must perform a table scan,
especially when the master has been running with
'--ndb-log-empty-epochs=ON'.  You can improve multi-master failover
times by adding an index to these columns, as shown here:

     ALTER TABLE mysql.ndb_binlog_index
         ADD INDEX orig_lookup USING BTREE (orig_server_id, orig_epoch);

Adding this index provides no benefit when replicating from a single
master to a single slave, since the query used to get the binary log
position in such cases makes no use of 'orig_server_id' or 'orig_epoch'.

The 'next_position' and 'next_file' columns were added in NDB 7.2.6; see
*note mysql-cluster-replication-failover::, for more information about
using these columns.

The following figure shows the relationship of the NDB Cluster
replication master server, its binary log injector thread, and the
'mysql.ndb_binlog_index' table.

FIGURE GOES HERE: The Replication Master Cluster

An additional table, named 'ndb_apply_status', is used to keep a record
of the operations that have been replicated from the master to the
slave.  Unlike the case with 'ndb_binlog_index', the data in this table
is not specific to any one SQL node in the (slave) cluster, and so
'ndb_apply_status' can use the 'NDBCLUSTER' storage engine, as shown
here:

     CREATE TABLE `ndb_apply_status` (
         `server_id`   INT(10) UNSIGNED NOT NULL,
         `epoch`       BIGINT(20) UNSIGNED NOT NULL,
         `log_name`    VARCHAR(255) CHARACTER SET latin1 COLLATE latin1_bin NOT NULL,
         `start_pos`   BIGINT(20) UNSIGNED NOT NULL,
         `end_pos`     BIGINT(20) UNSIGNED NOT NULL,
         PRIMARY KEY (`server_id`) USING HASH
     ) ENGINE=NDBCLUSTER   DEFAULT CHARSET=latin1;

The 'ndb_apply_status' table is populated only on slaves, which means
that, on the master, this table never contains any rows; thus, there is
no need to allow for 'DataMemory' or 'IndexMemory' to be allotted to
'ndb_apply_status' there.

Because this table is populated from data originating on the master, it
should be allowed to replicate; any replication filtering or binary log
filtering rules that inadvertently prevent the slave from updating
'ndb_apply_status' or the master from writing into the binary log may
prevent replication between clusters from operating properly.  For more
information about potential problems arising from such filtering rules,
see *note mysql-cluster-replication-issues-filtering::.

The 'ndb_binlog_index' and 'ndb_apply_status' tables are created in the
'mysql' database because they should not be explicitly replicated by the
user.  User intervention is normally not required to create or maintain
either of these tables, since both 'ndb_binlog_index' and the
'ndb_apply_status' are maintained by the *note 'NDB': mysql-cluster.
binary log (binlog) injector thread.  This keeps the master *note
'mysqld': mysqld. process updated to changes performed by the *note
'NDB': mysql-cluster. storage engine.  The *note 'NDB': mysql-cluster.
_binlog injector thread_ receives events directly from the *note 'NDB':
mysql-cluster. storage engine.  The *note 'NDB': mysql-cluster. injector
is responsible for capturing all the data events within the cluster, and
ensures that all events which change, insert, or delete data are
recorded in the 'ndb_binlog_index' table.  The slave I/O thread
transfers the events from the master's binary log to the slave's relay
log.

However, it is advisable to check for the existence and integrity of
these tables as an initial step in preparing an NDB Cluster for
replication.  It is possible to view event data recorded in the binary
log by querying the 'mysql.ndb_binlog_index' table directly on the
master.  This can be also be accomplished using the *note 'SHOW BINLOG
EVENTS': show-binlog-events. statement on either the replication master
or slave MySQL servers.  (See *note show-binlog-events::.)

You can also obtain useful information from the output of *note 'SHOW
ENGINE NDB STATUS': show-engine.

*Note*:

When performing schema changes on *note 'NDB': mysql-cluster. tables,
applications should wait until the *note 'ALTER TABLE': alter-table.
statement has returned in the MySQL client connection that issued the
statement before attempting to use the updated definition of the table.

If the 'ndb_apply_status' table does not exist on the slave, *note
'ndb_restore': mysql-cluster-programs-ndb-restore. re-creates it.

Conflict resolution for NDB Cluster Replication requires the presence of
an additional 'mysql.ndb_replication' table.  Currently, this table must
be created manually.  For information about how to do this, see *note
mysql-cluster-replication-conflict-resolution::.


File: manual.info.tmp,  Node: mysql-cluster-replication-preparation,  Next: mysql-cluster-replication-starting,  Prev: mysql-cluster-replication-schema,  Up: mysql-cluster-replication

18.6.5 Preparing the NDB Cluster for Replication
------------------------------------------------

Preparing the NDB Cluster for replication consists of the following
steps:

  1. Check all MySQL servers for version compatibility (see *note
     mysql-cluster-replication-general::).

  2. Create a slave account on the master Cluster with the appropriate
     privileges:

          mysqlM> GRANT REPLICATION SLAVE
               -> ON *.* TO 'SLAVE_USER'@'SLAVE_HOST'
               -> IDENTIFIED BY 'SLAVE_PASSWORD';

     In the previous statement, SLAVE_USER is the slave account user
     name, SLAVE_HOST is the host name or IP address of the replication
     slave, and SLAVE_PASSWORD is the password to assign to this
     account.

     For example, to create a slave user account with the name
     'myslave', logging in from the host named 'rep-slave', and using
     the password '53cr37', use the following *note 'GRANT': grant.
     statement:

          mysqlM> GRANT REPLICATION SLAVE
               -> ON *.* TO 'myslave'@'rep-slave'
               -> IDENTIFIED BY '53cr37';

     For security reasons, it is preferable to use a unique user
     account--not employed for any other purpose--for the replication
     slave account.

  3. 
     Configure the slave to use the master.  Using the MySQL Monitor,
     this can be accomplished with the *note 'CHANGE MASTER TO':
     change-master-to. statement:

          mysqlS> CHANGE MASTER TO
               -> MASTER_HOST='MASTER_HOST',
               -> MASTER_PORT=MASTER_PORT,
               -> MASTER_USER='SLAVE_USER',
               -> MASTER_PASSWORD='SLAVE_PASSWORD';

     In the previous statement, MASTER_HOST is the host name or IP
     address of the replication master, MASTER_PORT is the port for the
     slave to use for connecting to the master, SLAVE_USER is the user
     name set up for the slave on the master, and SLAVE_PASSWORD is the
     password set for that user account in the previous step.

     For example, to tell the slave to replicate from the MySQL server
     whose host name is 'rep-master', using the replication slave
     account created in the previous step, use the following statement:

          mysqlS> CHANGE MASTER TO
               -> MASTER_HOST='rep-master',
               -> MASTER_PORT=3306,
               -> MASTER_USER='myslave',
               -> MASTER_PASSWORD='53cr37';

     For a complete list of options that can be used with this
     statement, see *note change-master-to::.

     To provide replication backup capability, you also need to add an
     '--ndb-connectstring' option to the slave's 'my.cnf' file prior to
     starting the replication process.  See *note
     mysql-cluster-replication-backups::, for details.

     For additional options that can be set in 'my.cnf' for replication
     slaves, see *note replication-options::.

  4. If the master cluster is already in use, you can create a backup of
     the master and load this onto the slave to cut down on the amount
     of time required for the slave to synchronize itself with the
     master.  If the slave is also running NDB Cluster, this can be
     accomplished using the backup and restore procedure described in
     *note mysql-cluster-replication-backups::.

          ndb-connectstring=MANAGEMENT_HOST[:PORT]

     In the event that you are _not_ using NDB Cluster on the
     replication slave, you can create a backup with this command on the
     replication master:

          shellM> mysqldump --master-data=1

     Then import the resulting data dump onto the slave by copying the
     dump file over to the slave.  After this, you can use the *note
     'mysql': mysql. client to import the data from the dumpfile into
     the slave database as shown here, where DUMP_FILE is the name of
     the file that was generated using *note 'mysqldump': mysqldump. on
     the master, and DB_NAME is the name of the database to be
     replicated:

          shellS> mysql -u root -p DB_NAME < DUMP_FILE

     For a complete list of options to use with *note 'mysqldump':
     mysqldump, see *note mysqldump::.

     *Note*:

     If you copy the data to the slave in this fashion, you should make
     sure that the slave is started with the '--skip-slave-start' option
     on the command line, or else include 'skip-slave-start' in the
     slave's 'my.cnf' file to keep it from trying to connect to the
     master to begin replicating before all the data has been loaded.
     Once the data loading has completed, follow the additional steps
     outlined in the next two sections.

  5. Ensure that each MySQL server acting as a replication master is
     configured with a unique server ID, and with binary logging
     enabled, using the row format.  (See *note replication-formats::.)
     These options can be set either in the master server's 'my.cnf'
     file, or on the command line when starting the master *note
     'mysqld': mysqld. process.  See *note
     mysql-cluster-replication-starting::, for information regarding the
     latter option.


File: manual.info.tmp,  Node: mysql-cluster-replication-starting,  Next: mysql-cluster-replication-two-channels,  Prev: mysql-cluster-replication-preparation,  Up: mysql-cluster-replication

18.6.6 Starting NDB Cluster Replication (Single Replication Channel)
--------------------------------------------------------------------

This section outlines the procedure for starting NDB Cluster replication
using a single replication channel.

  1. Start the MySQL replication master server by issuing this command:

          shellM> mysqld --ndbcluster --server-id=ID \
                  --log-bin &

     If the master is running NDB 7.2.12 or earlier, it must also be
     started with '--binlog-format=ROW' (or 'MIXED').  (Bug #16417224)

     In the previous statement, ID is this server's unique ID (see *note
     mysql-cluster-replication-general::).  This starts the server's
     *note 'mysqld': mysqld. process with binary logging enabled using
     the proper logging format.

     *Note*:

     You can also start the master with '--binlog-format=MIXED', in
     which case row-based replication is used automatically when
     replicating between clusters.  'STATEMENT' based binary logging is
     not supported for NDB Cluster Replication (see *note
     mysql-cluster-replication-general::).

  2. Start the MySQL replication slave server as shown here:

          shellS> mysqld --ndbcluster --server-id=ID &

     In the command just shown, ID is the slave server's unique ID. It
     is not necessary to enable logging on the replication slave.

     *Note*:

     You should use the '--skip-slave-start' option with this command or
     else you should include 'skip-slave-start' in the slave server's
     'my.cnf' file, unless you want replication to begin immediately.
     With the use of this option, the start of replication is delayed
     until the appropriate *note 'START SLAVE': start-slave. statement
     has been issued, as explained in Step 4 below.

  3. It is necessary to synchronize the slave server with the master
     server's replication binary log.  If binary logging has not
     previously been running on the master, run the following statement
     on the slave:

          mysqlS> CHANGE MASTER TO
               -> MASTER_LOG_FILE='',
               -> MASTER_LOG_POS=4;

     This instructs the slave to begin reading the master's binary log
     from the log's starting point.  Otherwise--that is, if you are
     loading data from the master using a backup--see *note
     mysql-cluster-replication-failover::, for information on how to
     obtain the correct values to use for 'MASTER_LOG_FILE' and
     'MASTER_LOG_POS' in such cases.

  4. Finally, you must instruct the slave to begin applying replication
     by issuing this command from the *note 'mysql': mysql. client on
     the replication slave:

          mysqlS> START SLAVE;

     This also initiates the transmission of replication data from the
     master to the slave.

It is also possible to use two replication channels, in a manner similar
to the procedure described in the next section; the differences between
this and using a single replication channel are covered in *note
mysql-cluster-replication-two-channels::.

It is also possible to improve cluster replication performance by
enabling _batched updates_.  This can be accomplished by setting the
'slave_allow_batching' system variable on the slave *note 'mysqld':
mysqld. processes.  Normally, updates are applied as soon as they are
received.  However, the use of batching causes updates to be applied in
32 KB batches, which can result in higher throughput and less CPU usage,
particularly where individual updates are relatively small.

*Note*:

Slave batching works on a per-epoch basis; updates belonging to more
than one transaction can be sent as part of the same batch.

All outstanding updates are applied when the end of an epoch is reached,
even if the updates total less than 32 KB.

Batching can be turned on and off at runtime.  To activate it at
runtime, you can use either of these two statements:

     SET GLOBAL slave_allow_batching = 1;
     SET GLOBAL slave_allow_batching = ON;

If a particular batch causes problems (such as a statement whose effects
do not appear to be replicated correctly), slave batching can be
deactivated using either of the following statements:

     SET GLOBAL slave_allow_batching = 0;
     SET GLOBAL slave_allow_batching = OFF;

You can check whether slave batching is currently being used by means of
an appropriate *note 'SHOW VARIABLES': show-variables. statement, like
this one:

     mysql> SHOW VARIABLES LIKE 'slave%';
     +---------------------------+-------+
     | Variable_name             | Value |
     +---------------------------+-------+
     | slave_allow_batching      | ON    |
     | slave_compressed_protocol | OFF   |
     | slave_load_tmpdir         | /tmp  |
     | slave_net_timeout         | 3600  |
     | slave_skip_errors         | OFF   |
     | slave_transaction_retries | 10    |
     +---------------------------+-------+
     6 rows in set (0.00 sec)


File: manual.info.tmp,  Node: mysql-cluster-replication-two-channels,  Next: mysql-cluster-replication-failover,  Prev: mysql-cluster-replication-starting,  Up: mysql-cluster-replication

18.6.7 Using Two Replication Channels for NDB Cluster Replication
-----------------------------------------------------------------

In a more complete example scenario, we envision two replication
channels to provide redundancy and thereby guard against possible
failure of a single replication channel.  This requires a total of four
replication servers, two masters for the master cluster and two slave
servers for the slave cluster.  For purposes of the discussion that
follows, we assume that unique identifiers are assigned as shown here:

*NDB Cluster replication servers described in the text*

Server ID          Description
                   
1                  Master - primary replication channel (_M_)
                   
2                  Master - secondary replication channel (_M'_)
                   
3                  Slave - primary replication channel (_S_)
                   
4                  Slave - secondary replication channel (_S'_)

Setting up replication with two channels is not radically different from
setting up a single replication channel.  First, the *note 'mysqld':
mysqld. processes for the primary and secondary replication masters must
be started, followed by those for the primary and secondary slaves.
Then the replication processes may be initiated by issuing the *note
'START SLAVE': start-slave. statement on each of the slaves.  The
commands and the order in which they need to be issued are shown here:

  1. Start the primary replication master:

          shellM> mysqld --ndbcluster --server-id=1 \
                         --log-bin &

     For NDB 7.2.12 and earlier, you should use the following (Bug
     #16417224):

          shellM> mysqld --ndbcluster --server-id=1 \
                         --log-bin --binlog-format=ROW &

  2. Start the secondary replication master:

          shellM'> mysqld --ndbcluster --server-id=2 \
                         --log-bin &

     For NDB 7.2.12 and earlier, you should use this instead (Bug
     #16417224):

          shellM'> mysqld --ndbcluster --server-id=2 \
                         --log-bin --binlog-format=ROW &

  3. Start the primary replication slave server:

          shellS> mysqld --ndbcluster --server-id=3 \
                         --skip-slave-start &

  4. Start the secondary replication slave:

          shellS'> mysqld --ndbcluster --server-id=4 \
                          --skip-slave-start &

  5. Finally, initiate replication on the primary channel by executing
     the *note 'START SLAVE': start-slave. statement on the primary
     slave as shown here:

          mysqlS> START SLAVE;

     *Warning*:

     Only the primary channel is to be started at this point.  The
     secondary replication channel is to be started only in the event
     that the primary replication channel fails, as described in *note
     mysql-cluster-replication-failover::.  Running multiple replication
     channels simultaneously can result in unwanted duplicate records
     being created on the replication slaves.

As mentioned previously, it is not necessary to enable binary logging on
replication slaves.


File: manual.info.tmp,  Node: mysql-cluster-replication-failover,  Next: mysql-cluster-replication-backups,  Prev: mysql-cluster-replication-two-channels,  Up: mysql-cluster-replication

18.6.8 Implementing Failover with NDB Cluster Replication
---------------------------------------------------------

In the event that the primary Cluster replication process fails, it is
possible to switch over to the secondary replication channel.  The
following procedure describes the steps required to accomplish this.

  1. 
     Obtain the time of the most recent global checkpoint (GCP). That
     is, you need to determine the most recent epoch from the
     'ndb_apply_status' table on the slave cluster, which can be found
     using the following query:

          mysqlS'> SELECT @latest:=MAX(epoch)
                ->        FROM mysql.ndb_apply_status;

     In a circular replication topology, with a master and a slave
     running on each host, when you are using 'ndb_log_apply_status=1',
     NDB Cluster epochs are written in the slave binary logs.  This
     means that the 'ndb_apply_status' table contains information for
     the slave on this host as well as for any other host which acts as
     a slave of the master running on this host.

     In this case, you need to determine the latest epoch on this slave
     to the exclusion of any epochs from any other slaves in this
     slave's binary log that were not listed in the 'IGNORE_SERVER_IDS'
     options of the *note 'CHANGE MASTER TO': change-master-to.
     statement used to set up this slave.  The reason for excluding such
     epochs is that rows in the 'mysql.ndb_apply_status' table whose
     server IDs have a match in the 'IGNORE_SERVER_IDS' list used with
     the CHANGE MASTER TO statement used to prepare this slave's master
     are also considered to be from local servers, in addition to those
     having the slave's own server ID. You can retrieve this list as
     'Replicate_Ignore_Server_Ids' from the output of *note 'SHOW SLAVE
     STATUS': show-slave-status.  We assume that you have obtained this
     list and are substituting it for IGNORE_SERVER_IDS in the query
     shown here, which like the previous version of the query, selects
     the greatest epoch into a variable named '@latest':

          mysqlS'> SELECT @latest:=MAX(epoch)
                ->        FROM mysql.ndb_apply_status
                ->        WHERE server_id NOT IN (IGNORE_SERVER_IDS);

     In some cases, it may be simpler or more efficient (or both) to use
     a list of the server IDs to be included and 'server_id IN
     SERVER_ID_LIST' in the 'WHERE' condition of the preceding query.

  2. 
     Using the information obtained from the query shown in Step 1,
     obtain the corresponding records from the 'ndb_binlog_index' table
     on the master cluster.

     Prior to NDB 7.2.6, you should use the following query to
     accomplish this task:

          mysqlM'> SELECT
                ->     @file:=SUBSTRING_INDEX(File, '/', -1),
                ->     @pos:=Position
                -> FROM mysql.ndb_binlog_index
                -> WHERE epoch > @latest
                -> ORDER BY epoch ASC LIMIT 1;

     Beginning with NDB 7.2.6, you can take advantage of the improved
     binary logging of DDL statements implemented in those and later
     versions by using the following query to obtain the needed records
     from the master's 'ndb_binlog_index' table:

          mysqlM'> SELECT
                ->     @file:=SUBSTRING_INDEX(next_file, '/', -1),
                ->     @pos:=next_position
                -> FROM mysql.ndb_binlog_index
                -> WHERE epoch >= @latest
                -> ORDER BY epoch ASC LIMIT 1;

     In either case, these are the records saved on the master since the
     failure of the primary replication channel.  We have employed a
     user variable '@latest' here to represent the value obtained in
     Step 1.  Of course, it is not possible for one *note 'mysqld':
     mysqld. instance to access user variables set on another server
     instance directly.  These values must be 'plugged in' to the second
     query manually or in application code.

     *Important*:

     If (and only if) you use the second of the two queries just shown
     against 'ndb_binlog_index' (that is, the query that employs the
     'next_position' and 'next_file' columns), you must ensure that the
     slave *note 'mysqld': mysqld. is started with
     '--slave-skip-errors=ddl_exist_errors' before executing *note
     'START SLAVE': start-slave.  Otherwise, replication may stop with
     duplicate DDL errors.

  3. Now it is possible to synchronize the secondary channel by running
     the following query on the secondary slave server:

          mysqlS'> CHANGE MASTER TO
                ->     MASTER_LOG_FILE='@file',
                ->     MASTER_LOG_POS=@pos;

     Again we have employed user variables (in this case '@file' and
     '@pos') to represent the values obtained in Step 2 and applied in
     Step 3; in practice these values must be inserted manually or using
     application code that can access both of the servers involved.

     *Note*:

     '@file' is a string value such as
     ''/var/log/mysql/replication-master-bin.00001'', and so must be
     quoted when used in SQL or application code.  However, the value
     represented by '@pos' must _not_ be quoted.  Although MySQL
     normally attempts to convert strings to numbers, this case is an
     exception.

  4. You can now initiate replication on the secondary channel by
     issuing the appropriate command on the secondary slave *note
     'mysqld': mysqld.:

          mysqlS'> START SLAVE;

Once the secondary replication channel is active, you can investigate
the failure of the primary and effect repairs.  The precise actions
required to do this will depend upon the reasons for which the primary
channel failed.

*Warning*:

The secondary replication channel is to be started only if and when the
primary replication channel has failed.  Running multiple replication
channels simultaneously can result in unwanted duplicate records being
created on the replication slaves.

If the failure is limited to a single server, it should (in theory) be
possible to replicate from M to S', or from M' to S; however, this has
not yet been tested.


File: manual.info.tmp,  Node: mysql-cluster-replication-backups,  Next: mysql-cluster-replication-multi-master,  Prev: mysql-cluster-replication-failover,  Up: mysql-cluster-replication

18.6.9 NDB Cluster Backups With NDB Cluster Replication
-------------------------------------------------------

* Menu:

* mysql-cluster-replication-auto-sync::  NDB Cluster Replication: Automating Synchronization of the Replication Slave to the Master Binary Log
* mysql-cluster-replication-pitr::  Point-In-Time Recovery Using NDB Cluster Replication

This section discusses making backups and restoring from them using NDB
Cluster replication.  We assume that the replication servers have
already been configured as covered previously (see *note
mysql-cluster-replication-preparation::, and the sections immediately
following).  This having been done, the procedure for making a backup
and then restoring from it is as follows:

  1. There are two different methods by which the backup may be started.

        * Method A

          This method requires that the cluster backup process was
          previously enabled on the master server, prior to starting the
          replication process.  This can be done by including the
          following line in a '[mysql_cluster]' section in the 'my.cnf
          file', where MANAGEMENT_HOST is the IP address or host name of
          the *note 'NDB': mysql-cluster. management server for the
          master cluster, and PORT is the management server's port
          number:

               ndb-connectstring=MANAGEMENT_HOST[:PORT]

          *Note*:

          The port number needs to be specified only if the default port
          (1186) is not being used.  See *note
          mysql-cluster-install-configuration::, for more information
          about ports and port allocation in NDB Cluster.

          In this case, the backup can be started by executing this
          statement on the replication master:

               shellM> ndb_mgm -e "START BACKUP"

        * Method B

          If the 'my.cnf' file does not specify where to find the
          management host, you can start the backup process by passing
          this information to the *note 'NDB': mysql-cluster. management
          client as part of the *note 'START BACKUP':
          mysql-cluster-backup-using-management-client. command.  This
          can be done as shown here, where MANAGEMENT_HOST and PORT are
          the host name and port number of the management server:

               shellM> ndb_mgm MANAGEMENT_HOST:PORT -e "START BACKUP"

          In our scenario as outlined earlier (see *note
          mysql-cluster-replication-preparation::), this would be
          executed as follows:

               shellM> ndb_mgm rep-master:1186 -e "START BACKUP"

  2. Copy the cluster backup files to the slave that is being brought on
     line.  Each system running an *note 'ndbd':
     mysql-cluster-programs-ndbd. process for the master cluster will
     have cluster backup files located on it, and _all_ of these files
     must be copied to the slave to ensure a successful restore.  The
     backup files can be copied into any directory on the computer where
     the slave management host resides, so long as the MySQL and NDB
     binaries have read permissions in that directory.  In this case, we
     will assume that these files have been copied into the directory
     '/var/BACKUPS/BACKUP-1'.

     It is not necessary that the slave cluster have the same number of
     *note 'ndbd': mysql-cluster-programs-ndbd. processes (data nodes)
     as the master; however, it is highly recommended this number be the
     same.  It _is_ necessary that the slave be started with the
     '--skip-slave-start' option, to prevent premature startup of the
     replication process.

  3. Create any databases on the slave cluster that are present on the
     master cluster that are to be replicated to the slave.

     *Important*:

     A *note 'CREATE DATABASE': create-database. (or *note 'CREATE
     SCHEMA': create-database.) statement corresponding to each database
     to be replicated must be executed on each SQL node in the slave
     cluster.

  4. Reset the slave cluster using this statement in the MySQL Monitor:

          mysqlS> RESET SLAVE;

  5. You can now start the cluster restoration process on the
     replication slave using the *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. command for each backup file in
     turn.  For the first of these, it is necessary to include the '-m'
     option to restore the cluster metadata:

          shellS> ndb_restore -c SLAVE_HOST:PORT -n NODE-ID \
                  -b BACKUP-ID -m -r DIR

     DIR is the path to the directory where the backup files have been
     placed on the replication slave.  For the *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore. commands corresponding to the
     remaining backup files, the '-m' option should _not_ be used.

     For restoring from a master cluster with four data nodes (as shown
     in the figure in *note mysql-cluster-replication::) where the
     backup files have been copied to the directory
     '/var/BACKUPS/BACKUP-1', the proper sequence of commands to be
     executed on the slave might look like this:

          shellS> ndb_restore -c rep-slave:1186 -n 2 -b 1 -m \
                  -r ./var/BACKUPS/BACKUP-1
          shellS> ndb_restore -c rep-slave:1186 -n 3 -b 1 \
                  -r ./var/BACKUPS/BACKUP-1
          shellS> ndb_restore -c rep-slave:1186 -n 4 -b 1 \
                  -r ./var/BACKUPS/BACKUP-1
          shellS> ndb_restore -c rep-slave:1186 -n 5 -b 1 -e \
                  -r ./var/BACKUPS/BACKUP-1

     *Important*:

     The '-e' (or '--restore-epoch') option in the final invocation of
     *note 'ndb_restore': mysql-cluster-programs-ndb-restore. in this
     example is required in order that the epoch is written to the slave
     'mysql.ndb_apply_status'.  Without this information, the slave will
     not be able to synchronize properly with the master.  (See *note
     mysql-cluster-programs-ndb-restore::.)

  6. Now you need to obtain the most recent epoch from the
     'ndb_apply_status' table on the slave (as discussed in *note
     mysql-cluster-replication-failover::):

          mysqlS> SELECT @latest:=MAX(epoch)
                  FROM mysql.ndb_apply_status;

  7. Using '@latest' as the epoch value obtained in the previous step,
     you can obtain the correct starting position '@pos' in the correct
     binary log file '@file' from the master's 'mysql.ndb_binlog_index'
     table using the query shown here:

          mysqlM> SELECT
               ->     @file:=SUBSTRING_INDEX(File, '/', -1),
               ->     @pos:=Position
               -> FROM mysql.ndb_binlog_index
               -> WHERE epoch >= @latest
               -> ORDER BY epoch ASC LIMIT 1;

     In the event that there is currently no replication traffic, you
     can get this information by running *note 'SHOW MASTER STATUS':
     show-master-status. on the master and using the value in the
     'Position' column for the file whose name has the suffix with the
     greatest value for all files shown in the 'File' column.  However,
     in this case, you must determine this and supply it in the next
     step manually or by parsing the output with a script.

  8. Using the values obtained in the previous step, you can now issue
     the appropriate *note 'CHANGE MASTER TO': change-master-to.
     statement in the slave's *note 'mysql': mysql. client:

          mysqlS> CHANGE MASTER TO
               ->     MASTER_LOG_FILE='@file',
               ->     MASTER_LOG_POS=@pos;

  9. Now that the slave 'knows' from what point in which binary log file
     to start reading data from the master, you can cause the slave to
     begin replicating with this standard MySQL statement:

          mysqlS> START SLAVE;

To perform a backup and restore on a second replication channel, it is
necessary only to repeat these steps, substituting the host names and
IDs of the secondary master and slave for those of the primary master
and slave replication servers where appropriate, and running the
preceding statements on them.

For additional information on performing Cluster backups and restoring
Cluster from backups, see *note mysql-cluster-backup::.


File: manual.info.tmp,  Node: mysql-cluster-replication-auto-sync,  Next: mysql-cluster-replication-pitr,  Prev: mysql-cluster-replication-backups,  Up: mysql-cluster-replication-backups

18.6.9.1 NDB Cluster Replication: Automating Synchronization of the Replication Slave to the Master Binary Log
..............................................................................................................

It is possible to automate much of the process described in the previous
section (see *note mysql-cluster-replication-backups::).  The following
Perl script 'reset-slave.pl' serves as an example of how you can do
this.

     #!/user/bin/perl -w

     #  file: reset-slave.pl

     #  Copyright (C)2005-2017 Oracle and/or its affiliates

     #  This program is free software; you can redistribute it and/or modify
     #  it under the terms of the GNU General Public License as published by
     #  the Free Software Foundation; either version 2 of the License, or
     #  (at your option) any later version.

     #  This program is distributed in the hope that it will be useful,
     #  but WITHOUT ANY WARRANTY; without even the implied warranty of
     #  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
     #  GNU General Public License for more details.

     #  You should have received a copy of the GNU General Public License
     #  along with this program; if not, write to:
     #  Free Software Foundation, Inc.
     #  59 Temple Place, Suite 330
     #  Boston, MA 02111-1307 USA
     #
     #  Version 1.1

     ######################## Includes ###############################

     use DBI;

     ######################## Globals ################################

     my  $m_host='';
     my  $m_port='';
     my  $m_user='';
     my  $m_pass='';
     my  $s_host='';
     my  $s_port='';
     my  $s_user='';
     my  $s_pass='';
     my  $dbhM='';
     my  $dbhS='';

     ####################### Sub Prototypes ##########################

     sub CollectCommandPromptInfo;
     sub ConnectToDatabases;
     sub DisconnectFromDatabases;
     sub GetSlaveEpoch;
     sub GetMasterInfo;
     sub UpdateSlave;

     ######################## Program Main ###########################

     CollectCommandPromptInfo;
     ConnectToDatabases;
     GetSlaveEpoch;
     GetMasterInfo;
     UpdateSlave;
     DisconnectFromDatabases;

     ################## Collect Command Prompt Info ##################

     sub CollectCommandPromptInfo
     {
       ### Check that user has supplied correct number of command line args
       die "Usage:\n
            reset-slave >master MySQL host< >master MySQL port< \n
                        >master user< >master pass< >slave MySQL host< \n
                        >slave MySQL port< >slave user< >slave pass< \n
            All 8 arguments must be passed. Use BLANK for NULL passwords\n"
            unless @ARGV == 8;

       $m_host  =  $ARGV[0];
       $m_port  =  $ARGV[1];
       $m_user  =  $ARGV[2];
       $m_pass  =  $ARGV[3];
       $s_host  =  $ARGV[4];
       $s_port  =  $ARGV[5];
       $s_user  =  $ARGV[6];
       $s_pass  =  $ARGV[7];

       if ($m_pass eq "BLANK") { $m_pass = '';}
       if ($s_pass eq "BLANK") { $s_pass = '';}
     }

     ###############  Make connections to both databases #############

     sub ConnectToDatabases
     {
       ### Connect to both master and slave cluster databases

       ### Connect to master
       $dbhM
         = DBI->connect(
         "dbi:mysql:database=mysql;host=$m_host;port=$m_port",
         "$m_user", "$m_pass")
           or die "Can't connect to Master Cluster MySQL process!
                   Error: $DBI::errstr\n";

       ### Connect to slave
       $dbhS
         = DBI->connect(
               "dbi:mysql:database=mysql;host=$s_host",
               "$s_user", "$s_pass")
         or die "Can't connect to Slave Cluster MySQL process!
                 Error: $DBI::errstr\n";
     }

     ################  Disconnect from both databases ################

     sub DisconnectFromDatabases
     {
       ### Disconnect from master

       $dbhM->disconnect
       or warn " Disconnection failed: $DBI::errstr\n";

       ### Disconnect from slave

       $dbhS->disconnect
       or warn " Disconnection failed: $DBI::errstr\n";
     }

     ######################  Find the last good GCI ##################

     sub GetSlaveEpoch
     {
       $sth = $dbhS->prepare("SELECT MAX(epoch)
                              FROM mysql.ndb_apply_status;")
           or die "Error while preparing to select epoch from slave: ",
                  $dbhS->errstr;

       $sth->execute
           or die "Selecting epoch from slave error: ", $sth->errstr;

       $sth->bind_col (1, \$epoch);
       $sth->fetch;
       print "\tSlave Epoch =  $epoch\n";
       $sth->finish;
     }

     #######  Find the position of the last GCI in the binary log ########

     sub GetMasterInfo
     {
       $sth = $dbhM->prepare("SELECT
                                SUBSTRING_INDEX(File, '/', -1), Position
                              FROM mysql.ndb_binlog_index
                              WHERE epoch > $epoch
                              ORDER BY epoch ASC LIMIT 1;")
           or die "Prepare to select from master error: ", $dbhM->errstr;

       $sth->execute
           or die "Selecting from master error: ", $sth->errstr;

       $sth->bind_col (1, \$binlog);
       $sth->bind_col (2, \$binpos);
       $sth->fetch;
       print "\tMaster binary log =  $binlog\n";
       print "\tMaster binary log position =  $binpos\n";
       $sth->finish;
     }

     ##########  Set the slave to process from that location #########

     sub UpdateSlave
     {
       $sth = $dbhS->prepare("CHANGE MASTER TO
                              MASTER_LOG_FILE='$binlog',
                              MASTER_LOG_POS=$binpos;")
           or die "Prepare to CHANGE MASTER error: ", $dbhS->errstr;

       $sth->execute
            or die "CHANGE MASTER on slave error: ", $sth->errstr;
       $sth->finish;
       print "\tSlave has been updated. You may now start the slave.\n";
     }

     # end reset-slave.pl


File: manual.info.tmp,  Node: mysql-cluster-replication-pitr,  Prev: mysql-cluster-replication-auto-sync,  Up: mysql-cluster-replication-backups

18.6.9.2 Point-In-Time Recovery Using NDB Cluster Replication
.............................................................

_Point-in-time_ recovery--that is, recovery of data changes made since a
given point in time--is performed after restoring a full backup that
returns the server to its state when the backup was made.  Performing
point-in-time recovery of NDB Cluster tables with NDB Cluster and NDB
Cluster Replication can be accomplished using a native *note 'NDB':
mysql-cluster. data backup (taken by issuing 'CREATE BACKUP' in the
*note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. client) and restoring
the 'ndb_binlog_index' table (from a dump made using *note 'mysqldump':
mysqldump.).

To perform point-in-time recovery of NDB Cluster, it is necessary to
follow the steps shown here:

  1. Back up all 'NDB' databases in the cluster, using the *note 'START
     BACKUP': mysql-cluster-backup-using-management-client. command in
     the *note 'ndb_mgm': mysql-cluster-programs-ndb-mgm. client (see
     *note mysql-cluster-backup::).

  2. At some later point, prior to restoring the cluster, make a backup
     of the 'mysql.ndb_binlog_index' table.  It is probably simplest to
     use *note 'mysqldump': mysqldump. for this task.  Also back up the
     binary log files at this time.

     This backup should be updated regularly--perhaps even
     hourly--depending on your needs.

  3. (_Catastrophic failure or error occurs_.)

  4. Locate the last known good backup.

  5. Clear the data node file systems (using *note 'ndbd':
     mysql-cluster-programs-ndbd. '--initial' or *note 'ndbmtd':
     mysql-cluster-programs-ndbmtd. '--initial').

     *Note*:

     NDB Cluster Disk Data tablespace and log files are not removed by
     '--initial'.  You must delete these manually.

  6. Use *note 'DROP TABLE': drop-table. or *note 'TRUNCATE TABLE':
     truncate-table. with the 'mysql.ndb_binlog_index' table.

  7. Execute *note 'ndb_restore': mysql-cluster-programs-ndb-restore,
     restoring all data.  You must include the '--restore-epoch' option
     when you run *note 'ndb_restore':
     mysql-cluster-programs-ndb-restore, so that the 'ndb_apply_status'
     table is populated correctly.  (See *note
     mysql-cluster-programs-ndb-restore::, for more information.)

  8. Restore the 'ndb_binlog_index' table from the output of *note
     'mysqldump': mysqldump. and restore the binary log files from
     backup, if necessary.

  9. Find the epoch applied most recently--that is, the maximum 'epoch'
     column value in the 'ndb_apply_status' table--as the user variable
     '@LATEST_EPOCH' (emphasized):

          SELECT _@LATEST_EPOCH_:=MAX(epoch)
              FROM mysql.ndb_apply_status;

  10. Find the latest binary log file ('@FIRST_FILE') and position
     ('Position' column value) within this file that correspond to
     '@LATEST_EPOCH' in the 'ndb_binlog_index' table:

          SELECT Position, _@FIRST_FILE_:=File
              FROM mysql.ndb_binlog_index
              WHERE epoch > _@LATEST_EPOCH_ ORDER BY epoch ASC LIMIT 1;

  11. Using *note 'mysqlbinlog': mysqlbinlog, replay the binary log
     events from the given file and position up to the point of the
     failure.  (See *note mysqlbinlog::.)

See also *note point-in-time-recovery::, for more information about the
binary log, replication, and incremental recovery.


File: manual.info.tmp,  Node: mysql-cluster-replication-multi-master,  Next: mysql-cluster-replication-conflict-resolution,  Prev: mysql-cluster-replication-backups,  Up: mysql-cluster-replication

18.6.10 NDB Cluster Replication: Multi-Master and Circular Replication
----------------------------------------------------------------------

It is possible to use NDB Cluster in multi-master replication, including
circular replication between a number of NDB Clusters.

Circular replication example

In the next few paragraphs we consider the example of a replication
setup involving three NDB Clusters numbered 1, 2, and 3, in which
Cluster 1 acts as the replication master for Cluster 2, Cluster 2 acts
as the master for Cluster 3, and Cluster 3 acts as the master for
Cluster 1.  Each cluster has two SQL nodes, with SQL nodes A and B
belonging to Cluster 1, SQL nodes C and D belonging to Cluster 2, and
SQL nodes E and F belonging to Cluster 3.

Circular replication using these clusters is supported as long as the
following conditions are met:

   * The SQL nodes on all masters and slaves are the same.

   * All SQL nodes acting as replication masters and slaves are started
     with the 'log_slave_updates' system variable enabled.

This type of circular replication setup is shown in the following
diagram:

FIGURE GOES HERE: NDB Cluster Circular Replication with All Masters As
Slaves

In this scenario, SQL node A in Cluster 1 replicates to SQL node C in
Cluster 2; SQL node C replicates to SQL node E in Cluster 3; SQL node E
replicates to SQL node A. In other words, the replication line
(indicated by the curved arrows in the diagram) directly connects all
SQL nodes used as replication masters and slaves.

It is also possible to set up circular replication in such a way that
not all master SQL nodes are also slaves, as shown here:

FIGURE GOES HERE: NDB Cluster Circular Replication Where Not All Masters
Are Slaves

In this case, different SQL nodes in each cluster are used as
replication masters and slaves.  However, you must _not_ start any of
the SQL nodes with the 'log_slave_updates' system variable enabled.
This type of circular replication scheme for NDB Cluster, in which the
line of replication (again indicated by the curved arrows in the
diagram) is discontinuous, should be possible, but it should be noted
that it has not yet been thoroughly tested and must therefore still be
considered experimental.

Using NDB-native backup and restore to initialize a slave NDB Cluster

When setting up circular replication, it is possible to initialize the
slave cluster by using the management client 'BACKUP' command on one NDB
Cluster to create a backup and then applying this backup on another NDB
Cluster using *note 'ndb_restore': mysql-cluster-programs-ndb-restore.
However, this does not automatically create binary logs on the second
NDB Cluster's SQL node acting as the replication slave.  In order to
cause the binary logs to be created, you must issue a *note 'SHOW
TABLES': show-tables. statement on that SQL node; this should be done
prior to running *note 'START SLAVE': start-slave.

This is a known issue which we intend to address in a future release.

Multi-master failover example

In this section, we discuss failover in a multi-master NDB Cluster
replication setup with three NDB Clusters having server IDs 1, 2, and 3.
In this scenario, Cluster 1 replicates to Clusters 2 and 3; Cluster 2
also replicates to Cluster 3.  This relationship is shown here:

FIGURE GOES HERE: NDB Cluster Multi-Master Replication With 3 Masters

In other words, data replicates from Cluster 1 to Cluster 3 through 2
different routes: directly, and by way of Cluster 2.

Not all MySQL servers taking part in multi-master replication must act
as both master and slave, and a given NDB Cluster might use different
SQL nodes for different replication channels.  Such a case is shown
here:

FIGURE GOES HERE: NDB Cluster Multi-Master Replication, With MySQL
Servers

MySQL servers acting as replication slaves must be run with the
'log_slave_updates' system variable enabled.  Which *note 'mysqld':
mysqld. processes require this option is also shown in the preceding
diagram.

*Note*:

Using the 'log_slave_updates' system variable has no effect on servers
not being run as replication slaves.

The need for failover arises when one of the replicating clusters goes
down.  In this example, we consider the case where Cluster 1 is lost to
service, and so Cluster 3 loses 2 sources of updates from Cluster 1.
Because replication between NDB Clusters is asynchronous, there is no
guarantee that Cluster 3's updates originating directly from Cluster 1
are more recent than those received through Cluster 2.  You can handle
this by ensuring that Cluster 3 catches up to Cluster 2 with regard to
updates from Cluster 1.  In terms of MySQL servers, this means that you
need to replicate any outstanding updates from MySQL server C to server
F.

On server C, perform the following queries:

     mysqlC> SELECT @latest:=MAX(epoch)
          ->     FROM mysql.ndb_apply_status
          ->     WHERE server_id=1;

     mysqlC> SELECT
          ->     @file:=SUBSTRING_INDEX(File, '/', -1),
          ->     @pos:=Position
          ->     FROM mysql.ndb_binlog_index
          ->     WHERE orig_epoch >= @latest
          ->     AND orig_server_id = 1
          ->     ORDER BY epoch ASC LIMIT 1;

*Note*:

You can improve the performance of this query, and thus likely speed up
failover times significantly, by adding the appropriate index to the
'ndb_binlog_index' table.  See *note mysql-cluster-replication-schema::,
for more information.

Copy over the values for @FILE and @POS manually from server C to server
F (or have your application perform the equivalent).  Then, on server F,
execute the following *note 'CHANGE MASTER TO': change-master-to.
statement:

     mysqlF> CHANGE MASTER TO
          ->     MASTER_HOST = 'serverC'
          ->     MASTER_LOG_FILE='@file',
          ->     MASTER_LOG_POS=@pos;

Once this has been done, you can issue a *note 'START SLAVE':
start-slave. statement on MySQL server F, and any missing updates
originating from server B will be replicated to server F.

The *note 'CHANGE MASTER TO': change-master-to. statement also supports
an 'IGNORE_SERVER_IDS' option which takes a comma-separated list of
server IDs and causes events originating from the corresponding servers
to be ignored.  For more information, see *note change-master-to::, and
*note show-slave-status::.  For information about how this option
intereacts with the 'ndb_log_apply_status' variable, see *note
mysql-cluster-replication-failover::.


File: manual.info.tmp,  Node: mysql-cluster-replication-conflict-resolution,  Prev: mysql-cluster-replication-multi-master,  Up: mysql-cluster-replication

18.6.11 NDB Cluster Replication Conflict Resolution
---------------------------------------------------

When using a replication setup involving multiple masters (including
circular replication), it is possible that different masters may try to
update the same row on the slave with different data.  Conflict
resolution in NDB Cluster Replication provides a means of resolving such
conflicts by permitting a user-defined resolution column to be used to
determine whether or not an update on a given master should be applied
on the slave.

Some types of conflict resolution supported by NDB Cluster ('NDB$OLD()',
'NDB$MAX()', 'NDB$MAX_DELETE_WIN()') implement this user-defined column
as a 'timestamp' column (although its type cannot be *note 'TIMESTAMP':
datetime, as explained later in this section).  These types of conflict
resolution are always applied a row-by-row basis rather than a
transactional basis.  The epoch-based conflict resolution functions
introduced in NDB 7.2.1 ('NDB$EPOCH()' and 'NDB$EPOCH_TRANS()') compare
the order in which epochs are replicated (and thus these functions are
transactional).  Different methods can be used to compare resolution
column values on the slave when conflicts occur, as explained later in
this section; the method used can be set on a per-table basis.

You should also keep in mind that it is the application's responsibility
to ensure that the resolution column is correctly populated with
relevant values, so that the resolution function can make the
appropriate choice when determining whether to apply an update.

Requirements

Preparations for conflict resolution must be made on both the master and
the slave.  These tasks are described in the following list:

   * On the master writing the binary logs, you must determine which
     columns are sent (all columns or only those that have been
     updated).  This is done for the MySQL Server as a whole by applying
     the *note 'mysqld': mysqld. startup option '--ndb-log-updated-only'
     (described later in this section) or on a per-table basis by
     entries in the 'mysql.ndb_replication' table (see *note
     mysql-cluster-ndb-replication-table::).

     *Note*:

     If you are replicating tables with very large columns (such as
     *note 'TEXT': blob. or *note 'BLOB': blob. columns),
     '--ndb-log-updated-only' can also be useful for reducing the size
     of the master and slave binary logs and avoiding possible
     replication failures due to exceeding 'max_allowed_packet'.

     See *note replication-features-max-allowed-packet::, for more
     information about this issue.

   * On the slave, you must determine which type of conflict resolution
     to apply ('latest timestamp wins', 'same timestamp wins', 'primary
     wins', 'primary wins, complete transaction', or none).  This is
     done using the 'mysql.ndb_replication' system table, on a per-table
     basis (see *note mysql-cluster-ndb-replication-table::).

   * Prior to NDB 7.2.5, conflict detection and resolution did not
     always work properly unless set up for *note 'NDB': mysql-cluster.
     tables created on the same server only (Bug #13578660).

When using the functions 'NDB$OLD()', 'NDB$MAX()', and
'NDB$MAX_DELETE_WIN()' for timestamp-based conflict resolution, we often
refer to the column used for determining updates as a 'timestamp'
column.  However, the data type of this column is never *note
'TIMESTAMP': datetime.; instead, its data type should be *note 'INT':
integer-types. (*note 'INTEGER': integer-types.) or *note 'BIGINT':
integer-types.  The 'timestamp' column should also be 'UNSIGNED' and
'NOT NULL'.

The 'NDB$EPOCH()' and 'NDB$EPOCH_TRANS()' functions discussed later in
this section work by comparing the relative order of replication epochs
applied on a primary and secondary NDB Cluster, and do not make use of
timestamps.

Master column control

We can see update operations in terms of 'before' and 'after'
images--that is, the states of the table before and after the update is
applied.  Normally, when updating a table with a primary key, the
'before' image is not of great interest; however, when we need to
determine on a per-update basis whether or not to use the updated values
on a replication slave, we need to make sure that both images are
written to the master's binary log.  This is done with the
'--ndb-log-update-as-write' option for *note 'mysqld': mysqld, as
described later in this section.

*Important*:

Whether logging of complete rows or of updated columns only is done is
decided when the MySQL server is started, and cannot be changed online;
you must either restart *note 'mysqld': mysqld, or start a new *note
'mysqld': mysqld. instance with different logging options.

*Logging Full or Partial Rows (-ndb-log-updated-only Option)*

Property               Value
                       
*Command-Line          '--ndb-log-updated-only[={OFF|ON}]'
Format*                

*System Variable*      'ndb_log_updated_only'
                       
*Scope*                Global
                       
*Dynamic*              Yes
                       
*Type*                 Boolean
                       
*Default Value*        'ON'

For purposes of conflict resolution, there are two basic methods of
logging rows, as determined by the setting of the
'--ndb-log-updated-only' option for *note 'mysqld': mysqld.:

   * Log complete rows

   * Log only column data that has been updated--that is, column data
     whose value has been set, regardless of whether or not this value
     was actually changed.  This is the default behavior.

It is usually sufficient--and more efficient--to log updated columns
only; however, if you need to log full rows, you can do so by setting
'--ndb-log-updated-only' to '0' or 'OFF'.

*-ndb-log-update-as-write Option: Logging Changed Data as Updates*

Property               Value
                       
*Command-Line          '--ndb-log-update-as-write[={OFF|ON}]'
Format*                

*System Variable*      'ndb_log_update_as_write'
                       
*Scope*                Global
                       
*Dynamic*              Yes
                       
*Type*                 Boolean
                       
*Default Value*        'ON'

The setting of the MySQL Server's '--ndb-log-update-as-write' option
determines whether logging is performed with or without the 'before'
image.  Because conflict resolution is done in the MySQL Server's update
handler, it is necessary to control logging on the master such that
updates are updates and not writes; that is, such that updates are
treated as changes in existing rows rather than the writing of new rows
(even though these replace existing rows).  This option is turned on by
default; in other words, updates are treated as writes.  (That is,
updates are by default written as 'write_row' events in the binary log,
rather than as 'update_row' events.)

To turn off the option, start the master *note 'mysqld': mysqld. with
'--ndb-log-update-as-write=0' or '--ndb-log-update-as-write=OFF'.  You
must do this when replicating from NDB tables to tables using a
different storage engine; see *note
mysql-cluster-replication-ndb-to-non-ndb::.

Conflict resolution control

Conflict resolution is usually enabled on the server where conflicts can
occur.  Like logging method selection, it is enabled by entries in the
'mysql.ndb_replication' table.

The ndb_replication system table

To enable conflict resolution, it is necessary to create an
'ndb_replication' table in the 'mysql' system database on the master,
the slave, or both, depending on the conflict resolution type and method
to be employed.  This table is used to control logging and conflict
resolution functions on a per-table basis, and has one row per table
involved in replication.  'ndb_replication' is created and filled with
control information on the server where the conflict is to be resolved.
In a simple master-slave setup where data can also be changed locally on
the slave this will typically be the slave.  In a more complex
master-master (2-way) replication schema this will usually be all of the
masters involved.  Each row in 'mysql.ndb_replication' corresponds to a
table being replicated, and specifies how to log and resolve conflicts
(that is, which conflict resolution function, if any, to use) for that
table.  The definition of the 'mysql.ndb_replication' table is shown
here:

     CREATE TABLE mysql.ndb_replication  (
         db VARBINARY(63),
         table_name VARBINARY(63),
         server_id INT UNSIGNED,
         binlog_type INT UNSIGNED,
         conflict_fn VARBINARY(128),
         PRIMARY KEY USING HASH (db, table_name, server_id)
     )   ENGINE=NDB
     PARTITION BY KEY(db,table_name);

The columns in this table are described in the next few paragraphs.

db

The name of the database containing the table to be replicated.

Beginning with NDB 7.2.5, you may employ either or both of the wildcards
'_' and '%' as part of the database name.  Matching is similar to what
is implemented for the 'LIKE' operator.

table_name

The name of the table to be replicated.

Beginning with NDB 7.2.5, the table name may include either or both of
the wildcards '_' and '%'.  Matching is similar to what is implemented
for the 'LIKE' operator.

server_id

The unique server ID of the MySQL instance (SQL node) where the table
resides.

binlog_type

The type of binary logging to be employed.  This is determined as shown
in the following table:

*binlog_type values, with internal values and descriptions*

Value          Internal       Description
               Value          
               
0              'NBT_DEFAULT'  Use server default
                              
1              'NBT_NO_LOGGING'Do not log this table in the binary log
                              
2              'NBT_UPDATED_ONLY'Only updated attributes are logged
                              
3              'NBT_FULL'     Log full row, even if not updated (MySQL
                              server default behavior)
                              
4              'NBT_USE_UPDATE'(For generating
                              'NBT_UPDATED_ONLY_USE_UPDATE' and
                              'NBT_FULL_USE_UPDATE' values only--not
                              intended for separate use)
                              
5              [_Not used_]   --
                              
6              'NBT_UPDATED_ONLY_USE_UPDATE'Use updated attributes, even if values
               (equal to      are unchanged
               'NBT_UPDATED_ONLY
               |
               NBT_USE_UPDATE')
               
7              'NBT_FULL_USE_UPDATE'Use full row, even if values are
               (equal to      unchanged
               'NBT_FULL |
               NBT_USE_UPDATE')
               

conflict_fn

The conflict resolution function to be applied.  This function must be
specified as one of those shown in the following list:

   * *note mysql-cluster-replication-ndb-old::

   * *note mysql-cluster-replication-ndb-max::

   * *note mysql-cluster-replication-ndb-max-delete-win::

   * *note mysql-cluster-replication-ndb-epoch:: (NDB 7.2.1 and later)

   * *note mysql-cluster-replication-ndb-epoch-trans:: (NDB 7.2.1 and
     later)

   * 'NULL': Indicates that conflict resolution is not to be used for
     the corresponding table.

These functions are described in the next few paragraphs.

NDB$OLD(column_name)

If the value of COLUMN_NAME is the same on both the master and the
slave, then the update is applied; otherwise, the update is not applied
on the slave and an exception is written to the log.  This is
illustrated by the following pseudocode:

     if (MASTER_OLD_COLUMN_VALUE == SLAVE_CURRENT_COLUMN_VALUE)
       apply_update();
     else
       log_exception();

This function can be used for 'same value wins' conflict resolution.
This type of conflict resolution ensures that updates are not applied on
the slave from the wrong master.

*Important*:

The column value from the master's 'before' image is used by this
function.

NDB$MAX(column_name)

If the 'timestamp' column value for a given row coming from the master
is higher than that on the slave, it is applied; otherwise it is not
applied on the slave.  This is illustrated by the following pseudocode:

     if (MASTER_NEW_COLUMN_VALUE > SLAVE_CURRENT_COLUMN_VALUE)
       apply_update();

This function can be used for 'greatest timestamp wins' conflict
resolution.  This type of conflict resolution ensures that, in the event
of a conflict, the version of the row that was most recently updated is
the version that persists.

*Important*:

The column value from the master's 'after' image is used by this
function.

NDB$MAX_DELETE_WIN()

This is a variation on 'NDB$MAX()'.  Due to the fact that no timestamp
is available for a delete operation, a delete using 'NDB$MAX()' is in
fact processed as 'NDB$OLD'.  However, for some use cases, this is not
optimal.  For 'NDB$MAX_DELETE_WIN()', if the 'timestamp' column value
for a given row adding or updating an existing row coming from the
master is higher than that on the slave, it is applied.  However, delete
operations are treated as always having the higher value.  This is
illustrated in the following pseudocode:

     if ( (MASTER_NEW_COLUMN_VALUE > SLAVE_CURRENT_COLUMN_VALUE)
             ||
           OPERATION.TYPE == "delete")
       apply_update();

This function can be used for 'greatest timestamp, delete wins' conflict
resolution.  This type of conflict resolution ensures that, in the event
of a conflict, the version of the row that was deleted or (otherwise)
most recently updated is the version that persists.

*Note*:

As with 'NDB$MAX()', the column value from the master's 'after' image is
the value used by this function.

NDB$EPOCH() and NDB$EPOCH_TRANS()

The 'NDB$EPOCH()' function, available beginning with NDB 7.2.1, tracks
the order in which replicated epochs are applied on a slave NDB Cluster
relative to changes originating on the slave.  This relative ordering is
used to determine whether changes originating on the slave are
concurrent with any changes that originate locally, and are therefore
potentially in conflict.

Most of what follows in the description of 'NDB$EPOCH()' also applies to
'NDB$EPOCH_TRANS()'.  Any exceptions are noted in the text.

'NDB$EPOCH()' is asymmetric, operating on one NDB Cluster in a
two-cluster circular replication configuration (sometimes referred to as
'active-active' replication).  We refer here to cluster on which it
operates as the primary, and the other as the secondary.  The slave on
the primary is responsible for detecting and handling conflicts, while
the slave on the secondary is not involved in any conflict detection or
handling.

When the slave on the primary detects conflicts, it injects events into
its own binary log to compensate for these; this ensures that the
secondary NDB Cluster eventually realigns itself with the primary and so
keeps the primary and secondary from diverging.  This compensation and
realignment mechanism requires that the primary NDB Cluster always wins
any conflicts with the secondary--that is, that the primary's changes
are always used rather than those from the secondary in event of a
conflict.  This 'primary always wins' rule has the following
implications:

   * Operations that change data, once committed on the primary, are
     fully persistent and will not be undone or rolled back by conflict
     detection and resolution.

   * Data read from the primary is fully consistent.  Any changes
     committed on the Primary (locally or from the slave) will not be
     reverted later.

   * Operations that change data on the secondary may later be reverted
     if the primary determines that they are in conflict.

   * Individual rows read on the secondary are self-consistent at all
     times, each row always reflecting either a state committed by the
     secondary, or one committed by the primary.

   * Sets of rows read on the secondary may not necessarily be
     consistent at a given single point in time.  For
     'NDB$EPOCH_TRANS()', this is a transient state; for 'NDB$EPOCH()',
     it can be a persistent state.

   * Assuming a period of sufficient length without any conflicts, all
     data on the secondary NDB Cluster (eventually) becomes consistent
     with the primary's data.

'NDB$EPOCH()' and 'NDB$EPOCH_TRANS()' do not require any user schema
modifications, or application changes to provide conflict detection.
However, careful thought must be given to the schema used, and the
access patterns used, to verify that the complete system behaves within
specified limits.

Each of the 'NDB$EPOCH()' and 'NDB$EPOCH_TRANS()' functions can take an
optional parameter; this is the number of bits to use to represent the
lower 32 bits of the epoch, and should be set to no less than

     CEIL( LOG2( TimeBetweenGlobalCheckpoints / TimeBetweenEpochs ), 1)

For the default values of these configuration parameters (2000 and 100
milliseconds, respectively), this gives a value of 5 bits, so the
default value (6) should be sufficient, unless other values are used for
'TimeBetweenGlobalCheckpoints', 'TimeBetweenEpochs', or both.  A value
that is too small can result in false positives, while one that is too
large could lead to excessive wasted space in the database.

Both 'NDB$EPOCH()' and 'NDB$EPOCH_TRANS()' insert entries for
conflicting rows into the relevant exceptions tables, provided that
these tables have been defined according to the same exceptions table
schema rules as described elsewhere in this section (see *note
mysql-cluster-replication-ndb-old::).  You need to create any exceptions
table before creating the table with which it is to be used.

As with the other conflict detection functions discussed in this
section, 'NDB$EPOCH()' and 'NDB$EPOCH_TRANS()' are activated by
including relevant entries in the 'mysql.ndb_replication' table (see
*note mysql-cluster-ndb-replication-table::).  The roles of the primary
and secondary NDB Clusters in this scenario are fully determined by
'mysql.ndb_replication' table entries.

Because the conflict detection algorithms employed by 'NDB$EPOCH()' and
'NDB$EPOCH_TRANS()' are asymmetric, you must use different values for
the primary slave's and secondary slave's 'server_id' entries.

Prior to NDB 7.2.17, conflict between 'DELETE' operations were handled
like those for 'UPDATE' operations, and within the same epoch were
considered in conflict.  In NDB 7.2.17 and later, a conflict between
'DELETE' operations alone is not sufficient to trigger a conflict using
'NDB$EPOCH()' or 'NDB$EPOCH_TRANS()', and the relative placement within
epochs does not matter.  (Bug #18459944)

Conflict detection status variables

NDB 7.2.1 introduces several status variables that can be used to
monitor 'NDB$EPOCH()' and 'NDB$EPOCH_TRANS()' conflict detection.  You
can see how many rows have been found in conflict by 'NDB$EPOCH()' since
this slave was last restarted from the current value of the
'Ndb_conflict_fn_epoch' system status variable.

'Ndb_conflict_fn_epoch_trans' provides the number of rows that have been
found directly in conflict by 'NDB$EPOCH_TRANS()'; the number of rows
actually realigned, including those affected due to their membership in
or dependency on the same transactions as other conflicting rows, is
given by 'Ndb_conflict_trans_row_reject_count'.

For more information, see *note mysql-cluster-status-variables::.

Limitations on NDB$EPOCH()

The following limitations currently apply when using 'NDB$EPOCH()' to
perform conflict detection:

   * Conflicts are detected using NDB Cluster epoch boundaries, with
     granularity proportional to 'TimeBetweenEpochs' (default: 100
     milliseconds).  The minimum conflict window is the minimum time
     during which concurrent updates to the same data on both clusters
     always report a conflict.  This is always a nonzero length of time,
     and is roughly proportional to '2 * (latency + queueing +
     TimeBetweenEpochs)'.  This implies that--assuming the default for
     'TimeBetweenEpochs' and ignoring any latency between clusters (as
     well as any queuing delays)--the minimum conflict window size is
     approximately 200 milliseconds.  This minimum window should be
     considered when looking at expected application 'race' patterns.

   * Additional storage is required for tables using the 'NDB$EPOCH()'
     and 'NDB$EPOCH_TRANS()' functions; from 1 to 32 bits extra space
     per row is required, depending on the value passed to the function.

   * Conflicts between delete operations may result in divergence
     between the primary and secondary.  When a row is deleted on both
     clusters concurrently, the conflict can be detected, but is not
     recorded, since the row is deleted.  This means that further
     conflicts during the propagation of any subsequent realignment
     operations will not be detected, which can lead to divergence.

     Deletes should be externally serialized, or routed to one cluster
     only.  Alternatively, a separate row should be updated
     transactionally with such deletes and any inserts that follow them,
     so that conflicts can be tracked across row deletes.  This may
     require changes in applications.

   * Only two NDB Clusters in a circular 'active-active' configuration
     are currently supported when using 'NDB$EPOCH()' or
     'NDB$EPOCH_TRANS()' for conflict detection.

   * Tables having *note 'BLOB': blob. or *note 'TEXT': blob. columns
     are not currently supported with 'NDB$EPOCH()' or
     'NDB$EPOCH_TRANS()'.

NDB$EPOCH_TRANS()

'NDB$EPOCH_TRANS()' extends the 'NDB$EPOCH()' function, and, like
'NDB$EPOCH()', is available beginning with NDB 7.2.1.  Conflicts are
detected and handled in the same way using the 'primary wins all' rule
(see *note mysql-cluster-replication-ndb-epoch::) but with the extra
condition that any other rows updated in the same transaction in which
the conflict occurred are also regarded as being in conflict.  In other
words, where 'NDB$EPOCH()' realigns individual conflicting rows on the
secondary, 'NDB$EPOCH_TRANS()' realigns conflicting transactions.

In addition, any transactions which are detectably dependent on a
conflicting transaction are also regarded as being in conflict, these
dependencies being determined by the contents of the secondary cluster's
binary log.  Since the binary log contains only data modification
operations (inserts, updates, and deletes), only overlapping data
modifications are used to determine dependencies between transactions.

'NDB$EPOCH_TRANS()' is subject to the same conditions and limitations as
'NDB$EPOCH()', and in addition requires that Version 2 binary log row
events are used ('log_bin_use_v1_row_events' equal to 0), which adds a
storage overhead of 2 bytes per event in the binary log.  In addition,
all transaction IDs must be recorded in the secondary's binary log
('--ndb-log-transaction-id' option), which adds a further variable
overhead (up to 13 bytes per row).

See *note mysql-cluster-replication-ndb-epoch::.

Status information

A server status variable 'Ndb_conflict_fn_max' provides a count of the
number of times that a row was not applied on the current SQL node due
to 'greatest timestamp wins' conflict resolution since the last time
that *note 'mysqld': mysqld. was started.

The number of times that a row was not applied as the result of 'same
timestamp wins' conflict resolution on a given *note 'mysqld': mysqld.
since the last time it was restarted is given by the global status
variable 'Ndb_conflict_fn_old'.  In addition to incrementing
'Ndb_conflict_fn_old', the primary key of the row that was not used is
inserted into an _exceptions table_, as explained later in this section.

Conflict resolution exceptions table

To use the 'NDB$OLD()' conflict resolution function, it is also
necessary to create an exceptions table corresponding to each *note
'NDB': mysql-cluster. table for which this type of conflict resolution
is to be employed.  This is also true when using 'NDB$EPOCH()' or
'NDB$EPOCH_TRANS()' in NDB 7.2.1 and later.  The name of this table is
that of the table for which conflict resolution is to be applied, with
the string '$EX' appended.  (For example, if the name of the original
table is 'mytable', the name of the corresponding exceptions table name
should be 'mytable$EX'.)  This table is created as follows:

     CREATE TABLE ORIGINAL_TABLE$EX  (
         server_id INT UNSIGNED,
         master_server_id INT UNSIGNED,
         master_epoch BIGINT UNSIGNED,
         count INT UNSIGNED,

         ORIGINAL_TABLE_PK_COLUMNS,

         [ADDITIONAL_COLUMNS,]

         PRIMARY KEY(server_id, master_server_id, master_epoch, count)
     ) ENGINE=NDB;

The first four columns are required.  The names of the first four
columns and the columns matching the original table's primary key
columns are not critical; however, we suggest for reasons of clarity and
consistency, that you use the names shown here for the 'server_id',
'master_server_id', 'master_epoch', and 'count' columns, and that you
use the same names as in the original table for the columns matching
those in the original table's primary key.

Following these columns, the columns making up the original table's
primary key should be copied in the order in which they are used to
define the primary key of the original table.  The data types for the
columns duplicating the primary key columns of the original table should
be the same as (or larger than) those of the original columns.

Additional columns may optionally be defined following the copied
primary key columns, but not before any of them; any such extra columns
cannot be 'NOT NULL'.  The exceptions table's primary key must be
defined as shown.

The exceptions table must use the *note 'NDB': mysql-cluster. storage
engine.  An example that uses 'NDB$OLD()' with an exceptions table is
shown later in this section.

*Important*:

The 'mysql.ndb_replication' table is read when a data table is set up
for replication, so the row corresponding to a table to be replicated
must be inserted into 'mysql.ndb_replication' _before_ the table to be
replicated is created.

*Examples*

The following examples assume that you have already a working NDB
Cluster replication setup, as described in *note
mysql-cluster-replication-preparation::, and *note
mysql-cluster-replication-starting::.

NDB$MAX() example

Suppose you wish to enable 'greatest timestamp wins' conflict resolution
on table 'test.t1', using column 'mycol' as the 'timestamp'.  This can
be done using the following steps:

  1. Make sure that you have started the master *note 'mysqld': mysqld.
     with '--ndb-log-update-as-write=OFF'.

  2. On the master, perform this *note 'INSERT': insert. statement:

          INSERT INTO mysql.ndb_replication
              VALUES ('test', 't1', 0, NULL, 'NDB$MAX(mycol)');

     Inserting a 0 into the 'server_id' indicates that all SQL nodes
     accessing this table should use conflict resolution.  If you want
     to use conflict resolution on a specific *note 'mysqld': mysqld.
     only, use the actual server ID.

     Inserting 'NULL' into the 'binlog_type' column has the same effect
     as inserting 0 ('NBT_DEFAULT'); the server default is used.

  3. Create the 'test.t1' table:

          CREATE TABLE test.t1 (
              COLUMNS
              mycol INT UNSIGNED,
              COLUMNS
          ) ENGINE=NDB;

     Now, when updates are done on this table, conflict resolution is
     applied, and the version of the row having the greatest value for
     'mycol' is written to the slave.

*Note*:

Other 'binlog_type' options--such as 'NBT_UPDATED_ONLY_USE_UPDATE'
should be used to control logging on the master using the
'ndb_replication' table rather than by using command-line options.

NDB$OLD() example

Suppose an *note 'NDB': mysql-cluster. table such as the one defined
here is being replicated, and you wish to enable 'same timestamp wins'
conflict resolution for updates to this table:

     CREATE TABLE test.t2  (
         a INT UNSIGNED NOT NULL,
         b CHAR(25) NOT NULL,
         COLUMNS,
         mycol INT UNSIGNED NOT NULL,
         COLUMNS,
         PRIMARY KEY pk (a, b)
     )   ENGINE=NDB;

The following steps are required, in the order shown:

  1. First--and _prior_ to creating 'test.t2'--you must insert a row
     into the 'mysql.ndb_replication' table, as shown here:

          INSERT INTO mysql.ndb_replication
              VALUES ('test', 't2', 0, NULL, 'NDB$OLD(mycol)');

     Possible values for the 'binlog_type' column are shown earlier in
     this section.  The value ''NDB$OLD(mycol)'' should be inserted into
     the 'conflict_fn' column.

  2. Create an appropriate exceptions table for 'test.t2'.  The table
     creation statement shown here includes all required columns; any
     additional columns must be declared following these columns, and
     before the definition of the table's primary key.

          CREATE TABLE test.t2$EX  (
              server_id INT UNSIGNED,
              master_server_id INT UNSIGNED,
              master_epoch BIGINT UNSIGNED,
              count INT UNSIGNED,
              a INT UNSIGNED NOT NULL,
              b CHAR(25) NOT NULL,

              [ADDITIONAL_COLUMNS,]

              PRIMARY KEY(server_id, master_server_id, master_epoch, count)
          )   ENGINE=NDB;

  3. Create the table 'test.t2' as shown previously.

These steps must be followed for every table for which you wish to
perform conflict resolution using 'NDB$OLD()'.  For each such table,
there must be a corresponding row in 'mysql.ndb_replication', and there
must be an exceptions table in the same database as the table being
replicated.


File: manual.info.tmp,  Node: mysql-cluster-news,  Prev: mysql-cluster-replication,  Up: mysql-cluster

18.7 NDB Cluster Release Notes
==============================

NDB Cluster release notes are no longer published in the MySQL Reference
Manual.

Release notes for the changes in each release of NDB Cluster are located
at NDB Cluster 7.2 Release Notes
(https://dev.mysql.com/doc/relnotes/mysql-cluster/7.2/en/).


File: manual.info.tmp,  Node: partitioning,  Next: stored-objects,  Prev: mysql-cluster,  Up: Top

19 Partitioning
***************

* Menu:

* partitioning-overview::        Overview of Partitioning in MySQL
* partitioning-types::           Partitioning Types
* partitioning-management::      Partition Management
* partitioning-pruning::         Partition Pruning
* partitioning-limitations::     Restrictions and Limitations on Partitioning

This chapter discusses MySQL's implementation of _user-defined
partitioning_.  You can determine whether your MySQL Server supports
partitioning by means of a *note 'SHOW VARIABLES': show-variables.
statement such as this one:

     mysql> SHOW VARIABLES LIKE '%partition%';

     +-------------------+-------+
     | Variable_name     | Value |
     +-------------------+-------+
     | have_partitioning | YES   |
     +-------------------+-------+
     1 row in set (0.00 sec)

*Note*:

The 'have_partitioning' variable is deprecated, and removed in MySQL
5.6.1.

You can also check the output of the *note 'SHOW PLUGINS': show-plugins.
statement, like this:

     mysql> SHOW PLUGINS;
     +------------+----------+----------------+---------+---------+
     | Name       | Status   | Type           | Library | License |
     +------------+----------+----------------+---------+---------+
     | binlog     | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     *| partition  | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |*
     | ARCHIVE    | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     | BLACKHOLE  | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     | CSV        | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     | FEDERATED  | DISABLED | STORAGE ENGINE | NULL    | GPL     |
     | MEMORY     | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     | InnoDB     | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     | MRG_MYISAM | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     | MyISAM     | ACTIVE   | STORAGE ENGINE | NULL    | GPL     |
     | ndbcluster | DISABLED | STORAGE ENGINE | NULL    | GPL     |
     +------------+----------+----------------+---------+---------+
     11 rows in set (0.00 sec)

You can also check the *note 'INFORMATION_SCHEMA.PLUGINS':
plugins-table. table with a query similar to this one:

     mysql> SELECT
         ->     PLUGIN_NAME as Name,
         ->     PLUGIN_VERSION as Version,
         ->     PLUGIN_STATUS as Status
         -> FROM INFORMATION_SCHEMA.PLUGINS
         -> WHERE PLUGIN_TYPE='STORAGE ENGINE';
     +--------------------+---------+--------+
     | Name               | Version | Status |
     +--------------------+---------+--------+
     | binlog             | 1.0     | ACTIVE |
     | CSV                | 1.0     | ACTIVE |
     | MEMORY             | 1.0     | ACTIVE |
     | MRG_MYISAM         | 1.0     | ACTIVE |
     | MyISAM             | 1.0     | ACTIVE |
     | PERFORMANCE_SCHEMA | 0.1     | ACTIVE |
     | BLACKHOLE          | 1.0     | ACTIVE |
     | ARCHIVE            | 3.0     | ACTIVE |
     | InnoDB             | 5.6     | ACTIVE |
     *| partition          | 1.0     | ACTIVE |*
     +--------------------+---------+--------+
     10 rows in set (0.00 sec)

In either case, if you do not see the 'partition' plugin listed with the
value 'ACTIVE' for the 'Status' column in the output (shown in bold text
in each of the examples just given), then your version of MySQL was not
built with partitioning support.

MySQL 5.5 Community binaries provided by Oracle include partitioning
support.  For information about partitioning support offered in MySQL
Enterprise Edition binaries, see *note mysql-enterprise::.

To enable partitioning if you are compiling MySQL 5.5 from source, the
build must be configured with the '-DWITH_PARTITION_STORAGE_ENGINE'
option.  For more information, see *note source-installation::.

If your MySQL binary is built with partitioning support, nothing further
needs to be done to enable it (for example, no special entries are
required in your 'my.cnf' file).

If you want to disable partitioning support, you can start the MySQL
Server with the '--skip-partition' option, in which case the value of
'have_partitioning' is 'DISABLED'.  When partitioning support is
disabled, you can see any existing partitioned tables and drop them
(although doing this is not advised), but you cannot otherwise
manipulate them or access their data.

See *note partitioning-overview::, for an introduction to partitioning
and partitioning concepts.

MySQL supports several types of partitioning as well as subpartitioning;
see *note partitioning-types::, and *note partitioning-subpartitions::.

*note partitioning-management::, covers methods of adding, removing, and
altering partitions in existing partitioned tables.

*note partitioning-maintenance::, discusses table maintenance commands
for use with partitioned tables.

The *note 'PARTITIONS': partitions-table. table in the
'INFORMATION_SCHEMA' database provides information about partitions and
partitioned tables.  See *note partitions-table::, for more information;
for some examples of queries against this table, see *note
partitioning-handling-nulls::.

For known issues with partitioning in MySQL 5.5, see *note
partitioning-limitations::.

You may also find the following resources to be useful when working with
partitioned tables.

Additional Resources

Other sources of information about user-defined partitioning in MySQL
include the following:

   * MySQL Partitioning Forum (https://forums.mysql.com/list.php?106)

     This is the official discussion forum for those interested in or
     experimenting with MySQL Partitioning technology.  It features
     announcements and updates from MySQL developers and others.  It is
     monitored by members of the Partitioning Development and
     Documentation Teams.

   * Mikael Ronstro"m's Blog (http://mikaelronstrom.blogspot.com/)

     MySQL Partitioning Architect and Lead Developer Mikael Ronstro"m
     frequently posts articles here concerning his work with MySQL
     Partitioning and NDB Cluster.

   * PlanetMySQL (http://www.planetmysql.org/)

     A MySQL news site featuring MySQL-related blogs, which should be of
     interest to anyone using my MySQL. We encourage you to check here
     for links to blogs kept by those working with MySQL Partitioning,
     or to have your own blog added to those covered.

MySQL 5.5 binaries are available from
<https://dev.mysql.com/downloads/mysql/5.5.html>.  However, for the
latest partitioning bugfixes and feature additions, you can obtain the
source from our GitHub repository.  To enable partitioning, the build
must be configured with the '-DWITH_PARTITION_STORAGE_ENGINE' option.
For more information about building MySQL, see *note
source-installation::.  If you have problems compiling a
partitioning-enabled MySQL 5.5 build, check the MySQL Partitioning Forum
(https://forums.mysql.com/list.php?106) and ask for assistance there if
you do not find a solution to your problem already posted.


File: manual.info.tmp,  Node: partitioning-overview,  Next: partitioning-types,  Prev: partitioning,  Up: partitioning

19.1 Overview of Partitioning in MySQL
======================================

This section provides a conceptual overview of partitioning in MySQL
5.5.

For information on partitioning restrictions and feature limitations,
see *note partitioning-limitations::.

The SQL standard does not provide much in the way of guidance regarding
the physical aspects of data storage.  The SQL language itself is
intended to work independently of any data structures or media
underlying the schemas, tables, rows, or columns with which it works.
Nonetheless, most advanced database management systems have evolved some
means of determining the physical location to be used for storing
specific pieces of data in terms of the file system, hardware or even
both.  In MySQL, the 'InnoDB' storage engine has long supported the
notion of a tablespace, and the MySQL Server, even prior to the
introduction of partitioning, could be configured to employ different
physical directories for storing different databases (see *note
symbolic-links::, for an explanation of how this is done).

_Partitioning_ takes this notion a step further, by enabling you to
distribute portions of individual tables across a file system according
to rules which you can set largely as needed.  In effect, different
portions of a table are stored as separate tables in different
locations.  The user-selected rule by which the division of data is
accomplished is known as a _partitioning function_, which in MySQL can
be the modulus, simple matching against a set of ranges or value lists,
an internal hashing function, or a linear hashing function.  The
function is selected according to the partitioning type specified by the
user, and takes as its parameter the value of a user-supplied
expression.  This expression can be a column value, a function acting on
one or more column values, or a set of one or more column values,
depending on the type of partitioning that is used.

In the case of 'RANGE', 'LIST', and ['LINEAR'] 'HASH' partitioning, the
value of the partitioning column is passed to the partitioning function,
which returns an integer value representing the number of the partition
in which that particular record should be stored.  This function must be
nonconstant and nonrandom.  It may not contain any queries, but may use
an SQL expression that is valid in MySQL, as long as that expression
returns either 'NULL' or an integer INTVAL such that

     -MAXVALUE <= INTVAL <= MAXVALUE

('MAXVALUE' is used to represent the least upper bound for the type of
integer in question.  '-MAXVALUE' represents the greatest lower bound.)

For ['LINEAR'] 'KEY', 'RANGE COLUMNS', and 'LIST COLUMNS' partitioning,
the partitioning expression consists of a list of one or more columns.

For ['LINEAR'] 'KEY' partitioning, the partitioning function is supplied
by MySQL.

For more information about permitted partitioning column types and
partitioning functions, see *note partitioning-types::, as well as *note
create-table::, which provides partitioning syntax descriptions and
additional examples.  For information about restrictions on partitioning
functions, see *note partitioning-limitations-functions::.

This is known as _horizontal partitioning_--that is, different rows of a
table may be assigned to different physical partitions.  MySQL 5.5 does
not support _vertical partitioning_, in which different columns of a
table are assigned to different physical partitions.  There are no plans
at this time to introduce vertical partitioning into MySQL.

For information about determining whether your MySQL Server binary
supports user-defined partitioning, see *note partitioning::.

For creating partitioned tables, you can use most storage engines that
are supported by your MySQL server; the MySQL partitioning engine runs
in a separate layer and can interact with any of these.  In MySQL 5.5,
all partitions of the same partitioned table must use the same storage
engine; for example, you cannot use 'MyISAM' for one partition and
'InnoDB' for another.  However, there is nothing preventing you from
using different storage engines for different partitioned tables on the
same MySQL server or even in the same database.

MySQL partitioning cannot be used with the 'MERGE', 'CSV', or
'FEDERATED' storage engines.

Partitioning by 'KEY' or 'LINEAR KEY' is possible with *note
'NDBCLUSTER': mysql-cluster, but other types of user-defined
partitioning are not supported for tables using this storage engine.  In
addition, an *note 'NDBCLUSTER': mysql-cluster. table that employs
user-defined partitioning must have an explicit primary key, and any
columns referenced in the table's partitioning expression must be part
of the primary key.  However, if no columns are listed in the 'PARTITION
BY KEY' or 'PARTITION BY LINEAR KEY' clause of the *note 'CREATE TABLE':
create-table. or *note 'ALTER TABLE': alter-table-partition-operations.
statement used to create or modify a user-partitioned *note
'NDBCLUSTER': mysql-cluster. table, then the table is not required to
have an explicit primary key.  For more information, see *note
mysql-cluster-limitations-syntax::.

To employ a particular storage engine for a partitioned table, it is
necessary only to use the '[STORAGE] ENGINE' option just as you would
for a nonpartitioned table.  However, you should keep in mind that
'[STORAGE] ENGINE' (and other table options) need to be listed _before_
any partitioning options are used in a *note 'CREATE TABLE':
create-table. statement.  This example shows how to create a table that
is partitioned by hash into 6 partitions and which uses the 'InnoDB'
storage engine:

     CREATE TABLE ti (id INT, amount DECIMAL(7,2), tr_date DATE)
         ENGINE=INNODB
         PARTITION BY HASH( MONTH(tr_date) )
         PARTITIONS 6;

Each 'PARTITION' clause can include a '[STORAGE] ENGINE' option, but in
MySQL 5.5 this has no effect.

*Important*:

Partitioning applies to all data and indexes of a table; you cannot
partition only the data and not the indexes, or vice versa, nor can you
partition only a portion of the table.

Data and indexes for each partition can be assigned to a specific
directory using the 'DATA DIRECTORY' and 'INDEX DIRECTORY' options for
the 'PARTITION' clause of the *note 'CREATE TABLE': create-table.
statement used to create the partitioned table.

The 'DATA DIRECTORY' and 'INDEX DIRECTORY' options have no effect when
defining partitions for tables using the 'InnoDB' storage engine.

'DATA DIRECTORY' and 'INDEX DIRECTORY' are not supported for individual
partitions or subpartitions on Windows.  These options are ignored on
Windows, except that a warning is generated.

All columns used in the table's partitioning expression must be part of
every unique key that the table may have, including any primary key.
This means that a table such as this one, created by the following SQL
statement, cannot be partitioned:

     CREATE TABLE tnp (
         id INT NOT NULL AUTO_INCREMENT,
         ref BIGINT NOT NULL,
         name VARCHAR(255),
         PRIMARY KEY pk (id),
         UNIQUE KEY uk (name)
     );

Because the keys 'pk' and 'uk' have no columns in common, there are no
columns available for use in a partitioning expression.  Possible
workarounds in this situation include adding the 'name' column to the
table's primary key, adding the 'id' column to 'uk', or simply removing
the unique key altogether.  See *note
partitioning-limitations-partitioning-keys-unique-keys::, for more
information.

In addition, 'MAX_ROWS' and 'MIN_ROWS' can be used to determine the
maximum and minimum numbers of rows, respectively, that can be stored in
each partition.  The 'MAX_ROWS' option can be useful for causing NDB
Cluster tables to be created with extra partitions, thus allowing for
greater storage of hash indexes.  See the documentation for the
'DataMemory' data node configuration parameter, as well as *note
mysql-cluster-nodes-groups::, for more information.

Some advantages of partitioning are listed here:

   * Partitioning makes it possible to store more data in one table than
     can be held on a single disk or file system partition.

   * Data that loses its usefulness can often be easily removed from a
     partitioned table by dropping the partition (or partitions)
     containing only that data.  Conversely, the process of adding new
     data can in some cases be greatly facilitated by adding one or more
     new partitions for storing specifically that data.

   * Some queries can be greatly optimized in virtue of the fact that
     data satisfying a given 'WHERE' clause can be stored only on one or
     more partitions, which automatically excludes any remaining
     partitions from the search.  Because partitions can be altered
     after a partitioned table has been created, you can reorganize your
     data to enhance frequent queries that may not have been often used
     when the partitioning scheme was first set up.  This ability to
     exclude non-matching partitions (and thus any rows they contain) is
     often referred to as _partition pruning_.  For more information,
     see *note partitioning-pruning::.


File: manual.info.tmp,  Node: partitioning-types,  Next: partitioning-management,  Prev: partitioning-overview,  Up: partitioning

19.2 Partitioning Types
=======================

* Menu:

* partitioning-range::           RANGE Partitioning
* partitioning-list::            LIST Partitioning
* partitioning-columns::         COLUMNS Partitioning
* partitioning-hash::            HASH Partitioning
* partitioning-key::             KEY Partitioning
* partitioning-subpartitions::   Subpartitioning
* partitioning-handling-nulls::  How MySQL Partitioning Handles NULL

This section discusses the types of partitioning which are available in
MySQL 5.5.  These include the types listed here:

   * RANGE partitioning

     This type of partitioning assigns rows to partitions based on
     column values falling within a given range.  See *note
     partitioning-range::.  MySQL 5.5 adds an extension, 'RANGE
     COLUMNS', to this type.  See *note partitioning-columns-range::.

   * LIST partitioning

     Similar to partitioning by 'RANGE', except that the partition is
     selected based on columns matching one of a set of discrete values.
     See *note partitioning-list::.  MySQL 5.5 adds an extension, 'LIST
     COLUMNS', to this type.  See *note partitioning-columns-list::.

   * HASH partitioning

     With this type of partitioning, a partition is selected based on
     the value returned by a user-defined expression that operates on
     column values in rows to be inserted into the table.  The function
     may consist of any expression valid in MySQL that yields a
     nonnegative integer value.  An extension to this type, 'LINEAR
     HASH', is also available.  See *note partitioning-hash::.

   * KEY partitioning

     This type of partitioning is similar to partitioning by 'HASH',
     except that only one or more columns to be evaluated are supplied,
     and the MySQL server provides its own hashing function.  These
     columns can contain other than integer values, since the hashing
     function supplied by MySQL guarantees an integer result regardless
     of the column data type.  An extension to this type, 'LINEAR KEY',
     is also available.  See *note partitioning-key::.

A very common use of database partitioning is to segregate data by date.
Some database systems support explicit date partitioning, which MySQL
does not implement in 5.5.  However, it is not difficult in MySQL to
create partitioning schemes based on *note 'DATE': datetime, *note
'TIME': time, or *note 'DATETIME': datetime. columns, or based on
expressions making use of such columns.

When partitioning by 'KEY' or 'LINEAR KEY', you can use a *note 'DATE':
datetime, *note 'TIME': time, or *note 'DATETIME': datetime. column as
the partitioning column without performing any modification of the
column value.  For example, this table creation statement is perfectly
valid in MySQL:

     CREATE TABLE members (
         firstname VARCHAR(25) NOT NULL,
         lastname VARCHAR(25) NOT NULL,
         username VARCHAR(16) NOT NULL,
         email VARCHAR(35),
         joined DATE NOT NULL
     )
     PARTITION BY KEY(joined)
     PARTITIONS 6;

In MySQL 5.5, it is also possible to use a *note 'DATE': datetime. or
*note 'DATETIME': datetime. column as the partitioning column using
'RANGE COLUMNS' and 'LIST COLUMNS' partitioning.

MySQL's other partitioning types, however, require a partitioning
expression that yields an integer value or 'NULL'.  If you wish to use
date-based partitioning by 'RANGE', 'LIST', 'HASH', or 'LINEAR HASH',
you can simply employ a function that operates on a *note 'DATE':
datetime, *note 'TIME': time, or *note 'DATETIME': datetime. column and
returns such a value, as shown here:

     CREATE TABLE members (
         firstname VARCHAR(25) NOT NULL,
         lastname VARCHAR(25) NOT NULL,
         username VARCHAR(16) NOT NULL,
         email VARCHAR(35),
         joined DATE NOT NULL
     )
     PARTITION BY RANGE( YEAR(joined) ) (
         PARTITION p0 VALUES LESS THAN (1960),
         PARTITION p1 VALUES LESS THAN (1970),
         PARTITION p2 VALUES LESS THAN (1980),
         PARTITION p3 VALUES LESS THAN (1990),
         PARTITION p4 VALUES LESS THAN MAXVALUE
     );

Additional examples of partitioning using dates may be found in the
following sections of this chapter:

   * *note partitioning-range::

   * *note partitioning-hash::

   * *note partitioning-linear-hash::

For more complex examples of date-based partitioning, see the following
sections:

   * *note partitioning-pruning::

   * *note partitioning-subpartitions::

MySQL partitioning is optimized for use with the 'TO_DAYS()', 'YEAR()',
and 'TO_SECONDS()' functions.  However, you can use other date and time
functions that return an integer or 'NULL', such as 'WEEKDAY()',
'DAYOFYEAR()', or 'MONTH()'.  See *note date-and-time-functions::, for
more information about such functions.

It is important to remember--regardless of the type of partitioning that
you use--that partitions are always numbered automatically and in
sequence when created, starting with '0'.  When a new row is inserted
into a partitioned table, it is these partition numbers that are used in
identifying the correct partition.  For example, if your table uses 4
partitions, these partitions are numbered '0', '1', '2', and '3'.  For
the 'RANGE' and 'LIST' partitioning types, it is necessary to ensure
that there is a partition defined for each partition number.  For 'HASH'
partitioning, the user-supplied expression must evaluate to an integer
value greater than '0'.  For 'KEY' partitioning, this issue is taken
care of automatically by the hashing function which the MySQL server
employs internally.

Names of partitions generally follow the rules governing other MySQL
identifiers, such as those for tables and databases.  However, you
should note that partition names are not case-sensitive.  For example,
the following *note 'CREATE TABLE': create-table. statement fails as
shown:

     mysql> CREATE TABLE t2 (val INT)
         -> PARTITION BY LIST(val)(
         ->     PARTITION mypart VALUES IN (1,3,5),
         ->     PARTITION MyPart VALUES IN (2,4,6)
         -> );
     ERROR 1488 (HY000): Duplicate partition name mypart

Failure occurs because MySQL sees no difference between the partition
names 'mypart' and 'MyPart'.

When you specify the number of partitions for the table, this must be
expressed as a positive, nonzero integer literal with no leading zeros,
and may not be an expression such as '0.8E+01' or '6-2', even if it
evaluates to an integer value.  Decimal fractions are not permitted.

In the sections that follow, we do not necessarily provide all possible
forms for the syntax that can be used for creating each partition type;
this information may be found in *note create-table::.


File: manual.info.tmp,  Node: partitioning-range,  Next: partitioning-list,  Prev: partitioning-types,  Up: partitioning-types

19.2.1 RANGE Partitioning
-------------------------

A table that is partitioned by range is partitioned in such a way that
each partition contains rows for which the partitioning expression value
lies within a given range.  Ranges should be contiguous but not
overlapping, and are defined using the 'VALUES LESS THAN' operator.  For
the next few examples, suppose that you are creating a table such as the
following to hold personnel records for a chain of 20 video stores,
numbered 1 through 20:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT NOT NULL,
         store_id INT NOT NULL
     );

*Note*:

The 'employees' table used here has no primary or unique keys.  While
the examples work as shown for purposes of the present discussion, you
should keep in mind that tables are extremely likely in practice to have
primary keys, unique keys, or both, and that allowable choices for
partitioning columns depend on the columns used for these keys, if any
are present.  For a discussion of these issues, see *note
partitioning-limitations-partitioning-keys-unique-keys::.

This table can be partitioned by range in a number of ways, depending on
your needs.  One way would be to use the 'store_id' column.  For
instance, you might decide to partition the table 4 ways by adding a
'PARTITION BY RANGE' clause as shown here:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT NOT NULL,
         store_id INT NOT NULL
     )
     PARTITION BY RANGE (store_id) (
         PARTITION p0 VALUES LESS THAN (6),
         PARTITION p1 VALUES LESS THAN (11),
         PARTITION p2 VALUES LESS THAN (16),
         PARTITION p3 VALUES LESS THAN (21)
     );

In this partitioning scheme, all rows corresponding to employees working
at stores 1 through 5 are stored in partition 'p0', to those employed at
stores 6 through 10 are stored in partition 'p1', and so on.  Note that
each partition is defined in order, from lowest to highest.  This is a
requirement of the 'PARTITION BY RANGE' syntax; you can think of it as
being analogous to a series of 'if ... elseif ...' statements in C or
Java in this regard.

It is easy to determine that a new row containing the data '(72,
'Mitchell', 'Wilson', '1998-06-25', NULL, 13)' is inserted into
partition 'p2', but what happens when your chain adds a 21^st store?
Under this scheme, there is no rule that covers a row whose 'store_id'
is greater than 20, so an error results because the server does not know
where to place it.  You can keep this from occurring by using a
'catchall' 'VALUES LESS THAN' clause in the *note 'CREATE TABLE':
create-table. statement that provides for all values greater than the
highest value explicitly named:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT NOT NULL,
         store_id INT NOT NULL
     )
     PARTITION BY RANGE (store_id) (
         PARTITION p0 VALUES LESS THAN (6),
         PARTITION p1 VALUES LESS THAN (11),
         PARTITION p2 VALUES LESS THAN (16),
         _PARTITION p3 VALUES LESS THAN MAXVALUE_
     );

*Note*:

Another way to avoid an error when no matching value is found is to use
the 'IGNORE' keyword as part of the *note 'INSERT': insert. statement.
For an example, see *note partitioning-list::.  Also see *note insert::,
for general information about 'IGNORE'.

'MAXVALUE' represents an integer value that is always greater than the
largest possible integer value (in mathematical language, it serves as a
_least upper bound_).  Now, any rows whose 'store_id' column value is
greater than or equal to 16 (the highest value defined) are stored in
partition 'p3'.  At some point in the future--when the number of stores
has increased to 25, 30, or more--you can use an *note 'ALTER TABLE':
alter-table-partition-operations. statement to add new partitions for
stores 21-25, 26-30, and so on (see *note partitioning-management::, for
details of how to do this).

In much the same fashion, you could partition the table based on
employee job codes--that is, based on ranges of 'job_code' column
values.  For example--assuming that two-digit job codes are used for
regular (in-store) workers, three-digit codes are used for office and
support personnel, and four-digit codes are used for management
positions--you could create the partitioned table using the following
statement:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT NOT NULL,
         store_id INT NOT NULL
     )
     PARTITION BY RANGE (job_code) (
         PARTITION p0 VALUES LESS THAN (100),
         PARTITION p1 VALUES LESS THAN (1000),
         PARTITION p2 VALUES LESS THAN (10000)
     );

In this instance, all rows relating to in-store workers would be stored
in partition 'p0', those relating to office and support staff in 'p1',
and those relating to managers in partition 'p2'.

It is also possible to use an expression in 'VALUES LESS THAN' clauses.
However, MySQL must be able to evaluate the expression's return value as
part of a 'LESS THAN' ('<') comparison.

Rather than splitting up the table data according to store number, you
can use an expression based on one of the two *note 'DATE': datetime.
columns instead.  For example, let us suppose that you wish to partition
based on the year that each employee left the company; that is, the
value of 'YEAR(separated)'.  An example of a *note 'CREATE TABLE':
create-table. statement that implements such a partitioning scheme is
shown here:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT,
         store_id INT
     )
     PARTITION BY RANGE ( YEAR(separated) ) (
         PARTITION p0 VALUES LESS THAN (1991),
         PARTITION p1 VALUES LESS THAN (1996),
         PARTITION p2 VALUES LESS THAN (2001),
         PARTITION p3 VALUES LESS THAN MAXVALUE
     );

In this scheme, for all employees who left before 1991, the rows are
stored in partition 'p0'; for those who left in the years 1991 through
1995, in 'p1'; for those who left in the years 1996 through 2000, in
'p2'; and for any workers who left after the year 2000, in 'p3'.

It is also possible to partition a table by 'RANGE', based on the value
of a *note 'TIMESTAMP': datetime. column, using the 'UNIX_TIMESTAMP()'
function, as shown in this example:

     CREATE TABLE quarterly_report_status (
         report_id INT NOT NULL,
         report_status VARCHAR(20) NOT NULL,
         report_updated TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
     )
     PARTITION BY RANGE ( UNIX_TIMESTAMP(report_updated) ) (
         PARTITION p0 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-01-01 00:00:00') ),
         PARTITION p1 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-04-01 00:00:00') ),
         PARTITION p2 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-07-01 00:00:00') ),
         PARTITION p3 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-10-01 00:00:00') ),
         PARTITION p4 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-01-01 00:00:00') ),
         PARTITION p5 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-04-01 00:00:00') ),
         PARTITION p6 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-07-01 00:00:00') ),
         PARTITION p7 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-10-01 00:00:00') ),
         PARTITION p8 VALUES LESS THAN ( UNIX_TIMESTAMP('2010-01-01 00:00:00') ),
         PARTITION p9 VALUES LESS THAN (MAXVALUE)
     );

Any other expressions involving *note 'TIMESTAMP': datetime. values are
not permitted.  (See Bug #42849.)

Range partitioning is particularly useful when one or more of the
following conditions is true:

   * You want or need to delete 'old' data.  If you are using the
     partitioning scheme shown previously for the 'employees' table, you
     can simply use 'ALTER TABLE employees DROP PARTITION p0;' to delete
     all rows relating to employees who stopped working for the firm
     prior to 1991.  (See *note alter-table::, and *note
     partitioning-management::, for more information.)  For a table with
     a great many rows, this can be much more efficient than running a
     *note 'DELETE': delete. query such as 'DELETE FROM employees WHERE
     YEAR(separated) <= 1990;'.

   * You want to use a column containing date or time values, or
     containing values arising from some other series.

   * You frequently run queries that depend directly on the column used
     for partitioning the table.  For example, when executing a query
     such as *note 'EXPLAIN PARTITIONS SELECT COUNT(*) FROM employees
     WHERE separated BETWEEN '2000-01-01' AND '2000-12-31' GROUP BY
     store_id;': explain, MySQL can quickly determine that only
     partition 'p2' needs to be scanned because the remaining partitions
     cannot contain any records satisfying the 'WHERE' clause.  See
     *note partitioning-pruning::, for more information about how this
     is accomplished.

A variant on this type of partitioning, 'RANGE COLUMNS' partitioning,
was introduced in MySQL 5.5.0.  Partitioning by 'RANGE COLUMNS' makes it
possible to employ multiple columns for defining partitioning ranges
that apply both to placement of rows in partitions and for determining
the inclusion or exclusion of specific partitions when performing
partition pruning.  See *note partitioning-columns-range::, for more
information.

Partitioning schemes based on time intervals

If you wish to implement a partitioning scheme based on ranges or
intervals of time in MySQL 5.5, you have two options:

  1. Partition the table by 'RANGE', and for the partitioning
     expression, employ a function operating on a *note 'DATE':
     datetime, *note 'TIME': time, or *note 'DATETIME': datetime. column
     and returning an integer value, as shown here:

          CREATE TABLE members (
              firstname VARCHAR(25) NOT NULL,
              lastname VARCHAR(25) NOT NULL,
              username VARCHAR(16) NOT NULL,
              email VARCHAR(35),
              joined DATE NOT NULL
          )
          PARTITION BY RANGE( YEAR(joined) ) (
              PARTITION p0 VALUES LESS THAN (1960),
              PARTITION p1 VALUES LESS THAN (1970),
              PARTITION p2 VALUES LESS THAN (1980),
              PARTITION p3 VALUES LESS THAN (1990),
              PARTITION p4 VALUES LESS THAN MAXVALUE
          );

     Beginning with MySQL 5.5.1, it is also possible to partition a
     table by 'RANGE' based on the value of a *note 'TIMESTAMP':
     datetime. column, using the 'UNIX_TIMESTAMP()' function, as shown
     in this example:

          CREATE TABLE quarterly_report_status (
              report_id INT NOT NULL,
              report_status VARCHAR(20) NOT NULL,
              report_updated TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
          )
          PARTITION BY RANGE ( UNIX_TIMESTAMP(report_updated) ) (
              PARTITION p0 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-01-01 00:00:00') ),
              PARTITION p1 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-04-01 00:00:00') ),
              PARTITION p2 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-07-01 00:00:00') ),
              PARTITION p3 VALUES LESS THAN ( UNIX_TIMESTAMP('2008-10-01 00:00:00') ),
              PARTITION p4 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-01-01 00:00:00') ),
              PARTITION p5 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-04-01 00:00:00') ),
              PARTITION p6 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-07-01 00:00:00') ),
              PARTITION p7 VALUES LESS THAN ( UNIX_TIMESTAMP('2009-10-01 00:00:00') ),
              PARTITION p8 VALUES LESS THAN ( UNIX_TIMESTAMP('2010-01-01 00:00:00') ),
              PARTITION p9 VALUES LESS THAN (MAXVALUE)
          );

     Also beginning with MySQL 5.5.1, any other expressions involving
     *note 'TIMESTAMP': datetime. values are not permitted.  (See Bug
     #42849.)

     *Note*:

     It is also possible in MySQL 5.5.1 and later to use
     'UNIX_TIMESTAMP(timestamp_column)' as a partitioning expression for
     tables that are partitioned by 'LIST'.  However, it is usually not
     practical to do so.

  2. Partition the table by 'RANGE COLUMNS', using a *note 'DATE':
     datetime. or *note 'DATETIME': datetime. column as the partitioning
     column.  For example, the 'members' table could be defined using
     the 'joined' column directly, as shown here:

          CREATE TABLE members (
              firstname VARCHAR(25) NOT NULL,
              lastname VARCHAR(25) NOT NULL,
              username VARCHAR(16) NOT NULL,
              email VARCHAR(35),
              joined DATE NOT NULL
          )
          PARTITION BY RANGE COLUMNS(joined) (
              PARTITION p0 VALUES LESS THAN ('1960-01-01'),
              PARTITION p1 VALUES LESS THAN ('1970-01-01'),
              PARTITION p2 VALUES LESS THAN ('1980-01-01'),
              PARTITION p3 VALUES LESS THAN ('1990-01-01'),
              PARTITION p4 VALUES LESS THAN MAXVALUE
          );

*Note*:

The use of partitioning columns employing date or time types other than
*note 'DATE': datetime. or *note 'DATETIME': datetime. is not supported
with 'RANGE COLUMNS'.


File: manual.info.tmp,  Node: partitioning-list,  Next: partitioning-columns,  Prev: partitioning-range,  Up: partitioning-types

19.2.2 LIST Partitioning
------------------------

List partitioning in MySQL is similar to range partitioning in many
ways.  As in partitioning by 'RANGE', each partition must be explicitly
defined.  The chief difference between the two types of partitioning is
that, in list partitioning, each partition is defined and selected based
on the membership of a column value in one of a set of value lists,
rather than in one of a set of contiguous ranges of values.  This is
done by using 'PARTITION BY LIST(EXPR)' where EXPR is a column value or
an expression based on a column value and returning an integer value,
and then defining each partition by means of a 'VALUES IN (VALUE_LIST)',
where VALUE_LIST is a comma-separated list of integers.

*Note*:

In MySQL 5.5, it is possible to match against only a list of integers
(and possibly 'NULL'--see *note partitioning-handling-nulls::) when
partitioning by 'LIST'.

However, beginning with MySQL 5.5.0, other column types may be used in
value lists when employing 'LIST COLUMN' partitioning, which is
described later in this section.

Unlike the case with partitions defined by range, list partitions do not
need to be declared in any particular order.  For more detailed
syntactical information, see *note create-table::.

For the examples that follow, we assume that the basic definition of the
table to be partitioned is provided by the *note 'CREATE TABLE':
create-table. statement shown here:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT,
         store_id INT
     );

(This is the same table used as a basis for the examples in *note
partitioning-range::.)

Suppose that there are 20 video stores distributed among 4 franchises as
shown in the following table.

Region                 Store ID Numbers
                       
North                  3, 5, 6, 9, 17
                       
East                   1, 2, 10, 11, 19, 20
                       
West                   4, 12, 13, 14, 18
                       
Central                7, 8, 15, 16

To partition this table in such a way that rows for stores belonging to
the same region are stored in the same partition, you could use the
*note 'CREATE TABLE': create-table. statement shown here:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT,
         store_id INT
     )
     PARTITION BY LIST(store_id) (
         PARTITION pNorth VALUES IN (3,5,6,9,17),
         PARTITION pEast VALUES IN (1,2,10,11,19,20),
         PARTITION pWest VALUES IN (4,12,13,14,18),
         PARTITION pCentral VALUES IN (7,8,15,16)
     );

This makes it easy to add or drop employee records relating to specific
regions to or from the table.  For instance, suppose that all stores in
the West region are sold to another company.  Beginning with MySQL
5.5.0, all rows relating to employees working at stores in that region
can be deleted with the query 'ALTER TABLE employees TRUNCATE PARTITION
pWest', which can be executed much more efficiently than the equivalent
*note 'DELETE': delete. statement 'DELETE FROM employees WHERE store_id
IN (4,12,13,14,18);'.  (Using 'ALTER TABLE employees DROP PARTITION
pWest' would also delete all of these rows, but would also remove the
partition 'pWest' from the definition of the table; you would need to
use an 'ALTER TABLE ... ADD PARTITION' statement to restore the table's
original partitioning scheme.)

As with 'RANGE' partitioning, it is possible to combine 'LIST'
partitioning with partitioning by hash or key to produce a composite
partitioning (subpartitioning).  See *note partitioning-subpartitions::.

Unlike the case with 'RANGE' partitioning, there is no 'catch-all' such
as 'MAXVALUE'; all expected values for the partitioning expression
should be covered in 'PARTITION ... VALUES IN (...)' clauses.  An *note
'INSERT': insert. statement containing an unmatched partitioning column
value fails with an error, as shown in this example:

     mysql> CREATE TABLE h2 (
         ->   c1 INT,
         ->   c2 INT
         -> )
         -> PARTITION BY LIST(c1) (
         ->   PARTITION p0 VALUES IN (1, 4, 7),
         ->   PARTITION p1 VALUES IN (2, 5, 8)
         -> );
     Query OK, 0 rows affected (0.11 sec)

     mysql> INSERT INTO h2 VALUES (3, 5);
     ERROR 1525 (HY000): Table has no partition for value 3

When inserting multiple rows using a single *note 'INSERT': insert.
statement the behavior depends on whether the table uses a transactional
storage engine.  For an *note 'InnoDB': innodb-storage-engine. table,
the statement is considered a single transaction, so the presence of any
unmatched values causes the statement to fail completely, and no rows
are inserted.  For a table using a nontransactional storage engine such
as *note 'MyISAM': myisam-storage-engine, any rows coming before the row
containing the unmatched value are inserted, but any coming after it are
not.

You can cause this type of error to be ignored by using the 'IGNORE'
keyword.  If you do so, rows containing unmatched partitioning column
values are not inserted, but any rows with matching values _are_
inserted, and no errors are reported:

     mysql> TRUNCATE h2;
     Query OK, 1 row affected (0.00 sec)

     mysql> SELECT * FROM h2;
     Empty set (0.00 sec)

     mysql> INSERT IGNORE INTO h2 VALUES (2, 5), (6, 10), (7, 5), (3, 1), (1, 9);
     Query OK, 3 rows affected (0.00 sec)
     Records: 5  Duplicates: 2  Warnings: 0

     mysql> SELECT * FROM h2;
     +------+------+
     | c1   | c2   |
     +------+------+
     |    7 |    5 |
     |    1 |    9 |
     |    2 |    5 |
     +------+------+
     3 rows in set (0.00 sec)

MySQL 5.5 provides support for 'LIST COLUMNS' partitioning.  This is a
variant of 'LIST' partitioning that enables you to use columns of types
other than integer types for partitioning columns, as well as to use
multiple columns as partitioning keys.  For more information, see *note
partitioning-columns-list::.


File: manual.info.tmp,  Node: partitioning-columns,  Next: partitioning-hash,  Prev: partitioning-list,  Up: partitioning-types

19.2.3 COLUMNS Partitioning
---------------------------

* Menu:

* partitioning-columns-range::   RANGE COLUMNS partitioning
* partitioning-columns-list::    LIST COLUMNS partitioning

The next two sections discuss _'COLUMNS' partitioning_, which are
variants on 'RANGE' and 'LIST' partitioning that were introduced in
MySQL 5.5.0.  'COLUMNS' partitioning enables the use of multiple columns
in partitioning keys.  All of these columns are taken into account both
for the purpose of placing rows in partitions and for the determination
of which partitions are to be checked for matching rows in partition
pruning.

In addition, both 'RANGE COLUMNS' partitioning and 'LIST COLUMNS'
partitioning support the use of non-integer columns for defining value
ranges or list members.  The permitted data types are shown in the
following list:

   * All integer types: *note 'TINYINT': integer-types, *note
     'SMALLINT': integer-types, *note 'MEDIUMINT': integer-types, *note
     'INT': integer-types. (*note 'INTEGER': integer-types.), and *note
     'BIGINT': integer-types.  (This is the same as with partitioning by
     'RANGE' and 'LIST'.)

     Other numeric data types (such as *note 'DECIMAL':
     fixed-point-types. or *note 'FLOAT': floating-point-types.) are not
     supported as partitioning columns.

   * *note 'DATE': datetime. and *note 'DATETIME': datetime.

     Columns using other data types relating to dates or times are not
     supported as partitioning columns.

   * The following string types: *note 'CHAR': char, *note 'VARCHAR':
     char, *note 'BINARY': binary-varbinary, and *note 'VARBINARY':
     binary-varbinary.

     *note 'TEXT': blob. and *note 'BLOB': blob. columns are not
     supported as partitioning columns.

The discussions of 'RANGE COLUMNS' and 'LIST COLUMNS' partitioning in
the next two sections assume that you are already familiar with
partitioning based on ranges and lists as supported in MySQL 5.1 and
later; for more information about these, see *note partitioning-range::,
and *note partitioning-list::, respectively.


File: manual.info.tmp,  Node: partitioning-columns-range,  Next: partitioning-columns-list,  Prev: partitioning-columns,  Up: partitioning-columns

19.2.3.1 RANGE COLUMNS partitioning
...................................

Range columns partitioning is similar to range partitioning, but enables
you to define partitions using ranges based on multiple column values.
In addition, you can define the ranges using columns of types other than
integer types.

'RANGE COLUMNS' partitioning differs significantly from 'RANGE'
partitioning in the following ways:

   * 'RANGE COLUMNS' does not accept expressions, only names of columns.

   * 'RANGE COLUMNS' accepts a list of one or more columns.

     'RANGE COLUMNS' partitions are based on comparisons between
     _tuples_ (lists of column values) rather than comparisons between
     scalar values.  Placement of rows in 'RANGE COLUMNS' partitions is
     also based on comparisons between tuples; this is discussed further
     later in this section.

   * 'RANGE COLUMNS' partitioning columns are not restricted to integer
     columns; string, *note 'DATE': datetime. and *note 'DATETIME':
     datetime. columns can also be used as partitioning columns.  (See
     *note partitioning-columns::, for details.)

The basic syntax for creating a table partitioned by 'RANGE COLUMNS' is
shown here:

     CREATE TABLE TABLE_NAME
     PARTITIONED BY RANGE COLUMNS(COLUMN_LIST) (
         PARTITION PARTITION_NAME VALUES LESS THAN (VALUE_LIST)[,
         PARTITION PARTITION_NAME VALUES LESS THAN (VALUE_LIST)][,
         ...]
     )

     COLUMN_LIST:
         COLUMN_NAME[, COLUMN_NAME][, ...]

     VALUE_LIST:
         VALUE[, VALUE][, ...]

*Note*:

Not all *note 'CREATE TABLE': create-table. options that can be used
when creating partitioned tables are shown here.  For complete
information, see *note create-table::.

In the syntax just shown, COLUMN_LIST is a list of one or more columns
(sometimes called a _partitioning column list_), and VALUE_LIST is a
list of values (that is, it is a _partition definition value list_).  A
VALUE_LIST must be supplied for each partition definition, and each
VALUE_LIST must have the same number of values as the COLUMN_LIST has
columns.  Generally speaking, if you use N columns in the 'COLUMNS'
clause, then each 'VALUES LESS THAN' clause must also be supplied with a
list of N values.

The elements in the partitioning column list and in the value list
defining each partition must occur in the same order.  In addition, each
element in the value list must be of the same data type as the
corresponding element in the column list.  However, the order of the
column names in the partitioning column list and the value lists does
not have to be the same as the order of the table column definitions in
the main part of the *note 'CREATE TABLE': create-table. statement.  As
with table partitioned by 'RANGE', you can use 'MAXVALUE' to represent a
value such that any legal value inserted into a given column is always
less than this value.  Here is an example of a *note 'CREATE TABLE':
create-table. statement that helps to illustrate all of these points:

     mysql> CREATE TABLE rcx (
         ->     a INT,
         ->     b INT,
         ->     c CHAR(3),
         ->     d INT
         -> )
         -> PARTITION BY RANGE COLUMNS(a,d,c) (
         ->     PARTITION p0 VALUES LESS THAN (5,10,'ggg'),
         ->     PARTITION p1 VALUES LESS THAN (10,20,'mmm'),
         ->     PARTITION p2 VALUES LESS THAN (15,30,'sss'),
         ->     PARTITION p3 VALUES LESS THAN (MAXVALUE,MAXVALUE,MAXVALUE)
         -> );
     Query OK, 0 rows affected (0.15 sec)

Table 'rcx' contains the columns 'a', 'b', 'c', 'd'.  The partitioning
column list supplied to the 'COLUMNS' clause uses 3 of these columns, in
the order 'a', 'd', 'c'.  Each value list used to define a partition
contains 3 values in the same order; that is, each value list tuple has
the form ('INT', 'INT', 'CHAR(3)'), which corresponds to the data types
used by columns 'a', 'd', and 'c' (in that order).

Placement of rows into partitions is determined by comparing the tuple
from a row to be inserted that matches the column list in the 'COLUMNS'
clause with the tuples used in the 'VALUES LESS THAN' clauses to define
partitions of the table.  Because we are comparing tuples (that is,
lists or sets of values) rather than scalar values, the semantics of
'VALUES LESS THAN' as used with 'RANGE COLUMNS' partitions differs
somewhat from the case with simple 'RANGE' partitions.  In 'RANGE'
partitioning, a row generating an expression value that is equal to a
limiting value in a 'VALUES LESS THAN' is never placed in the
corresponding partition; however, when using 'RANGE COLUMNS'
partitioning, it is sometimes possible for a row whose partitioning
column list's first element is equal in value to the that of the first
element in a 'VALUES LESS THAN' value list to be placed in the
corresponding partition.

Consider the 'RANGE' partitioned table created by this statement:

     CREATE TABLE r1 (
         a INT,
         b INT
     )
     PARTITION BY RANGE (a)  (
         PARTITION p0 VALUES LESS THAN (5),
         PARTITION p1 VALUES LESS THAN (MAXVALUE)
     );

If we insert 3 rows into this table such that the column value for 'a'
is '5' for each row, all 3 rows are stored in partition 'p1' because the
'a' column value is in each case not less than 5, as we can see by
executing the proper query against the *note
'INFORMATION_SCHEMA.PARTITIONS': partitions-table. table:

     mysql> INSERT INTO r1 VALUES (5,10), (5,11), (5,12);
     Query OK, 3 rows affected (0.00 sec)
     Records: 3  Duplicates: 0  Warnings: 0

     mysql> SELECT PARTITION_NAME,TABLE_ROWS
         ->     FROM INFORMATION_SCHEMA.PARTITIONS
         ->     WHERE TABLE_NAME = 'r1';
     +----------------+------------+
     | PARTITION_NAME | TABLE_ROWS |
     +----------------+------------+
     | p0             |          0 |
     | p1             |          3 |
     +----------------+------------+
     2 rows in set (0.00 sec)

Now consider a similar table 'rc1' that uses 'RANGE COLUMNS'
partitioning with both columns 'a' and 'b' referenced in the 'COLUMNS'
clause, created as shown here:

     CREATE TABLE rc1 (
         a INT,
         b INT
     )
     PARTITION BY RANGE COLUMNS(a, b) (
         PARTITION p0 VALUES LESS THAN (5, 12),
         PARTITION p3 VALUES LESS THAN (MAXVALUE, MAXVALUE)
     );

If we insert exactly the same rows into 'rc1' as we just inserted into
'r1', the distribution of the rows is quite different:

     mysql> INSERT INTO rc1 VALUES (5,10), (5,11), (5,12);
     Query OK, 3 rows affected (0.00 sec)
     Records: 3  Duplicates: 0  Warnings: 0

     mysql> SELECT PARTITION_NAME,TABLE_ROWS
         ->     FROM INFORMATION_SCHEMA.PARTITIONS
         ->     WHERE TABLE_NAME = 'rc1';
     +--------------+----------------+------------+
     | TABLE_SCHEMA | PARTITION_NAME | TABLE_ROWS |
     +--------------+----------------+------------+
     | p            | p0             |          2 |
     | p            | p1             |          1 |
     +--------------+----------------+------------+
     2 rows in set (0.00 sec)

This is because we are comparing rows rather than scalar values.  We can
compare the row values inserted with the limiting row value from the
'VALUES THAN LESS THAN' clause used to define partition 'p0' in table
'rc1', like this:

     mysql> SELECT (5,10) < (5,12), (5,11) < (5,12), (5,12) < (5,12);
     +-----------------+-----------------+-----------------+
     | (5,10) < (5,12) | (5,11) < (5,12) | (5,12) < (5,12) |
     +-----------------+-----------------+-----------------+
     |               1 |               1 |               0 |
     +-----------------+-----------------+-----------------+
     1 row in set (0.00 sec)

The 2 tuples '(5,10)' and '(5,11)' evaluate as less than '(5,12)', so
they are stored in partition 'p0'.  Since 5 is not less than 5 and 12 is
not less than 12, '(5,12)' is considered not less than '(5,12)', and is
stored in partition 'p1'.

The *note 'SELECT': select. statement in the preceding example could
also have been written using explicit row constructors, like this:

     SELECT ROW(5,10) < ROW(5,12), ROW(5,11) < ROW(5,12), ROW(5,12) < ROW(5,12);

For more information about the use of row constructors in MySQL, see
*note row-subqueries::.

For a table partitioned by 'RANGE COLUMNS' using only a single
partitioning column, the storing of rows in partitions is the same as
that of an equivalent table that is partitioned by 'RANGE'.  The
following 'CREATE TABLE' statement creates a table partitioned by 'RANGE
COLUMNS' using 1 partitioning column:

     CREATE TABLE rx (
         a INT,
         b INT
     )
     PARTITION BY RANGE COLUMNS (a)  (
         PARTITION p0 VALUES LESS THAN (5),
         PARTITION p1 VALUES LESS THAN (MAXVALUE)
     );

If we insert the rows '(5,10)', '(5,11)', and '(5,12)' into this table,
we can see that their placement is the same as it is for the table 'r'
we created and populated earlier:

     mysql> INSERT INTO rx VALUES (5,10), (5,11), (5,12);
     Query OK, 3 rows affected (0.00 sec)
     Records: 3  Duplicates: 0  Warnings: 0

     mysql> SELECT PARTITION_NAME,TABLE_ROWS
         ->     FROM INFORMATION_SCHEMA.PARTITIONS
         ->     WHERE TABLE_NAME = 'rx';
     +--------------+----------------+------------+
     | TABLE_SCHEMA | PARTITION_NAME | TABLE_ROWS |
     +--------------+----------------+------------+
     | p            | p0             |          0 |
     | p            | p1             |          3 |
     +--------------+----------------+------------+
     2 rows in set (0.00 sec)

It is also possible to create tables partitioned by 'RANGE COLUMNS'
where limiting values for one or more columns are repeated in successive
partition definitions.  You can do this as long as the tuples of column
values used to define the partitions are strictly increasing.  For
example, each of the following *note 'CREATE TABLE': create-table.
statements is valid:

     CREATE TABLE rc2 (
         a INT,
         b INT
     )
     PARTITION BY RANGE COLUMNS(a,b) (
         PARTITION p0 VALUES LESS THAN (0,10),
         PARTITION p1 VALUES LESS THAN (10,20),
         PARTITION p2 VALUES LESS THAN (10,30),
         PARTITION p3 VALUES LESS THAN (MAXVALUE,MAXVALUE)
      );

     CREATE TABLE rc3 (
         a INT,
         b INT
     )
     PARTITION BY RANGE COLUMNS(a,b) (
         PARTITION p0 VALUES LESS THAN (0,10),
         PARTITION p1 VALUES LESS THAN (10,20),
         PARTITION p2 VALUES LESS THAN (10,30),
         PARTITION p3 VALUES LESS THAN (10,35),
         PARTITION p4 VALUES LESS THAN (20,40),
         PARTITION p5 VALUES LESS THAN (MAXVALUE,MAXVALUE)
      );

The following statement also succeeds, even though it might appear at
first glance that it would not, since the limiting value of column 'b'
is 25 for partition 'p0' and 20 for partition 'p1', and the limiting
value of column 'c' is 100 for partition 'p1' and 50 for partition 'p2':

     CREATE TABLE rc4 (
         a INT,
         b INT,
         c INT
     )
     PARTITION BY RANGE COLUMNS(a,b,c) (
         PARTITION p0 VALUES LESS THAN (0,25,50),
         PARTITION p1 VALUES LESS THAN (10,20,100),
         PARTITION p2 VALUES LESS THAN (10,30,50)
         PARTITION p3 VALUES LESS THAN (MAXVALUE,MAXVALUE,MAXVALUE)
      );

When designing tables partitioned by 'RANGE COLUMNS', you can always
test successive partition definitions by comparing the desired tuples
using the *note 'mysql': mysql. client, like this:

     mysql> SELECT (0,25,50) < (10,20,100), (10,20,100) < (10,30,50);
     +-------------------------+--------------------------+
     | (0,25,50) < (10,20,100) | (10,20,100) < (10,30,50) |
     +-------------------------+--------------------------+
     |                       1 |                        1 |
     +-------------------------+--------------------------+
     1 row in set (0.00 sec)

If a *note 'CREATE TABLE': create-table. statement contains partition
definitions that are not in strictly increasing order, it fails with an
error, as shown in this example:

     mysql> CREATE TABLE rcf (
         ->     a INT,
         ->     b INT,
         ->     c INT
         -> )
         -> PARTITION BY RANGE COLUMNS(a,b,c) (
         ->     PARTITION p0 VALUES LESS THAN (0,25,50),
         ->     PARTITION p1 VALUES LESS THAN (20,20,100),
         ->     PARTITION p2 VALUES LESS THAN (10,30,50),
         ->     PARTITION p3 VALUES LESS THAN (MAXVALUE,MAXVALUE,MAXVALUE)
         ->  );
     ERROR 1493 (HY000): VALUES LESS THAN value must be strictly increasing for each partition

When you get such an error, you can deduce which partition definitions
are invalid by making 'less than' comparisons between their column
lists.  In this case, the problem is with the definition of partition
'p2' because the tuple used to define it is not less than the tuple used
to define partition 'p3', as shown here:

     mysql> SELECT (0,25,50) < (20,20,100), (20,20,100) < (10,30,50);
     +-------------------------+--------------------------+
     | (0,25,50) < (20,20,100) | (20,20,100) < (10,30,50) |
     +-------------------------+--------------------------+
     |                       1 |                        0 |
     +-------------------------+--------------------------+
     1 row in set (0.00 sec)

It is also possible for 'MAXVALUE' to appear for the same column in more
than one 'VALUES LESS THAN' clause when using 'RANGE COLUMNS'.  However,
the limiting values for individual columns in successive partition
definitions should otherwise be increasing, there should be no more than
one partition defined where 'MAXVALUE' is used as the upper limit for
all column values, and this partition definition should appear last in
the list of 'PARTITION ... VALUES LESS THAN' clauses.  In addition, you
cannot use 'MAXVALUE' as the limiting value for the first column in more
than one partition definition.

As stated previously, it is also possible with 'RANGE COLUMNS'
partitioning to use non-integer columns as partitioning columns.  (See
*note partitioning-columns::, for a complete listing of these.)
Consider a table named 'employees' (which is not partitioned), created
using the following statement:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT NOT NULL,
         store_id INT NOT NULL
     );

Using 'RANGE COLUMNS' partitioning, you can create a version of this
table that stores each row in one of four partitions based on the
employee's last name, like this:

     CREATE TABLE employees_by_lname (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT NOT NULL,
         store_id INT NOT NULL
     )
     PARTITION BY RANGE COLUMNS (lname)  (
         PARTITION p0 VALUES LESS THAN ('g'),
         PARTITION p1 VALUES LESS THAN ('m'),
         PARTITION p2 VALUES LESS THAN ('t'),
         PARTITION p3 VALUES LESS THAN (MAXVALUE)
     );

Alternatively, you could cause the 'employees' table as created
previously to be partitioned using this scheme by executing the
following *note 'ALTER TABLE': alter-table-partition-operations.
statement:

     ALTER TABLE employees PARTITION BY RANGE COLUMNS (lname)  (
         PARTITION p0 VALUES LESS THAN ('g'),
         PARTITION p1 VALUES LESS THAN ('m'),
         PARTITION p2 VALUES LESS THAN ('t'),
         PARTITION p3 VALUES LESS THAN (MAXVALUE)
     );

*Note*:

Because different character sets and collations have different sort
orders, the character sets and collations in use may effect which
partition of a table partitioned by 'RANGE COLUMNS' a given row is
stored in when using string columns as partitioning columns.  In
addition, changing the character set or collation for a given database,
table, or column after such a table is created may cause changes in how
rows are distributed.  For example, when using a case-sensitive
collation, ''and'' sorts before ''Andersen'', but when using a collation
that is case-insensitive, the reverse is true.

For information about how MySQL handles character sets and collations,
see *note charset::.

Similarly, you can cause the 'employees' table to be partitioned in such
a way that each row is stored in one of several partitions based on the
decade in which the corresponding employee was hired using the *note
'ALTER TABLE': alter-table-partition-operations. statement shown here:

     ALTER TABLE employees PARTITION BY RANGE COLUMNS (hired)  (
         PARTITION p0 VALUES LESS THAN ('1970-01-01'),
         PARTITION p1 VALUES LESS THAN ('1980-01-01'),
         PARTITION p2 VALUES LESS THAN ('1990-01-01'),
         PARTITION p3 VALUES LESS THAN ('2000-01-01'),
         PARTITION p4 VALUES LESS THAN ('2010-01-01'),
         PARTITION p5 VALUES LESS THAN (MAXVALUE)
     );

See *note create-table::, for additional information about 'PARTITION BY
RANGE COLUMNS' syntax.


File: manual.info.tmp,  Node: partitioning-columns-list,  Prev: partitioning-columns-range,  Up: partitioning-columns

19.2.3.2 LIST COLUMNS partitioning
..................................

MySQL 5.5 provides support for 'LIST COLUMNS' partitioning.  This is a
variant of 'LIST' partitioning that enables the use of multiple columns
as partition keys, and for columns of data types other than integer
types to be used as partitioning columns; you can use string types,
*note 'DATE': datetime, and *note 'DATETIME': datetime. columns.  (For
more information about permitted data types for 'COLUMNS' partitioning
columns, see *note partitioning-columns::.)

Suppose that you have a business that has customers in 12 cities which,
for sales and marketing purposes, you organize into 4 regions of 3
cities each as shown in the following table:

Region                               Cities
                                     
1                                    Oskarshamn, Ho"gsby, Mo"nsteraas
                                     
2                                    Vimmerby, Hultsfred, Va"stervik
                                     
3                                    Na"ssjo", Eksjo", Vetlanda
                                     
4                                    Uppvidinge, Alvesta, Va"xjo

With 'LIST COLUMNS' partitioning, you can create a table for customer
data that assigns a row to any of 4 partitions corresponding to these
regions based on the name of the city where a customer resides, as shown
here:

     CREATE TABLE customers_1 (
         first_name VARCHAR(25),
         last_name VARCHAR(25),
         street_1 VARCHAR(30),
         street_2 VARCHAR(30),
         city VARCHAR(15),
         renewal DATE
     )
     PARTITION BY LIST COLUMNS(city) (
         PARTITION pRegion_1 VALUES IN('Oskarshamn', 'Ho"gsby', 'Mo"nsteraas'),
         PARTITION pRegion_2 VALUES IN('Vimmerby', 'Hultsfred', 'Va"stervik'),
         PARTITION pRegion_3 VALUES IN('Na"ssjo"', 'Eksjo"', 'Vetlanda'),
         PARTITION pRegion_4 VALUES IN('Uppvidinge', 'Alvesta', 'Va"xjo')
     );

As with partitioning by 'RANGE COLUMNS', you do not need to use
expressions in the 'COLUMNS()' clause to convert column values into
integers.  (In fact, the use of expressions other than column names is
not permitted with 'COLUMNS()'.)

It is also possible to use *note 'DATE': datetime. and *note 'DATETIME':
datetime. columns, as shown in the following example that uses the same
name and columns as the 'customers_1' table shown previously, but
employs 'LIST COLUMNS' partitioning based on the 'renewal' column to
store rows in one of 4 partitions depending on the week in February 2010
the customer's account is scheduled to renew:

     CREATE TABLE customers_2 (
         first_name VARCHAR(25),
         last_name VARCHAR(25),
         street_1 VARCHAR(30),
         street_2 VARCHAR(30),
         city VARCHAR(15),
         renewal DATE
     )
     PARTITION BY LIST COLUMNS(renewal) (
         PARTITION pWeek_1 VALUES IN('2010-02-01', '2010-02-02', '2010-02-03',
             '2010-02-04', '2010-02-05', '2010-02-06', '2010-02-07'),
         PARTITION pWeek_2 VALUES IN('2010-02-08', '2010-02-09', '2010-02-10',
             '2010-02-11', '2010-02-12', '2010-02-13', '2010-02-14'),
         PARTITION pWeek_3 VALUES IN('2010-02-15', '2010-02-16', '2010-02-17',
             '2010-02-18', '2010-02-19', '2010-02-20', '2010-02-21'),
         PARTITION pWeek_4 VALUES IN('2010-02-22', '2010-02-23', '2010-02-24',
             '2010-02-25', '2010-02-26', '2010-02-27', '2010-02-28')
     );

This works, but becomes cumbersome to define and maintain if the number
of dates involved grows very large; in such cases, it is usually more
practical to employ 'RANGE' or 'RANGE COLUMNS' partitioning instead.  In
this case, since the column we wish to use as the partitioning key is a
*note 'DATE': datetime. column, we use 'RANGE COLUMNS' partitioning, as
shown here:

     CREATE TABLE customers_3 (
         first_name VARCHAR(25),
         last_name VARCHAR(25),
         street_1 VARCHAR(30),
         street_2 VARCHAR(30),
         city VARCHAR(15),
         renewal DATE
     )
     PARTITION BY RANGE COLUMNS(renewal) (
         PARTITION pWeek_1 VALUES LESS THAN('2010-02-09'),
         PARTITION pWeek_2 VALUES LESS THAN('2010-02-15'),
         PARTITION pWeek_3 VALUES LESS THAN('2010-02-22'),
         PARTITION pWeek_4 VALUES LESS THAN('2010-03-01')
     );

See *note partitioning-columns-range::, for more information.

In addition (as with 'RANGE COLUMNS' partitioning), you can use multiple
columns in the 'COLUMNS()' clause.

See *note create-table::, for additional information about 'PARTITION BY
LIST COLUMNS()' syntax.


File: manual.info.tmp,  Node: partitioning-hash,  Next: partitioning-key,  Prev: partitioning-columns,  Up: partitioning-types

19.2.4 HASH Partitioning
------------------------

* Menu:

* partitioning-linear-hash::     LINEAR HASH Partitioning

Partitioning by 'HASH' is used primarily to ensure an even distribution
of data among a predetermined number of partitions.  With range or list
partitioning, you must specify explicitly into which partition a given
column value or set of column values is to be stored; with hash
partitioning, MySQL takes care of this for you, and you need only
specify a column value or expression based on a column value to be
hashed and the number of partitions into which the partitioned table is
to be divided.

To partition a table using 'HASH' partitioning, it is necessary to
append to the *note 'CREATE TABLE': create-table. statement a 'PARTITION
BY HASH (EXPR)' clause, where EXPR is an expression that returns an
integer.  This can simply be the name of a column whose type is one of
MySQL's integer types.  In addition, you most likely want to follow this
with 'PARTITIONS NUM', where NUM is a positive integer representing the
number of partitions into which the table is to be divided.

*Note*:

For simplicity, the tables in the examples that follow do not use any
keys.  You should be aware that, if a table has any unique keys, every
column used in the partitioning expression for this table must be part
of every unique key, including the primary key.  See *note
partitioning-limitations-partitioning-keys-unique-keys::, for more
information.

The following statement creates a table that uses hashing on the
'store_id' column and is divided into 4 partitions:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT,
         store_id INT
     )
     PARTITION BY HASH(store_id)
     PARTITIONS 4;

If you do not include a 'PARTITIONS' clause, the number of partitions
defaults to '1'.

Using the 'PARTITIONS' keyword without a number following it results in
a syntax error.

You can also use an SQL expression that returns an integer for EXPR.
For instance, you might want to partition based on the year in which an
employee was hired.  This can be done as shown here:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT,
         store_id INT
     )
     PARTITION BY HASH( YEAR(hired) )
     PARTITIONS 4;

EXPR must return a nonconstant, nonrandom integer value (in other words,
it should be varying but deterministic), and must not contain any
prohibited constructs as described in *note partitioning-limitations::.
You should also keep in mind that this expression is evaluated each time
a row is inserted or updated (or possibly deleted); this means that very
complex expressions may give rise to performance issues, particularly
when performing operations (such as batch inserts) that affect a great
many rows at one time.

The most efficient hashing function is one which operates upon a single
table column and whose value increases or decreases consistently with
the column value, as this allows for 'pruning' on ranges of partitions.
That is, the more closely that the expression varies with the value of
the column on which it is based, the more efficiently MySQL can use the
expression for hash partitioning.

For example, where 'date_col' is a column of type *note 'DATE':
datetime, then the expression 'TO_DAYS(date_col)' is said to vary
directly with the value of 'date_col', because for every change in the
value of 'date_col', the value of the expression changes in a consistent
manner.  The variance of the expression 'YEAR(date_col)' with respect to
'date_col' is not quite as direct as that of 'TO_DAYS(date_col)',
because not every possible change in 'date_col' produces an equivalent
change in 'YEAR(date_col)'.  Even so, 'YEAR(date_col)' is a good
candidate for a hashing function, because it varies directly with a
portion of 'date_col' and there is no possible change in 'date_col' that
produces a disproportionate change in 'YEAR(date_col)'.

By way of contrast, suppose that you have a column named 'int_col' whose
type is *note 'INT': integer-types.  Now consider the expression
'POW(5-int_col,3) + 6'.  This would be a poor choice for a hashing
function because a change in the value of 'int_col' is not guaranteed to
produce a proportional change in the value of the expression.  Changing
the value of 'int_col' by a given amount can produce widely differing
changes in the value of the expression.  For example, changing 'int_col'
from '5' to '6' produces a change of '-1' in the value of the
expression, but changing the value of 'int_col' from '6' to '7' produces
a change of '-7' in the expression value.

In other words, the more closely the graph of the column value versus
the value of the expression follows a straight line as traced by the
equation 'y=Cx' where C is some nonzero constant, the better the
expression is suited to hashing.  This has to do with the fact that the
more nonlinear an expression is, the more uneven the distribution of
data among the partitions it tends to produce.

In theory, pruning is also possible for expressions involving more than
one column value, but determining which of such expressions are suitable
can be quite difficult and time-consuming.  For this reason, the use of
hashing expressions involving multiple columns is not particularly
recommended.

When 'PARTITION BY HASH' is used, MySQL determines which partition of
NUM partitions to use based on the modulus of the result of the
expression.  In other words, for a given expression EXPR, the partition
in which the record is stored is partition number N, where 'N =
MOD(EXPR, NUM)'.  Suppose that table 't1' is defined as follows, so that
it has 4 partitions:

     CREATE TABLE t1 (col1 INT, col2 CHAR(5), col3 DATE)
         PARTITION BY HASH( YEAR(col3) )
         PARTITIONS 4;

If you insert a record into 't1' whose 'col3' value is ''2005-09-15'',
then the partition in which it is stored is determined as follows:

     MOD(YEAR('2005-09-01'),4)
     =  MOD(2005,4)
     =  1

MySQL 5.5 also supports a variant of 'HASH' partitioning known as
_linear hashing_ which employs a more complex algorithm for determining
the placement of new rows inserted into the partitioned table.  See
*note partitioning-linear-hash::, for a description of this algorithm.

The user-supplied expression is evaluated each time a record is inserted
or updated.  It may also--depending on the circumstances--be evaluated
when records are deleted.


File: manual.info.tmp,  Node: partitioning-linear-hash,  Prev: partitioning-hash,  Up: partitioning-hash

19.2.4.1 LINEAR HASH Partitioning
.................................

MySQL also supports linear hashing, which differs from regular hashing
in that linear hashing utilizes a linear powers-of-two algorithm whereas
regular hashing employs the modulus of the hashing function's value.

Syntactically, the only difference between linear-hash partitioning and
regular hashing is the addition of the 'LINEAR' keyword in the
'PARTITION BY' clause, as shown here:

     CREATE TABLE employees (
         id INT NOT NULL,
         fname VARCHAR(30),
         lname VARCHAR(30),
         hired DATE NOT NULL DEFAULT '1970-01-01',
         separated DATE NOT NULL DEFAULT '9999-12-31',
         job_code INT,
         store_id INT
     )
     PARTITION BY LINEAR HASH( YEAR(hired) )
     PARTITIONS 4;

Given an expression EXPR, the partition in which the record is stored
when linear hashing is used is partition number N from among NUM
partitions, where N is derived according to the following algorithm:

  1. Find the next power of 2 greater than NUM.  We call this value V;
     it can be calculated as:

          V = POWER(2, CEILING(LOG(2, NUM)))

     (Suppose that NUM is 13.  Then 'LOG(2,13)' is 3.7004397181411.
     'CEILING(3.7004397181411)' is 4, and V = 'POWER(2,4)', which is
     16.)

  2. Set N = F(COLUMN_LIST) & (V - 1).

  3. While N >= NUM:

        * Set V = V / 2

        * Set N = N & (V - 1)

Suppose that the table 't1', using linear hash partitioning and having 6
partitions, is created using this statement:

     CREATE TABLE t1 (col1 INT, col2 CHAR(5), col3 DATE)
         PARTITION BY LINEAR HASH( YEAR(col3) )
         PARTITIONS 6;

Now assume that you want to insert two records into 't1' having the
'col3' column values ''2003-04-14'' and ''1998-10-19''.  The partition
number for the first of these is determined as follows:

     V = POWER(2, CEILING( LOG(2,6) )) = 8
     N = YEAR('2003-04-14') & (8 - 1)
        = 2003 & 7
        = 3

     (_3 >= 6 is FALSE: record stored in partition #3_)

The number of the partition where the second record is stored is
calculated as shown here:

     V = 8
     N = YEAR('1998-10-19') & (8 - 1)
       = 1998 & 7
       = 6

     (_6 >= 6 is TRUE: additional step required_)

     N = 6 & ((8 / 2) - 1)
       = 6 & 3
       = 2

     (_2 >= 6 is FALSE: record stored in partition #2_)

The advantage in partitioning by linear hash is that the adding,
dropping, merging, and splitting of partitions is made much faster,
which can be beneficial when dealing with tables containing extremely
large amounts (terabytes) of data.  The disadvantage is that data is
less likely to be evenly distributed between partitions as compared with
the distribution obtained using regular hash partitioning.


File: manual.info.tmp,  Node: partitioning-key,  Next: partitioning-subpartitions,  Prev: partitioning-hash,  Up: partitioning-types

19.2.5 KEY Partitioning
-----------------------

Partitioning by key is similar to partitioning by hash, except that
where hash partitioning employs a user-defined expression, the hashing
function for key partitioning is supplied by the MySQL server.  NDB
Cluster uses 'MD5()' for this purpose; for tables using other storage
engines, the server employs its own internal hashing function which is
based on the same algorithm as 'PASSWORD()'.

The syntax rules for 'CREATE TABLE ... PARTITION BY KEY' are similar to
those for creating a table that is partitioned by hash.  The major
differences are listed here:

   * 'KEY' is used rather than 'HASH'.

   * 'KEY' takes only a list of zero or more column names.  Any columns
     used as the partitioning key must comprise part or all of the
     table's primary key, if the table has one.  Where no column name is
     specified as the partitioning key, the table's primary key is used,
     if there is one.  For example, the following *note 'CREATE TABLE':
     create-table. statement is valid in MySQL 5.5:

          CREATE TABLE k1 (
              id INT NOT NULL PRIMARY KEY,
              name VARCHAR(20)
          )
          PARTITION BY KEY()
          PARTITIONS 2;

     If there is no primary key but there is a unique key, then the
     unique key is used for the partitioning key:

          CREATE TABLE k1 (
              id INT NOT NULL,
              name VARCHAR(20),
              UNIQUE KEY (id)
          )
          PARTITION BY KEY()
          PARTITIONS 2;

     However, if the unique key column were not defined as 'NOT NULL',
     then the previous statement would fail.

     In both of these cases, the partitioning key is the 'id' column,
     even though it is not shown in the output of *note 'SHOW CREATE
     TABLE': show-create-table. or in the 'PARTITION_EXPRESSION' column
     of the *note 'INFORMATION_SCHEMA.PARTITIONS': partitions-table.
     table.

     Unlike the case with other partitioning types, columns used for
     partitioning by 'KEY' are not restricted to integer or 'NULL'
     values.  For example, the following *note 'CREATE TABLE':
     create-table. statement is valid:

          CREATE TABLE tm1 (
              s1 CHAR(32) PRIMARY KEY
          )
          PARTITION BY KEY(s1)
          PARTITIONS 10;

     The preceding statement would _not_ be valid, were a different
     partitioning type to be specified.  (In this case, simply using
     'PARTITION BY KEY()' would also be valid and have the same effect
     as 'PARTITION BY KEY(s1)', since 's1' is the table's primary key.)

     For additional information about this issue, see *note
     partitioning-limitations::.

     *Note*:

     Tables using the *note 'NDBCLUSTER': mysql-cluster. storage engine
     are implicitly partitioned by 'KEY', again using the table's
     primary key as the partitioning key.  In the event that the NDB
     Cluster table has no explicit primary key, the 'hidden' primary key
     generated by the *note 'NDBCLUSTER': mysql-cluster. storage engine
     for each NDB Cluster table is used as the partitioning key.

     If you define an explicit partitioning scheme for an *note
     'NDBCLUSTER': mysql-cluster. table, the table must have an explicit
     primary key, and any columns used in the partitioning expression
     must be part of this key.  However, if the table uses an 'empty'
     partitioning expression--that is, 'PARTITION BY KEY()' with no
     column references--then no explicit primary key is required.

     You can observe this partitioning using the *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc. utility (with the '-p' option).

     *Important*:

     For a key-partitioned table, you cannot execute an 'ALTER TABLE
     DROP PRIMARY KEY', as doing so generates the error 'ERROR 1466
     (HY000): Field in list of fields for partition function not found
     in table'.  This is not an issue for NDB Cluster tables which are
     partitioned by 'KEY'; in such cases, the table is reorganized using
     the 'hidden' primary key as the table's new partitioning key.  See
     *note mysql-cluster::.

It is also possible to partition a table by linear key.  Here is a
simple example:

     CREATE TABLE tk (
         col1 INT NOT NULL,
         col2 CHAR(5),
         col3 DATE
     )
     PARTITION BY LINEAR KEY (col1)
     PARTITIONS 3;

Using 'LINEAR' has the same effect on 'KEY' partitioning as it does on
'HASH' partitioning, with the partition number being derived using a
powers-of-two algorithm rather than modulo arithmetic.  See *note
partitioning-linear-hash::, for a description of this algorithm and its
implications.


File: manual.info.tmp,  Node: partitioning-subpartitions,  Next: partitioning-handling-nulls,  Prev: partitioning-key,  Up: partitioning-types

19.2.6 Subpartitioning
----------------------

Subpartitioning--also known as _composite partitioning_--is the further
division of each partition in a partitioned table.  Consider the
following *note 'CREATE TABLE': create-table. statement:

     CREATE TABLE ts (id INT, purchased DATE)
         PARTITION BY RANGE( YEAR(purchased) )
         SUBPARTITION BY HASH( TO_DAYS(purchased) )
         SUBPARTITIONS 2 (
             PARTITION p0 VALUES LESS THAN (1990),
             PARTITION p1 VALUES LESS THAN (2000),
             PARTITION p2 VALUES LESS THAN MAXVALUE
         );

Table 'ts' has 3 'RANGE' partitions.  Each of these partitions--'p0',
'p1', and 'p2'--is further divided into 2 subpartitions.  In effect, the
entire table is divided into '3 * 2 = 6' partitions.  However, due to
the action of the 'PARTITION BY RANGE' clause, the first 2 of these
store only those records with a value less than 1990 in the 'purchased'
column.

In MySQL 5.5, it is possible to subpartition tables that are partitioned
by 'RANGE' or 'LIST'.  Subpartitions may use either 'HASH' or 'KEY'
partitioning.  This is also known as _composite partitioning_.

*Note*:

'SUBPARTITION BY HASH' and 'SUBPARTITION BY KEY' generally follow the
same syntax rules as 'PARTITION BY HASH' and 'PARTITION BY KEY',
respectively.  An exception to this is that 'SUBPARTITION BY KEY'
(unlike 'PARTITION BY KEY') does not currently support a default column,
so the column used for this purpose must be specified, even if the table
has an explicit primary key.  This is a known issue which we are working
to address; see *note partitioning-limitations-subpartitions::, for more
information and an example.

It is also possible to define subpartitions explicitly using
'SUBPARTITION' clauses to specify options for individual subpartitions.
For example, a more verbose fashion of creating the same table 'ts' as
shown in the previous example would be:

     CREATE TABLE ts (id INT, purchased DATE)
         PARTITION BY RANGE( YEAR(purchased) )
         SUBPARTITION BY HASH( TO_DAYS(purchased) ) (
             PARTITION p0 VALUES LESS THAN (1990) (
                 SUBPARTITION s0,
                 SUBPARTITION s1
             ),
             PARTITION p1 VALUES LESS THAN (2000) (
                 SUBPARTITION s2,
                 SUBPARTITION s3
             ),
             PARTITION p2 VALUES LESS THAN MAXVALUE (
                 SUBPARTITION s4,
                 SUBPARTITION s5
             )
         );

Some syntactical items of note are listed here:

   * Each partition must have the same number of subpartitions.

   * If you explicitly define any subpartitions using 'SUBPARTITION' on
     any partition of a partitioned table, you must define them all.  In
     other words, the following statement will fail:

          CREATE TABLE ts (id INT, purchased DATE)
              PARTITION BY RANGE( YEAR(purchased) )
              SUBPARTITION BY HASH( TO_DAYS(purchased) ) (
                  PARTITION p0 VALUES LESS THAN (1990) (
                      SUBPARTITION s0,
                      SUBPARTITION s1
                  ),
                  PARTITION p1 VALUES LESS THAN (2000),
                  PARTITION p2 VALUES LESS THAN MAXVALUE (
                      SUBPARTITION s2,
                      SUBPARTITION s3
                  )
              );

     This statement would still fail even if it included a
     'SUBPARTITIONS 2' clause.

   * Each 'SUBPARTITION' clause must include (at a minimum) a name for
     the subpartition.  Otherwise, you may set any desired option for
     the subpartition or allow it to assume its default setting for that
     option.

   * Subpartition names must be unique across the entire table.  For
     example, the following *note 'CREATE TABLE': create-table.
     statement is valid in MySQL 5.5:

          CREATE TABLE ts (id INT, purchased DATE)
              PARTITION BY RANGE( YEAR(purchased) )
              SUBPARTITION BY HASH( TO_DAYS(purchased) ) (
                  PARTITION p0 VALUES LESS THAN (1990) (
                      SUBPARTITION s0,
                      SUBPARTITION s1
                  ),
                  PARTITION p1 VALUES LESS THAN (2000) (
                      SUBPARTITION s2,
                      SUBPARTITION s3
                  ),
                  PARTITION p2 VALUES LESS THAN MAXVALUE (
                      SUBPARTITION s4,
                      SUBPARTITION s5
                  )
              );

Subpartitions can be used with especially large *note 'MyISAM':
myisam-storage-engine. tables to distribute data and indexes across many
disks.  Suppose that you have 6 disks mounted as '/disk0', '/disk1',
'/disk2', and so on.  Now consider the following example:

     CREATE TABLE ts (id INT, purchased DATE)
         ENGINE = MYISAM
         PARTITION BY RANGE( YEAR(purchased) )
         SUBPARTITION BY HASH( TO_DAYS(purchased) ) (
             PARTITION p0 VALUES LESS THAN (1990) (
                 SUBPARTITION s0
                     DATA DIRECTORY = '/disk0/data'
                     INDEX DIRECTORY = '/disk0/idx',
                 SUBPARTITION s1
                     DATA DIRECTORY = '/disk1/data'
                     INDEX DIRECTORY = '/disk1/idx'
             ),
             PARTITION p1 VALUES LESS THAN (2000) (
                 SUBPARTITION s2
                     DATA DIRECTORY = '/disk2/data'
                     INDEX DIRECTORY = '/disk2/idx',
                 SUBPARTITION s3
                     DATA DIRECTORY = '/disk3/data'
                     INDEX DIRECTORY = '/disk3/idx'
             ),
             PARTITION p2 VALUES LESS THAN MAXVALUE (
                 SUBPARTITION s4
                     DATA DIRECTORY = '/disk4/data'
                     INDEX DIRECTORY = '/disk4/idx',
                 SUBPARTITION s5
                     DATA DIRECTORY = '/disk5/data'
                     INDEX DIRECTORY = '/disk5/idx'
             )
         );

In this case, a separate disk is used for the data and for the indexes
of each 'RANGE'.  Many other variations are possible; another example
might be:

     CREATE TABLE ts (id INT, purchased DATE)
         ENGINE = MYISAM
         PARTITION BY RANGE(YEAR(purchased))
         SUBPARTITION BY HASH( TO_DAYS(purchased) ) (
             PARTITION p0 VALUES LESS THAN (1990) (
                 SUBPARTITION s0a
                     DATA DIRECTORY = '/disk0'
                     INDEX DIRECTORY = '/disk1',
                 SUBPARTITION s0b
                     DATA DIRECTORY = '/disk2'
                     INDEX DIRECTORY = '/disk3'
             ),
             PARTITION p1 VALUES LESS THAN (2000) (
                 SUBPARTITION s1a
                     DATA DIRECTORY = '/disk4/data'
                     INDEX DIRECTORY = '/disk4/idx',
                 SUBPARTITION s1b
                     DATA DIRECTORY = '/disk5/data'
                     INDEX DIRECTORY = '/disk5/idx'
             ),
             PARTITION p2 VALUES LESS THAN MAXVALUE (
                 SUBPARTITION s2a,
                 SUBPARTITION s2b
             )
         );

Here, the storage is as follows:

   * Rows with 'purchased' dates from before 1990 take up a vast amount
     of space, so are split up 4 ways, with a separate disk dedicated to
     the data and to the indexes for each of the two subpartitions
     ('s0a' and 's0b') making up partition 'p0'.  In other words:

        * The data for subpartition 's0a' is stored on '/disk0'.

        * The indexes for subpartition 's0a' are stored on '/disk1'.

        * The data for subpartition 's0b' is stored on '/disk2'.

        * The indexes for subpartition 's0b' are stored on '/disk3'.

   * Rows containing dates ranging from 1990 to 1999 (partition 'p1') do
     not require as much room as those from before 1990.  These are
     split between 2 disks ('/disk4' and '/disk5') rather than 4 disks
     as with the legacy records stored in 'p0':

        * Data and indexes belonging to 'p1''s first subpartition
          ('s1a') are stored on '/disk4'--the data in '/disk4/data', and
          the indexes in '/disk4/idx'.

        * Data and indexes belonging to 'p1''s second subpartition
          ('s1b') are stored on '/disk5'--the data in '/disk5/data', and
          the indexes in '/disk5/idx'.

   * Rows reflecting dates from the year 2000 to the present (partition
     'p2') do not take up as much space as required by either of the two
     previous ranges.  Currently, it is sufficient to store all of these
     in the default location.

     In future, when the number of purchases for the decade beginning
     with the year 2000 grows to a point where the default location no
     longer provides sufficient space, the corresponding rows can be
     moved using an 'ALTER TABLE ... REORGANIZE PARTITION' statement.
     See *note partitioning-management::, for an explanation of how this
     can be done.

The 'DATA DIRECTORY' and 'INDEX DIRECTORY' options are not permitted in
partition definitions when the 'NO_DIR_IN_CREATE' server SQL mode is in
effect.  Beginning with MySQL 5.5.5, these options are also not
permitted when defining subpartitions (Bug #42954).


File: manual.info.tmp,  Node: partitioning-handling-nulls,  Prev: partitioning-subpartitions,  Up: partitioning-types

19.2.7 How MySQL Partitioning Handles NULL
------------------------------------------

Partitioning in MySQL does nothing to disallow 'NULL' as the value of a
partitioning expression, whether it is a column value or the value of a
user-supplied expression.  Even though it is permitted to use 'NULL' as
the value of an expression that must otherwise yield an integer, it is
important to keep in mind that 'NULL' is not a number.  MySQL's
partitioning implementation treats 'NULL' as being less than any
non-'NULL' value, just as 'ORDER BY' does.

This means that treatment of 'NULL' varies between partitioning of
different types, and may produce behavior which you do not expect if you
are not prepared for it.  This being the case, we discuss in this
section how each MySQL partitioning type handles 'NULL' values when
determining the partition in which a row should be stored, and provide
examples for each.

Handling of NULL with RANGE partitioning

If you insert a row into a table partitioned by 'RANGE' such that the
column value used to determine the partition is 'NULL', the row is
inserted into the lowest partition.  Consider these two tables in a
database named 'p', created as follows:

     mysql> CREATE TABLE t1 (
         ->     c1 INT,
         ->     c2 VARCHAR(20)
         -> )
         -> PARTITION BY RANGE(c1) (
         ->     PARTITION p0 VALUES LESS THAN (0),
         ->     PARTITION p1 VALUES LESS THAN (10),
         ->     PARTITION p2 VALUES LESS THAN MAXVALUE
         -> );
     Query OK, 0 rows affected (0.09 sec)

     mysql> CREATE TABLE t2 (
         ->     c1 INT,
         ->     c2 VARCHAR(20)
         -> )
         -> PARTITION BY RANGE(c1) (
         ->     PARTITION p0 VALUES LESS THAN (-5),
         ->     PARTITION p1 VALUES LESS THAN (0),
         ->     PARTITION p2 VALUES LESS THAN (10),
         ->     PARTITION p3 VALUES LESS THAN MAXVALUE
         -> );
     Query OK, 0 rows affected (0.09 sec)

You can see the partitions created by these two *note 'CREATE TABLE':
create-table. statements using the following query against the *note
'PARTITIONS': partitions-table. table in the 'INFORMATION_SCHEMA'
database:

     mysql> SELECT TABLE_NAME, PARTITION_NAME, TABLE_ROWS, AVG_ROW_LENGTH, DATA_LENGTH
          >   FROM INFORMATION_SCHEMA.PARTITIONS
          >   WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME LIKE 't_';
     +------------+----------------+------------+----------------+-------------+
     | TABLE_NAME | PARTITION_NAME | TABLE_ROWS | AVG_ROW_LENGTH | DATA_LENGTH |
     +------------+----------------+------------+----------------+-------------+
     | t1         | p0             |          0 |              0 |           0 |
     | t1         | p1             |          0 |              0 |           0 |
     | t1         | p2             |          0 |              0 |           0 |
     | t2         | p0             |          0 |              0 |           0 |
     | t2         | p1             |          0 |              0 |           0 |
     | t2         | p2             |          0 |              0 |           0 |
     | t2         | p3             |          0 |              0 |           0 |
     +------------+----------------+------------+----------------+-------------+
     7 rows in set (0.00 sec)

(For more information about this table, see *note partitions-table::.)
Now let us populate each of these tables with a single row containing a
'NULL' in the column used as the partitioning key, and verify that the
rows were inserted using a pair of *note 'SELECT': select. statements:

     mysql> INSERT INTO t1 VALUES (NULL, 'mothra');
     Query OK, 1 row affected (0.00 sec)

     mysql> INSERT INTO t2 VALUES (NULL, 'mothra');
     Query OK, 1 row affected (0.00 sec)

     mysql> SELECT * FROM t1;
     +------+--------+
     | id   | name   |
     +------+--------+
     | NULL | mothra |
     +------+--------+
     1 row in set (0.00 sec)

     mysql> SELECT * FROM t2;
     +------+--------+
     | id   | name   |
     +------+--------+
     | NULL | mothra |
     +------+--------+
     1 row in set (0.00 sec)

You can see which partitions are used to store the inserted rows by
rerunning the previous query against *note
'INFORMATION_SCHEMA.PARTITIONS': partitions-table. and inspecting the
output:

     mysql> SELECT TABLE_NAME, PARTITION_NAME, TABLE_ROWS, AVG_ROW_LENGTH, DATA_LENGTH
          >   FROM INFORMATION_SCHEMA.PARTITIONS
          >   WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME LIKE 't_';
     +------------+----------------+------------+----------------+-------------+
     | TABLE_NAME | PARTITION_NAME | TABLE_ROWS | AVG_ROW_LENGTH | DATA_LENGTH |
     +------------+----------------+------------+----------------+-------------+
     _| t1         | p0             |          1 |             20 |          20 |_
     | t1         | p1             |          0 |              0 |           0 |
     | t1         | p2             |          0 |              0 |           0 |
     _| t2         | p0             |          1 |             20 |          20 |_
     | t2         | p1             |          0 |              0 |           0 |
     | t2         | p2             |          0 |              0 |           0 |
     | t2         | p3             |          0 |              0 |           0 |
     +------------+----------------+------------+----------------+-------------+
     7 rows in set (0.01 sec)

You can also demonstrate that these rows were stored in the lowest
partition of each table by dropping these partitions, and then
re-running the *note 'SELECT': select. statements:

     mysql> ALTER TABLE t1 DROP PARTITION p0;
     Query OK, 0 rows affected (0.16 sec)

     mysql> ALTER TABLE t2 DROP PARTITION p0;
     Query OK, 0 rows affected (0.16 sec)

     mysql> SELECT * FROM t1;
     Empty set (0.00 sec)

     mysql> SELECT * FROM t2;
     Empty set (0.00 sec)

(For more information on 'ALTER TABLE ... DROP PARTITION', see *note
alter-table::.)

'NULL' is also treated in this way for partitioning expressions that use
SQL functions.  Suppose that we define a table using a *note 'CREATE
TABLE': create-table. statement such as this one:

     CREATE TABLE tndate (
         id INT,
         dt DATE
     )
     PARTITION BY RANGE( YEAR(dt) ) (
         PARTITION p0 VALUES LESS THAN (1990),
         PARTITION p1 VALUES LESS THAN (2000),
         PARTITION p2 VALUES LESS THAN MAXVALUE
     );

As with other MySQL functions, 'YEAR(NULL)' returns 'NULL'.  A row with
a 'dt' column value of 'NULL' is treated as though the partitioning
expression evaluated to a value less than any other value, and so is
inserted into partition 'p0'.

Handling of NULL with LIST partitioning

A table that is partitioned by 'LIST' admits 'NULL' values if and only
if one of its partitions is defined using that value-list that contains
'NULL'.  The converse of this is that a table partitioned by 'LIST'
which does not explicitly use 'NULL' in a value list rejects rows
resulting in a 'NULL' value for the partitioning expression, as shown in
this example:

     mysql> CREATE TABLE ts1 (
         ->     c1 INT,
         ->     c2 VARCHAR(20)
         -> )
         -> PARTITION BY LIST(c1) (
         ->     PARTITION p0 VALUES IN (0, 3, 6),
         ->     PARTITION p1 VALUES IN (1, 4, 7),
         ->     PARTITION p2 VALUES IN (2, 5, 8)
         -> );
     Query OK, 0 rows affected (0.01 sec)

     mysql> INSERT INTO ts1 VALUES (9, 'mothra');
     ERROR 1504 (HY000): Table has no partition for value 9

     mysql> INSERT INTO ts1 VALUES (NULL, 'mothra');
     ERROR 1504 (HY000): Table has no partition for value NULL

Only rows having a 'c1' value between '0' and '8' inclusive can be
inserted into 'ts1'.  'NULL' falls outside this range, just like the
number '9'.  We can create tables 'ts2' and 'ts3' having value lists
containing 'NULL', as shown here:

     mysql> CREATE TABLE ts2 (
         ->     c1 INT,
         ->     c2 VARCHAR(20)
         -> )
         -> PARTITION BY LIST(c1) (
         ->     PARTITION p0 VALUES IN (0, 3, 6),
         ->     PARTITION p1 VALUES IN (1, 4, 7),
         ->     PARTITION p2 VALUES IN (2, 5, 8),
         ->     PARTITION p3 VALUES IN (NULL)
         -> );
     Query OK, 0 rows affected (0.01 sec)

     mysql> CREATE TABLE ts3 (
         ->     c1 INT,
         ->     c2 VARCHAR(20)
         -> )
         -> PARTITION BY LIST(c1) (
         ->     PARTITION p0 VALUES IN (0, 3, 6),
         ->     PARTITION p1 VALUES IN (1, 4, 7, NULL),
         ->     PARTITION p2 VALUES IN (2, 5, 8)
         -> );
     Query OK, 0 rows affected (0.01 sec)

When defining value lists for partitioning, you can (and should) treat
'NULL' just as you would any other value.  For example, both 'VALUES IN
(NULL)' and 'VALUES IN (1, 4, 7, NULL)' are valid, as are 'VALUES IN (1,
NULL, 4, 7)', 'VALUES IN (NULL, 1, 4, 7)', and so on.  You can insert a
row having 'NULL' for column 'c1' into each of the tables 'ts2' and
'ts3':

     mysql> INSERT INTO ts2 VALUES (NULL, 'mothra');
     Query OK, 1 row affected (0.00 sec)

     mysql> INSERT INTO ts3 VALUES (NULL, 'mothra');
     Query OK, 1 row affected (0.00 sec)

By issuing the appropriate query against *note
'INFORMATION_SCHEMA.PARTITIONS': partitions-table, you can determine
which partitions were used to store the rows just inserted (we assume,
as in the previous examples, that the partitioned tables were created in
the 'p' database):

     mysql> SELECT TABLE_NAME, PARTITION_NAME, TABLE_ROWS, AVG_ROW_LENGTH, DATA_LENGTH
          >   FROM INFORMATION_SCHEMA.PARTITIONS
          >   WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME LIKE 'ts_';
     +------------+----------------+------------+----------------+-------------+
     | TABLE_NAME | PARTITION_NAME | TABLE_ROWS | AVG_ROW_LENGTH | DATA_LENGTH |
     +------------+----------------+------------+----------------+-------------+
     | ts2        | p0             |          0 |              0 |           0 |
     | ts2        | p1             |          0 |              0 |           0 |
     | ts2        | p2             |          0 |              0 |           0 |
     _| ts2        | p3             |          1 |             20 |          20 |_
     | ts3        | p0             |          0 |              0 |           0 |
     _| ts3        | p1             |          1 |             20 |          20 |_
     | ts3        | p2             |          0 |              0 |           0 |
     +------------+----------------+------------+----------------+-------------+
     7 rows in set (0.01 sec)

As shown earlier in this section, you can also verify which partitions
were used for storing the rows by deleting these partitions and then
performing a *note 'SELECT': select.

Handling of NULL with HASH and KEY partitioning

'NULL' is handled somewhat differently for tables partitioned by 'HASH'
or 'KEY'.  In these cases, any partition expression that yields a 'NULL'
value is treated as though its return value were zero.  We can verify
this behavior by examining the effects on the file system of creating a
table partitioned by 'HASH' and populating it with a record containing
appropriate values.  Suppose that you have a table 'th' (also in the 'p'
database) created using the following statement:

     mysql> CREATE TABLE th (
         ->     c1 INT,
         ->     c2 VARCHAR(20)
         -> )
         -> PARTITION BY HASH(c1)
         -> PARTITIONS 2;
     Query OK, 0 rows affected (0.00 sec)

The partitions belonging to this table can be viewed using the query
shown here:

     mysql> SELECT TABLE_NAME,PARTITION_NAME,TABLE_ROWS,AVG_ROW_LENGTH,DATA_LENGTH
          >   FROM INFORMATION_SCHEMA.PARTITIONS
          >   WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME ='th';
     +------------+----------------+------------+----------------+-------------+
     | TABLE_NAME | PARTITION_NAME | TABLE_ROWS | AVG_ROW_LENGTH | DATA_LENGTH |
     +------------+----------------+------------+----------------+-------------+
     | th         | p0             |          0 |              0 |           0 |
     | th         | p1             |          0 |              0 |           0 |
     +------------+----------------+------------+----------------+-------------+
     2 rows in set (0.00 sec)

'TABLE_ROWS' for each partition is 0.  Now insert two rows into 'th'
whose 'c1' column values are 'NULL' and 0, and verify that these rows
were inserted, as shown here:

     mysql> INSERT INTO th VALUES (NULL, 'mothra'), (0, 'gigan');
     Query OK, 1 row affected (0.00 sec)

     mysql> SELECT * FROM th;
     +------+---------+
     | c1   | c2      |
     +------+---------+
     | NULL | mothra  |
     +------+---------+
     |    0 | gigan   |
     +------+---------+
     2 rows in set (0.01 sec)

Recall that for any integer N, the value of 'NULL MOD N' is always
'NULL'.  For tables that are partitioned by 'HASH' or 'KEY', this result
is treated for determining the correct partition as '0'.  Checking the
*note 'INFORMATION_SCHEMA.PARTITIONS': partitions-table. table once
again, we can see that both rows were inserted into partition 'p0':

     mysql> SELECT TABLE_NAME, PARTITION_NAME, TABLE_ROWS, AVG_ROW_LENGTH, DATA_LENGTH
          >   FROM INFORMATION_SCHEMA.PARTITIONS
          >   WHERE TABLE_SCHEMA = 'p' AND TABLE_NAME ='th';
     +------------+----------------+------------+----------------+-------------+
     | TABLE_NAME | PARTITION_NAME | TABLE_ROWS | AVG_ROW_LENGTH | DATA_LENGTH |
     +------------+----------------+------------+----------------+-------------+
     _| th         | p0             |          2 |             20 |          20 |_
     | th         | p1             |          0 |              0 |           0 |
     +------------+----------------+------------+----------------+-------------+
     2 rows in set (0.00 sec)

If you repeat this example using 'PARTITION BY KEY' in place of
'PARTITION BY HASH' in the definition of the table, you can verify
easily that 'NULL' is also treated like 0 for this type of partitioning.


File: manual.info.tmp,  Node: partitioning-management,  Next: partitioning-pruning,  Prev: partitioning-types,  Up: partitioning

19.3 Partition Management
=========================

* Menu:

* partitioning-management-range-list::  Management of RANGE and LIST Partitions
* partitioning-management-hash-key::  Management of HASH and KEY Partitions
* partitioning-maintenance::     Maintenance of Partitions
* partitioning-info::            Obtaining Information About Partitions

MySQL 5.5 provides a number of ways to modify partitioned tables.  It is
possible to add, drop, redefine, merge, or split existing partitions.
All of these actions can be carried out using the partitioning
extensions to the *note 'ALTER TABLE': alter-table-partition-operations.
statement.  There are also ways to obtain information about partitioned
tables and partitions.  We discuss these topics in the sections that
follow.

   * For information about partition management in tables partitioned by
     'RANGE' or 'LIST', see *note partitioning-management-range-list::.

   * For a discussion of managing 'HASH' and 'KEY' partitions, see *note
     partitioning-management-hash-key::.

   * See *note partitioning-info::, for a discussion of mechanisms
     provided in MySQL 5.5 for obtaining information about partitioned
     tables and partitions.

   * For a discussion of performing maintenance operations on
     partitions, see *note partitioning-maintenance::.

*Note*:

In MySQL 5.5, all partitions of a partitioned table must have the same
number of subpartitions, and it is not possible to change the
subpartitioning once the table has been created.

To change a table's partitioning scheme, it is necessary only to use the
*note 'ALTER TABLE': alter-table-partition-operations. statement with a
PARTITION_OPTIONS clause.  This clause has the same syntax as that as
used with *note 'CREATE TABLE': create-table. for creating a partitioned
table, and always begins with the keywords 'PARTITION BY'.  Suppose that
you have a table partitioned by range using the following *note 'CREATE
TABLE': create-table. statement:

     CREATE TABLE trb3 (id INT, name VARCHAR(50), purchased DATE)
         PARTITION BY RANGE( YEAR(purchased) ) (
             PARTITION p0 VALUES LESS THAN (1990),
             PARTITION p1 VALUES LESS THAN (1995),
             PARTITION p2 VALUES LESS THAN (2000),
             PARTITION p3 VALUES LESS THAN (2005)
         );

To repartition this table so that it is partitioned by key into two
partitions using the 'id' column value as the basis for the key, you can
use this statement:

     ALTER TABLE trb3 PARTITION BY KEY(id) PARTITIONS 2;

This has the same effect on the structure of the table as dropping the
table and re-creating it using 'CREATE TABLE trb3 PARTITION BY KEY(id)
PARTITIONS 2;'.

'ALTER TABLE ... ENGINE = ...' changes only the storage engine used by
the table, and leaves the table's partitioning scheme intact.  Use
'ALTER TABLE ... REMOVE PARTITIONING' to remove a table's partitioning.
See *note alter-table::.

*Important*:

Only a single 'PARTITION BY', 'ADD PARTITION', 'DROP PARTITION',
'REORGANIZE PARTITION', or 'COALESCE PARTITION' clause can be used in a
given *note 'ALTER TABLE': alter-table-partition-operations. statement.
If you (for example) wish to drop a partition and reorganize a table's
remaining partitions, you must do so in two separate *note 'ALTER
TABLE': alter-table-partition-operations. statements (one using 'DROP
PARTITION' and then a second one using 'REORGANIZE PARTITION').

Beginning with MySQL 5.5.0, it is possible to delete all rows from one
or more selected partitions using *note 'ALTER TABLE ... TRUNCATE
PARTITION': alter-table.


File: manual.info.tmp,  Node: partitioning-management-range-list,  Next: partitioning-management-hash-key,  Prev: partitioning-management,  Up: partitioning-management

19.3.1 Management of RANGE and LIST Partitions
----------------------------------------------

Adding and dropping of range and list partitions are handled in a
similar fashion, so we discuss the management of both sorts of
partitioning in this section.  For information about working with tables
that are partitioned by hash or key, see *note
partitioning-management-hash-key::.

Dropping a partition from a table that is partitioned by either 'RANGE'
or by 'LIST' can be accomplished using the *note 'ALTER TABLE':
alter-table-partition-operations. statement with the 'DROP PARTITION'
option.  Suppose that you have created a table that is partitioned by
range and then populated with 10 records using the following *note
'CREATE TABLE': create-table. and *note 'INSERT': insert. statements:

     mysql> CREATE TABLE tr (id INT, name VARCHAR(50), purchased DATE)
         ->     PARTITION BY RANGE( YEAR(purchased) ) (
         ->         PARTITION p0 VALUES LESS THAN (1990),
         ->         PARTITION p1 VALUES LESS THAN (1995),
         ->         PARTITION p2 VALUES LESS THAN (2000),
         ->         PARTITION p3 VALUES LESS THAN (2005),
         ->         PARTITION p4 VALUES LESS THAN (2010),
         ->         PARTITION p5 VALUES LESS THAN (2015)
         ->     );
     Query OK, 0 rows affected (0.28 sec)

     mysql> INSERT INTO tr VALUES
         ->     (1, 'desk organiser', '2003-10-15'),
         ->     (2, 'alarm clock', '1997-11-05'),
         ->     (3, 'chair', '2009-03-10'),
         ->     (4, 'bookcase', '1989-01-10'),
         ->     (5, 'exercise bike', '2014-05-09'),
         ->     (6, 'sofa', '1987-06-05'),
         ->     (7, 'espresso maker', '2011-11-22'),
         ->     (8, 'aquarium', '1992-08-04'),
         ->     (9, 'study desk', '2006-09-16'),
         ->     (10, 'lava lamp', '1998-12-25');
     Query OK, 10 rows affected (0.05 sec)
     Records: 10  Duplicates: 0  Warnings: 0

You can see which items should have been inserted into partition 'p2' as
shown here:

     mysql> SELECT * FROM tr
         ->     WHERE purchased BETWEEN '1995-01-01' AND '1999-12-31';
     +------+-------------+------------+
     | id   | name        | purchased  |
     +------+-------------+------------+
     |    2 | alarm clock | 1997-11-05 |
     |   10 | lava lamp   | 1998-12-25 |
     +------+-------------+------------+
     2 rows in set (0.00 sec)

To drop the partition named 'p2', execute the following command:

     mysql> ALTER TABLE tr DROP PARTITION p2;
     Query OK, 0 rows affected (0.03 sec)

*Note*:

The *note 'NDBCLUSTER': mysql-cluster. storage engine does not support
'ALTER TABLE ... DROP PARTITION'.  It does, however, support the other
partitioning-related extensions to *note 'ALTER TABLE':
alter-table-partition-operations. that are described in this chapter.

It is very important to remember that, _when you drop a partition, you
also delete all the data that was stored in that partition_.  You can
see that this is the case by re-running the previous *note 'SELECT':
select. query:

     mysql> SELECT * FROM tr WHERE purchased
         -> BETWEEN '1995-01-01' AND '1999-12-31';
     Empty set (0.00 sec)

Because of this, you must have the 'DROP' privilege for a table before
you can execute 'ALTER TABLE ... DROP PARTITION' on that table.

If you wish to drop all data from all partitions while preserving the
table definition and its partitioning scheme, use the *note 'TRUNCATE
TABLE': truncate-table. statement.  (See *note truncate-table::.)

If you intend to change the partitioning of a table _without_ losing
data, use 'ALTER TABLE ... REORGANIZE PARTITION' instead.  See below or
in *note alter-table::, for information about 'REORGANIZE PARTITION'.

If you now execute a *note 'SHOW CREATE TABLE': show-create-table.
statement, you can see how the partitioning makeup of the table has been
changed:

     mysql> SHOW CREATE TABLE tr\G
     *************************** 1. row ***************************
            Table: tr
     Create Table: CREATE TABLE `tr` (
       `id` int(11) DEFAULT NULL,
       `name` varchar(50) DEFAULT NULL,
       `purchased` date DEFAULT NULL
     ) ENGINE=InnoDB DEFAULT CHARSET=latin1
     /*!50100 PARTITION BY RANGE ( YEAR(purchased))
     (PARTITION p0 VALUES LESS THAN (1990) ENGINE = InnoDB,
      PARTITION p1 VALUES LESS THAN (1995) ENGINE = InnoDB,
      PARTITION p3 VALUES LESS THAN (2005) ENGINE = InnoDB,
      PARTITION p4 VALUES LESS THAN (2010) ENGINE = InnoDB,
      PARTITION p5 VALUES LESS THAN (2015) ENGINE = InnoDB) */
     1 row in set (0.00 sec)

When you insert new rows into the changed table with 'purchased' column
values between ''1995-01-01'' and ''2004-12-31'' inclusive, those rows
will be stored in partition 'p3'.  You can verify this as follows:

     mysql> INSERT INTO tr VALUES (11, 'pencil holder', '1995-07-12');
     Query OK, 1 row affected (0.00 sec)

     mysql> SELECT * FROM tr WHERE purchased
         -> BETWEEN '1995-01-01' AND '2004-12-31';
     +------+----------------+------------+
     | id   | name           | purchased  |
     +------+----------------+------------+
     |    1 | desk organiser | 2003-10-15 |
     |   11 | pencil holder  | 1995-07-12 |
     +------+----------------+------------+
     2 rows in set (0.00 sec)

     mysql> ALTER TABLE tr DROP PARTITION p3;
     Query OK, 0 rows affected (0.03 sec)

     mysql> SELECT * FROM tr WHERE purchased
         -> BETWEEN '1995-01-01' AND '2004-12-31';
     Empty set (0.00 sec)

The number of rows dropped from the table as a result of 'ALTER TABLE
... DROP PARTITION' is not reported by the server as it would be by the
equivalent *note 'DELETE': delete. query.

Dropping 'LIST' partitions uses exactly the same 'ALTER TABLE ... DROP
PARTITION' syntax as used for dropping 'RANGE' partitions.  However,
there is one important difference in the effect this has on your use of
the table afterward: You can no longer insert into the table any rows
having any of the values that were included in the value list defining
the deleted partition.  (See *note partitioning-list::, for an example.)

To add a new range or list partition to a previously partitioned table,
use the 'ALTER TABLE ... ADD PARTITION' statement.  For tables which are
partitioned by 'RANGE', this can be used to add a new range to the end
of the list of existing partitions.  Suppose that you have a partitioned
table containing membership data for your organization, which is defined
as follows:

     CREATE TABLE members (
         id INT,
         fname VARCHAR(25),
         lname VARCHAR(25),
         dob DATE
     )
     PARTITION BY RANGE( YEAR(dob) ) (
         PARTITION p0 VALUES LESS THAN (1980),
         PARTITION p1 VALUES LESS THAN (1990),
         PARTITION p2 VALUES LESS THAN (2000)
     );

Suppose further that the minimum age for members is 16.  As the calendar
approaches the end of 2015, you realize that you will soon be admitting
members who were born in 2000 (and later).  You can modify the 'members'
table to accommodate new members born in the years 2000 to 2010 as shown
here:

     ALTER TABLE members ADD PARTITION (PARTITION p3 VALUES LESS THAN (2010));

With tables that are partitioned by range, you can use 'ADD PARTITION'
to add new partitions to the high end of the partitions list only.
Trying to add a new partition in this manner between or before existing
partitions results in an error as shown here:

     mysql> ALTER TABLE members
          >     ADD PARTITION (
          >     PARTITION n VALUES LESS THAN (1970));
     ERROR 1463 (HY000): VALUES LESS THAN value must be strictly 
        increasing for each partition

You can work around this problem by reorganizing the first partition
into two new ones that split the range between them, like this:

     ALTER TABLE members
         REORGANIZE PARTITION p0 INTO (
             PARTITION n0 VALUES LESS THAN (1970),
             PARTITION n1 VALUES LESS THAN (1980)
     );

Using *note 'SHOW CREATE TABLE': show-create-table. you can see that the
'ALTER TABLE' statement has had the desired effect:

     mysql> SHOW CREATE TABLE members\G
     *************************** 1. row ***************************
            Table: members
     Create Table: CREATE TABLE `members` (
       `id` int(11) DEFAULT NULL,
       `fname` varchar(25) DEFAULT NULL,
       `lname` varchar(25) DEFAULT NULL,
       `dob` date DEFAULT NULL
     ) ENGINE=InnoDB DEFAULT CHARSET=latin1
     /*!50100 PARTITION BY RANGE ( YEAR(dob))
     (PARTITION n0 VALUES LESS THAN (1970) ENGINE = InnoDB,
      PARTITION n1 VALUES LESS THAN (1980) ENGINE = InnoDB,
      PARTITION p1 VALUES LESS THAN (1990) ENGINE = InnoDB,
      PARTITION p2 VALUES LESS THAN (2000) ENGINE = InnoDB,
      PARTITION p3 VALUES LESS THAN (2010) ENGINE = InnoDB) */
     1 row in set (0.00 sec)

See also *note alter-table-partition-operations::.

You can also use 'ALTER TABLE ... ADD PARTITION' to add new partitions
to a table that is partitioned by 'LIST'.  Suppose a table 'tt' is
defined using the following *note 'CREATE TABLE': create-table.
statement:

     CREATE TABLE tt (
         id INT,
         data INT
     )
     PARTITION BY LIST(data) (
         PARTITION p0 VALUES IN (5, 10, 15),
         PARTITION p1 VALUES IN (6, 12, 18)
     );

You can add a new partition in which to store rows having the 'data'
column values '7', '14', and '21' as shown:

     ALTER TABLE tt ADD PARTITION (PARTITION p2 VALUES IN (7, 14, 21));

Keep in mind that you _cannot_ add a new 'LIST' partition encompassing
any values that are already included in the value list of an existing
partition.  If you attempt to do so, an error will result:

     mysql> ALTER TABLE tt ADD PARTITION
          >     (PARTITION np VALUES IN (4, 8, 12));
     ERROR 1465 (HY000): Multiple definition of same constant 
                         in list partitioning

Because any rows with the 'data' column value '12' have already been
assigned to partition 'p1', you cannot create a new partition on table
'tt' that includes '12' in its value list.  To accomplish this, you
could drop 'p1', and add 'np' and then a new 'p1' with a modified
definition.  However, as discussed earlier, this would result in the
loss of all data stored in 'p1'--and it is often the case that this is
not what you really want to do.  Another solution might appear to be to
make a copy of the table with the new partitioning and to copy the data
into it using *note 'CREATE TABLE ... SELECT ...': create-table, then
drop the old table and rename the new one, but this could be very
time-consuming when dealing with a large amounts of data.  This also
might not be feasible in situations where high availability is a
requirement.

You can add multiple partitions in a single 'ALTER TABLE ... ADD
PARTITION' statement as shown here:

     CREATE TABLE employees (
       id INT NOT NULL,
       fname VARCHAR(50) NOT NULL,
       lname VARCHAR(50) NOT NULL,
       hired DATE NOT NULL
     )
     PARTITION BY RANGE( YEAR(hired) ) (
       PARTITION p1 VALUES LESS THAN (1991),
       PARTITION p2 VALUES LESS THAN (1996),
       PARTITION p3 VALUES LESS THAN (2001),
       PARTITION p4 VALUES LESS THAN (2005)
     );

     ALTER TABLE employees ADD PARTITION (
         PARTITION p5 VALUES LESS THAN (2010),
         PARTITION p6 VALUES LESS THAN MAXVALUE
     );

Fortunately, MySQL's partitioning implementation provides ways to
redefine partitions without losing data.  Let us look first at a couple
of simple examples involving 'RANGE' partitioning.  Recall the 'members'
table which is now defined as shown here:

     mysql> SHOW CREATE TABLE members\G
     *************************** 1. row ***************************
            Table: members
     Create Table: CREATE TABLE `members` (
       `id` int(11) DEFAULT NULL,
       `fname` varchar(25) DEFAULT NULL,
       `lname` varchar(25) DEFAULT NULL,
       `dob` date DEFAULT NULL
     ) ENGINE=InnoDB DEFAULT CHARSET=latin1
     /*!50100 PARTITION BY RANGE ( YEAR(dob))
     (PARTITION n0 VALUES LESS THAN (1970) ENGINE = InnoDB,
      PARTITION n1 VALUES LESS THAN (1980) ENGINE = InnoDB,
      PARTITION p1 VALUES LESS THAN (1990) ENGINE = InnoDB,
      PARTITION p2 VALUES LESS THAN (2000) ENGINE = InnoDB,
      PARTITION p3 VALUES LESS THAN (2010) ENGINE = InnoDB) */
     1 row in set (0.00 sec)

Suppose that you would like to move all rows representing members born
before 1960 into a separate partition.  As we have already seen, this
cannot be done using *note 'ALTER TABLE ... ADD PARTITION':
alter-table-partition-operations.  However, you can use another
partition-related extension to *note 'ALTER TABLE':
alter-table-partition-operations. to accomplish this:

     ALTER TABLE members REORGANIZE PARTITION n0 INTO (
         PARTITION s0 VALUES LESS THAN (1960),
         PARTITION s1 VALUES LESS THAN (1970)
     );

In effect, this command splits partition 'p0' into two new partitions
's0' and 's1'.  It also moves the data that was stored in 'p0' into the
new partitions according to the rules embodied in the two 'PARTITION ...
VALUES ...' clauses, so that 's0' contains only those records for which
'YEAR(dob)' is less than 1960 and 's1' contains those rows in which
'YEAR(dob)' is greater than or equal to 1960 but less than 1970.

A 'REORGANIZE PARTITION' clause may also be used for merging adjacent
partitions.  You can reverse the effect of the previous statement on the
'members' table as shown here:

     ALTER TABLE members REORGANIZE PARTITION s0,s1 INTO (
         PARTITION p0 VALUES LESS THAN (1970)
     );

No data is lost in splitting or merging partitions using 'REORGANIZE
PARTITION'.  In executing the above statement, MySQL moves all of the
records that were stored in partitions 's0' and 's1' into partition
'p0'.

The general syntax for 'REORGANIZE PARTITION' is shown here:

     ALTER TABLE TBL_NAME
         REORGANIZE PARTITION PARTITION_LIST
         INTO (PARTITION_DEFINITIONS);

Here, TBL_NAME is the name of the partitioned table, and PARTITION_LIST
is a comma-separated list of names of one or more existing partitions to
be changed.  PARTITION_DEFINITIONS is a comma-separated list of new
partition definitions, which follow the same rules as for the
PARTITION_DEFINITIONS list used in *note 'CREATE TABLE': create-table.
You are not limited to merging several partitions into one, or to
splitting one partition into many, when using 'REORGANIZE PARTITION'.
For example, you can reorganize all four partitions of the 'members'
table into two, like this:

     ALTER TABLE members REORGANIZE PARTITION p0,p1,p2,p3 INTO (
         PARTITION m0 VALUES LESS THAN (1980),
         PARTITION m1 VALUES LESS THAN (2000)
     );

You can also use 'REORGANIZE PARTITION' with tables that are partitioned
by 'LIST'.  Let us return to the problem of adding a new partition to
the list-partitioned 'tt' table and failing because the new partition
had a value that was already present in the value-list of one of the
existing partitions.  We can handle this by adding a partition that
contains only nonconflicting values, and then reorganizing the new
partition and the existing one so that the value which was stored in the
existing one is now moved to the new one:

     ALTER TABLE tt ADD PARTITION (PARTITION np VALUES IN (4, 8));
     ALTER TABLE tt REORGANIZE PARTITION p1,np INTO (
         PARTITION p1 VALUES IN (6, 18),
         PARTITION np VALUES in (4, 8, 12)
     );

Here are some key points to keep in mind when using 'ALTER TABLE ...
REORGANIZE PARTITION' to repartition tables that are partitioned by
'RANGE' or 'LIST':

   * The 'PARTITION' options used to determine the new partitioning
     scheme are subject to the same rules as those used with a *note
     'CREATE TABLE': create-table. statement.

     A new 'RANGE' partitioning scheme cannot have any overlapping
     ranges; a new 'LIST' partitioning scheme cannot have any
     overlapping sets of values.

   * The combination of partitions in the PARTITION_DEFINITIONS list
     should account for the same range or set of values overall as the
     combined partitions named in the PARTITION_LIST.

     For example, partitions 'p1' and 'p2' together cover the years 1980
     through 1999 in the 'members' table used as an example in this
     section.  Any reorganization of these two partitions should cover
     the same range of years overall.

   * For tables partitioned by 'RANGE', you can reorganize only adjacent
     partitions; you cannot skip range partitions.

     For instance, you could not reorganize the example 'members' table
     using a statement beginning with 'ALTER TABLE members REORGANIZE
     PARTITION p0,p2 INTO ...' because 'p0' covers the years prior to
     1970 and 'p2' the years from 1990 through 1999 inclusive, so these
     are not adjacent partitions.  (You cannot skip partition 'p1' in
     this case.)

   * You cannot use 'REORGANIZE PARTITION' to change the type of
     partitioning used by the table (for example, you cannot change
     'RANGE' partitions to 'HASH' partitions or the reverse).  You also
     cannot use this statement to change the partitioning expression or
     column.  To accomplish either of these tasks without dropping and
     re-creating the table, you can use *note 'ALTER TABLE ... PARTITION
     BY ...': alter-table-partition-operations, as shown here:

          ALTER TABLE members
              PARTITION BY HASH( YEAR(dob) )
              PARTITIONS 8;


File: manual.info.tmp,  Node: partitioning-management-hash-key,  Next: partitioning-maintenance,  Prev: partitioning-management-range-list,  Up: partitioning-management

19.3.2 Management of HASH and KEY Partitions
--------------------------------------------

Tables which are partitioned by hash or by key are very similar to one
another with regard to making changes in a partitioning setup, and both
differ in a number of ways from tables which have been partitioned by
range or list.  For that reason, this section addresses the modification
of tables partitioned by hash or by key only.  For a discussion of
adding and dropping of partitions of tables that are partitioned by
range or list, see *note partitioning-management-range-list::.

You cannot drop partitions from tables that are partitioned by 'HASH' or
'KEY' in the same way that you can from tables that are partitioned by
'RANGE' or 'LIST'.  However, you can merge 'HASH' or 'KEY' partitions
using the 'ALTER TABLE ... COALESCE PARTITION' statement.  Suppose that
you have a table containing data about clients, which is divided into
twelve partitions.  The 'clients' table is defined as shown here:

     CREATE TABLE clients (
         id INT,
         fname VARCHAR(30),
         lname VARCHAR(30),
         signed DATE
     )
     PARTITION BY HASH( MONTH(signed) )
     PARTITIONS 12;

To reduce the number of partitions from twelve to eight, execute the
following *note 'ALTER TABLE': alter-table-partition-operations.
command:

     mysql> ALTER TABLE clients COALESCE PARTITION 4;
     Query OK, 0 rows affected (0.02 sec)

'COALESCE' works equally well with tables that are partitioned by
'HASH', 'KEY', 'LINEAR HASH', or 'LINEAR KEY'.  Here is an example
similar to the previous one, differing only in that the table is
partitioned by 'LINEAR KEY':

     mysql> CREATE TABLE clients_lk (
         ->     id INT,
         ->     fname VARCHAR(30),
         ->     lname VARCHAR(30),
         ->     signed DATE
         -> )
         -> PARTITION BY LINEAR KEY(signed)
         -> PARTITIONS 12;
     Query OK, 0 rows affected (0.03 sec)

     mysql> ALTER TABLE clients_lk COALESCE PARTITION 4;
     Query OK, 0 rows affected (0.06 sec)
     Records: 0  Duplicates: 0  Warnings: 0

The number following 'COALESCE PARTITION' is the number of partitions to
merge into the remainder--in other words, it is the number of partitions
to remove from the table.

If you attempt to remove more partitions than the table has, the result
is an error like the one shown:

     mysql> ALTER TABLE clients COALESCE PARTITION 18;
     ERROR 1478 (HY000): Cannot remove all partitions, use DROP TABLE instead

To increase the number of partitions for the 'clients' table from 12 to
18.  use 'ALTER TABLE ... ADD PARTITION' as shown here:

     ALTER TABLE clients ADD PARTITION PARTITIONS 6;


File: manual.info.tmp,  Node: partitioning-maintenance,  Next: partitioning-info,  Prev: partitioning-management-hash-key,  Up: partitioning-management

19.3.3 Maintenance of Partitions
--------------------------------

A number of table and partition maintenance tasks can be carried out
using SQL statements intended for such purposes on partitioned tables in
MySQL 5.5.

Table maintenance of partitioned tables can be accomplished using the
statements *note 'CHECK TABLE': check-table, *note 'OPTIMIZE TABLE':
optimize-table, *note 'ANALYZE TABLE': analyze-table, and *note 'REPAIR
TABLE': repair-table, which are supported for partitioned tables.

You can use a number of extensions to *note 'ALTER TABLE':
alter-table-partition-operations. for performing operations of this type
on one or more partitions directly, as described in the following list:

   * Rebuilding partitions

     Rebuilds the partition; this has the same effect as dropping all
     records stored in the partition, then reinserting them.  This can
     be useful for purposes of defragmentation.

     Example:

          ALTER TABLE t1 REBUILD PARTITION p0, p1;

   * Optimizing partitions

     If you have deleted a large number of rows from a partition or if
     you have made many changes to a partitioned table with
     variable-length rows (that is, having *note 'VARCHAR': char, *note
     'BLOB': blob, or *note 'TEXT': blob. columns), you can use *note
     'ALTER TABLE ... OPTIMIZE PARTITION':
     alter-table-partition-operations. to reclaim any unused space and
     to defragment the partition data file.

     Example:

          ALTER TABLE t1 OPTIMIZE PARTITION p0, p1;

     Using 'OPTIMIZE PARTITION' on a given partition is equivalent to
     running 'CHECK PARTITION', 'ANALYZE PARTITION', and 'REPAIR
     PARTITION' on that partition.

     Some MySQL storage engines, including *note 'InnoDB':
     innodb-storage-engine, do not support per-partition optimization;
     in these cases, *note 'ALTER TABLE ... OPTIMIZE PARTITION':
     alter-table-partition-operations. rebuilds the entire table.  In
     MySQL 5.5.30 and later, running this statement on such a table
     causes the entire table to rebuilt and analyzed, and an appropriate
     warning to be issued.  (Bug #11751825, Bug #42822) Use 'ALTER TABLE
     ... REBUILD PARTITION' and 'ALTER TABLE ... ANALYZE PARTITION'
     instead, to avoid this issue.

   * Analyzing partitions

     This reads and stores the key distributions for partitions.

     Example:

          ALTER TABLE t1 ANALYZE PARTITION p3;

   * Repairing partitions

     This repairs corrupted partitions.

     Example:

          ALTER TABLE t1 REPAIR PARTITION p0,p1;

   * Checking partitions

     You can check partitions for errors in much the same way that you
     can use *note 'CHECK TABLE': check-table. with nonpartitioned
     tables.

     Example:

          ALTER TABLE trb3 CHECK PARTITION p1;

     This command will tell you if the data or indexes in partition 'p1'
     of table 't1' are corrupted.  If this is the case, use *note 'ALTER
     TABLE ... REPAIR PARTITION': alter-table-partition-operations. to
     repair the partition.

Each of the statements in the list just shown also supports the keyword
'ALL' in place of the list of partition names.  Using 'ALL' causes the
statement to act on all partitions in the table.

The use of *note 'mysqlcheck': mysqlcheck. and *note 'myisamchk':
myisamchk. is not supported with partitioned tables.

Beginning with MySQL 5.5.0, you can also truncate partitions using *note
'ALTER TABLE ... TRUNCATE PARTITION': alter-table-partition-operations.
This statement can be used to delete all rows from one or more
partitions in much the same way that *note 'TRUNCATE TABLE':
truncate-table. deletes all rows from a table.

'ALTER TABLE ... TRUNCATE PARTITION ALL' truncates all partitions in the
table.

'ANALYZE', 'CHECK', 'OPTIMIZE', 'REBUILD', 'REPAIR', and 'TRUNCATE'
operations are not supported for subpartitions.


File: manual.info.tmp,  Node: partitioning-info,  Prev: partitioning-maintenance,  Up: partitioning-management

19.3.4 Obtaining Information About Partitions
---------------------------------------------

This section discusses obtaining information about existing partitions,
which can be done in a number of ways.  Methods of obtaining such
information include the following:

   * Using the *note 'SHOW CREATE TABLE': show-create-table. statement
     to view the partitioning clauses used in creating a partitioned
     table.

   * Using the *note 'SHOW TABLE STATUS': show-table-status. statement
     to determine whether a table is partitioned.

   * Querying the *note 'INFORMATION_SCHEMA.PARTITIONS':
     partitions-table. table.

   * Using the statement *note 'EXPLAIN PARTITIONS SELECT': explain. to
     see which partitions are used by a given *note 'SELECT': select.

As discussed elsewhere in this chapter, *note 'SHOW CREATE TABLE':
show-create-table. includes in its output the 'PARTITION BY' clause used
to create a partitioned table.  For example:

     mysql> SHOW CREATE TABLE trb3\G
     *************************** 1. row ***************************
            Table: trb3
     Create Table: CREATE TABLE `trb3` (
       `id` int(11) default NULL,
       `name` varchar(50) default NULL,
       `purchased` date default NULL
     ) ENGINE=MyISAM DEFAULT CHARSET=latin1
     PARTITION BY RANGE (YEAR(purchased)) (
       PARTITION p0 VALUES LESS THAN (1990) ENGINE = MyISAM,
       PARTITION p1 VALUES LESS THAN (1995) ENGINE = MyISAM,
       PARTITION p2 VALUES LESS THAN (2000) ENGINE = MyISAM,
       PARTITION p3 VALUES LESS THAN (2005) ENGINE = MyISAM
     )
     1 row in set (0.00 sec)

The output from *note 'SHOW TABLE STATUS': show-table-status. for
partitioned tables is the same as that for nonpartitioned tables, except
that the 'Create_options' column contains the string 'partitioned'.  The
'Engine' column contains the name of the storage engine used by all
partitions of the table.  (See *note show-table-status::, for more
information about this statement.)

You can also obtain information about partitions from
'INFORMATION_SCHEMA', which contains a *note 'PARTITIONS':
partitions-table. table.  See *note partitions-table::.

It is possible to determine which partitions of a partitioned table are
involved in a given *note 'SELECT': select. query using *note 'EXPLAIN
PARTITIONS': explain.  The 'PARTITIONS' keyword adds a 'partitions'
column to the output of *note 'EXPLAIN': explain. listing the partitions
from which records would be matched by the query.

Suppose that you have a table 'trb1' created and populated as follows:

     CREATE TABLE trb1 (id INT, name VARCHAR(50), purchased DATE)
         PARTITION BY RANGE(id)
         (
             PARTITION p0 VALUES LESS THAN (3),
             PARTITION p1 VALUES LESS THAN (7),
             PARTITION p2 VALUES LESS THAN (9),
             PARTITION p3 VALUES LESS THAN (11)
         );

     INSERT INTO trb1 VALUES
         (1, 'desk organiser', '2003-10-15'),
         (2, 'CD player', '1993-11-05'),
         (3, 'TV set', '1996-03-10'),
         (4, 'bookcase', '1982-01-10'),
         (5, 'exercise bike', '2004-05-09'),
         (6, 'sofa', '1987-06-05'),
         (7, 'popcorn maker', '2001-11-22'),
         (8, 'aquarium', '1992-08-04'),
         (9, 'study desk', '1984-09-16'),
         (10, 'lava lamp', '1998-12-25');

You can see which partitions are used in a query such as 'SELECT * FROM
trb1;', as shown here:

     mysql> EXPLAIN PARTITIONS SELECT * FROM trb1\G
     *************************** 1. row ***************************
                id: 1
       select_type: SIMPLE
             table: trb1
        partitions: p0,p1,p2,p3
              type: ALL
     possible_keys: NULL
               key: NULL
           key_len: NULL
               ref: NULL
              rows: 10
             Extra: Using filesort

In this case, all four partitions are searched.  However, when a
limiting condition making use of the partitioning key is added to the
query, you can see that only those partitions containing matching values
are scanned, as shown here:

     mysql> EXPLAIN PARTITIONS SELECT * FROM trb1 WHERE id < 5\G
     *************************** 1. row ***************************
                id: 1
       select_type: SIMPLE
             table: trb1
        partitions: p0,p1
              type: ALL
     possible_keys: NULL
               key: NULL
           key_len: NULL
               ref: NULL
              rows: 10
             Extra: Using where

*note 'EXPLAIN PARTITIONS': explain. provides information about keys
used and possible keys, just as with the standard *note 'EXPLAIN
SELECT': explain. statement:

     mysql> ALTER TABLE trb1 ADD PRIMARY KEY (id);
     Query OK, 10 rows affected (0.03 sec)
     Records: 10  Duplicates: 0  Warnings: 0

     mysql> EXPLAIN PARTITIONS SELECT * FROM trb1 WHERE id < 5\G
     *************************** 1. row ***************************
                id: 1
       select_type: SIMPLE
             table: trb1
        partitions: p0,p1
              type: range
     possible_keys: PRIMARY
               key: PRIMARY
           key_len: 4
               ref: NULL
              rows: 7
             Extra: Using where

You should take note of the following restrictions and limitations on
*note 'EXPLAIN PARTITIONS': explain.:

   * You cannot use the 'PARTITIONS' and 'EXTENDED' keywords together in
     the same *note 'EXPLAIN ... SELECT': explain. statement.
     Attempting to do so produces a syntax error.

   * If *note 'EXPLAIN PARTITIONS': explain. is used to examine a query
     against a nonpartitioned table, no error is produced, but the value
     of the 'partitions' column is always 'NULL'.

The 'rows' column of *note 'EXPLAIN PARTITIONS': explain. output
displays the total number of rows in the table.

See also *note explain::.


File: manual.info.tmp,  Node: partitioning-pruning,  Next: partitioning-limitations,  Prev: partitioning-management,  Up: partitioning

19.4 Partition Pruning
======================

This section discusses an optimization known as _partition pruning_.
The core concept behind partition pruning is relatively simple, and can
be described as 'Do not scan partitions where there can be no matching
values'.  Suppose that you have a partitioned table 't1' defined by this
statement:

     CREATE TABLE t1 (
         fname VARCHAR(50) NOT NULL,
         lname VARCHAR(50) NOT NULL,
         region_code TINYINT UNSIGNED NOT NULL,
         dob DATE NOT NULL
     )
     PARTITION BY RANGE( region_code ) (
         PARTITION p0 VALUES LESS THAN (64),
         PARTITION p1 VALUES LESS THAN (128),
         PARTITION p2 VALUES LESS THAN (192),
         PARTITION p3 VALUES LESS THAN MAXVALUE
     );

Consider the case where you wish to obtain results from a *note
'SELECT': select. statement such as this one:

     SELECT fname, lname, region_code, dob
         FROM t1
         WHERE region_code > 125 AND region_code < 130;

It is easy to see that none of the rows which ought to be returned will
be in either of the partitions 'p0' or 'p3'; that is, we need to search
only in partitions 'p1' and 'p2' to find matching rows.  By doing so, it
is possible to expend much less time and effort in finding matching rows
than would be required to scan all partitions in the table.  This
'cutting away' of unneeded partitions is known as _pruning_.  When the
optimizer can make use of partition pruning in performing this query,
execution of the query can be an order of magnitude faster than the same
query against a nonpartitioned table containing the same column
definitions and data.

*Note*:

When pruning is performed on a partitioned *note 'MyISAM':
myisam-storage-engine. table, all partitions are opened, whether or not
they are examined, due to the design of the 'MyISAM' storage engine.
This means that you must have a sufficient number of file descriptors
available to cover all partitions of the table.  See *note
partitioning-limitations-myisam-file-descriptors::.

This limitation does not apply to partitioned tables using other MySQL
storage engines such as *note 'InnoDB': innodb-storage-engine.

The optimizer can perform pruning whenever a 'WHERE' condition can be
reduced to either one of the following two cases:

   * 'PARTITION_COLUMN = CONSTANT'

   * 'PARTITION_COLUMN IN (CONSTANT1, CONSTANT2, ..., CONSTANTN)'

In the first case, the optimizer simply evaluates the partitioning
expression for the value given, determines which partition contains that
value, and scans only this partition.  In many cases, the equal sign can
be replaced with another arithmetic comparison, including '<', '>',
'<=', '>=', and '<>'.  Some queries using 'BETWEEN' in the 'WHERE'
clause can also take advantage of partition pruning.  See the examples
later in this section.

In the second case, the optimizer evaluates the partitioning expression
for each value in the list, creates a list of matching partitions, and
then scans only the partitions in this partition list.

MySQL 5.5 and later can apply partition pruning to *note 'SELECT':
select, *note 'DELETE': delete, and *note 'UPDATE': update. statements.
An *note 'INSERT': insert. statement also accesses only one partition
per inserted row; this is true even for a table that is partitioned by
'HASH' or 'KEY' although this is not currently shown in the output of
*note 'EXPLAIN': explain.

Pruning can also be applied to short ranges, which the optimizer can
convert into equivalent lists of values.  For instance, in the previous
example, the 'WHERE' clause can be converted to 'WHERE region_code IN
(126, 127, 128, 129)'.  Then the optimizer can determine that the first
two values in the list are found in partition 'p1', the remaining two
values in partition 'p2', and that the other partitions contain no
relevant values and so do not need to be searched for matching rows.

Beginning with MySQL 5.5.0, the optimizer can also perform pruning for
'WHERE' conditions that involve comparisons of the preceding types on
multiple columns for tables that use 'RANGE COLUMNS' or 'LIST COLUMNS'
partitioning.

This type of optimization can be applied whenever the partitioning
expression consists of an equality or a range which can be reduced to a
set of equalities, or when the partitioning expression represents an
increasing or decreasing relationship.  Pruning can also be applied for
tables partitioned on a *note 'DATE': datetime. or *note 'DATETIME':
datetime. column when the partitioning expression uses the 'YEAR()' or
'TO_DAYS()' function.  In addition, in MySQL 5.5, pruning can be applied
for such tables when the partitioning expression uses the 'TO_SECONDS()'
function.

Suppose that table 't2', defined as shown here, is partitioned on a
*note 'DATE': datetime. column:

     CREATE TABLE t2 (
         fname VARCHAR(50) NOT NULL,
         lname VARCHAR(50) NOT NULL,
         region_code TINYINT UNSIGNED NOT NULL,
         dob DATE NOT NULL
     )
     PARTITION BY RANGE( YEAR(dob) ) (
         PARTITION d0 VALUES LESS THAN (1970),
         PARTITION d1 VALUES LESS THAN (1975),
         PARTITION d2 VALUES LESS THAN (1980),
         PARTITION d3 VALUES LESS THAN (1985),
         PARTITION d4 VALUES LESS THAN (1990),
         PARTITION d5 VALUES LESS THAN (2000),
         PARTITION d6 VALUES LESS THAN (2005),
         PARTITION d7 VALUES LESS THAN MAXVALUE
     );

The following statements using 't2' can make of use partition pruning:

     SELECT * FROM t2 WHERE dob = '1982-06-23';

     UPDATE t2 SET region_code = 8 WHERE dob BETWEEN '1991-02-15' AND '1997-04-25';

     DELETE FROM t2 WHERE dob >= '1984-06-21' AND dob <= '1999-06-21'

In the case of the last statement, the optimizer can also act as
follows:

  1. _Find the partition containing the low end of the range_.

     'YEAR('1984-06-21')' yields the value '1984', which is found in
     partition 'd3'.

  2. _Find the partition containing the high end of the range_.

     'YEAR('1999-06-21')' evaluates to '1999', which is found in
     partition 'd5'.

  3. _Scan only these two partitions and any partitions that may lie
     between them_.

     In this case, this means that only partitions 'd3', 'd4', and 'd5'
     are scanned.  The remaining partitions may be safely ignored (and
     are ignored).

*Important*:

Invalid 'DATE' and 'DATETIME' values referenced in the 'WHERE' condition
of a statement against a partitioned table are treated as 'NULL'.  This
means that a query such as 'SELECT * FROM PARTITIONED_TABLE WHERE
DATE_COLUMN < '2008-12-00'' does not return any values (see Bug #40972).

So far, we have looked only at examples using 'RANGE' partitioning, but
pruning can be applied with other partitioning types as well.

Consider a table that is partitioned by 'LIST', where the partitioning
expression is increasing or decreasing, such as the table 't3' shown
here.  (In this example, we assume for the sake of brevity that the
'region_code' column is limited to values between 1 and 10 inclusive.)

     CREATE TABLE t3 (
         fname VARCHAR(50) NOT NULL,
         lname VARCHAR(50) NOT NULL,
         region_code TINYINT UNSIGNED NOT NULL,
         dob DATE NOT NULL
     )
     PARTITION BY LIST(region_code) (
         PARTITION r0 VALUES IN (1, 3),
         PARTITION r1 VALUES IN (2, 5, 8),
         PARTITION r2 VALUES IN (4, 9),
         PARTITION r3 VALUES IN (6, 7, 10)
     );

For a statement such as 'SELECT * FROM t3 WHERE region_code BETWEEN 1
AND 3', the optimizer determines in which partitions the values 1, 2,
and 3 are found ('r0' and 'r1') and skips the remaining ones ('r2' and
'r3').

For tables that are partitioned by 'HASH' or '[LINEAR] KEY', partition
pruning is also possible in cases in which the 'WHERE' clause uses a
simple '=' relation against a column used in the partitioning
expression.  Consider a table created like this:

     CREATE TABLE t4 (
         fname VARCHAR(50) NOT NULL,
         lname VARCHAR(50) NOT NULL,
         region_code TINYINT UNSIGNED NOT NULL,
         dob DATE NOT NULL
     )
     PARTITION BY KEY(region_code)
     PARTITIONS 8;

A statement that compares a column value with a constant can be pruned:

     UPDATE t4 WHERE region_code = 7;

Pruning can also be employed for short ranges, because the optimizer can
turn such conditions into 'IN' relations.  For example, using the same
table 't4' as defined previously, queries such as these can be pruned:

     SELECT * FROM t4 WHERE region_code > 2 AND region_code < 6;

     SELECT * FROM t4 WHERE region_code BETWEEN 3 AND 5;

In both these cases, the 'WHERE' clause is transformed by the optimizer
into 'WHERE region_code IN (3, 4, 5)'.

*Important*:

This optimization is used only if the range size is smaller than the
number of partitions.  Consider this statement:

     DELETE FROM t4 WHERE region_code BETWEEN 4 AND 12;

The range in the 'WHERE' clause covers 9 values (4, 5, 6, 7, 8, 9, 10,
11, 12), but 't4' has only 8 partitions.  This means that the 'DELETE'
cannot be pruned.

When a table is partitioned by 'HASH' or '[LINEAR] KEY', pruning can be
used only on integer columns.  For example, this statement cannot use
pruning because 'dob' is a *note 'DATE': datetime. column:

     SELECT * FROM t4 WHERE dob >= '2001-04-14' AND dob <= '2005-10-15';

However, if the table stores year values in an *note 'INT':
integer-types. column, then a query having 'WHERE year_col >= 2001 AND
year_col <= 2005' can be pruned.

*Note*:

In MySQL 5.1, a query against a table partitioned by 'KEY' and having a
composite partitioning key could be pruned only if the query's 'WHERE'
clause compared every column in the key to a constant.  In MySQL 5.5, it
is possible to prune queries against such tables even if the 'WHERE'
clause does not reference every column in the partitioning key.


File: manual.info.tmp,  Node: partitioning-limitations,  Prev: partitioning-pruning,  Up: partitioning

19.5 Restrictions and Limitations on Partitioning
=================================================

* Menu:

* partitioning-limitations-partitioning-keys-unique-keys::  Partitioning Keys, Primary Keys, and Unique Keys
* partitioning-limitations-storage-engines::  Partitioning Limitations Relating to Storage Engines
* partitioning-limitations-functions::  Partitioning Limitations Relating to Functions
* partitioning-limitations-locking::  Partitioning and Table-Level Locking

This section discusses current restrictions and limitations on MySQL
partitioning support.

Prohibited constructs

The following constructs are not permitted in partitioning expressions:

   * Stored procedures, stored functions, UDFs, or plugins.

   * Declared variables or user variables.

For a list of SQL functions which are permitted in partitioning
expressions, see *note partitioning-limitations-functions::.

Arithmetic and logical operators

Use of the arithmetic operators '+', '-', and '*' is permitted in
partitioning expressions.  However, the result must be an integer value
or 'NULL' (except in the case of '[LINEAR] KEY' partitioning, as
discussed elsewhere in this chapter; see *note partitioning-types::, for
more information).

The 'DIV' operator is also supported, and the '/' operator is not
permitted.  (Bug #30188, Bug #33182)

The bit operators '|', '&', '^', '<<', '>>', and '~' are not permitted
in partitioning expressions.

HANDLER statements

In MySQL 5.5, the *note 'HANDLER': handler. statement is not supported
with partitioned tables.

Server SQL mode

Tables employing user-defined partitioning do not preserve the SQL mode
in effect at the time that they were created.  As discussed in *note
sql-mode::, the results of many MySQL functions and operators may change
according to the server SQL mode.  Therefore, a change in the SQL mode
at any time after the creation of partitioned tables may lead to major
changes in the behavior of such tables, and could easily lead to
corruption or loss of data.  For these reasons, _it is strongly
recommended that you never change the server SQL mode after creating
partitioned tables_.

Examples

The following examples illustrate some changes in behavior of
partitioned tables due to a change in the server SQL mode:

  1. Error handling

     Suppose that you create a partitioned table whose partitioning
     expression is one such as 'COLUMN DIV 0' or 'COLUMN MOD 0', as
     shown here:

          mysql> CREATE TABLE tn (c1 INT)
              ->     PARTITION BY LIST(1 DIV c1) (
              ->       PARTITION p0 VALUES IN (NULL),
              ->       PARTITION p1 VALUES IN (1)
              -> );
          Query OK, 0 rows affected (0.05 sec)

     The default behavior for MySQL is to return 'NULL' for the result
     of a division by zero, without producing any errors:

          mysql> SELECT @@sql_mode;
          +------------+
          | @@sql_mode |
          +------------+
          |            |
          +------------+
          1 row in set (0.00 sec)

          mysql> INSERT INTO tn VALUES (NULL), (0), (1);
          Query OK, 3 rows affected (0.00 sec)
          Records: 3  Duplicates: 0  Warnings: 0

     However, changing the server SQL mode to treat division by zero as
     an error and to enforce strict error handling causes the same *note
     'INSERT': insert. statement to fail, as shown here:

          mysql> SET sql_mode='STRICT_ALL_TABLES,ERROR_FOR_DIVISION_BY_ZERO';
          Query OK, 0 rows affected (0.00 sec)

          mysql> INSERT INTO tn VALUES (NULL), (0), (1);
          ERROR 1365 (22012): Division by 0

  2. Table accessibility

     Sometimes a change in the server SQL mode can make partitioned
     tables unusable.  The following *note 'CREATE TABLE': create-table.
     statement can be executed successfully only if the
     'NO_UNSIGNED_SUBTRACTION' mode is in effect:

          mysql> SELECT @@sql_mode;
          +------------+
          | @@sql_mode |
          +------------+
          |            |
          +------------+
          1 row in set (0.00 sec)

          mysql> CREATE TABLE tu (c1 BIGINT UNSIGNED)
              ->   PARTITION BY RANGE(c1 - 10) (
              ->     PARTITION p0 VALUES LESS THAN (-5),
              ->     PARTITION p1 VALUES LESS THAN (0),
              ->     PARTITION p2 VALUES LESS THAN (5),
              ->     PARTITION p3 VALUES LESS THAN (10),
              ->     PARTITION p4 VALUES LESS THAN (MAXVALUE)
              -> );
          ERROR 1563 (HY000): Partition constant is out of partition function domain

          mysql> SET sql_mode='NO_UNSIGNED_SUBTRACTION';
          Query OK, 0 rows affected (0.00 sec)

          mysql> SELECT @@sql_mode;
          +-------------------------+
          | @@sql_mode              |
          +-------------------------+
          | NO_UNSIGNED_SUBTRACTION |
          +-------------------------+
          1 row in set (0.00 sec)

          mysql> CREATE TABLE tu (c1 BIGINT UNSIGNED)
              ->   PARTITION BY RANGE(c1 - 10) (
              ->     PARTITION p0 VALUES LESS THAN (-5),
              ->     PARTITION p1 VALUES LESS THAN (0),
              ->     PARTITION p2 VALUES LESS THAN (5),
              ->     PARTITION p3 VALUES LESS THAN (10),
              ->     PARTITION p4 VALUES LESS THAN (MAXVALUE)
              -> );
          Query OK, 0 rows affected (0.05 sec)

     If you remove the 'NO_UNSIGNED_SUBTRACTION' server SQL mode after
     creating 'tu', you may no longer be able to access this table:

          mysql> SET sql_mode='';
          Query OK, 0 rows affected (0.00 sec)

          mysql> SELECT * FROM tu;
          ERROR 1563 (HY000): Partition constant is out of partition function domain
          mysql> INSERT INTO tu VALUES (20);
          ERROR 1563 (HY000): Partition constant is out of partition function domain

Server SQL modes also impact replication of partitioned tables.
Differing SQL modes on master and slave can lead to partitioning
expressions being evaluated differently; this can cause the distribution
of data among partitions to be different in the master's and slave's
copies of a given table, and may even cause inserts into partitioned
tables that succeed on the master to fail on the slave.  For best
results, you should always use the same server SQL mode on the master
and on the slave.

Performance considerations

Some effects of partitioning operations on performance are given in the
following list:

   * File system operations

     Partitioning and repartitioning operations (such as *note 'ALTER
     TABLE': alter-table-partition-operations. with 'PARTITION BY ...',
     'REORGANIZE PARTITION', or 'REMOVE PARTITIONING') depend on file
     system operations for their implementation.  This means that the
     speed of these operations is affected by such factors as file
     system type and characteristics, disk speed, swap space, file
     handling efficiency of the operating system, and MySQL server
     options and variables that relate to file handling.  In particular,
     you should make sure that 'large_files_support' is enabled and that
     'open_files_limit' is set properly.  For partitioned tables using
     the 'MyISAM' storage engine, increasing 'myisam_max_sort_file_size'
     may improve performance; partitioning and repartitioning operations
     involving 'InnoDB' tables may be made more efficient by enabling
     'innodb_file_per_table'.

     See also *note partitioning-limitations-max-partitions::.

   * MyISAM and partition file descriptor usage

     For a partitioned *note 'MyISAM': myisam-storage-engine. table,
     MySQL uses 2 file descriptors for each partition, for each such
     table that is open.  This means that you need many more file
     descriptors to perform operations on a partitioned 'MyISAM' table
     than on a table which is identical to it except that the latter
     table is not partitioned, particularly when performing *note 'ALTER
     TABLE': alter-table-partition-operations. operations.

     Assume a 'MyISAM' table 't' with 100 partitions, such as the table
     created by this SQL statement:

          CREATE TABLE t (c1 VARCHAR(50))
          PARTITION BY KEY (c1) PARTITIONS 100
          ENGINE=MYISAM;

     *Note*:

     For brevity, we use 'KEY' partitioning for the table shown in this
     example, but file descriptor usage as described here applies to all
     partitioned 'MyISAM' tables, regardless of the type of partitioning
     that is employed.  Partitioned tables using other storage engines
     such as *note 'InnoDB': innodb-storage-engine. are not affected by
     this issue.

     Now assume that you wish to repartition 't' so that it has 101
     partitions, using the statement shown here:

          ALTER TABLE t PARTITION BY KEY (c1) PARTITIONS 101;

     To process this 'ALTER TABLE' statement, MySQL uses 402 file
     descriptors--that is, two for each of the 100 original partitions,
     plus two for each of the 101 new partitions.  This is because all
     partitions (old and new) must be opened concurrently during the
     reorganization of the table data.  It is recommended that, if you
     expect to perform such operations, you should make sure that the
     'open_files_limit' system variable is not set too low to
     accommodate them.

   * Table locks

     The process executing a partitioning operation on a table takes a
     write lock on the table.  Reads from such tables are relatively
     unaffected; pending *note 'INSERT': insert. and *note 'UPDATE':
     update. operations are performed as soon as the partitioning
     operation has completed.

   * Storage engine

     Partitioning operations, queries, and update operations generally
     tend to be faster with 'MyISAM' tables than with 'InnoDB' or *note
     'NDB': mysql-cluster. tables.

   * Indexes; partition pruning

     As with nonpartitioned tables, proper use of indexes can speed up
     queries on partitioned tables significantly.  In addition,
     designing partitioned tables and statements using these tables to
     take advantage of _partition pruning_ can improve performance
     dramatically.  See *note partitioning-pruning::, for more
     information.

   * Performance with LOAD DATA

     In MySQL 5.5, *note 'LOAD DATA': load-data. uses buffering to
     improve performance.  You should be aware that the buffer uses 130
     KB memory per partition to achieve this.

Maximum number of partitions

The maximum possible number of partitions for a given table (that does
not use the *note 'NDB': mysql-cluster. storage engine) is 1024.  This
number includes subpartitions.

The maximum possible number of user-defined partitions for a table using
the *note 'NDBCLUSTER': mysql-cluster. storage engine is determined
according to the version of the NDB Cluster software being used, the
number of data nodes, and other factors.  See *note
mysql-cluster-nodes-groups-user-partitioning::, for more information.

If, when creating tables with a large number of partitions (but less
than the maximum), you encounter an error message such as 'Got error ...
from storage engine: Out of resources when opening file', you may be
able to address the issue by increasing the value of the
'open_files_limit' system variable.  However, this is dependent on the
operating system, and may not be possible or advisable on all platforms;
see *note not-enough-file-handles::, for more information.  In some
cases, using large numbers (hundreds) of partitions may also not be
advisable due to other concerns, so using more partitions does not
automatically lead to better results.

See also *note partitioning-limitations-file-system-ops::.

Query cache not supported

The query cache is not supported for partitioned tables.  Beginning with
MySQL 5.5.23, the query cache is automatically disabled for queries
involving partitioned tables, and cannot be enabled for such queries.
(Bug #53775)

Per-partition key caches

In MySQL 5.5, key caches are supported for partitioned *note 'MyISAM':
myisam-storage-engine. tables, using the *note 'CACHE INDEX':
cache-index. and *note 'LOAD INDEX INTO CACHE': load-index. statements.
Key caches may be defined for one, several, or all partitions, and
indexes for one, several, or all partitions may be preloaded into key
caches.

Foreign keys not supported for partitioned InnoDB tables

Partitioned tables using the *note 'InnoDB': innodb-storage-engine.
storage engine do not support foreign keys.  More specifically, this
means that the following two statements are true:

  1. No definition of an 'InnoDB' table employing user-defined
     partitioning may contain foreign key references; no 'InnoDB' table
     whose definition contains foreign key references may be
     partitioned.

  2. No 'InnoDB' table definition may contain a foreign key reference to
     a user-partitioned table; no 'InnoDB' table with user-defined
     partitioning may contain columns referenced by foreign keys.

The scope of the restrictions just listed includes all tables that use
the 'InnoDB' storage engine.  *note 'CREATE TABLE':
create-table-foreign-keys. and *note 'ALTER TABLE': alter-table.
statements that would result in tables violating these restrictions are
not allowed.

ALTER TABLE ...  ORDER BY

An 'ALTER TABLE ... ORDER BY COLUMN' statement run against a partitioned
table causes ordering of rows only within each partition.

Effects on REPLACE statements by modification of primary keys

It can be desirable in some cases (see *note
partitioning-limitations-partitioning-keys-unique-keys::) to modify a
table's primary key.  Be aware that, if your application uses *note
'REPLACE': replace. statements and you do this, the results of these
statements can be drastically altered.  See *note replace::, for more
information and an example.

FULLTEXT indexes

Partitioned tables do not support 'FULLTEXT' indexes or searches.  This
includes partitioned tables employing the *note 'MyISAM':
myisam-storage-engine. storage engine.

Spatial columns

Columns with spatial data types such as 'POINT' or 'GEOMETRY' cannot be
used in partitioned tables.

Temporary tables

Temporary tables cannot be partitioned.  (Bug #17497)

Log tables

It is not possible to partition the log tables; an *note 'ALTER TABLE
... PARTITION BY ...': alter-table-partition-operations. statement on
such a table fails with an error.

Data type of partitioning key

A partitioning key must be either an integer column or an expression
that resolves to an integer.  Expressions employing *note 'ENUM': enum.
columns cannot be used.  The column or expression value may also be
'NULL'.  (See *note partitioning-handling-nulls::.)

There are two exceptions to this restriction:

  1. When partitioning by '[LINEAR] KEY', it is possible to use columns
     of any valid MySQL data type other than *note 'TEXT': blob. or
     *note 'BLOB': blob. as partitioning keys, because MySQL's internal
     key-hashing functions produce the correct data type from these
     types.  For example, the following two *note 'CREATE TABLE':
     create-table. statements are valid:

          CREATE TABLE tkc (c1 CHAR)
          PARTITION BY KEY(c1)
          PARTITIONS 4;

          CREATE TABLE tke
              ( c1 ENUM('red', 'orange', 'yellow', 'green', 'blue', 'indigo', 'violet') )
          PARTITION BY LINEAR KEY(c1)
          PARTITIONS 6;

  2. When partitioning by 'RANGE COLUMNS' or 'LIST COLUMNS', it is
     possible to use string, *note 'DATE': datetime, and *note
     'DATETIME': datetime. columns.  For example, each of the following
     *note 'CREATE TABLE': create-table. statements is valid:

          CREATE TABLE rc (c1 INT, c2 DATE)
          PARTITION BY RANGE COLUMNS(c2) (
              PARTITION p0 VALUES LESS THAN('1990-01-01'),
              PARTITION p1 VALUES LESS THAN('1995-01-01'),
              PARTITION p2 VALUES LESS THAN('2000-01-01'),
              PARTITION p3 VALUES LESS THAN('2005-01-01'),
              PARTITION p4 VALUES LESS THAN(MAXVALUE)
          );

          CREATE TABLE lc (c1 INT, c2 CHAR(1))
          PARTITION BY LIST COLUMNS(c2) (
              PARTITION p0 VALUES IN('a', 'd', 'g', 'j', 'm', 'p', 's', 'v', 'y'),
              PARTITION p1 VALUES IN('b', 'e', 'h', 'k', 'n', 'q', 't', 'w', 'z'),
              PARTITION p2 VALUES IN('c', 'f', 'i', 'l', 'o', 'r', 'u', 'x', NULL)
          );

Neither of the preceding exceptions applies to *note 'BLOB': blob. or
*note 'TEXT': blob. column types.

Subqueries

A partitioning key may not be a subquery, even if that subquery resolves
to an integer value or 'NULL'.

Issues with subpartitions

Subpartitions must use 'HASH' or 'KEY' partitioning.  Only 'RANGE' and
'LIST' partitions may be subpartitioned; 'HASH' and 'KEY' partitions
cannot be subpartitioned.

'SUBPARTITION BY KEY' requires that the subpartitioning column or
columns be specified explicitly, unlike the case with 'PARTITION BY
KEY', where it can be omitted (in which case the table's primary key
column is used by default).  Consider the table created by this
statement:

     CREATE TABLE ts (
         id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
         name VARCHAR(30)
     );

You can create a table having the same columns, partitioned by 'KEY',
using a statement such as this one:

     CREATE TABLE ts (
         id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
         name VARCHAR(30)
     )
     PARTITION BY KEY()
     PARTITIONS 4;

The previous statement is treated as though it had been written like
this, with the table's primary key column used as the partitioning
column:

     CREATE TABLE ts (
         id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
         name VARCHAR(30)
     )
     PARTITION BY KEY(id)
     PARTITIONS 4;

However, the following statement that attempts to create a
subpartitioned table using the default column as the subpartitioning
column fails, and the column must be specified for the statement to
succeed, as shown here:

     mysql> CREATE TABLE ts (
         ->     id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
         ->     name VARCHAR(30)
         -> )
         -> PARTITION BY RANGE(id)
         -> SUBPARTITION BY KEY()
         -> SUBPARTITIONS 4
         -> (
         ->     PARTITION p0 VALUES LESS THAN (100),
         ->     PARTITION p1 VALUES LESS THAN (MAXVALUE)
         -> );
     ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that
     corresponds to your MySQL server version for the right syntax to use near ')

     mysql> CREATE TABLE ts (
         ->     id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
         ->     name VARCHAR(30)
         -> )
         -> PARTITION BY RANGE(id)
         -> SUBPARTITION BY KEY(id)
         -> SUBPARTITIONS 4
         -> (
         ->     PARTITION p0 VALUES LESS THAN (100),
         ->     PARTITION p1 VALUES LESS THAN (MAXVALUE)
         -> );
     Query OK, 0 rows affected (0.07 sec)

This is a known issue (see Bug #51470).

DELAYED option not supported

Use of *note 'INSERT DELAYED': insert-delayed. to insert rows into a
partitioned table is not supported.  Attempting to do so fails with an
error.

DATA DIRECTORY and INDEX DIRECTORY options

'DATA DIRECTORY' and 'INDEX DIRECTORY' are subject to the following
restrictions when used with partitioned tables:

   * Table-level 'DATA DIRECTORY' and 'INDEX DIRECTORY' options are
     ignored (see Bug #32091).

   * On Windows, the 'DATA DIRECTORY' and 'INDEX DIRECTORY' options are
     not supported for individual partitions or subpartitions (Bug
     #30459).

Repairing and rebuilding partitioned tables

The statements *note 'CHECK TABLE': check-table, *note 'OPTIMIZE TABLE':
optimize-table, *note 'ANALYZE TABLE': analyze-table, and *note 'REPAIR
TABLE': repair-table. are supported for partitioned tables.

In addition, you can use 'ALTER TABLE ... REBUILD PARTITION' to rebuild
one or more partitions of a partitioned table; 'ALTER TABLE ...
REORGANIZE PARTITION' also causes partitions to be rebuilt.  See *note
alter-table::, for more information about these two statements.

*note 'mysqlcheck': mysqlcheck, *note 'myisamchk': myisamchk, and *note
'myisampack': myisampack. are not supported with partitioned tables.


File: manual.info.tmp,  Node: partitioning-limitations-partitioning-keys-unique-keys,  Next: partitioning-limitations-storage-engines,  Prev: partitioning-limitations,  Up: partitioning-limitations

19.5.1 Partitioning Keys, Primary Keys, and Unique Keys
-------------------------------------------------------

This section discusses the relationship of partitioning keys with
primary keys and unique keys.  The rule governing this relationship can
be expressed as follows: All columns used in the partitioning expression
for a partitioned table must be part of every unique key that the table
may have.

In other words, _every unique key on the table must use every column in
the table's partitioning expression_.  (This also includes the table's
primary key, since it is by definition a unique key.  This particular
case is discussed later in this section.)  For example, each of the
following table creation statements is invalid:

     CREATE TABLE t1 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         UNIQUE KEY (col1, col2)
     )
     PARTITION BY HASH(col3)
     PARTITIONS 4;

     CREATE TABLE t2 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         UNIQUE KEY (col1),
         UNIQUE KEY (col3)
     )
     PARTITION BY HASH(col1 + col3)
     PARTITIONS 4;

In each case, the proposed table would have at least one unique key that
does not include all columns used in the partitioning expression.

Each of the following statements is valid, and represents one way in
which the corresponding invalid table creation statement could be made
to work:

     CREATE TABLE t1 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         UNIQUE KEY (col1, col2, col3)
     )
     PARTITION BY HASH(col3)
     PARTITIONS 4;

     CREATE TABLE t2 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         UNIQUE KEY (col1, col3)
     )
     PARTITION BY HASH(col1 + col3)
     PARTITIONS 4;

This example shows the error produced in such cases:

     mysql> CREATE TABLE t3 (
         ->     col1 INT NOT NULL,
         ->     col2 DATE NOT NULL,
         ->     col3 INT NOT NULL,
         ->     col4 INT NOT NULL,
         ->     UNIQUE KEY (col1, col2),
         ->     UNIQUE KEY (col3)
         -> )
         -> PARTITION BY HASH(col1 + col3)
         -> PARTITIONS 4;
     ERROR 1491 (HY000): A PRIMARY KEY must include all columns in the table's partitioning function

The *note 'CREATE TABLE': create-table. statement fails because both
'col1' and 'col3' are included in the proposed partitioning key, but
neither of these columns is part of both of unique keys on the table.
This shows one possible fix for the invalid table definition:

     mysql> CREATE TABLE t3 (
         ->     col1 INT NOT NULL,
         ->     col2 DATE NOT NULL,
         ->     col3 INT NOT NULL,
         ->     col4 INT NOT NULL,
         ->     UNIQUE KEY (col1, col2, col3),
         ->     UNIQUE KEY (col3)
         -> )
         -> PARTITION BY HASH(col3)
         -> PARTITIONS 4;
     Query OK, 0 rows affected (0.05 sec)

In this case, the proposed partitioning key 'col3' is part of both
unique keys, and the table creation statement succeeds.

The following table cannot be partitioned at all, because there is no
way to include in a partitioning key any columns that belong to both
unique keys:

     CREATE TABLE t4 (
         col1 INT NOT NULL,
         col2 INT NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         UNIQUE KEY (col1, col3),
         UNIQUE KEY (col2, col4)
     );

Since every primary key is by definition a unique key, this restriction
also includes the table's primary key, if it has one.  For example, the
next two statements are invalid:

     CREATE TABLE t5 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         PRIMARY KEY(col1, col2)
     )
     PARTITION BY HASH(col3)
     PARTITIONS 4;

     CREATE TABLE t6 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         PRIMARY KEY(col1, col3),
         UNIQUE KEY(col2)
     )
     PARTITION BY HASH( YEAR(col2) )
     PARTITIONS 4;

In both cases, the primary key does not include all columns referenced
in the partitioning expression.  However, both of the next two
statements are valid:

     CREATE TABLE t7 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         PRIMARY KEY(col1, col2)
     )
     PARTITION BY HASH(col1 + YEAR(col2))
     PARTITIONS 4;

     CREATE TABLE t8 (
         col1 INT NOT NULL,
         col2 DATE NOT NULL,
         col3 INT NOT NULL,
         col4 INT NOT NULL,
         PRIMARY KEY(col1, col2, col4),
         UNIQUE KEY(col2, col1)
     )
     PARTITION BY HASH(col1 + YEAR(col2))
     PARTITIONS 4;

If a table has no unique keys--this includes having no primary key--then
this restriction does not apply, and you may use any column or columns
in the partitioning expression as long as the column type is compatible
with the partitioning type.

For the same reason, you cannot later add a unique key to a partitioned
table unless the key includes all columns used by the table's
partitioning expression.  Consider the partitioned table created as
shown here:

     mysql> CREATE TABLE t_no_pk (c1 INT, c2 INT)
         ->     PARTITION BY RANGE(c1) (
         ->         PARTITION p0 VALUES LESS THAN (10),
         ->         PARTITION p1 VALUES LESS THAN (20),
         ->         PARTITION p2 VALUES LESS THAN (30),
         ->         PARTITION p3 VALUES LESS THAN (40)
         ->     );
     Query OK, 0 rows affected (0.12 sec)

It is possible to add a primary key to 't_no_pk' using either of these
*note 'ALTER TABLE': alter-table-partition-operations. statements:

     #  possible PK
     mysql> ALTER TABLE t_no_pk ADD PRIMARY KEY(c1);
     Query OK, 0 rows affected (0.13 sec)
     Records: 0  Duplicates: 0  Warnings: 0

     # drop this PK
     mysql> ALTER TABLE t_no_pk DROP PRIMARY KEY;
     Query OK, 0 rows affected (0.10 sec)
     Records: 0  Duplicates: 0  Warnings: 0

     #  use another possible PK
     mysql> ALTER TABLE t_no_pk ADD PRIMARY KEY(c1, c2);
     Query OK, 0 rows affected (0.12 sec)
     Records: 0  Duplicates: 0  Warnings: 0

     # drop this PK
     mysql> ALTER TABLE t_no_pk DROP PRIMARY KEY;
     Query OK, 0 rows affected (0.09 sec)
     Records: 0  Duplicates: 0  Warnings: 0

However, the next statement fails, because 'c1' is part of the
partitioning key, but is not part of the proposed primary key:

     #  fails with error 1503
     mysql> ALTER TABLE t_no_pk ADD PRIMARY KEY(c2);
     ERROR 1503 (HY000): A PRIMARY KEY must include all columns in the table's partitioning function

Since 't_no_pk' has only 'c1' in its partitioning expression, attempting
to adding a unique key on 'c2' alone fails.  However, you can add a
unique key that uses both 'c1' and 'c2'.

These rules also apply to existing nonpartitioned tables that you wish
to partition using *note 'ALTER TABLE ... PARTITION BY':
alter-table-partition-operations.  Consider a table 'np_pk' created as
shown here:

     mysql> CREATE TABLE np_pk (
         ->     id INT NOT NULL AUTO_INCREMENT,
         ->     name VARCHAR(50),
         ->     added DATE,
         ->     PRIMARY KEY (id)
         -> );
     Query OK, 0 rows affected (0.08 sec)

The following *note 'ALTER TABLE': alter-table-partition-operations.
statement fails with an error, because the 'added' column is not part of
any unique key in the table:

     mysql> ALTER TABLE np_pk
         ->     PARTITION BY HASH( TO_DAYS(added) )
         ->     PARTITIONS 4;
     ERROR 1503 (HY000): A PRIMARY KEY must include all columns in the table's partitioning function

However, this statement using the 'id' column for the partitioning
column is valid, as shown here:

     mysql> ALTER TABLE np_pk
         ->     PARTITION BY HASH(id)
         ->     PARTITIONS 4;
     Query OK, 0 rows affected (0.11 sec)
     Records: 0  Duplicates: 0  Warnings: 0

In the case of 'np_pk', the only column that may be used as part of a
partitioning expression is 'id'; if you wish to partition this table
using any other column or columns in the partitioning expression, you
must first modify the table, either by adding the desired column or
columns to the primary key, or by dropping the primary key altogether.


File: manual.info.tmp,  Node: partitioning-limitations-storage-engines,  Next: partitioning-limitations-functions,  Prev: partitioning-limitations-partitioning-keys-unique-keys,  Up: partitioning-limitations

19.5.2 Partitioning Limitations Relating to Storage Engines
-----------------------------------------------------------

The following limitations apply to the use of storage engines with
user-defined partitioning of tables.

MERGE storage engine

User-defined partitioning and the 'MERGE' storage engine are not
compatible.  Tables using the 'MERGE' storage engine cannot be
partitioned.  Partitioned tables cannot be merged.

FEDERATED storage engine

Partitioning of 'FEDERATED' tables is not supported; it is not possible
to create partitioned 'FEDERATED' tables.

CSV storage engine

Partitioned tables using the 'CSV' storage engine are not supported; it
is not possible to create partitioned 'CSV' tables.

InnoDB storage engine

*note 'InnoDB': innodb-storage-engine. foreign keys and MySQL
partitioning are not compatible.  Partitioned 'InnoDB' tables cannot
have foreign key references, nor can they have columns referenced by
foreign keys.  'InnoDB' tables which have or which are referenced by
foreign keys cannot be partitioned.

'InnoDB' does not support the use of multiple disks for subpartitions.
(This is currently supported only by 'MyISAM'.)

In addition, *note 'ALTER TABLE ... OPTIMIZE PARTITION':
alter-table-partition-operations. does not work correctly with
partitioned tables that use the 'InnoDB' storage engine.  Use 'ALTER
TABLE ... REBUILD PARTITION' and 'ALTER TABLE ... ANALYZE PARTITION',
instead, for such tables.  For more information, see *note
alter-table-partition-operations::.

User-defined partitioning and the NDB storage engine (NDB Cluster)

Partitioning by 'KEY' (including 'LINEAR KEY') is the only type of
partitioning supported for the *note 'NDB': mysql-cluster. storage
engine.  It is not possible under normal circumstances in MySQL NDB
Cluster 7.2 or MySQL NDB Cluster 7.3 to create an NDB Cluster table
using any partitioning type other than ['LINEAR'] 'KEY', and attempting
to do so fails with an error.

_Exception (not for production)_: It is possible to override this
restriction by setting the 'new' system variable on NDB Cluster SQL
nodes to 'ON'.  If you choose to do this, you should be aware that
tables using partitioning types other than '[LINEAR] KEY' are not
supported in production.  _In such cases, you can create and use tables
with partitioning types other than 'KEY' or 'LINEAR KEY', but you do
this entirely at your own risk_.

The maximum number of partitions that can be defined for an *note 'NDB':
mysql-cluster. table depends on the number of data nodes and node groups
in the cluster, the version of the NDB Cluster software in use, and
other factors.  See *note
mysql-cluster-nodes-groups-user-partitioning::, for more information.

The maximum amount of fixed-size data that can be stored per partition
in an 'NDB' table is 16 GB.

*note 'CREATE TABLE': create-table. and *note 'ALTER TABLE':
alter-table-partition-operations. statements that would cause a
user-partitioned *note 'NDB': mysql-cluster. table not to meet either or
both of the following two requirements are not permitted, and fail with
an error:

  1. The table must have an explicit primary key.

  2. All columns listed in the table's partitioning expression must be
     part of the primary key.

Exception

If a user-partitioned *note 'NDB': mysql-cluster. table is created using
an empty column-list (that is, using 'PARTITION BY KEY()' or 'PARTITION
BY LINEAR KEY()'), then no explicit primary key is required.

Upgrading partitioned tables

When performing an upgrade, tables which are partitioned by 'KEY' and
which use any storage engine other than *note 'NDB': mysql-cluster. must
be dumped and reloaded.

Same storage engine for all partitions

All partitions of a partitioned table must use the same storage engine
and it must be the same storage engine used by the table as a whole.  In
addition, if one does not specify an engine on the table level, then one
must do either of the following when creating or altering a partitioned
table:

   * Do _not_ specify any engine for _any_ partition or subpartition

   * Specify the engine for _all_ partitions or subpartitions


File: manual.info.tmp,  Node: partitioning-limitations-functions,  Next: partitioning-limitations-locking,  Prev: partitioning-limitations-storage-engines,  Up: partitioning-limitations

19.5.3 Partitioning Limitations Relating to Functions
-----------------------------------------------------

This section discusses limitations in MySQL Partitioning relating
specifically to functions used in partitioning expressions.

Only the MySQL functions shown in the following list are allowed in
partitioning expressions:

   * 'ABS()'

   * 'CEILING()' (see *note partitioning-limitations-ceiling-floor::)

   * 'DATEDIFF()'

   * 'DAY()'

   * 'DAYOFMONTH()'

   * 'DAYOFWEEK()'

   * 'DAYOFYEAR()'

   * 'EXTRACT()' (see *note partitioning-limitations-extract::)

   * 'FLOOR()' (see *note partitioning-limitations-ceiling-floor::)

   * 'HOUR()'

   * 'MICROSECOND()'

   * 'MINUTE()'

   * 'MOD()'

   * 'MONTH()'

   * 'QUARTER()'

   * 'SECOND()'

   * 'TIME_TO_SEC()'

   * 'TO_DAYS()'

   * 'TO_SECONDS()'

   * 'UNIX_TIMESTAMP()' (permitted beginning with MySQL 5.5.1 and fully
     supported beginning with MySQL 5.5.15, with *note 'TIMESTAMP':
     datetime. columns)

   * 'WEEKDAY()'

   * 'YEAR()'

   * 'YEARWEEK()'

In MySQL 5.5, range optimization can be used for the 'TO_DAYS()',
'TO_SECONDS()', and 'YEAR()' functions.  In addition, beginning with
MySQL 5.5.15, 'UNIX_TIMESTAMP()' is treated as monotonic in partitioning
expressions.  See *note partitioning-pruning::, for more information.

CEILING() and FLOOR()

Each of these functions returns an integer only if it is passed an
argument of an exact numeric type, such as one of the *note 'INT':
integer-types. types or *note 'DECIMAL': fixed-point-types.  This means,
for example, that the following *note 'CREATE TABLE': create-table.
statement fails with an error, as shown here:

     mysql> CREATE TABLE t (c FLOAT) PARTITION BY LIST( FLOOR(c) )(
         ->     PARTITION p0 VALUES IN (1,3,5),
         ->     PARTITION p1 VALUES IN (2,4,6)
         -> );
     ERROR 1490 (HY000): The PARTITION function returns the wrong type

EXTRACT() function with WEEK specifier

The value returned by the 'EXTRACT()' function, when used as
'EXTRACT(WEEK FROM COL)', depends on the value of the
'default_week_format' system variable.  For this reason, beginning with
MySQL 5.5.9, 'EXTRACT()' is no longer permitted as a partitioning
function when it specifies the unit as 'WEEK'.  (Bug #54483)

See *note mathematical-functions::, for more information about the
return types of these functions, as well as *note numeric-types::.


File: manual.info.tmp,  Node: partitioning-limitations-locking,  Prev: partitioning-limitations-functions,  Up: partitioning-limitations

19.5.4 Partitioning and Table-Level Locking
-------------------------------------------

For storage engines such as *note 'MyISAM': myisam-storage-engine. that
actually execute table-level locks when executing DML or DDL statements,
such a statement affecting a partitioned table imposes a lock on the
table as a whole; that is, all partitions are locked until the statement
was finished.  For example, a *note 'SELECT': select. from a partitioned
'MyISAM' table causes a lock on the entire table.

In practical terms, what this means is that the statements discussed
later in this section tend to execute more slowly as the number of
partitions increases.  This limitation is greatly reduced in MySQL 5.6,
with the introduction of _partition lock pruning_ in MySQL 5.6.6.

This is not true for statements affecting partitioned tables using
storage engines such as *note 'InnoDB': innodb-storage-engine, that
employ row-level locking and do not actually perform (or need to
perform) the locks prior to partition pruning.

The next few paragraphs discuss the effects of MySQL statements on
partitioned tables using storage engines that employ table-level locks.

*DML statements*

*note 'SELECT': select. statements lock the entire table.  'SELECT'
statements containing unions or joins lock all tables named in the union
or join.

*note 'UPDATE': update. also locks the entire table.

*note 'REPLACE': replace. and *note 'INSERT': insert. (including *note
'INSERT ... ON DUPLICATE KEY UPDATE': insert-on-duplicate.) lock the
entire table.

*note 'INSERT ... SELECT': insert-select. locks both the source table
and the target table.

*Note*:

*note 'INSERT DELAYED': insert-delayed. is not supported for partitioned
tables.

A *note 'LOAD DATA': load-data. statement on a partitioned table locks
the entire table.

A trigger on a partitioned table, once activated, locks the entire
table.

*DDL statements*

*note 'CREATE VIEW': create-view. causes a lock on any partitioned table
from which it reads.

*note 'ALTER TABLE': alter-table. locks the affected partitioned table.

*Other statements*

*note 'LOCK TABLES': lock-tables. locks all partitions of a partioned
table.

Evaluating the EXPR in a *note 'CALL stored_procedure(EXPR)': call.
statement locks all partitions of any partitioned table referenced by
EXPR.

*note 'ALTER TABLE': alter-table. also takes a metadata lock on the
table level.


File: manual.info.tmp,  Node: stored-objects,  Next: information-schema,  Prev: partitioning,  Up: Top

20 Stored Objects
*****************

* Menu:

* stored-programs-defining::     Defining Stored Programs
* stored-routines::              Using Stored Routines
* triggers::                     Using Triggers
* event-scheduler::              Using the Event Scheduler
* views::                        Using Views
* stored-objects-security::      Stored Object Access Control
* stored-programs-logging::      Stored Program Binary Logging
* stored-program-restrictions::  Restrictions on Stored Programs
* view-restrictions::            Restrictions on Views

This chapter discusses stored database objects that are defined in terms
of SQL code that is stored on the server for later execution.

Stored objects include these object types:

   * Stored procedure: An object created with *note 'CREATE PROCEDURE':
     create-procedure. and invoked using the *note 'CALL': call.
     statement.  A procedure does not have a return value but can modify
     its parameters for later inspection by the caller.  It can also
     generate result sets to be returned to the client program.

   * Stored function: An object created with *note 'CREATE FUNCTION':
     create-function. and used much like a built-in function.  You
     invoke it in an expression and it returns a value during expression
     evaluation.

   * Trigger: An object created with *note 'CREATE TRIGGER':
     create-trigger. that is associated with a table.  A trigger is
     activated when a particular event occurs for the table, such as an
     insert or update.

   * Event: An object created with *note 'CREATE EVENT': create-event.
     and invoked by the server according to schedule.

   * View: An object created with *note 'CREATE VIEW': create-view. that
     when referenced produces a result set.  A view acts as a virtual
     table.

Terminology used in this document reflects the stored object hierarchy:

   * Stored routines include stored procedures and functions.

   * Stored programs include stored routines, triggers, and events.

   * Stored objects include stored programs and views.

This chapter describes how to use stored objects.  The following
sections provide additional information about SQL syntax for statements
related to these objects:

   * For each object type, there are 'CREATE', 'ALTER', and 'DROP'
     statements that control which objects exist and how they are
     defined.  See *note sql-data-definition-statements::.

   * The *note 'CALL': call. statement is used to invoke stored
     procedures.  See *note call::.

   * Stored program definitions include a body that may use compound
     statements, loops, conditionals, and declared variables.  See *note
     sql-compound-statements::.


File: manual.info.tmp,  Node: stored-programs-defining,  Next: stored-routines,  Prev: stored-objects,  Up: stored-objects

20.1 Defining Stored Programs
=============================

Each stored program contains a body that consists of an SQL statement.
This statement may be a compound statement made up of several statements
separated by semicolon (';') characters.  For example, the following
stored procedure has a body made up of a *note 'BEGIN ... END':
begin-end. block that contains a *note 'SET': set-variable. statement
and a *note 'REPEAT': repeat. loop that itself contains another *note
'SET': set-variable. statement:

     CREATE PROCEDURE dorepeat(p1 INT)
     BEGIN
       SET @x = 0;
       REPEAT SET @x = @x + 1; UNTIL @x > p1 END REPEAT;
     END;

If you use the *note 'mysql': mysql. client program to define a stored
program containing semicolon characters, a problem arises.  By default,
*note 'mysql': mysql. itself recognizes the semicolon as a statement
delimiter, so you must redefine the delimiter temporarily to cause *note
'mysql': mysql. to pass the entire stored program definition to the
server.

To redefine the *note 'mysql': mysql. delimiter, use the 'delimiter'
command.  The following example shows how to do this for the
'dorepeat()' procedure just shown.  The delimiter is changed to '//' to
enable the entire definition to be passed to the server as a single
statement, and then restored to ';' before invoking the procedure.  This
enables the ';' delimiter used in the procedure body to be passed
through to the server rather than being interpreted by *note 'mysql':
mysql. itself.

     mysql> delimiter //

     mysql> CREATE PROCEDURE dorepeat(p1 INT)
         -> BEGIN
         ->   SET @x = 0;
         ->   REPEAT SET @x = @x + 1; UNTIL @x > p1 END REPEAT;
         -> END
         -> //
     Query OK, 0 rows affected (0.00 sec)

     mysql> delimiter ;

     mysql> CALL dorepeat(1000);
     Query OK, 0 rows affected (0.00 sec)

     mysql> SELECT @x;
     +------+
     | @x   |
     +------+
     | 1001 |
     +------+
     1 row in set (0.00 sec)

You can redefine the delimiter to a string other than '//', and the
delimiter can consist of a single character or multiple characters.  You
should avoid the use of the backslash ('\') character because that is
the escape character for MySQL.

The following is an example of a function that takes a parameter,
performs an operation using an SQL function, and returns the result.  In
this case, it is unnecessary to use 'delimiter' because the function
definition contains no internal ';' statement delimiters:

     mysql> CREATE FUNCTION hello (s CHAR(20))
     mysql> RETURNS CHAR(50) DETERMINISTIC
         -> RETURN CONCAT('Hello, ',s,'!');
     Query OK, 0 rows affected (0.00 sec)

     mysql> SELECT hello('world');
     +----------------+
     | hello('world') |
     +----------------+
     | Hello, world!  |
     +----------------+
     1 row in set (0.00 sec)


File: manual.info.tmp,  Node: stored-routines,  Next: triggers,  Prev: stored-programs-defining,  Up: stored-objects

20.2 Using Stored Routines
==========================

* Menu:

* stored-routines-syntax::       Stored Routine Syntax
* stored-routines-privileges::   Stored Routines and MySQL Privileges
* stored-routines-metadata::     Stored Routine Metadata
* stored-routines-last-insert-id::  Stored Procedures, Functions, Triggers, and LAST_INSERT_ID()

MySQL supports stored routines (procedures and functions).  A stored
routine is a set of SQL statements that can be stored in the server.
Once this has been done, clients don't need to keep reissuing the
individual statements but can refer to the stored routine instead.

Stored routines require the 'proc' table in the 'mysql' database.  This
table is created during the MySQL installation procedure.  If you are
upgrading to MySQL 5.5 from an earlier version, be sure to update your
grant tables to make sure that the 'proc' table exists.  See *note
mysql-upgrade::.

Stored routines can be particularly useful in certain situations:

   * When multiple client applications are written in different
     languages or work on different platforms, but need to perform the
     same database operations.

   * When security is paramount.  Banks, for example, use stored
     procedures and functions for all common operations.  This provides
     a consistent and secure environment, and routines can ensure that
     each operation is properly logged.  In such a setup, applications
     and users would have no access to the database tables directly, but
     can only execute specific stored routines.

Stored routines can provide improved performance because less
information needs to be sent between the server and the client.  The
tradeoff is that this does increase the load on the database server
because more of the work is done on the server side and less is done on
the client (application) side.  Consider this if many client machines
(such as Web servers) are serviced by only one or a few database
servers.

Stored routines also enable you to have libraries of functions in the
database server.  This is a feature shared by modern application
languages that enable such design internally (for example, by using
classes).  Using these client application language features is
beneficial for the programmer even outside the scope of database use.

MySQL follows the SQL:2003 syntax for stored routines, which is also
used by IBM's DB2.  All syntax described here is supported and any
limitations and extensions are documented where appropriate.

*Additional Resources*

   * You may find the Stored Procedures User Forum
     (https://forums.mysql.com/list.php?98) of use when working with
     stored procedures and functions.

   * For answers to some commonly asked questions regarding stored
     routines in MySQL, see *note faqs-stored-procs::.

   * There are some restrictions on the use of stored routines.  See
     *note stored-program-restrictions::.

   * Binary logging for stored routines takes place as described in
     *note stored-programs-logging::.


File: manual.info.tmp,  Node: stored-routines-syntax,  Next: stored-routines-privileges,  Prev: stored-routines,  Up: stored-routines

20.2.1 Stored Routine Syntax
----------------------------

A stored routine is either a procedure or a function.  Stored routines
are created with the *note 'CREATE PROCEDURE': create-procedure. and
*note 'CREATE FUNCTION': create-function. statements (see *note
create-procedure::).  A procedure is invoked using a *note 'CALL': call.
statement (see *note call::), and can only pass back values using output
variables.  A function can be called from inside a statement just like
any other function (that is, by invoking the function's name), and can
return a scalar value.  The body of a stored routine can use compound
statements (see *note sql-compound-statements::).

Stored routines can be dropped with the *note 'DROP PROCEDURE':
drop-procedure. and *note 'DROP FUNCTION': drop-function. statements
(see *note drop-procedure::), and altered with the *note 'ALTER
PROCEDURE': alter-procedure. and *note 'ALTER FUNCTION': alter-function.
statements (see *note alter-procedure::).

A stored procedure or function is associated with a particular database.
This has several implications:

   * When the routine is invoked, an implicit 'USE DB_NAME' is performed
     (and undone when the routine terminates).  *note 'USE': use.
     statements within stored routines are not permitted.

   * You can qualify routine names with the database name.  This can be
     used to refer to a routine that is not in the current database.
     For example, to invoke a stored procedure 'p' or function 'f' that
     is associated with the 'test' database, you can say 'CALL test.p()'
     or 'test.f()'.

   * When a database is dropped, all stored routines associated with it
     are dropped as well.

Stored functions cannot be recursive.

Recursion in stored procedures is permitted but disabled by default.  To
enable recursion, set the 'max_sp_recursion_depth' server system
variable to a value greater than zero.  Stored procedure recursion
increases the demand on thread stack space.  If you increase the value
of 'max_sp_recursion_depth', it may be necessary to increase thread
stack size by increasing the value of 'thread_stack' at server startup.
See *note server-system-variables::, for more information.

MySQL supports a very useful extension that enables the use of regular
*note 'SELECT': select. statements (that is, without using cursors or
local variables) inside a stored procedure.  The result set of such a
query is simply sent directly to the client.  Multiple *note 'SELECT':
select. statements generate multiple result sets, so the client must use
a MySQL client library that supports multiple result sets.  This means
the client must use a client library from a version of MySQL at least as
recent as 4.1.  The client should also specify the
'CLIENT_MULTI_RESULTS' option when it connects.  For C programs, this
can be done with the *note 'mysql_real_connect()': mysql-real-connect. C
API function.  See *note mysql-real-connect::, and *note
c-api-multiple-queries::.


File: manual.info.tmp,  Node: stored-routines-privileges,  Next: stored-routines-metadata,  Prev: stored-routines-syntax,  Up: stored-routines

20.2.2 Stored Routines and MySQL Privileges
-------------------------------------------

The MySQL grant system takes stored routines into account as follows:

   * The 'CREATE ROUTINE' privilege is needed to create stored routines.

   * The 'ALTER ROUTINE' privilege is needed to alter or drop stored
     routines.  This privilege is granted automatically to the creator
     of a routine if necessary, and dropped from the creator when the
     routine is dropped.

   * The 'EXECUTE' privilege is required to execute stored routines.
     However, this privilege is granted automatically to the creator of
     a routine if necessary (and dropped from the creator when the
     routine is dropped).  Also, the default 'SQL SECURITY'
     characteristic for a routine is 'DEFINER', which enables users who
     have access to the database with which the routine is associated to
     execute the routine.

   * If the 'automatic_sp_privileges' system variable is 0, the
     'EXECUTE' and 'ALTER ROUTINE' privileges are not automatically
     granted to and dropped from the routine creator.

   * The creator of a routine is the account used to execute the
     'CREATE' statement for it.  This might not be the same as the
     account named as the 'DEFINER' in the routine definition.

The server manipulates the 'mysql.proc' table in response to statements
that create, alter, or drop stored routines.  It is not supported that
the server will notice manual manipulation of this table.


File: manual.info.tmp,  Node: stored-routines-metadata,  Next: stored-routines-last-insert-id,  Prev: stored-routines-privileges,  Up: stored-routines

20.2.3 Stored Routine Metadata
------------------------------

Metadata about stored routines can be obtained as follows:

   * Query the *note 'ROUTINES': routines-table. table of the
     'INFORMATION_SCHEMA' database.  See *note routines-table::.

   * Use the *note 'SHOW CREATE PROCEDURE': show-create-procedure. and
     *note 'SHOW CREATE FUNCTION': show-create-function. statements to
     see routine definitions.  See *note show-create-procedure::.

   * Use the *note 'SHOW PROCEDURE STATUS': show-procedure-status. and
     *note 'SHOW FUNCTION STATUS': show-function-status. statements to
     see routine characteristics.  See *note show-procedure-status::.


File: manual.info.tmp,  Node: stored-routines-last-insert-id,  Prev: stored-routines-metadata,  Up: stored-routines

20.2.4 Stored Procedures, Functions, Triggers, and LAST_INSERT_ID()
-------------------------------------------------------------------

Within the body of a stored routine (procedure or function) or a
trigger, the value of 'LAST_INSERT_ID()' changes the same way as for
statements executed outside the body of these kinds of objects (see
*note information-functions::).  The effect of a stored routine or
trigger upon the value of 'LAST_INSERT_ID()' that is seen by following
statements depends on the kind of routine:

   * If a stored procedure executes statements that change the value of
     'LAST_INSERT_ID()', the changed value is seen by statements that
     follow the procedure call.

   * For stored functions and triggers that change the value, the value
     is restored when the function or trigger ends, so following
     statements do not see a changed value.


File: manual.info.tmp,  Node: triggers,  Next: event-scheduler,  Prev: stored-routines,  Up: stored-objects

20.3 Using Triggers
===================

* Menu:

* trigger-syntax::               Trigger Syntax and Examples
* trigger-metadata::             Trigger Metadata

A trigger is a named database object that is associated with a table,
and that activates when a particular event occurs for the table.  Some
uses for triggers are to perform checks of values to be inserted into a
table or to perform calculations on values involved in an update.

A trigger is defined to activate when a statement inserts, updates, or
deletes rows in the associated table.  These row operations are trigger
events.  For example, rows can be inserted by *note 'INSERT': insert. or
*note 'LOAD DATA': load-data. statements, and an insert trigger
activates for each inserted row.  A trigger can be set to activate
either before or after the trigger event.  For example, you can have a
trigger activate before each row that is inserted into a table or after
each row that is updated.

*Important*:

MySQL triggers activate only for changes made to tables by SQL
statements.  This includes changes to base tables that underlie
updatable views.  Triggers do not activate for changes to tables made by
APIs that do not transmit SQL statements to the MySQL Server.  This
means that triggers are not activated by updates made using the *note
'NDB': mysql-cluster. API.

Triggers are not activated by changes in 'INFORMATION_SCHEMA' or
'performance_schema' tables.  Those tables are actually views and
triggers are not permitted on views.

To use triggers if you have upgraded to MySQL 5.5 from an older release
that did not support triggers, you should upgrade your grant tables so
that they contain the trigger-related privileges.  See *note
mysql-upgrade::.

The following sections describe the syntax for creating and dropping
triggers, show some examples of how to use them, and indicate how to
obtain trigger metadata.

*Additional Resources*

   * You may find the Triggers User Forum
     (https://forums.mysql.com/list.php?100) of use when working with
     triggers.

   * For answers to commonly asked questions regarding triggers in
     MySQL, see *note faqs-triggers::.

   * There are some restrictions on the use of triggers; see *note
     stored-program-restrictions::.

   * Binary logging for triggers takes place as described in *note
     stored-programs-logging::.


File: manual.info.tmp,  Node: trigger-syntax,  Next: trigger-metadata,  Prev: triggers,  Up: triggers

20.3.1 Trigger Syntax and Examples
----------------------------------

To create a trigger or drop a trigger, use the *note 'CREATE TRIGGER':
create-trigger. or *note 'DROP TRIGGER': drop-trigger. statement,
described in *note create-trigger::, and *note drop-trigger::.

Here is a simple example that associates a trigger with a table, to
activate for *note 'INSERT': insert. operations.  The trigger acts as an
accumulator, summing the values inserted into one of the columns of the
table.

     mysql> CREATE TABLE account (acct_num INT, amount DECIMAL(10,2));
     Query OK, 0 rows affected (0.03 sec)

     mysql> CREATE TRIGGER ins_sum BEFORE INSERT ON account
            FOR EACH ROW SET @sum = @sum + NEW.amount;
     Query OK, 0 rows affected (0.01 sec)

The *note 'CREATE TRIGGER': create-trigger. statement creates a trigger
named 'ins_sum' that is associated with the 'account' table.  It also
includes clauses that specify the trigger action time, the triggering
event, and what to do when the trigger activates:

   * The keyword 'BEFORE' indicates the trigger action time.  In this
     case, the trigger activates before each row inserted into the
     table.  The other permitted keyword here is 'AFTER'.

   * The keyword 'INSERT' indicates the trigger event; that is, the type
     of operation that activates the trigger.  In the example, *note
     'INSERT': insert. operations cause trigger activation.  You can
     also create triggers for *note 'DELETE': delete. and *note
     'UPDATE': update. operations.

   * The statement following 'FOR EACH ROW' defines the trigger body;
     that is, the statement to execute each time the trigger activates,
     which occurs once for each row affected by the triggering event.
     In the example, the trigger body is a simple *note 'SET':
     set-variable. that accumulates into a user variable the values
     inserted into the 'amount' column.  The statement refers to the
     column as 'NEW.amount' which means 'the value of the 'amount'
     column to be inserted into the new row.'

To use the trigger, set the accumulator variable to zero, execute an
*note 'INSERT': insert. statement, and then see what value the variable
has afterward:

     mysql> SET @sum = 0;
     mysql> INSERT INTO account VALUES(137,14.98),(141,1937.50),(97,-100.00);
     mysql> SELECT @sum AS 'Total amount inserted';
     +-----------------------+
     | Total amount inserted |
     +-----------------------+
     |               1852.48 |
     +-----------------------+

In this case, the value of '@sum' after the *note 'INSERT': insert.
statement has executed is '14.98 + 1937.50 - 100', or '1852.48'.

To destroy the trigger, use a *note 'DROP TRIGGER': drop-trigger.
statement.  You must specify the schema name if the trigger is not in
the default schema:

     mysql> DROP TRIGGER test.ins_sum;

If you drop a table, any triggers for the table are also dropped.

Trigger names exist in the schema namespace, meaning that all triggers
must have unique names within a schema.  Triggers in different schemas
can have the same name.

In addition to the requirement that trigger names be unique for a
schema, there are other limitations on the types of triggers you can
create.  In particular, there cannot be multiple triggers for a given
table that have the same trigger event and action time.  For example,
you cannot have two 'BEFORE UPDATE' triggers for a table.  To work
around this, you can define a trigger that executes multiple statements
by using the *note 'BEGIN ... END': begin-end. compound statement
construct after 'FOR EACH ROW'.  (An example appears later in this
section.)

Within the trigger body, the 'OLD' and 'NEW' keywords enable you to
access columns in the rows affected by a trigger.  'OLD' and 'NEW' are
MySQL extensions to triggers; they are not case-sensitive.

In an 'INSERT' trigger, only 'NEW.COL_NAME' can be used; there is no old
row.  In a 'DELETE' trigger, only 'OLD.COL_NAME' can be used; there is
no new row.  In an 'UPDATE' trigger, you can use 'OLD.COL_NAME' to refer
to the columns of a row before it is updated and 'NEW.COL_NAME' to refer
to the columns of the row after it is updated.

A column named with 'OLD' is read only.  You can refer to it (if you
have the *note 'SELECT': select. privilege), but not modify it.  You can
refer to a column named with 'NEW' if you have the 'SELECT' privilege
for it.  In a 'BEFORE' trigger, you can also change its value with 'SET
NEW.COL_NAME = VALUE' if you have the 'UPDATE' privilege for it.  This
means you can use a trigger to modify the values to be inserted into a
new row or used to update a row.  (Such a 'SET' statement has no effect
in an 'AFTER' trigger because the row change will have already
occurred.)

In a 'BEFORE' trigger, the 'NEW' value for an 'AUTO_INCREMENT' column is
0, not the sequence number that is generated automatically when the new
row actually is inserted.

By using the *note 'BEGIN ... END': begin-end. construct, you can define
a trigger that executes multiple statements.  Within the 'BEGIN' block,
you also can use other syntax that is permitted within stored routines
such as conditionals and loops.  However, just as for stored routines,
if you use the *note 'mysql': mysql. program to define a trigger that
executes multiple statements, it is necessary to redefine the *note
'mysql': mysql. statement delimiter so that you can use the ';'
statement delimiter within the trigger definition.  The following
example illustrates these points.  It defines an 'UPDATE' trigger that
checks the new value to be used for updating each row, and modifies the
value to be within the range from 0 to 100.  This must be a 'BEFORE'
trigger because the value must be checked before it is used to update
the row:

     mysql> delimiter //
     mysql> CREATE TRIGGER upd_check BEFORE UPDATE ON account
         -> FOR EACH ROW
         -> BEGIN
         ->     IF NEW.amount < 0 THEN
         ->         SET NEW.amount = 0;
         ->     ELSEIF NEW.amount > 100 THEN
         ->         SET NEW.amount = 100;
         ->     END IF;
         -> END;//
     mysql> delimiter ;

It can be easier to define a stored procedure separately and then invoke
it from the trigger using a simple *note 'CALL': call. statement.  This
is also advantageous if you want to execute the same code from within
several triggers.

There are limitations on what can appear in statements that a trigger
executes when activated:

   * The trigger cannot use the *note 'CALL': call. statement to invoke
     stored procedures that return data to the client or that use
     dynamic SQL. (Stored procedures are permitted to return data to the
     trigger through 'OUT' or 'INOUT' parameters.)

   * The trigger cannot use statements that explicitly or implicitly
     begin or end a transaction, such as *note 'START TRANSACTION':
     commit, *note 'COMMIT': commit, or *note 'ROLLBACK': commit.
     (*note 'ROLLBACK to SAVEPOINT': commit. is permitted because it
     does not end a transaction.).

See also *note stored-program-restrictions::.

MySQL handles errors during trigger execution as follows:

   * If a 'BEFORE' trigger fails, the operation on the corresponding row
     is not performed.

   * A 'BEFORE' trigger is activated by the _attempt_ to insert or
     modify the row, regardless of whether the attempt subsequently
     succeeds.

   * An 'AFTER' trigger is executed only if any 'BEFORE' triggers and
     the row operation execute successfully.

   * An error during either a 'BEFORE' or 'AFTER' trigger results in
     failure of the entire statement that caused trigger invocation.

   * For transactional tables, failure of a statement should cause
     rollback of all changes performed by the statement.  Failure of a
     trigger causes the statement to fail, so trigger failure also
     causes rollback.  For nontransactional tables, such rollback cannot
     be done, so although the statement fails, any changes performed
     prior to the point of the error remain in effect.

In MySQL 5.5, triggers can contain direct references to tables by name,
such as the trigger named 'testref' shown in this example:

     CREATE TABLE test1(a1 INT);
     CREATE TABLE test2(a2 INT);
     CREATE TABLE test3(a3 INT NOT NULL AUTO_INCREMENT PRIMARY KEY);
     CREATE TABLE test4(
       a4 INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
       b4 INT DEFAULT 0
     );

     delimiter |

     CREATE TRIGGER testref BEFORE INSERT ON test1
       FOR EACH ROW
       BEGIN
         INSERT INTO test2 SET a2 = NEW.a1;
         DELETE FROM test3 WHERE a3 = NEW.a1;
         UPDATE test4 SET b4 = b4 + 1 WHERE a4 = NEW.a1;
       END;
     |

     delimiter ;

     INSERT INTO test3 (a3) VALUES
       (NULL), (NULL), (NULL), (NULL), (NULL),
       (NULL), (NULL), (NULL), (NULL), (NULL);

     INSERT INTO test4 (a4) VALUES
       (0), (0), (0), (0), (0), (0), (0), (0), (0), (0);

Suppose that you insert the following values into table 'test1' as shown
here:

     mysql> INSERT INTO test1 VALUES
            (1), (3), (1), (7), (1), (8), (4), (4);
     Query OK, 8 rows affected (0.01 sec)
     Records: 8  Duplicates: 0  Warnings: 0

As a result, the four tables contain the following data:

     mysql> SELECT * FROM test1;
     +------+
     | a1   |
     +------+
     |    1 |
     |    3 |
     |    1 |
     |    7 |
     |    1 |
     |    8 |
     |    4 |
     |    4 |
     +------+
     8 rows in set (0.00 sec)

     mysql> SELECT * FROM test2;
     +------+
     | a2   |
     +------+
     |    1 |
     |    3 |
     |    1 |
     |    7 |
     |    1 |
     |    8 |
     |    4 |
     |    4 |
     +------+
     8 rows in set (0.00 sec)

     mysql> SELECT * FROM test3;
     +----+
     | a3 |
     +----+
     |  2 |
     |  5 |
     |  6 |
     |  9 |
     | 10 |
     +----+
     5 rows in set (0.00 sec)

     mysql> SELECT * FROM test4;
     +----+------+
     | a4 | b4   |
     +----+------+
     |  1 |    3 |
     |  2 |    0 |
     |  3 |    1 |
     |  4 |    2 |
     |  5 |    0 |
     |  6 |    0 |
     |  7 |    1 |
     |  8 |    1 |
     |  9 |    0 |
     | 10 |    0 |
     +----+------+
     10 rows in set (0.00 sec)


File: manual.info.tmp,  Node: trigger-metadata,  Prev: trigger-syntax,  Up: triggers

20.3.2 Trigger Metadata
-----------------------

Metadata about triggers can be obtained as follows:

   * Query the *note 'TRIGGERS': triggers-table. table of the
     'INFORMATION_SCHEMA' database.  See *note triggers-table::.

   * Use the *note 'SHOW CREATE TRIGGER': show-create-trigger.
     statement.  See *note show-create-trigger::.

   * Use the *note 'SHOW TRIGGERS': show-triggers. statement.  See *note
     show-triggers::.


File: manual.info.tmp,  Node: event-scheduler,  Next: views,  Prev: triggers,  Up: stored-objects

20.4 Using the Event Scheduler
==============================

* Menu:

* events-overview::              Event Scheduler Overview
* events-configuration::         Event Scheduler Configuration
* events-syntax::                Event Syntax
* events-metadata::              Event Metadata
* events-status-info::           Event Scheduler Status
* events-privileges::            The Event Scheduler and MySQL Privileges

The _MySQL Event Scheduler_ manages the scheduling and execution of
events, that is, tasks that run according to a schedule.  The following
discussion covers the Event Scheduler and is divided into the following
sections:

   * *note events-overview::, provides an introduction to and conceptual
     overview of MySQL Events.

   * *note events-syntax::, discusses the SQL statements for creating,
     altering, and dropping MySQL Events.

   * *note events-metadata::, shows how to obtain information about
     events and how this information is stored by the MySQL Server.

   * *note events-privileges::, discusses the privileges required to
     work with events and the ramifications that events have with regard
     to privileges when executing.

Stored routines require the 'event' table in the 'mysql' database.  This
table is created during the MySQL 5.5 installation procedure.  If you
are upgrading to MySQL 5.5 from an earlier version, be sure to update
your grant tables to make sure that the 'event' table exists.  See *note
upgrading::.

*Additional Resources*

   * You may find the MySQL Event Scheduler User Forum
     (https://forums.mysql.com/list.php?119) of use when working with
     scheduled events.

   * There are some restrictions on the use of events; see *note
     stored-program-restrictions::.

   * Binary logging for events takes place as described in *note
     stored-programs-logging::.


File: manual.info.tmp,  Node: events-overview,  Next: events-configuration,  Prev: event-scheduler,  Up: event-scheduler

20.4.1 Event Scheduler Overview
-------------------------------

MySQL Events are tasks that run according to a schedule.  Therefore, we
sometimes refer to them as _scheduled_ events.  When you create an
event, you are creating a named database object containing one or more
SQL statements to be executed at one or more regular intervals,
beginning and ending at a specific date and time.  Conceptually, this is
similar to the idea of the Unix 'crontab' (also known as a 'cron job')
or the Windows Task Scheduler.

Scheduled tasks of this type are also sometimes known as 'temporal
triggers', implying that these are objects that are triggered by the
passage of time.  While this is essentially correct, we prefer to use
the term _events_ to avoid confusion with triggers of the type discussed
in *note triggers::.  Events should more specifically not be confused
with 'temporary triggers'.  Whereas a trigger is a database object whose
statements are executed in response to a specific type of event that
occurs on a given table, a (scheduled) event is an object whose
statements are executed in response to the passage of a specified time
interval.

While there is no provision in the SQL Standard for event scheduling,
there are precedents in other database systems, and you may notice some
similarities between these implementations and that found in the MySQL
Server.

MySQL Events have the following major features and properties:

   * In MySQL, an event is uniquely identified by its name and the
     schema to which it is assigned.

   * An event performs a specific action according to a schedule.  This
     action consists of an SQL statement, which can be a compound
     statement in a *note 'BEGIN ... END': begin-end. block if desired
     (see *note sql-compound-statements::).  An event's timing can be
     either _one-time_ or _recurrent_.  A one-time event executes one
     time only.  A recurrent event repeats its action at a regular
     interval, and the schedule for a recurring event can be assigned a
     specific start day and time, end day and time, both, or neither.
     (By default, a recurring event's schedule begins as soon as it is
     created, and continues indefinitely, until it is disabled or
     dropped.)

     If a repeating event does not terminate within its scheduling
     interval, the result may be multiple instances of the event
     executing simultaneously.  If this is undesirable, you should
     institute a mechanism to prevent simultaneous instances.  For
     example, you could use the 'GET_LOCK()' function, or row or table
     locking.

   * Users can create, modify, and drop scheduled events using SQL
     statements intended for these purposes.  Syntactically invalid
     event creation and modification statements fail with an appropriate
     error message.  _A user may include statements in an event's action
     which require privileges that the user does not actually have_.
     The event creation or modification statement succeeds but the
     event's action fails.  See *note events-privileges:: for details.

   * Many of the properties of an event can be set or modified using SQL
     statements.  These properties include the event's name, timing,
     persistence (that is, whether it is preserved following the
     expiration of its schedule), status (enabled or disabled), action
     to be performed, and the schema to which it is assigned.  See *note
     alter-event::.

     The default definer of an event is the user who created the event,
     unless the event has been altered, in which case the definer is the
     user who issued the last *note 'ALTER EVENT': alter-event.
     statement affecting that event.  An event can be modified by any
     user having the 'EVENT' privilege on the database for which the
     event is defined.  See *note events-privileges::.

   * An event's action statement may include most SQL statements
     permitted within stored routines.  For restrictions, see *note
     stored-program-restrictions::.


File: manual.info.tmp,  Node: events-configuration,  Next: events-syntax,  Prev: events-overview,  Up: event-scheduler

20.4.2 Event Scheduler Configuration
------------------------------------

Events are executed by a special _event scheduler thread_; when we refer
to the Event Scheduler, we actually refer to this thread.  When running,
the event scheduler thread and its current state can be seen by users
having the 'PROCESS' privilege in the output of *note 'SHOW
PROCESSLIST': show-processlist, as shown in the discussion that follows.

The global 'event_scheduler' system variable determines whether the
Event Scheduler is enabled and running on the server.  It has one of
these 3 values, which affect event scheduling as described here:

   * 'OFF': The Event Scheduler is stopped.  The event scheduler thread
     does not run, is not shown in the output of *note 'SHOW
     PROCESSLIST': show-processlist, and no scheduled events are
     executed.  'OFF' is the default value for 'event_scheduler'.

     When the Event Scheduler is stopped ('event_scheduler' is 'OFF'),
     it can be started by setting the value of 'event_scheduler' to
     'ON'.  (See next item.)

   * 'ON': The Event Scheduler is started; the event scheduler thread
     runs and executes all scheduled events.

     When the Event Scheduler is 'ON', the event scheduler thread is
     listed in the output of *note 'SHOW PROCESSLIST': show-processlist.
     as a daemon process, and its state is represented as shown here:

          mysql> SHOW PROCESSLIST\G
          *************************** 1. row ***************************
               Id: 1
             User: root
             Host: localhost
               db: NULL
          Command: Query
             Time: 0
            State: NULL
             Info: show processlist
          *************************** 2. row ***************************
               Id: 2
             User: event_scheduler
             Host: localhost
               db: NULL
          Command: Daemon
             Time: 3
            State: Waiting for next activation
             Info: NULL
          2 rows in set (0.00 sec)

     Event scheduling can be stopped by setting the value of
     'event_scheduler' to 'OFF'.

   * 'DISABLED': This value renders the Event Scheduler nonoperational.
     When the Event Scheduler is 'DISABLED', the event scheduler thread
     does not run (and so does not appear in the output of *note 'SHOW
     PROCESSLIST': show-processlist.).  In addition, the Event Scheduler
     state cannot be changed at runtime.

If the Event Scheduler status has not been set to 'DISABLED',
'event_scheduler' can be toggled between 'ON' and 'OFF' (using *note
'SET': set-variable.).  It is also possible to use '0' for 'OFF', and
'1' for 'ON' when setting this variable.  Thus, any of the following 4
statements can be used in the *note 'mysql': mysql. client to turn on
the Event Scheduler:

     SET GLOBAL event_scheduler = ON;
     SET @@GLOBAL.event_scheduler = ON;
     SET GLOBAL event_scheduler = 1;
     SET @@GLOBAL.event_scheduler = 1;

Similarly, any of these 4 statements can be used to turn off the Event
Scheduler:

     SET GLOBAL event_scheduler = OFF;
     SET @@GLOBAL.event_scheduler = OFF;
     SET GLOBAL event_scheduler = 0;
     SET @@GLOBAL.event_scheduler = 0;

Although 'ON' and 'OFF' have numeric equivalents, the value displayed
for 'event_scheduler' by *note 'SELECT': select. or *note 'SHOW
VARIABLES': show-variables. is always one of 'OFF', 'ON', or 'DISABLED'.
_'DISABLED' has no numeric equivalent_.  For this reason, 'ON' and 'OFF'
are usually preferred over '1' and '0' when setting this variable.

Note that attempting to set 'event_scheduler' without specifying it as a
global variable causes an error:

     mysql< SET @@event_scheduler = OFF;
     ERROR 1229 (HY000): Variable 'event_scheduler' is a GLOBAL
     variable and should be set with SET GLOBAL

*Important*:

It is possible to set the Event Scheduler to 'DISABLED' only at server
startup.  If 'event_scheduler' is 'ON' or 'OFF', you cannot set it to
'DISABLED' at runtime.  Also, if the Event Scheduler is set to
'DISABLED' at startup, you cannot change the value of 'event_scheduler'
at runtime.

To disable the event scheduler, use one of the following two methods:

   * As a command-line option when starting the server:

          --event-scheduler=DISABLED

   * In the server configuration file ('my.cnf', or 'my.ini' on Windows
     systems), include the line where it will be read by the server (for
     example, in a '[mysqld]' section):

          event_scheduler=DISABLED

To enable the Event Scheduler, restart the server without the
'--event-scheduler=DISABLED' command-line option, or after removing or
commenting out the line containing 'event-scheduler=DISABLED' in the
server configuration file, as appropriate.  Alternatively, you can use
'ON' (or '1') or 'OFF' (or '0') in place of the 'DISABLED' value when
starting the server.

*Note*:

You can issue event-manipulation statements when 'event_scheduler' is
set to 'DISABLED'.  No warnings or errors are generated in such cases
(provided that the statements are themselves valid).  However, scheduled
events cannot execute until this variable is set to 'ON' (or '1').  Once
this has been done, the event scheduler thread executes all events whose
scheduling conditions are satisfied.

Starting the MySQL server with the '--skip-grant-tables' option causes
'event_scheduler' to be set to 'DISABLED', overriding any other value
set either on the command line or in the 'my.cnf' or 'my.ini' file (Bug
#26807).

For SQL statements used to create, alter, and drop events, see *note
events-syntax::.

MySQL provides an *note 'EVENTS': events-table. table in the
'INFORMATION_SCHEMA' database.  This table can be queried to obtain
information about scheduled events which have been defined on the
server.  See *note events-metadata::, and *note events-table::, for more
information.

For information regarding event scheduling and the MySQL privilege
system, see *note events-privileges::.


File: manual.info.tmp,  Node: events-syntax,  Next: events-metadata,  Prev: events-configuration,  Up: event-scheduler

20.4.3 Event Syntax
-------------------

MySQL provides several SQL statements for working with scheduled events:

   * New events are defined using the *note 'CREATE EVENT':
     create-event. statement.  See *note create-event::.

   * The definition of an existing event can be changed by means of the
     *note 'ALTER EVENT': alter-event. statement.  See *note
     alter-event::.

   * When a scheduled event is no longer wanted or needed, it can be
     deleted from the server by its definer using the *note 'DROP
     EVENT': drop-event. statement.  See *note drop-event::.  Whether an
     event persists past the end of its schedule also depends on its 'ON
     COMPLETION' clause, if it has one.  See *note create-event::.

     An event can be dropped by any user having the 'EVENT' privilege
     for the database on which the event is defined.  See *note
     events-privileges::.


File: manual.info.tmp,  Node: events-metadata,  Next: events-status-info,  Prev: events-syntax,  Up: event-scheduler

20.4.4 Event Metadata
---------------------

Metadata about events can be obtained as follows:

   * Query the 'event' table of the 'mysql' database.

   * Query the *note 'EVENTS': events-table. table of the
     'INFORMATION_SCHEMA' database.  See *note events-table::.

   * Use the *note 'SHOW CREATE EVENT': show-create-event. statement.
     See *note show-create-event::.

   * Use the *note 'SHOW EVENTS': show-events. statement.  See *note
     show-events::.

*Event Scheduler Time Representation*

Each session in MySQL has a session time zone (STZ). This is the session
'time_zone' value that is initialized from the server's global
'time_zone' value when the session begins but may be changed during the
session.

The session time zone that is current when a *note 'CREATE EVENT':
create-event. or *note 'ALTER EVENT': alter-event. statement executes is
used to interpret times specified in the event definition.  This becomes
the event time zone (ETZ); that is, the time zone that is used for event
scheduling and is in effect within the event as it executes.

For representation of event information in the 'mysql.event' table, the
'execute_at', 'starts', and 'ends' times are converted to UTC and stored
along with the event time zone.  This enables event execution to proceed
as defined regardless of any subsequent changes to the server time zone
or daylight saving time effects.  The 'last_executed' time is also
stored in UTC.

If you select information from 'mysql.event', the times just mentioned
are retrieved as UTC values.  These times can also be obtained by
selecting from the *note 'INFORMATION_SCHEMA.EVENTS': events-table.
table or from *note 'SHOW EVENTS': show-events, but they are reported as
ETZ values.  Other times available from these sources indicate when an
event was created or last altered; these are displayed as STZ values.
The following table summarizes representation of event times.

Value              'mysql.event'      *note 'INFORMATION_SCHEMA.EVENTS': events-table.*note 'SHOW EVENTS': show-events.
                                                         
Execute at         UTC                ETZ                ETZ
                                                         
Starts             UTC                ETZ                ETZ
                                                         
Ends               UTC                ETZ                ETZ
                                                         
Last executed      UTC                ETZ                n/a
                                                         
Created            STZ                STZ                n/a
                                                         
Last altered       STZ                STZ                n/a
                                      


File: manual.info.tmp,  Node: events-status-info,  Next: events-privileges,  Prev: events-metadata,  Up: event-scheduler

20.4.5 Event Scheduler Status
-----------------------------

The Event Scheduler writes information about event execution that
terminates with an error or warning to the MySQL Server's error log.
See *note events-privileges:: for an example.

Information about the state of the Event Scheduler for debugging and
troubleshooting purposes can be obtained by running *note 'mysqladmin
debug': mysqladmin. (see *note mysqladmin::); after running this
command, the server's error log contains output relating to the Event
Scheduler, similar to what is shown here:

     Events status:
     LLA = Last Locked At  LUA = Last Unlocked At
     WOC = Waiting On Condition  DL = Data Locked

     Event scheduler status:
     State      : INITIALIZED
     Thread id  : 0
     LLA        : init_scheduler:313
     LUA        : init_scheduler:318
     WOC        : NO
     Workers    : 0
     Executed   : 0
     Data locked: NO

     Event queue status:
     Element count   : 1
     Data locked     : NO
     Attempting lock : NO
     LLA             : init_queue:148
     LUA             : init_queue:168
     WOC             : NO
     Next activation : 0000-00-00 00:00:00

In statements that occur as part of events executed by the Event
Scheduler, diagnostics messages (not only errors, but also warnings) are
written to the error log, and, on Windows, to the application event log.
For frequently executed events, it is possible for this to result in
many logged messages.  For example, for 'SELECT ... INTO VAR_LIST'
statements, if the query returns no rows, a warning with error code 1329
occurs ('No data'), and the variable values remain unchanged.  If the
query returns multiple rows, error 1172 occurs ('Result consisted of
more than one row').  For either condition, you can avoid having the
warnings be logged by declaring a condition handler; see *note
declare-handler::.  For statements that may retrieve multiple rows,
another strategy is to use 'LIMIT 1' to limit the result set to a single
row.


File: manual.info.tmp,  Node: events-privileges,  Prev: events-status-info,  Up: event-scheduler

20.4.6 The Event Scheduler and MySQL Privileges
-----------------------------------------------

To enable or disable the execution of scheduled events, it is necessary
to set the value of the global 'event_scheduler' system variable.  This
requires privileges sufficient to set global system variables.  See
*note system-variable-privileges::.

The 'EVENT' privilege governs the creation, modification, and deletion
of events.  This privilege can be bestowed using *note 'GRANT': grant.
For example, this *note 'GRANT': grant. statement confers the 'EVENT'
privilege for the schema named 'myschema' on the user 'jon@ghidora':

     GRANT EVENT ON myschema.* TO jon@ghidora;

(We assume that this user account already exists, and that we wish for
it to remain unchanged otherwise.)

To grant this same user the 'EVENT' privilege on all schemas, use the
following statement:

     GRANT EVENT ON *.* TO jon@ghidora;

The 'EVENT' privilege has global or schema-level scope.  Therefore,
trying to grant it on a single table results in an error as shown:

     mysql> GRANT EVENT ON myschema.mytable TO jon@ghidora;
     ERROR 1144 (42000): Illegal GRANT/REVOKE command; please
     consult the manual to see which privileges can be used

It is important to understand that an event is executed with the
privileges of its definer, and that it cannot perform any actions for
which its definer does not have the requisite privileges.  For example,
suppose that 'jon@ghidora' has the 'EVENT' privilege for 'myschema'.
Suppose also that this user has the 'SELECT' privilege for 'myschema',
but no other privileges for this schema.  It is possible for
'jon@ghidora' to create a new event such as this one:

     CREATE EVENT e_store_ts
         ON SCHEDULE
           EVERY 10 SECOND
         DO
           INSERT INTO myschema.mytable VALUES (UNIX_TIMESTAMP());

The user waits for a minute or so, and then performs a 'SELECT * FROM
mytable;' query, expecting to see several new rows in the table.
Instead, the table is empty.  Since the user does not have the 'INSERT'
privilege for the table in question, the event has no effect.

If you inspect the MySQL error log ('HOSTNAME.err'), you can see that
the event is executing, but the action it is attempting to perform
fails, as indicated by 'RetCode=0':

     060209 22:39:44 [Note]     EVEX EXECUTING event newdb.e [EXPR:10]
     060209 22:39:44 [Note]     EVEX EXECUTED event newdb.e  [EXPR:10]. RetCode=0
     060209 22:39:54 [Note]     EVEX EXECUTING event newdb.e [EXPR:10]
     060209 22:39:54 [Note]     EVEX EXECUTED event newdb.e  [EXPR:10]. RetCode=0
     060209 22:40:04 [Note]     EVEX EXECUTING event newdb.e [EXPR:10]
     060209 22:40:04 [Note]     EVEX EXECUTED event newdb.e  [EXPR:10]. RetCode=0

Since this user very likely does not have access to the error log, it is
possible to verify whether the event's action statement is valid by
executing it directly:

     mysql> INSERT INTO myschema.mytable VALUES (UNIX_TIMESTAMP());
     ERROR 1142 (42000): INSERT command denied to user
     'jon'@'ghidora' for table 'mytable'

Inspection of the *note 'INFORMATION_SCHEMA.EVENTS': events-table. table
shows that 'e_store_ts' exists and is enabled, but its 'LAST_EXECUTED'
column is 'NULL':

     mysql> SELECT * FROM INFORMATION_SCHEMA.EVENTS
          >     WHERE EVENT_NAME='e_store_ts'
          >     AND EVENT_SCHEMA='myschema'\G
     *************************** 1. row ***************************
        EVENT_CATALOG: NULL
         EVENT_SCHEMA: myschema
           EVENT_NAME: e_store_ts
              DEFINER: jon@ghidora
           EVENT_BODY: SQL
     EVENT_DEFINITION: INSERT INTO myschema.mytable VALUES (UNIX_TIMESTAMP())
           EVENT_TYPE: RECURRING
           EXECUTE_AT: NULL
       INTERVAL_VALUE: 5
       INTERVAL_FIELD: SECOND
             SQL_MODE: NULL
               STARTS: 0000-00-00 00:00:00
                 ENDS: 0000-00-00 00:00:00
               STATUS: ENABLED
        ON_COMPLETION: NOT PRESERVE
              CREATED: 2006-02-09 22:36:06
         LAST_ALTERED: 2006-02-09 22:36:06
        LAST_EXECUTED: NULL
        EVENT_COMMENT:
     1 row in set (0.00 sec)

To rescind the 'EVENT' privilege, use the *note 'REVOKE': revoke.
statement.  In this example, the 'EVENT' privilege on the schema
'myschema' is removed from the 'jon@ghidora' user account:

     REVOKE EVENT ON myschema.* FROM jon@ghidora;

*Important*:

Revoking the 'EVENT' privilege from a user does not delete or disable
any events that may have been created by that user.

An event is not migrated or dropped as a result of renaming or dropping
the user who created it.

Suppose that the user 'jon@ghidora' has been granted the 'EVENT' and
'INSERT' privileges on the 'myschema' schema.  This user then creates
the following event:

     CREATE EVENT e_insert
         ON SCHEDULE
           EVERY 7 SECOND
         DO
           INSERT INTO myschema.mytable;

After this event has been created, 'root' revokes the 'EVENT' privilege
for 'jon@ghidora'.  However, 'e_insert' continues to execute, inserting
a new row into 'mytable' each seven seconds.  The same would be true if
'root' had issued either of these statements:

   * 'DROP USER jon@ghidora;'

   * 'RENAME USER jon@ghidora TO someotherguy@ghidora;'

You can verify that this is true by examining the 'mysql.event' table
(discussed later in this section) or the *note
'INFORMATION_SCHEMA.EVENTS': events-table. table (see *note
events-table::) before and after issuing a *note 'DROP USER': drop-user.
or *note 'RENAME USER': rename-user. statement.

Event definitions are stored in the 'mysql.event' table.  To drop an
event created by another user account, the MySQL 'root' user (or another
user with the necessary privileges) can delete rows from this table.
For example, to remove the event 'e_insert' shown previously, 'root' can
use the following statement:

     DELETE FROM mysql.event
         WHERE db = 'myschema'
           AND name = 'e_insert';

It is very important to match the event name and database schema name
when deleting rows from the 'mysql.event' table.  This is because
different events of the same name can exist in different schemas.

Users' 'EVENT' privileges are stored in the 'Event_priv' columns of the
'mysql.user' and 'mysql.db' tables.  In both cases, this column holds
one of the values ''Y'' or ''N''.  ''N'' is the default.
'mysql.user.Event_priv' is set to ''Y'' for a given user only if that
user has the global 'EVENT' privilege (that is, if the privilege was
bestowed using 'GRANT EVENT ON *.*').  For a schema-level 'EVENT'
privilege, *note 'GRANT': grant. creates a row in 'mysql.db' and sets
that row's 'Db' column to the name of the schema, the 'User' column to
the name of the user, and the 'Event_priv' column to ''Y''.  There
should never be any need to manipulate these tables directly, since the
*note 'GRANT EVENT': grant. and 'REVOKE EVENT' statements perform the
required operations on them.

Five status variables provide counts of event-related operations (but
_not_ of statements executed by events; see *note
stored-program-restrictions::).  These are:

   * 'Com_create_event': The number of *note 'CREATE EVENT':
     create-event. statements executed since the last server restart.

   * 'Com_alter_event': The number of *note 'ALTER EVENT': alter-event.
     statements executed since the last server restart.

   * 'Com_drop_event': The number of *note 'DROP EVENT': drop-event.
     statements executed since the last server restart.

   * 'Com_show_create_event': The number of *note 'SHOW CREATE EVENT':
     show-create-event. statements executed since the last server
     restart.

   * 'Com_show_events': The number of *note 'SHOW EVENTS': show-events.
     statements executed since the last server restart.

You can view current values for all of these at one time by running the
statement 'SHOW STATUS LIKE '%event%';'.


File: manual.info.tmp,  Node: views,  Next: stored-objects-security,  Prev: event-scheduler,  Up: stored-objects

20.5 Using Views
================

* Menu:

* view-syntax::                  View Syntax
* view-algorithms::              View Processing Algorithms
* view-updatability::            Updatable and Insertable Views
* view-check-option::            The View WITH CHECK OPTION Clause
* view-metadata::                View Metadata

MySQL supports views, including updatable views.  Views are stored
queries that when invoked produce a result set.  A view acts as a
virtual table.

To use views if you have upgraded to MySQL 5.5 from an older release
that did not support views, you should upgrade your grant tables so that
they contain the view-related privileges.  See *note mysql-upgrade::.

The following discussion describes the syntax for creating and dropping
views, and shows some examples of how to use them.

*Additional Resources*

   * You may find the Views User Forum
     (https://forums.mysql.com/list.php?100) of use when working with
     views.

   * For answers to some commonly asked questions regarding views in
     MySQL, see *note faqs-views::.

   * There are some restrictions on the use of views; see *note
     view-restrictions::.


File: manual.info.tmp,  Node: view-syntax,  Next: view-algorithms,  Prev: views,  Up: views

20.5.1 View Syntax
------------------

The *note 'CREATE VIEW': create-view. statement creates a new view (see
*note create-view::).  To alter the definition of a view or drop a view,
use *note 'ALTER VIEW': alter-view. (see *note alter-view::), or *note
'DROP VIEW': drop-view. (see *note drop-view::).

A view can be created from many kinds of *note 'SELECT': select.
statements.  It can refer to base tables or other views.  It can use
joins, *note 'UNION': union, and subqueries.  The *note 'SELECT':
select. need not even refer to any tables.  The following example
defines a view that selects two columns from another table, as well as
an expression calculated from those columns:

     mysql> CREATE TABLE t (qty INT, price INT);
     mysql> INSERT INTO t VALUES(3, 50), (5, 60);
     mysql> CREATE VIEW v AS SELECT qty, price, qty*price AS value FROM t;
     mysql> SELECT * FROM v;
     +------+-------+-------+
     | qty  | price | value |
     +------+-------+-------+
     |    3 |    50 |   150 |
     |    5 |    60 |   300 |
     +------+-------+-------+
     mysql> SELECT * FROM v WHERE qty = 5;
     +------+-------+-------+
     | qty  | price | value |
     +------+-------+-------+
     |    5 |    60 |   300 |
     +------+-------+-------+


File: manual.info.tmp,  Node: view-algorithms,  Next: view-updatability,  Prev: view-syntax,  Up: views

20.5.2 View Processing Algorithms
---------------------------------

The optional 'ALGORITHM' clause for *note 'CREATE VIEW': create-view. or
*note 'ALTER VIEW': alter-view. is a MySQL extension to standard SQL. It
affects how MySQL processes the view.  'ALGORITHM' takes three values:
'MERGE', 'TEMPTABLE', or 'UNDEFINED'.

   * For 'MERGE', the text of a statement that refers to the view and
     the view definition are merged such that parts of the view
     definition replace corresponding parts of the statement.

   * For 'TEMPTABLE', the results from the view are retrieved into a
     temporary table, which then is used to execute the statement.

   * For 'UNDEFINED', MySQL chooses which algorithm to use.  It prefers
     'MERGE' over 'TEMPTABLE' if possible, because 'MERGE' is usually
     more efficient and because a view cannot be updatable if a
     temporary table is used.

   * If no 'ALGORITHM' clause is present, 'UNDEFINED' is the default
     algorithm.

A reason to specify 'TEMPTABLE' explicitly is that locks can be released
on underlying tables after the temporary table has been created and
before it is used to finish processing the statement.  This might result
in quicker lock release than the 'MERGE' algorithm so that other clients
that use the view are not blocked as long.

A view algorithm can be 'UNDEFINED' for three reasons:

   * No 'ALGORITHM' clause is present in the *note 'CREATE VIEW':
     create-view. statement.

   * The *note 'CREATE VIEW': create-view. statement has an explicit
     'ALGORITHM = UNDEFINED' clause.

   * 'ALGORITHM = MERGE' is specified for a view that can be processed
     only with a temporary table.  In this case, MySQL generates a
     warning and sets the algorithm to 'UNDEFINED'.

As mentioned earlier, 'MERGE' is handled by merging corresponding parts
of a view definition into the statement that refers to the view.  The
following examples briefly illustrate how the 'MERGE' algorithm works.
The examples assume that there is a view 'v_merge' that has this
definition:

     CREATE ALGORITHM = MERGE VIEW v_merge (vc1, vc2) AS
     SELECT c1, c2 FROM t WHERE c3 > 100;

Example 1: Suppose that we issue this statement:

     SELECT * FROM v_merge;

MySQL handles the statement as follows:

   * 'v_merge' becomes 't'

   * '*' becomes 'vc1, vc2', which corresponds to 'c1, c2'

   * The view 'WHERE' clause is added

The resulting statement to be executed becomes:

     SELECT c1, c2 FROM t WHERE c3 > 100;

Example 2: Suppose that we issue this statement:

     SELECT * FROM v_merge WHERE vc1 < 100;

This statement is handled similarly to the previous one, except that
'vc1 < 100' becomes 'c1 < 100' and the view 'WHERE' clause is added to
the statement 'WHERE' clause using an 'AND' connective (and parentheses
are added to make sure the parts of the clause are executed with correct
precedence).  The resulting statement to be executed becomes:

     SELECT c1, c2 FROM t WHERE (c3 > 100) AND (c1 < 100);

Effectively, the statement to be executed has a 'WHERE' clause of this
form:

     WHERE (select WHERE) AND (view WHERE)

If the 'MERGE' algorithm cannot be used, a temporary table must be used
instead.  'MERGE' cannot be used if the view contains any of the
following constructs:

   * Aggregate functions ('SUM()', 'MIN()', 'MAX()', 'COUNT()', and so
     forth)

   * 'DISTINCT'

   * 'GROUP BY'

   * 'HAVING'

   * 'LIMIT'

   * *note 'UNION': union. or *note 'UNION ALL': union.

   * Subquery in the select list

   * Assignment to user variables

   * Refers only to literal values (in this case, there is no underlying
     table)


File: manual.info.tmp,  Node: view-updatability,  Next: view-check-option,  Prev: view-algorithms,  Up: views

20.5.3 Updatable and Insertable Views
-------------------------------------

Some views are updatable and references to them can be used to specify
tables to be updated in data change statements.  That is, you can use
them in statements such as *note 'UPDATE': update, *note 'DELETE':
delete, or *note 'INSERT': insert. to update the contents of the
underlying table.

For a view to be updatable, there must be a one-to-one relationship
between the rows in the view and the rows in the underlying table.
There are also certain other constructs that make a view nonupdatable.
To be more specific, a view is not updatable if it contains any of the
following:

   * Aggregate functions ('SUM()', 'MIN()', 'MAX()', 'COUNT()', and so
     forth)

   * 'DISTINCT'

   * 'GROUP BY'

   * 'HAVING'

   * *note 'UNION': union. or *note 'UNION ALL': union.

   * Subquery in the select list

   * Certain joins (see additional join discussion later in this
     section)

   * Reference to nonupdatable view in the 'FROM' clause

   * Subquery in the 'WHERE' clause that refers to a table in the 'FROM'
     clause

   * Refers only to literal values (in this case, there is no underlying
     table to update)

   * 'ALGORITHM = TEMPTABLE' (use of a temporary table always makes a
     view nonupdatable)

   * Multiple references to any column of a base table

It is sometimes possible for a multiple-table view to be updatable,
assuming that it can be processed with the 'MERGE' algorithm.  For this
to work, the view must use an inner join (not an outer join or a *note
'UNION': union.).  Also, only a single table in the view definition can
be updated, so the 'SET' clause must name only columns from one of the
tables in the view.  Views that use *note 'UNION ALL': union. are not
permitted even though they might be theoretically updatable.

With respect to insertability (being updatable with *note 'INSERT':
insert. statements), an updatable view is insertable if it also
satisfies these additional requirements for the view columns:

   * There must be no duplicate view column names.

   * The view must contain all columns in the base table that do not
     have a default value.

   * The view columns must be simple column references.  They must not
     be expressions or composite expressions, such as these:

          3.14159
          col1 + 3
          UPPER(col2)
          col3 / col4
          (SUBQUERY)

MySQL sets a flag, called the view updatability flag, at *note 'CREATE
VIEW': create-view. time.  The flag is set to 'YES' (true) if *note
'UPDATE': update. and *note 'DELETE': delete. (and similar operations)
are legal for the view.  Otherwise, the flag is set to 'NO' (false).
The 'IS_UPDATABLE' column in the *note 'INFORMATION_SCHEMA.VIEWS':
views-table. table displays the status of this flag.  It means that the
server always knows whether a view is updatable.

If a view is not updatable, statements such *note 'UPDATE': update,
*note 'DELETE': delete, and *note 'INSERT': insert. are illegal and are
rejected.  (Even if a view is updatable, it might not be possible to
insert into it, as described elsewhere in this section.)

The updatability of views may be affected by the value of the
'updatable_views_with_limit' system variable.  See *note
server-system-variables::.

Earlier discussion in this section pointed out that a view is not
insertable if not all columns are simple column references (for example,
if it contains columns that are expressions or composite expressions).
Although such a view is not insertable, it can be updatable if you
update only columns that are not expressions.  Consider this view:

     CREATE VIEW v AS SELECT col1, 1 AS col2 FROM t;

This view is not insertable because 'col2' is an expression.  But it is
updatable if the update does not try to update 'col2'.  This update is
permissible:

     UPDATE v SET col1 = 0;

This update is not permissible because it attempts to update an
expression column:

     UPDATE v SET col2 = 0;

For a multiple-table updatable view, *note 'INSERT': insert. can work if
it inserts into a single table.  *note 'DELETE': delete. is not
supported.

*note 'INSERT DELAYED': insert-delayed. is not supported for views.

If a table contains an 'AUTO_INCREMENT' column, inserting into an
insertable view on the table that does not include the 'AUTO_INCREMENT'
column does not change the value of 'LAST_INSERT_ID()', because the side
effects of inserting default values into columns not part of the view
should not be visible.


File: manual.info.tmp,  Node: view-check-option,  Next: view-metadata,  Prev: view-updatability,  Up: views

20.5.4 The View WITH CHECK OPTION Clause
----------------------------------------

The 'WITH CHECK OPTION' clause can be given for an updatable view to
prevent inserts to rows for which the 'WHERE' clause in the
SELECT_STATEMENT is not true.  It also prevents updates to rows for
which the 'WHERE' clause is true but the update would cause it to be not
true (in other words, it prevents visible rows from being updated to
nonvisible rows).

In a 'WITH CHECK OPTION' clause for an updatable view, the 'LOCAL' and
'CASCADED' keywords determine the scope of check testing when the view
is defined in terms of another view.  When neither keyword is given, the
default is 'CASCADED'.  The 'LOCAL' keyword restricts the 'CHECK OPTION'
only to the view being defined.  'CASCADED' causes the checks for
underlying views to be evaluated as well.

Consider the definitions for the following table and set of views:

     CREATE TABLE t1 (a INT);
     CREATE VIEW v1 AS SELECT * FROM t1 WHERE a < 2
     WITH CHECK OPTION;
     CREATE VIEW v2 AS SELECT * FROM v1 WHERE a > 0
     WITH LOCAL CHECK OPTION;
     CREATE VIEW v3 AS SELECT * FROM v1 WHERE a > 0
     WITH CASCADED CHECK OPTION;

Here the 'v2' and 'v3' views are defined in terms of another view, 'v1'.
'v2' has a 'LOCAL' check option, so inserts are tested only against the
'v2' check.  'v3' has a 'CASCADED' check option, so inserts are tested
not only against its own check, but against those of underlying views.
The following statements illustrate these differences:

     mysql> INSERT INTO v2 VALUES (2);
     Query OK, 1 row affected (0.00 sec)
     mysql> INSERT INTO v3 VALUES (2);
     ERROR 1369 (HY000): CHECK OPTION failed 'test.v3'


File: manual.info.tmp,  Node: view-metadata,  Prev: view-check-option,  Up: views

20.5.5 View Metadata
--------------------

Metadata about views can be obtained as follows:

   * Query the *note 'VIEWS': views-table. table of the
     'INFORMATION_SCHEMA' database.  See *note views-table::.

   * Use the *note 'SHOW CREATE VIEW': show-create-view. statement.  See
     *note show-create-view::.


File: manual.info.tmp,  Node: stored-objects-security,  Next: stored-programs-logging,  Prev: views,  Up: stored-objects

20.6 Stored Object Access Control
=================================

Stored programs (procedures, functions, triggers, and events) and views
are defined prior to use and, when referenced, execute within a security
context that determines their privileges.  These privileges are
controlled by their 'DEFINER' attribute and 'SQL SECURITY'
characteristic.

   * *note stored-objects-security-definer::

   * *note stored-objects-security-sql-security::

   * *note stored-objects-security-examples::

   * *note stored-objects-security-guidelines::

*The DEFINER Attribute*

All stored object definitions can include a 'DEFINER' attribute that
names a MySQL account.  If a definition omits the 'DEFINER' attribute,
the default definer is the user who creates the object.

MySQL uses the following rules to control which accounts a user can
specify in an object 'DEFINER' attribute:

   * If you have the 'SUPER' privilege, you can specify any account as
     the 'DEFINER' value, although a warning is generated if the account
     does not exist.

   * Otherwise, the only permitted account is your own, either specified
     literally or as 'CURRENT_USER' or 'CURRENT_USER()'.  You cannot set
     the definer to some other account.

Creating a stored object with a nonexistent 'DEFINER' account may have
negative consequences:

   * For a stored routine, an error occurs at routine execution time if
     the 'SQL SECURITY' value is 'DEFINER' but the definer account does
     not exist.

   * For a trigger, it is not a good idea for trigger activation to
     occur until the account actually does exist.  Otherwise, the
     behavior with respect to privilege checking is undefined.

   * For an event, an error occurs at event execution time if the
     account does not exist.

   * For a view, an error occurs when the view is referenced if the 'SQL
     SECURITY' value is 'DEFINER' but the definer account does not
     exist.

*The SQL SECURITY Characteristic*

Definitions for stored routines (procedures and functions) and views can
include an 'SQL SECURITY' characteristic with a value of 'DEFINER' or
'INVOKER' to specify whether the object executes in definer or invoker
context.  If a definition omits the 'SQL SECURITY' characteristic, the
default is definer context.

Triggers and events have no 'SQL SECURITY' characteristic and always
execute in definer context.  The server invokes these objects
automatically as necessary, so there is no invoking user.

Definer and invoker security contexts differ as follows:

   * A stored object that executes in definer security context executes
     with the privileges of the account named by its 'DEFINER'
     attribute.  These privileges may be entirely different from those
     of the invoking user.  The invoker must have appropriate privileges
     to reference the object (for example, 'EXECUTE' to call a stored
     procedure or 'SELECT' to select from a view), but during object
     execution, the invoker's privileges are ignored and only the
     'DEFINER' account privileges matter.  If the 'DEFINER' account has
     few privileges, the object is correspondingly limited in the
     operations it can perform.  If the 'DEFINER' account is highly
     privileged (such as a 'root' account), the object can perform
     powerful operations _no matter who invokes it._

   * A stored routine or view that executes in invoker security context
     can perform only operations for which the invoker has privileges.
     The 'DEFINER' attribute has no effect during object execution.

*Examples*

Consider the following stored procedure, which is declared with 'SQL
SECURITY DEFINER' to execute in definer security context:

     CREATE DEFINER = 'admin'@'localhost' PROCEDURE p1()
     SQL SECURITY DEFINER
     BEGIN
       UPDATE t1 SET counter = counter + 1;
     END;

Any user who has the 'EXECUTE' privilege for 'p1' can invoke it with a
*note 'CALL': call. statement.  However, when 'p1' executes, it does so
in definer security context and thus executes with the privileges of
''admin'@'localhost'', the account named in the 'DEFINER' attribute.
This account must have the 'EXECUTE' privilege for 'p1' as well as the
'UPDATE' privilege for the table 't1' referenced within the object body.
Otherwise, the procedure fails.

Now consider this stored procedure, which is identical to 'p1' except
that its 'SQL SECURITY' characteristic is 'INVOKER':

     CREATE DEFINER = 'admin'@'localhost' PROCEDURE p2()
     SQL SECURITY INVOKER
     BEGIN
       UPDATE t1 SET counter = counter + 1;
     END;

Unlike 'p1', 'p2' executes in invoker security context and thus with the
privileges of the invoking user regardless of the 'DEFINER' attribute
value.  'p2' fails if the invoker lacks the 'EXECUTE' privilege for 'p2'
or the 'UPDATE' privilege for the table 't1'.

*Risk-Minimization Guidelines*

To minimize the risk potential for stored object creation and use,
follow these guidelines:

   * For a stored routine or view, use 'SQL SECURITY INVOKER' in the
     object definition when possible so that it can be used only by
     users with permissions appropriate for the operations performed by
     the object.

   * If you create definer-context stored objects while using an account
     that has the 'SUPER' privilege, specify an explicit 'DEFINER'
     attribute that names an account possessing only the privileges
     required for the operations performed by the object.  Specify a
     highly privileged 'DEFINER' account only when absolutely necessary.

   * Administrators can prevent users from creating stored objects that
     specify highly privileged 'DEFINER' accounts by not granting them
     the 'SUPER' privilege.

   * Definer-context objects should be written keeping in mind that they
     may be able to access data for which the invoking user has no
     privileges.  In some cases, you can prevent references to these
     objects by not granting unauthorized users particular privileges:

        * A stored routine cannot be referenced by a user who does not
          have the 'EXECUTE' privilege for it.

        * A view cannot be referenced by a user who does not have the
          appropriate privilege for it ('SELECT' to select from it,
          'INSERT' to insert into it, and so forth).

     However, no such control exists for triggers and events because
     they always execute in definer context.  The server invokes these
     objects automatically as necessary; users do not reference them
     directly:

        * A trigger is activated by access to the table with which it is
          associated, even ordinary table accesses by users with no
          special privileges.

        * An event is executed by the server on a scheduled basis.

     In both cases, if the 'DEFINER' account is highly privileged, the
     object may be able to perform sensitive or dangerous operations.
     This remains true if the privileges needed to create the object are
     revoked from the account of the user who created it.
     Administrators should be especially careful about granting users
     object-creation privileges.


File: manual.info.tmp,  Node: stored-programs-logging,  Next: stored-program-restrictions,  Prev: stored-objects-security,  Up: stored-objects

20.7 Stored Program Binary Logging
==================================

The binary log contains information about SQL statements that modify
database contents.  This information is stored in the form of 'events'
that describe the modifications.  (Binary log events differ from
scheduled event stored objects.)  The binary log has two important
purposes:

   * For replication, the binary log is used on master replication
     servers as a record of the statements to be sent to slave servers.
     The master server sends the events contained in its binary log to
     its slaves, which execute those events to make the same data
     changes that were made on the master.  See *note
     replication-implementation::.

   * Certain data recovery operations require use of the binary log.
     After a backup file has been restored, the events in the binary log
     that were recorded after the backup was made are re-executed.
     These events bring databases up to date from the point of the
     backup.  See *note recovery-from-backups::.

However, if logging occurs at the statement level, there are certain
binary logging issues with respect to stored programs (stored procedures
and functions, triggers, and events):

   * In some cases, a statement might affect different sets of rows on
     master and slave.

   * Replicated statements executed on a slave are processed by the
     slave SQL thread, which has full privileges.  It is possible for a
     procedure to follow different execution paths on master and slave
     servers, so a user can write a routine containing a dangerous
     statement that will execute only on the slave where it is processed
     by a thread that has full privileges.

   * If a stored program that modifies data is nondeterministic, it is
     not repeatable.  This can result in different data on master and
     slave, or cause restored data to differ from the original data.

This section describes how MySQL handles binary logging for stored
programs.  It states the current conditions that the implementation
places on the use of stored programs, and what you can do to avoid
logging problems.  It also provides additional information about the
reasons for these conditions.

In general, the issues described here result when binary logging occurs
at the SQL statement level (statement-based binary logging).  If you use
row-based binary logging, the log contains changes made to individual
rows as a result of executing SQL statements.  When routines or triggers
execute, row changes are logged, not the statements that make the
changes.  For stored procedures, this means that the *note 'CALL': call.
statement is not logged.  For stored functions, row changes made within
the function are logged, not the function invocation.  For triggers, row
changes made by the trigger are logged.  On the slave side, only the row
changes are seen, not the stored program invocation.

Mixed format binary logging ('binlog_format=MIXED') uses statement-based
binary logging, except for cases where only row-based binary logging is
guaranteed to lead to proper results.  With mixed format, when a stored
function, stored procedure, trigger, event, or prepared statement
contains anything that is not safe for statement-based binary logging,
the entire statement is marked as unsafe and logged in row format.  The
statements used to create and drop procedures, functions, triggers, and
events are always safe, and are logged in statement format.  For more
information about row-based, mixed, and statement-based logging, and how
safe and unsafe statements are determined, see *note
replication-formats::.

Unless noted otherwise, the remarks here assume that binary logging is
enabled on the server (see *note binary-log::.)  If the binary log is
not enabled, replication is not possible, nor is the binary log
available for data recovery.

The conditions on the use of stored functions in MySQL can be summarized
as follows.  These conditions do not apply to stored procedures or Event
Scheduler events and they do not apply unless binary logging is enabled.

   * To create or alter a stored function, you must have the 'SUPER'
     privilege, in addition to the 'CREATE ROUTINE' or 'ALTER ROUTINE'
     privilege that is normally required.  (Depending on the 'DEFINER'
     value in the function definition, 'SUPER' might be required
     regardless of whether binary logging is enabled.  See *note
     create-procedure::.)

   * When you create a stored function, you must declare either that it
     is deterministic or that it does not modify data.  Otherwise, it
     may be unsafe for data recovery or replication.

     By default, for a *note 'CREATE FUNCTION': create-function.
     statement to be accepted, at least one of 'DETERMINISTIC', 'NO
     SQL', or 'READS SQL DATA' must be specified explicitly.  Otherwise
     an error occurs:

          ERROR 1418 (HY000): This function has none of DETERMINISTIC, NO SQL,
          or READS SQL DATA in its declaration and binary logging is enabled
          (you *might* want to use the less safe log_bin_trust_function_creators
          variable)

     This function is deterministic (and does not modify data), so it is
     safe:

          CREATE FUNCTION f1(i INT)
          RETURNS INT
          DETERMINISTIC
          READS SQL DATA
          BEGIN
            RETURN i;
          END;

     This function uses 'UUID()', which is not deterministic, so the
     function also is not deterministic and is not safe:

          CREATE FUNCTION f2()
          RETURNS CHAR(36) CHARACTER SET utf8
          BEGIN
            RETURN UUID();
          END;

     This function modifies data, so it may not be safe:

          CREATE FUNCTION f3(p_id INT)
          RETURNS INT
          BEGIN
            UPDATE t SET modtime = NOW() WHERE id = p_id;
            RETURN ROW_COUNT();
          END;

     Assessment of the nature of a function is based on the 'honesty' of
     the creator.  MySQL does not check that a function declared
     'DETERMINISTIC' is free of statements that produce nondeterministic
     results.

   * When you attempt to execute a stored function, if
     'binlog_format=STATEMENT' is set, the 'DETERMINISTIC' keyword must
     be specified in the function definition.  If this is not the case,
     an error is generated and the function does not run, unless
     'log_bin_trust_function_creators=1' is specified to override this
     check (see below).  For recursive function calls, the
     'DETERMINISTIC' keyword is required on the outermost call only.  If
     row-based or mixed binary logging is in use, the statement is
     accepted and replicated even if the function was defined without
     the 'DETERMINISTIC' keyword.

   * Because MySQL does not check if a function really is deterministic
     at creation time, the invocation of a stored function with the
     'DETERMINISTIC' keyword might carry out an action that is unsafe
     for statement-based logging, or invoke a function or procedure
     containing unsafe statements.  If this occurs when
     'binlog_format=STATEMENT' is set, a warning message is issued.  If
     row-based or mixed binary logging is in use, no warning is issued,
     and the statement is replicated in row-based format.

   * To relax the preceding conditions on function creation (that you
     must have the 'SUPER' privilege and that a function must be
     declared deterministic or to not modify data), set the global
     'log_bin_trust_function_creators' system variable to 1.  By
     default, this variable has a value of 0, but you can change it like
     this:

          mysql> SET GLOBAL log_bin_trust_function_creators = 1;

     You can also set this variable at server startup.

     If binary logging is not enabled, 'log_bin_trust_function_creators'
     does not apply.  'SUPER' is not required for function creation
     unless, as described previously, the 'DEFINER' value in the
     function definition requires it.

   * For information about built-in functions that may be unsafe for
     replication (and thus cause stored functions that use them to be
     unsafe as well), see *note replication-features::.

Triggers are similar to stored functions, so the preceding remarks
regarding functions also apply to triggers with the following exception:
*note 'CREATE TRIGGER': create-trigger. does not have an optional
'DETERMINISTIC' characteristic, so triggers are assumed to be always
deterministic.  However, this assumption might be invalid in some cases.
For example, the 'UUID()' function is nondeterministic (and does not
replicate).  Be careful about using such functions in triggers.

Triggers can update tables, so error messages similar to those for
stored functions occur with *note 'CREATE TRIGGER': create-trigger. if
you do not have the required privileges.  On the slave side, the slave
uses the trigger 'DEFINER' attribute to determine which user is
considered to be the creator of the trigger.

The rest of this section provides additional detail about the logging
implementation and its implications.  You need not read it unless you
are interested in the background on the rationale for the current
logging-related conditions on stored routine use.  This discussion
applies only for statement-based logging, and not for row-based logging,
with the exception of the first item: 'CREATE' and 'DROP' statements are
logged as statements regardless of the logging mode.

   * The server writes *note 'CREATE EVENT': create-event, *note 'CREATE
     PROCEDURE': create-procedure, *note 'CREATE FUNCTION':
     create-function, *note 'ALTER EVENT': alter-event, *note 'ALTER
     PROCEDURE': alter-procedure, *note 'ALTER FUNCTION':
     alter-function, *note 'DROP EVENT': drop-event, *note 'DROP
     PROCEDURE': drop-procedure, and *note 'DROP FUNCTION':
     drop-function. statements to the binary log.

   * A stored function invocation is logged as a *note 'SELECT': select.
     statement if the function changes data and occurs within a
     statement that would not otherwise be logged.  This prevents
     nonreplication of data changes that result from use of stored
     functions in nonlogged statements.  For example, *note 'SELECT':
     select. statements are not written to the binary log, but a *note
     'SELECT': select. might invoke a stored function that makes
     changes.  To handle this, a 'SELECT FUNC_NAME()' statement is
     written to the binary log when the given function makes a change.
     Suppose that the following statements are executed on the master:

          CREATE FUNCTION f1(a INT) RETURNS INT
          BEGIN
            IF (a < 3) THEN
              INSERT INTO t2 VALUES (a);
            END IF;
            RETURN 0;
          END;

          CREATE TABLE t1 (a INT);
          INSERT INTO t1 VALUES (1),(2),(3);

          SELECT f1(a) FROM t1;

     When the *note 'SELECT': select. statement executes, the function
     'f1()' is invoked three times.  Two of those invocations insert a
     row, and MySQL logs a *note 'SELECT': select. statement for each of
     them.  That is, MySQL writes the following statements to the binary
     log:

          SELECT f1(1);
          SELECT f1(2);

     The server also logs a *note 'SELECT': select. statement for a
     stored function invocation when the function invokes a stored
     procedure that causes an error.  In this case, the server writes
     the *note 'SELECT': select. statement to the log along with the
     expected error code.  On the slave, if the same error occurs, that
     is the expected result and replication continues.  Otherwise,
     replication stops.

   * Logging stored function invocations rather than the statements
     executed by a function has a security implication for replication,
     which arises from two factors:

        * It is possible for a function to follow different execution
          paths on master and slave servers.

        * Statements executed on a slave are processed by the slave SQL
          thread which has full privileges.

     The implication is that although a user must have the 'CREATE
     ROUTINE' privilege to create a function, the user can write a
     function containing a dangerous statement that will execute only on
     the slave where it is processed by a thread that has full
     privileges.  For example, if the master and slave servers have
     server ID values of 1 and 2, respectively, a user on the master
     server could create and invoke an unsafe function 'unsafe_func()'
     as follows:

          mysql> delimiter //
          mysql> CREATE FUNCTION unsafe_func () RETURNS INT
              -> BEGIN
              ->   IF @@server_id=2 THEN DANGEROUS_STATEMENT; END IF;
              ->   RETURN 1;
              -> END;
              -> //
          mysql> delimiter ;
          mysql> INSERT INTO t VALUES(unsafe_func());

     The *note 'CREATE FUNCTION': create-function. and *note 'INSERT':
     insert. statements are written to the binary log, so the slave will
     execute them.  Because the slave SQL thread has full privileges, it
     will execute the dangerous statement.  Thus, the function
     invocation has different effects on the master and slave and is not
     replication-safe.

     To guard against this danger for servers that have binary logging
     enabled, stored function creators must have the 'SUPER' privilege,
     in addition to the usual 'CREATE ROUTINE' privilege that is
     required.  Similarly, to use *note 'ALTER FUNCTION':
     alter-function, you must have the 'SUPER' privilege in addition to
     the 'ALTER ROUTINE' privilege.  Without the 'SUPER' privilege, an
     error will occur:

          ERROR 1419 (HY000): You do not have the SUPER privilege and
          binary logging is enabled (you *might* want to use the less safe
          log_bin_trust_function_creators variable)

     If you do not want to require function creators to have the 'SUPER'
     privilege (for example, if all users with the 'CREATE ROUTINE'
     privilege on your system are experienced application developers),
     set the global 'log_bin_trust_function_creators' system variable to
     1.  You can also set this variable at server startup.  If binary
     logging is not enabled, 'log_bin_trust_function_creators' does not
     apply.  'SUPER' is not required for function creation unless, as
     described previously, the 'DEFINER' value in the function
     definition requires it.

   * If a function that performs updates is nondeterministic, it is not
     repeatable.  This can have two undesirable effects:

        * It will make a slave different from the master.

        * Restored data will be different from the original data.

     To deal with these problems, MySQL enforces the following
     requirement: On a master server, creation and alteration of a
     function is refused unless you declare the function to be
     deterministic or to not modify data.  Two sets of function
     characteristics apply here:

        * The 'DETERMINISTIC' and 'NOT DETERMINISTIC' characteristics
          indicate whether a function always produces the same result
          for given inputs.  The default is 'NOT DETERMINISTIC' if
          neither characteristic is given.  To declare that a function
          is deterministic, you must specify 'DETERMINISTIC' explicitly.

        * The 'CONTAINS SQL', 'NO SQL', 'READS SQL DATA', and 'MODIFIES
          SQL DATA' characteristics provide information about whether
          the function reads or writes data.  Either 'NO SQL' or 'READS
          SQL DATA' indicates that a function does not change data, but
          you must specify one of these explicitly because the default
          is 'CONTAINS SQL' if no characteristic is given.

     By default, for a *note 'CREATE FUNCTION': create-function.
     statement to be accepted, at least one of 'DETERMINISTIC', 'NO
     SQL', or 'READS SQL DATA' must be specified explicitly.  Otherwise
     an error occurs:

          ERROR 1418 (HY000): This function has none of DETERMINISTIC, NO SQL,
          or READS SQL DATA in its declaration and binary logging is enabled
          (you *might* want to use the less safe log_bin_trust_function_creators
          variable)

     If you set 'log_bin_trust_function_creators' to 1, the requirement
     that functions be deterministic or not modify data is dropped.

   * Stored procedure calls are logged at the statement level rather
     than at the *note 'CALL': call. level.  That is, the server does
     not log the *note 'CALL': call. statement, it logs those statements
     within the procedure that actually execute.  As a result, the same
     changes that occur on the master will be observed on slave servers.
     This prevents problems that could result from a procedure having
     different execution paths on different machines.

     In general, statements executed within a stored procedure are
     written to the binary log using the same rules that would apply
     were the statements to be executed in standalone fashion.  Some
     special care is taken when logging procedure statements because
     statement execution within procedures is not quite the same as in
     nonprocedure context:

        * 
          A statement to be logged might contain references to local
          procedure variables.  These variables do not exist outside of
          stored procedure context, so a statement that refers to such a
          variable cannot be logged literally.  Instead, each reference
          to a local variable is replaced by this construct for logging
          purposes:

               NAME_CONST(VAR_NAME, VAR_VALUE)

          VAR_NAME is the local variable name, and VAR_VALUE is a
          constant indicating the value that the variable has at the
          time the statement is logged.  'NAME_CONST()' has a value of
          VAR_VALUE, and a 'name' of VAR_NAME.  Thus, if you invoke this
          function directly, you get a result like this:

               mysql> SELECT NAME_CONST('myname', 14);
               +--------+
               | myname |
               +--------+
               |     14 |
               +--------+

          'NAME_CONST()' enables a logged standalone statement to be
          executed on a slave with the same effect as the original
          statement that was executed on the master within a stored
          procedure.

          The use of 'NAME_CONST()' can result in a problem for *note
          'CREATE TABLE ... SELECT': create-table. statements when the
          source column expressions refer to local variables.
          Converting these references to 'NAME_CONST()' expressions can
          result in column names that are different on the master and
          slave servers, or names that are too long to be legal column
          identifiers.  A workaround is to supply aliases for columns
          that refer to local variables.  Consider this statement when
          'myvar' has a value of 1:

               CREATE TABLE t1 SELECT myvar;

          That will be rewritten as follows:

               CREATE TABLE t1 SELECT NAME_CONST(myvar, 1);

          To ensure that the master and slave tables have the same
          column names, write the statement like this:

               CREATE TABLE t1 SELECT myvar AS myvar;

          The rewritten statement becomes:

               CREATE TABLE t1 SELECT NAME_CONST(myvar, 1) AS myvar;

        * A statement to be logged might contain references to
          user-defined variables.  To handle this, MySQL writes a *note
          'SET': set-variable. statement to the binary log to make sure
          that the variable exists on the slave with the same value as
          on the master.  For example, if a statement refers to a
          variable '@my_var', that statement will be preceded in the
          binary log by the following statement, where VALUE is the
          value of '@my_var' on the master:

               SET @my_var = VALUE;

        * Procedure calls can occur within a committed or rolled-back
          transaction.  Transactional context is accounted for so that
          the transactional aspects of procedure execution are
          replicated correctly.  That is, the server logs those
          statements within the procedure that actually execute and
          modify data, and also logs *note 'BEGIN': commit, *note
          'COMMIT': commit, and *note 'ROLLBACK': commit. statements as
          necessary.  For example, if a procedure updates only
          transactional tables and is executed within a transaction that
          is rolled back, those updates are not logged.  If the
          procedure occurs within a committed transaction, *note
          'BEGIN': commit. and *note 'COMMIT': commit. statements are
          logged with the updates.  For a procedure that executes within
          a rolled-back transaction, its statements are logged using the
          same rules that would apply if the statements were executed in
          standalone fashion:

             * Updates to transactional tables are not logged.

             * Updates to nontransactional tables are logged because
               rollback does not cancel them.

             * Updates to a mix of transactional and nontransactional
               tables are logged surrounded by *note 'BEGIN': commit.
               and *note 'ROLLBACK': commit. so that slaves will make
               the same changes and rollbacks as on the master.

   * A stored procedure call is _not_ written to the binary log at the
     statement level if the procedure is invoked from within a stored
     function.  In that case, the only thing logged is the statement
     that invokes the function (if it occurs within a statement that is
     logged) or a *note 'DO': do. statement (if it occurs within a
     statement that is not logged).  For this reason, care should be
     exercised in the use of stored functions that invoke a procedure,
     even if the procedure is otherwise safe in itself.


File: manual.info.tmp,  Node: stored-program-restrictions,  Next: view-restrictions,  Prev: stored-programs-logging,  Up: stored-objects

20.8 Restrictions on Stored Programs
====================================

These restrictions apply to the features described in *note
stored-objects::.

Some of the restrictions noted here apply to all stored routines; that
is, both to stored procedures and stored functions.  There are also some
restrictions specific to stored functions but not to stored procedures.

The restrictions for stored functions also apply to triggers.  There are
also some restrictions specific to triggers.

The restrictions for stored procedures also apply to the *note 'DO': do.
clause of Event Scheduler event definitions.  There are also some
restrictions specific to events.

*SQL Statements Not Permitted in Stored Routines*

Stored routines cannot contain arbitrary SQL statements.  The following
statements are not permitted:

   * The locking statements *note 'LOCK TABLES': lock-tables. and *note
     'UNLOCK TABLES': lock-tables.

   * *note 'ALTER VIEW': alter-view.

   * *note 'LOAD DATA': load-data. and 'LOAD TABLE'.

   * SQL prepared statements (*note 'PREPARE': prepare, *note 'EXECUTE':
     execute, *note 'DEALLOCATE PREPARE': deallocate-prepare.) can be
     used in stored procedures, but not stored functions or triggers.
     Thus, stored functions and triggers cannot use dynamic SQL (where
     you construct statements as strings and then execute them).

   * Generally, statements not permitted in SQL prepared statements are
     also not permitted in stored programs.  For a list of statements
     supported as prepared statements, see *note
     sql-prepared-statements::.  Exceptions are *note 'SIGNAL': signal.
     and *note 'RESIGNAL': resignal, which are not permissible as
     prepared statements but are permitted in stored programs.

   * Because local variables are in scope only during stored program
     execution, references to them are not permitted in prepared
     statements created within a stored program.  Prepared statement
     scope is the current session, not the stored program, so the
     statement could be executed after the program ends, at which point
     the variables would no longer be in scope.  For example, 'SELECT
     ... INTO LOCAL_VAR' cannot be used as a prepared statement.  This
     restriction also applies to stored procedure and function
     parameters.  See *note prepare::.

   * Inserts cannot be delayed.  *note 'INSERT DELAYED': insert-delayed.
     syntax is accepted, but the statement is handled as a normal *note
     'INSERT': insert.

   * Within all stored programs (stored procedures and functions,
     triggers, and events), the parser treats *note 'BEGIN [WORK]':
     commit. as the beginning of a *note 'BEGIN ... END': begin-end.
     block.  To begin a transaction in this context, use *note 'START
     TRANSACTION': commit. instead.

*Restrictions for Stored Functions*

The following additional statements or operations are not permitted
within stored functions.  They are permitted within stored procedures,
except stored procedures that are invoked from within a stored function
or trigger.  For example, if you use *note 'FLUSH': flush. in a stored
procedure, that stored procedure cannot be called from a stored function
or trigger.

   * Statements that perform explicit or implicit commit or rollback.
     Support for these statements is not required by the SQL standard,
     which states that each DBMS vendor may decide whether to permit
     them.

   * Statements that return a result set.  This includes *note 'SELECT':
     select. statements that do not have an 'INTO VAR_LIST' clause and
     other statements such as *note 'SHOW': show, *note 'EXPLAIN':
     explain, and *note 'CHECK TABLE': check-table.  A function can
     process a result set either with *note 'SELECT ... INTO VAR_LIST':
     select-into. or by using a cursor and *note 'FETCH': fetch.
     statements.  See *note select-into::, and *note cursors::.

   * *note 'FLUSH': flush. statements.

   * Stored functions cannot be used recursively.

   * A stored function or trigger cannot modify a table that is already
     being used (for reading or writing) by the statement that invoked
     the function or trigger.

   * If you refer to a temporary table multiple times in a stored
     function under different aliases, a 'Can't reopen table:
     'TBL_NAME'' error occurs, even if the references occur in different
     statements within the function.

   * *note 'HANDLER ... READ': handler. statements that invoke stored
     functions can cause replication errors.  As of MySQL 5.5.7, such
     statements are disallowed.

*Restrictions for Triggers*

For triggers, the following additional restrictions apply:

   * Triggers are not activated by foreign key actions.

   * When using row-based replication, triggers on the slave are not
     activated by statements originating on the master.  The triggers on
     the slave are activated when using statement-based replication.
     For more information, see *note replication-features-triggers::.

   * The *note 'RETURN': return. statement is not permitted in triggers,
     which cannot return a value.  To exit a trigger immediately, use
     the *note 'LEAVE': leave. statement.

   * Triggers are not permitted on tables in the 'mysql' database.  Nor
     are they permitted on 'INFORMATION_SCHEMA' or 'performance_schema'
     tables.  Those tables are actually views and triggers are not
     permitted on views.

   * The trigger cache does not detect when metadata of the underlying
     objects has changed.  If a trigger uses a table and the table has
     changed since the trigger was loaded into the cache, the trigger
     operates using the outdated metadata.

*Name Conflicts within Stored Routines*

The same identifier might be used for a routine parameter, a local
variable, and a table column.  Also, the same local variable name can be
used in nested blocks.  For example:

     CREATE PROCEDURE p (i INT)
     BEGIN
       DECLARE i INT DEFAULT 0;
       SELECT i FROM t;
       BEGIN
         DECLARE i INT DEFAULT 1;
         SELECT i FROM t;
       END;
     END;

In such cases, the identifier is ambiguous and the following precedence
rules apply:

   * A local variable takes precedence over a routine parameter or table
     column.

   * A routine parameter takes precedence over a table column.

   * A local variable in an inner block takes precedence over a local
     variable in an outer block.

The behavior that variables take precedence over table columns is
nonstandard.

*Replication Considerations*

Use of stored routines can cause replication problems.  This issue is
discussed further in *note stored-programs-logging::.

The '--replicate-wild-do-table=DB_NAME.TBL_NAME' option applies to
tables, views, and triggers.  It does not apply to stored procedures and
functions, or events.  To filter statements operating on the latter
objects, use one or more of the '--replicate-*-db' options.

*Debugging Considerations*

There are no stored routine debugging facilities.

*Unsupported Syntax from the SQL:2003 Standard*

The MySQL stored routine syntax is based on the SQL:2003 standard.  The
following items from that standard are not currently supported:

   * 'UNDO' handlers

   * 'FOR' loops

*Stored Routine Concurrency Considerations*

To prevent problems of interaction between sessions, when a client
issues a statement, the server uses a snapshot of routines and triggers
available for execution of the statement.  That is, the server
calculates a list of procedures, functions, and triggers that may be
used during execution of the statement, loads them, and then proceeds to
execute the statement.  While the statement executes, it does not see
changes to routines performed by other sessions.

For maximum concurrency, stored functions should minimize their
side-effects; in particular, updating a table within a stored function
can reduce concurrent operations on that table.  A stored function
acquires table locks before executing, to avoid inconsistency in the
binary log due to mismatch of the order in which statements execute and
when they appear in the log.  When statement-based binary logging is
used, statements that invoke a function are recorded rather than the
statements executed within the function.  Consequently, stored functions
that update the same underlying tables do not execute in parallel.  In
contrast, stored procedures do not acquire table-level locks.  All
statements executed within stored procedures are written to the binary
log, even for statement-based binary logging.  See *note
stored-programs-logging::.

*Event Scheduler Restrictions*

The following limitations are specific to the Event Scheduler:

   * Event names are handled in case-insensitive fashion.  For example,
     you cannot have two events in the same database with the names
     'anEvent' and 'AnEvent'.

   * An event may not be created, altered, or dropped from within a
     stored program, if the event name is specified by means of a
     variable.  An event also may not create, alter, or drop stored
     routines or triggers.

   * DDL statements on events are prohibited while a *note 'LOCK
     TABLES': lock-tables. statement is in effect.

   * Event timings using the intervals 'YEAR', 'QUARTER', 'MONTH', and
     'YEAR_MONTH' are resolved in months; those using any other interval
     are resolved in seconds.  There is no way to cause events scheduled
     to occur at the same second to execute in a given order.  In
     addition--due to rounding, the nature of threaded applications, and
     the fact that a nonzero length of time is required to create events
     and to signal their execution--events may be delayed by as much as
     1 or 2 seconds.  However, the time shown in the *note
     'INFORMATION_SCHEMA.EVENTS': events-table. table's 'LAST_EXECUTED'
     column or the 'mysql.event' table's 'last_executed' column is
     always accurate to within one second of the actual event execution
     time.  (See also Bug #16522.)

   * Each execution of the statements contained in the body of an event
     takes place in a new connection; thus, these statements has no
     effect in a given user session on the server's statement counts
     such as 'Com_select' and 'Com_insert' that are displayed by *note
     'SHOW STATUS': show-status.  However, such counts _are_ updated in
     the global scope.  (Bug #16422)

   * Events do not support times later than the end of the Unix Epoch;
     this is approximately the beginning of the year 2038.  Such dates
     are specifically not permitted by the Event Scheduler.  (Bug
     #16396)

   * References to stored functions, user-defined functions, and tables
     in the 'ON SCHEDULE' clauses of *note 'CREATE EVENT': create-event.
     and *note 'ALTER EVENT': alter-event. statements are not supported.
     These sorts of references are not permitted.  (See Bug #22830 for
     more information.)

Stored routines and triggers in NDB Cluster

Stored procedures, stored functions, and triggers are all supported by
tables using the *note 'NDB': mysql-cluster. storage engine; however, it
is important to keep in mind that they do _not_ propagate automatically
between MySQL Servers acting as Cluster SQL nodes.  This is because of
the following:

   * Stored routine definitions are kept in tables in the 'mysql' system
     database using the 'MyISAM' storage engine, and so do not
     participate in clustering.

   * The '.TRN' and '.TRG' files containing trigger definitions are not
     read by the *note 'NDB': mysql-cluster. storage engine, and are not
     copied between Cluster nodes.

Any stored routine or trigger that interacts with NDB Cluster tables
must be re-created by running the appropriate *note 'CREATE PROCEDURE':
create-procedure, *note 'CREATE FUNCTION': create-function, or *note
'CREATE TRIGGER': create-trigger. statements on each MySQL Server that
participates in the cluster where you wish to use the stored routine or
trigger.  Similarly, any changes to existing stored routines or triggers
must be carried out explicitly on all Cluster SQL nodes, using the
appropriate 'ALTER' or 'DROP' statements on each MySQL Server accessing
the cluster.

*Warning*:

Do _not_ attempt to work around the issue described in the first item
mentioned previously by converting any 'mysql' database tables to use
the *note 'NDB': mysql-cluster. storage engine.  _Altering the system
tables in the 'mysql' database is not supported_ and is very likely to
produce undesirable results.


File: manual.info.tmp,  Node: view-restrictions,  Prev: stored-program-restrictions,  Up: stored-objects

20.9 Restrictions on Views
==========================

The maximum number of tables that can be referenced in the definition of
a view is 61.

View processing is not optimized:

   * It is not possible to create an index on a view.

   * Indexes can be used for views processed using the merge algorithm.
     However, a view that is processed with the temptable algorithm is
     unable to take advantage of indexes on its underlying tables
     (although indexes can be used during generation of the temporary
     tables).

Subqueries cannot be used in the 'FROM' clause of a view.

There is a general principle that you cannot modify a table and select
from the same table in a subquery.  See *note subquery-restrictions::.

The same principle also applies if you select from a view that selects
from the table, if the view selects from the table in a subquery and the
view is evaluated using the merge algorithm.  Example:

     CREATE VIEW v1 AS
     SELECT * FROM t2 WHERE EXISTS (SELECT 1 FROM t1 WHERE t1.a = t2.a);

     UPDATE t1, v2 SET t1.a = 1 WHERE t1.b = v2.b;

If the view is evaluated using a temporary table, you _can_ select from
the table in the view subquery and still modify that table in the outer
query.  In this case the view will be stored in a temporary table and
thus you are not really selecting from the table in a subquery and
modifying it 'at the same time.' (This is another reason you might wish
to force MySQL to use the temptable algorithm by specifying 'ALGORITHM =
TEMPTABLE' in the view definition.)

You can use *note 'DROP TABLE': drop-table. or *note 'ALTER TABLE':
alter-table. to drop or alter a table that is used in a view definition.
No warning results from the 'DROP' or 'ALTER' operation, even though
this invalidates the view.  Instead, an error occurs later, when the
view is used.  *note 'CHECK TABLE': check-table. can be used to check
for views that have been invalidated by 'DROP' or 'ALTER' operations.

A view definition is 'frozen' by certain statements.  If a statement
prepared by *note 'PREPARE': prepare. refers to a view, the view
definition seen each time the statement is executed later will be the
definition of the view at the time it was prepared.  This is true even
if the view definition is changed after the statement is prepared and
before it is executed.  In the following example, the result returned by
the *note 'EXECUTE': execute. statement is a random number, not the
current date and time:

     CREATE VIEW v AS SELECT RAND();
     PREPARE s FROM 'SELECT * FROM v';
     ALTER VIEW v AS SELECT NOW();
     EXECUTE s;

With regard to view updatability, the overall goal for views is that if
any view is theoretically updatable, it should be updatable in practice.
MySQL as quickly as possible.  Many theoretically updatable views can be
updated now, but limitations still exist.  For details, see *note
view-updatability::.

There exists a shortcoming with the current implementation of views.  If
a user is granted the basic privileges necessary to create a view (the
'CREATE VIEW' and 'SELECT' privileges), that user will be unable to call
*note 'SHOW CREATE VIEW': show-create-view. on that object unless the
user is also granted the 'SHOW VIEW' privilege.

That shortcoming can lead to problems backing up a database with *note
'mysqldump': mysqldump, which may fail due to insufficient privileges.
This problem is described in Bug #22062.

The workaround to the problem is for the administrator to manually grant
the 'SHOW VIEW' privilege to users who are granted 'CREATE VIEW', since
MySQL doesn't grant it implicitly when views are created.

Views do not have indexes, so index hints do not apply.  Use of index
hints when selecting from a view is not permitted.

*note 'SHOW CREATE VIEW': show-create-view. displays view definitions
using an 'AS ALIAS_NAME' clause for each column.  If a column is created
from an expression, the default alias is the expression text, which can
be quite long.  Aliases for column names in *note 'CREATE VIEW':
create-view. statements are checked against the maximum column length of
64 characters (not the maximum alias length of 256 characters).  As a
result, views created from the output of *note 'SHOW CREATE VIEW':
show-create-view. fail if any column alias exceeds 64 characters.  This
can cause problems in the following circumstances for views with
too-long aliases:

   * View definitions fail to replicate to newer slaves that enforce the
     column-length restriction.

   * Dump files created with *note 'mysqldump': mysqldump. cannot be
     loaded into servers that enforce the column-length restriction.

A workaround for either problem is to modify each problematic view
definition to use aliases that provide shorter column names.  Then the
view will replicate properly, and can be dumped and reloaded without
causing an error.  To modify the definition, drop and create the view
again with *note 'DROP VIEW': drop-view. and *note 'CREATE VIEW':
create-view, or replace the definition with *note 'CREATE OR REPLACE
VIEW': create-view.

For problems that occur when reloading view definitions in dump files,
another workaround is to edit the dump file to modify its *note 'CREATE
VIEW': create-view. statements.  However, this does not change the
original view definitions, which may cause problems for subsequent dump
operations.


File: manual.info.tmp,  Node: information-schema,  Next: performance-schema,  Prev: stored-objects,  Up: Top

21 INFORMATION_SCHEMA Tables
****************************

* Menu:

* information-schema-introduction::  Introduction
* character-sets-table::         The INFORMATION_SCHEMA CHARACTER_SETS Table
* collations-table::             The INFORMATION_SCHEMA COLLATIONS Table
* collation-character-set-applicability-table::  The INFORMATION_SCHEMA COLLATION_CHARACTER_SET_APPLICABILITY Table
* columns-table::                The INFORMATION_SCHEMA COLUMNS Table
* column-privileges-table::      The INFORMATION_SCHEMA COLUMN_PRIVILEGES Table
* engines-table::                The INFORMATION_SCHEMA ENGINES Table
* events-table::                 The INFORMATION_SCHEMA EVENTS Table
* status-table::                 The INFORMATION_SCHEMA GLOBAL_STATUS and SESSION_STATUS Tables
* variables-table::              The INFORMATION_SCHEMA GLOBAL_VARIABLES and SESSION_VARIABLES Tables
* key-column-usage-table::       The INFORMATION_SCHEMA KEY_COLUMN_USAGE Table
* parameters-table::             The INFORMATION_SCHEMA PARAMETERS Table
* partitions-table::             The INFORMATION_SCHEMA PARTITIONS Table
* plugins-table::                The INFORMATION_SCHEMA PLUGINS Table
* processlist-table::            The INFORMATION_SCHEMA PROCESSLIST Table
* profiling-table::              The INFORMATION_SCHEMA PROFILING Table
* referential-constraints-table::  The INFORMATION_SCHEMA REFERENTIAL_CONSTRAINTS Table
* routines-table::               The INFORMATION_SCHEMA ROUTINES Table
* schemata-table::               The INFORMATION_SCHEMA SCHEMATA Table
* schema-privileges-table::      The INFORMATION_SCHEMA SCHEMA_PRIVILEGES Table
* statistics-table::             The INFORMATION_SCHEMA STATISTICS Table
* tables-table::                 The INFORMATION_SCHEMA TABLES Table
* tablespaces-table::            The INFORMATION_SCHEMA TABLESPACES Table
* table-constraints-table::      The INFORMATION_SCHEMA TABLE_CONSTRAINTS Table
* table-privileges-table::       The INFORMATION_SCHEMA TABLE_PRIVILEGES Table
* triggers-table::               The INFORMATION_SCHEMA TRIGGERS Table
* user-privileges-table::        The INFORMATION_SCHEMA USER_PRIVILEGES Table
* views-table::                  The INFORMATION_SCHEMA VIEWS Table
* innodb-i_s-tables::            INFORMATION_SCHEMA InnoDB Tables
* mysql-cluster-i_s-tables::     INFORMATION_SCHEMA NDB Cluster Tables
* thread-pool-i_s-tables::       INFORMATION_SCHEMA Thread Pool Tables
* extended-show::                Extensions to SHOW Statements

'INFORMATION_SCHEMA' provides access to database _metadata_, information
about the MySQL server such as the name of a database or table, the data
type of a column, or access privileges.  Other terms that are sometimes
used for this information are _data dictionary_ and _system catalog_.


File: manual.info.tmp,  Node: information-schema-introduction,  Next: character-sets-table,  Prev: information-schema,  Up: information-schema

21.1 Introduction
=================

'INFORMATION_SCHEMA' provides access to database _metadata_, information
about the MySQL server such as the name of a database or table, the data
type of a column, or access privileges.  Other terms that are sometimes
used for this information are _data dictionary_ and _system catalog_.

   * *note information-schema-usage-notes::

   * *note information-schema-character-set-considerations::

   * *note information-schema-as-show-alternative::

   * *note information-schema-privileges::

   * *note information-schema-performance-considerations::

   * *note information-schema-standards-considerations::

   * *note information-schema-conventions::

   * *note information-schema-related-information::

*INFORMATION_SCHEMA Usage Notes*

'INFORMATION_SCHEMA' is a database within each MySQL instance, the place
that stores information about all the other databases that the MySQL
server maintains.  The 'INFORMATION_SCHEMA' database contains several
read-only tables.  They are actually views, not base tables, so there
are no files associated with them, and you cannot set triggers on them.
Also, there is no database directory with that name.

Although you can select 'INFORMATION_SCHEMA' as the default database
with a *note 'USE': use. statement, you can only read the contents of
tables, not perform *note 'INSERT': insert, *note 'UPDATE': update, or
*note 'DELETE': delete. operations on them.

Here is an example of a statement that retrieves information from
'INFORMATION_SCHEMA':

     mysql> SELECT table_name, table_type, engine
            FROM information_schema.tables
            WHERE table_schema = 'db5'
            ORDER BY table_name;
     +------------+------------+--------+
     | table_name | table_type | engine |
     +------------+------------+--------+
     | fk         | BASE TABLE | InnoDB |
     | fk2        | BASE TABLE | InnoDB |
     | goto       | BASE TABLE | MyISAM |
     | into       | BASE TABLE | MyISAM |
     | k          | BASE TABLE | MyISAM |
     | kurs       | BASE TABLE | MyISAM |
     | loop       | BASE TABLE | MyISAM |
     | pk         | BASE TABLE | InnoDB |
     | t          | BASE TABLE | MyISAM |
     | t2         | BASE TABLE | MyISAM |
     | t3         | BASE TABLE | MyISAM |
     | t7         | BASE TABLE | MyISAM |
     | tables     | BASE TABLE | MyISAM |
     | v          | VIEW       | NULL   |
     | v2         | VIEW       | NULL   |
     | v3         | VIEW       | NULL   |
     | v56        | VIEW       | NULL   |
     +------------+------------+--------+
     17 rows in set (0.01 sec)

Explanation: The statement requests a list of all the tables in database
'db5', showing just three pieces of information: the name of the table,
its type, and its storage engine.

*Character Set Considerations*

The definition for character columns (for example, 'TABLES.TABLE_NAME')
is generally 'VARCHAR(N) CHARACTER SET utf8' where N is at least 64.
MySQL uses the default collation for this character set
('utf8_general_ci') for all searches, sorts, comparisons, and other
string operations on such columns.

Because some MySQL objects are represented as files, searches in
'INFORMATION_SCHEMA' string columns can be affected by file system case
sensitivity.  For more information, see *note
charset-collation-information-schema::.

*INFORMATION_SCHEMA as Alternative to SHOW Statements*

The 'SELECT ... FROM INFORMATION_SCHEMA' statement is intended as a more
consistent way to provide access to the information provided by the
various *note 'SHOW': show. statements that MySQL supports (*note 'SHOW
DATABASES': show-databases, *note 'SHOW TABLES': show-tables, and so
forth).  Using *note 'SELECT': select. has these advantages, compared to
*note 'SHOW': show.:

   * It conforms to Codd's rules, because all access is done on tables.

   * You can use the familiar syntax of the *note 'SELECT': select.
     statement, and only need to learn some table and column names.

   * The implementor need not worry about adding keywords.

   * You can filter, sort, concatenate, and transform the results from
     'INFORMATION_SCHEMA' queries into whatever format your application
     needs, such as a data structure or a text representation to parse.

   * This technique is more interoperable with other database systems.
     For example, Oracle Database users are familiar with querying
     tables in the Oracle data dictionary.

Because *note 'SHOW': show. is familiar and widely used, the *note
'SHOW': show. statements remain as an alternative.  In fact, along with
the implementation of 'INFORMATION_SCHEMA', there are enhancements to
*note 'SHOW': show. as described in *note extended-show::.

*INFORMATION_SCHEMA and Privileges*

Each MySQL user has the right to access these tables, but can see only
the rows in the tables that correspond to objects for which the user has
the proper access privileges.  In some cases (for example, the
'ROUTINE_DEFINITION' column in the 'INFORMATION_SCHEMA' *note
'ROUTINES': routines-table. table), users who have insufficient
privileges see 'NULL'.  These restrictions do not apply for *note
'InnoDB': innodb-storage-engine. tables; you can see them with only the
'PROCESS' privilege.

The same privileges apply to selecting information from
'INFORMATION_SCHEMA' and viewing the same information through *note
'SHOW': show. statements.  In either case, you must have some privilege
on an object to see information about it.

*Performance Considerations*

'INFORMATION_SCHEMA' queries that search for information from more than
one database might take a long time and impact performance.  To check
the efficiency of a query, you can use *note 'EXPLAIN': explain.  For
information about using *note 'EXPLAIN': explain. output to tune
'INFORMATION_SCHEMA' queries, see *note
information-schema-optimization::.

*Standards Considerations*

The implementation for the 'INFORMATION_SCHEMA' table structures in
MySQL follows the ANSI/ISO SQL:2003 standard Part 11 'Schemata'.  Our
intent is approximate compliance with SQL:2003 core feature F021 'Basic
information schema'.

Users of SQL Server 2000 (which also follows the standard) may notice a
strong similarity.  However, MySQL has omitted many columns that are not
relevant for our implementation, and added columns that are
MySQL-specific.  One such added column is the 'ENGINE' column in the
'INFORMATION_SCHEMA' *note 'TABLES': tables-table. table.

Although other DBMSs use a variety of names, like 'syscat' or 'system',
the standard name is 'INFORMATION_SCHEMA'.

To avoid using any name that is reserved in the standard or in DB2, SQL
Server, or Oracle, we changed the names of some columns marked 'MySQL
extension'.  (For example, we changed 'COLLATION' to 'TABLE_COLLATION'
in the *note 'TABLES': tables-table. table.)  See the list of reserved
words near the end of this article:
<https://web.archive.org/web/20070428032454/http://www.dbazine.com/db2/db2-disarticles/gulutzan5>.

*Conventions in the INFORMATION_SCHEMA Reference Sections*

The following sections describe each of the tables and columns in
'INFORMATION_SCHEMA'.  For each column, there are three pieces of
information:

   * ''INFORMATION_SCHEMA' Name' indicates the name for the column in
     the 'INFORMATION_SCHEMA' table.  This corresponds to the standard
     SQL name unless the 'Remarks' field says 'MySQL extension.'

   * '*note 'SHOW': show. Name' indicates the equivalent field name in
     the closest *note 'SHOW': show. statement, if there is one.

   * 'Remarks' provides additional information where applicable.  If
     this field is 'NULL', it means that the value of the column is
     always 'NULL'.  If this field says 'MySQL extension,' the column is
     a MySQL extension to standard SQL.

Many sections indicate what *note 'SHOW': show. statement is equivalent
to a *note 'SELECT': select. that retrieves information from
'INFORMATION_SCHEMA'.  For *note 'SHOW': show. statements that display
information for the default database if you omit a 'FROM DB_NAME'
clause, you can often select information for the default database by
adding an 'AND TABLE_SCHEMA = SCHEMA()' condition to the 'WHERE' clause
of a query that retrieves information from an 'INFORMATION_SCHEMA'
table.

*Related Information*

These sections discuss additional 'INFORMATION_SCHEMA'-related topics:

   * information about 'INFORMATION_SCHEMA' tables specific to the *note
     'InnoDB': innodb-storage-engine. storage engine: *note
     innodb-i_s-tables::

   * information about 'INFORMATION_SCHEMA' tables specific to the *note
     'NDB': mysql-cluster. storage engine (NDB Cluster): *note
     mysql-cluster-i_s-tables::

   * information about 'INFORMATION_SCHEMA' tables specific to the
     thread pool plugin: *note thread-pool-i_s-tables::

   * Answers to questions that are often asked concerning the
     'INFORMATION_SCHEMA' database: *note faqs-information-schema::

   * 'INFORMATION_SCHEMA' queries and the optimizer: *note
     information-schema-optimization::

   * The effect of collation on 'INFORMATION_SCHEMA' comparisons: *note
     charset-collation-information-schema::


File: manual.info.tmp,  Node: character-sets-table,  Next: collations-table,  Prev: information-schema-introduction,  Up: information-schema

21.2 The INFORMATION_SCHEMA CHARACTER_SETS Table
================================================

The *note 'CHARACTER_SETS': character-sets-table. table provides
information about available character sets.

The *note 'CHARACTER_SETS': character-sets-table. table has these
columns:

   * 'CHARACTER_SET_NAME'

     The character set name.

   * 'DEFAULT_COLLATE_NAME'

     The default collation for the character set.

   * 'DESCRIPTION'

     A description of the character set.

   * 'MAXLEN'

     The maximum number of bytes required to store one character.

*Notes*

Character set information is also available from the *note 'SHOW
CHARACTER SET': show-character-set. statement.  See *note
show-character-set::.  The following statements are equivalent:

     SELECT * FROM INFORMATION_SCHEMA.CHARACTER_SETS
       [WHERE CHARACTER_SET_NAME LIKE 'WILD']

     SHOW CHARACTER SET
       [LIKE 'WILD']


File: manual.info.tmp,  Node: collations-table,  Next: collation-character-set-applicability-table,  Prev: character-sets-table,  Up: information-schema

21.3 The INFORMATION_SCHEMA COLLATIONS Table
============================================

The *note 'COLLATIONS': collations-table. table provides information
about collations for each character set.

The *note 'COLLATIONS': collations-table. table has these columns:

   * 'COLLATION_NAME'

     The collation name.

   * 'CHARACTER_SET_NAME'

     The name of the character set with which the collation is
     associated.

   * 'ID'

     The collation ID.

   * 'IS_DEFAULT'

     Whether the collation is the default for its character set.

   * 'IS_COMPILED'

     Whether the character set is compiled into the server.

   * 'SORTLEN'

     This is related to the amount of memory required to sort strings
     expressed in the character set.

*Notes*

Collation information is also available from the *note 'SHOW COLLATION':
show-collation. statement.  See *note show-collation::.  The following
statements are equivalent:

     SELECT COLLATION_NAME FROM INFORMATION_SCHEMA.COLLATIONS
       [WHERE COLLATION_NAME LIKE 'WILD']

     SHOW COLLATION
       [LIKE 'WILD']


File: manual.info.tmp,  Node: collation-character-set-applicability-table,  Next: columns-table,  Prev: collations-table,  Up: information-schema

21.4 The INFORMATION_SCHEMA COLLATION_CHARACTER_SET_APPLICABILITY Table
=======================================================================

The *note 'COLLATION_CHARACTER_SET_APPLICABILITY':
collation-character-set-applicability-table. table indicates what
character set is applicable for what collation.

The *note 'COLLATION_CHARACTER_SET_APPLICABILITY':
collation-character-set-applicability-table. table has these columns:

   * 'COLLATION_NAME'

     The collation name.

   * 'CHARACTER_SET_NAME'

     The name of the character set with which the collation is
     associated.

*Notes*

The *note 'COLLATION_CHARACTER_SET_APPLICABILITY':
collation-character-set-applicability-table. columns are equivalent to
the first two columns displayed by the *note 'SHOW COLLATION':
show-collation. statement.


File: manual.info.tmp,  Node: columns-table,  Next: column-privileges-table,  Prev: collation-character-set-applicability-table,  Up: information-schema

21.5 The INFORMATION_SCHEMA COLUMNS Table
=========================================

The *note 'COLUMNS': columns-table. table provides information about
columns in tables.

The *note 'COLUMNS': columns-table. table has these columns:

   * 'TABLE_CATALOG'

     The name of the catalog to which the table containing the column
     belongs.  This value is always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the table containing the
     column belongs.

   * 'TABLE_NAME'

     The name of the table containing the column.

   * 'COLUMN_NAME'

     The name of the column.

   * 'ORDINAL_POSITION'

     The position of the column within the table.  'ORDINAL_POSITION' is
     necessary because you might want to say 'ORDER BY
     ORDINAL_POSITION'.  Unlike *note 'SHOW COLUMNS': show-columns,
     *note 'SELECT': select. from the *note 'COLUMNS': columns-table.
     table does not have automatic ordering.

   * 'COLUMN_DEFAULT'

     The default value for the column.  This is 'NULL' if the column has
     an explicit default of 'NULL', or if the column definition includes
     no 'DEFAULT' clause.

   * 'IS_NULLABLE'

     The column nullability.  The value is 'YES' if 'NULL' values can be
     stored in the column, 'NO' if not.

   * 'DATA_TYPE'

     The column data type.

     The 'DATA_TYPE' value is the type name only with no other
     information.  The 'COLUMN_TYPE' value contains the type name and
     possibly other information such as the precision or length.

   * 'CHARACTER_MAXIMUM_LENGTH'

     For string columns, the maximum length in characters.

   * 'CHARACTER_OCTET_LENGTH'

     For string columns, the maximum length in bytes.

   * 'NUMERIC_PRECISION'

     For numeric columns, the numeric precision.

   * 'NUMERIC_SCALE'

     For numeric columns, the numeric scale.

   * 'CHARACTER_SET_NAME'

     For character string columns, the character set name.

   * 'COLLATION_NAME'

     For character string columns, the collation name.

   * 'COLUMN_TYPE'

     The column data type.

     The 'DATA_TYPE' value is the type name only with no other
     information.  The 'COLUMN_TYPE' value contains the type name and
     possibly other information such as the precision or length.

   * 'COLUMN_KEY'

     Whether the column is indexed:

        * If 'COLUMN_KEY' is empty, the column either is not indexed or
          is indexed only as a secondary column in a multiple-column,
          nonunique index.

        * If 'COLUMN_KEY' is 'PRI', the column is a 'PRIMARY KEY' or is
          one of the columns in a multiple-column 'PRIMARY KEY'.

        * If 'COLUMN_KEY' is 'UNI', the column is the first column of a
          'UNIQUE' index.  (A 'UNIQUE' index permits multiple 'NULL'
          values, but you can tell whether the column permits 'NULL' by
          checking the 'Null' column.)

        * If 'COLUMN_KEY' is 'MUL', the column is the first column of a
          nonunique index in which multiple occurrences of a given value
          are permitted within the column.

     If more than one of the 'COLUMN_KEY' values applies to a given
     column of a table, 'COLUMN_KEY' displays the one with the highest
     priority, in the order 'PRI', 'UNI', 'MUL'.

     A 'UNIQUE' index may be displayed as 'PRI' if it cannot contain
     'NULL' values and there is no 'PRIMARY KEY' in the table.  A
     'UNIQUE' index may display as 'MUL' if several columns form a
     composite 'UNIQUE' index; although the combination of the columns
     is unique, each column can still hold multiple occurrences of a
     given value.

   * 'EXTRA'

     Any additional information that is available about a given column.
     The value is nonempty in these cases: 'auto_increment' for columns
     that have the 'AUTO_INCREMENT' attribute; 'on update
     CURRENT_TIMESTAMP' for *note 'TIMESTAMP': datetime. columns that
     have the 'ON UPDATE CURRENT_TIMESTAMP' attribute.

   * 'PRIVILEGES'

     The privileges you have for the column.

   * 'COLUMN_COMMENT'

     Any comment included in the column definition.

*Notes*

   * In *note 'SHOW COLUMNS': show-columns, the 'Type' display includes
     values from several different *note 'COLUMNS': columns-table.
     columns.

   * 'CHARACTER_OCTET_LENGTH' should be the same as
     'CHARACTER_MAXIMUM_LENGTH', except for multibyte character sets.

   * 'CHARACTER_SET_NAME' can be derived from 'COLLATION_NAME'.  For
     example, if you say 'SHOW FULL COLUMNS FROM t', and you see in the
     'COLLATION_NAME' column a value of 'latin1_swedish_ci', the
     character set is what is before the first underscore: 'latin1'.

Column information is also available from the *note 'SHOW COLUMNS':
show-columns. statement.  See *note show-columns::.  The following
statements are nearly equivalent:

     SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, COLUMN_DEFAULT
       FROM INFORMATION_SCHEMA.COLUMNS
       WHERE table_name = 'TBL_NAME'
       [AND table_schema = 'DB_NAME']
       [AND column_name LIKE 'WILD']

     SHOW COLUMNS
       FROM TBL_NAME
       [FROM DB_NAME]
       [LIKE 'WILD']


File: manual.info.tmp,  Node: column-privileges-table,  Next: engines-table,  Prev: columns-table,  Up: information-schema

21.6 The INFORMATION_SCHEMA COLUMN_PRIVILEGES Table
===================================================

The *note 'COLUMN_PRIVILEGES': column-privileges-table. table provides
information about column privileges.  It takes its values from the
'mysql.columns_priv' system table.

The *note 'COLUMN_PRIVILEGES': column-privileges-table. table has these
columns:

   * 'GRANTEE'

     The name of the account to which the privilege is granted, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'TABLE_CATALOG'

     The name of the catalog to which the table containing the column
     belongs.  This value is always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the table containing the
     column belongs.

   * 'TABLE_NAME'

     The name of the table containing the column.

   * 'COLUMN_NAME'

     The name of the column.

   * 'PRIVILEGE_TYPE'

     The privilege granted.  The value can be any privilege that can be
     granted at the column level; see *note grant::.  Each row lists a
     single privilege, so there is one row per column privilege held by
     the grantee.

     In the output from *note 'SHOW FULL COLUMNS': show-columns, the
     privileges are all in one column and in lowercase, for example,
     'select,insert,update,references'.  In *note 'COLUMN_PRIVILEGES':
     column-privileges-table, there is one privilege per row, in
     uppercase.

   * 'IS_GRANTABLE'

     'YES' if the user has the 'GRANT OPTION' privilege, 'NO' otherwise.
     The output does not list 'GRANT OPTION' as a separate row with
     'PRIVILEGE_TYPE='GRANT OPTION''.

*Notes*

   * The *note 'COLUMN_PRIVILEGES': column-privileges-table. table is a
     nonstandard 'INFORMATION_SCHEMA' table.

The following statements are _not_ equivalent:

     SELECT ... FROM INFORMATION_SCHEMA.COLUMN_PRIVILEGES

     SHOW GRANTS ...


File: manual.info.tmp,  Node: engines-table,  Next: events-table,  Prev: column-privileges-table,  Up: information-schema

21.7 The INFORMATION_SCHEMA ENGINES Table
=========================================

The *note 'ENGINES': engines-table. table provides information about
storage engines.  This is particularly useful for checking whether a
storage engine is supported, or to see what the default engine is.

The *note 'ENGINES': engines-table. table has these columns:

   * 'ENGINE'

     The name of the storage engine.

   * 'SUPPORT'

     The server's level of support for the storage engine, as shown in
     the following table.

     Value       Meaning
                 
     'YES'       The engine is supported and is active
                 
     'DEFAULT'   Like 'YES', plus this is the default engine
                 
     'NO'        The engine is not supported
                 
     'DISABLED'  The engine is supported but has been disabled

     A value of 'NO' means that the server was compiled without support
     for the engine, so it cannot be enabled at runtime.

     A value of 'DISABLED' occurs either because the server was started
     with an option that disables the engine, or because not all options
     required to enable it were given.  In the latter case, the error
     log should contain a reason indicating why the option is disabled.
     See *note error-log::.

     You might also see 'DISABLED' for a storage engine if the server
     was compiled to support it, but was started with a
     '--skip-ENGINE_NAME' option.  For the *note 'NDB': mysql-cluster.
     storage engine, 'DISABLED' means the server was compiled with
     support for NDB Cluster, but was not started with the
     '--ndbcluster' option.

     All MySQL servers support 'MyISAM' tables.  It is not possible to
     disable 'MyISAM'.

   * 'COMMENT'

     A brief description of the storage engine.

   * 'TRANSACTIONS'

     Whether the storage engine supports transactions.

   * 'XA'

     Whether the storage engine supports XA transactions.

   * 'SAVEPOINTS'

     Whether the storage engine supports savepoints.

*Notes*

   * The *note 'ENGINES': engines-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

Storage engine information is also available from the *note 'SHOW
ENGINES': show-engines. statement.  See *note show-engines::.  The
following statements are equivalent:

     SELECT * FROM INFORMATION_SCHEMA.ENGINES

     SHOW ENGINES


File: manual.info.tmp,  Node: events-table,  Next: status-table,  Prev: engines-table,  Up: information-schema

21.8 The INFORMATION_SCHEMA EVENTS Table
========================================

The *note 'EVENTS': events-table. table provides information about Event
Manager events, which are discussed in *note event-scheduler::.

The *note 'EVENTS': events-table. table has these columns:

   * 'EVENT_CATALOG'

     The name of the catalog to which the event belongs.  This value is
     always 'def'.

   * 'EVENT_SCHEMA'

     The name of the schema (database) to which the event belongs.

   * 'EVENT_NAME'

     The name of the event.

   * 'DEFINER'

     The account of the user who created the event, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'TIME_ZONE'

     The event time zone, which is the time zone used for scheduling the
     event and that is in effect within the event as it executes.  The
     default value is 'SYSTEM'.

   * 'EVENT_BODY'

     The language used for the statements in the event's *note 'DO': do.
     clause.  The value is always 'SQL'.

   * 'EVENT_DEFINITION'

     The text of the SQL statement making up the event's *note 'DO': do.
     clause; in other words, the statement executed by this event.

   * 'EVENT_TYPE'

     The event repetition type, either 'ONE TIME' (transient) or
     'RECURRING' (repeating).

   * 'EXECUTE_AT'

     For a one-time event, this is the *note 'DATETIME': datetime. value
     specified in the 'AT' clause of the *note 'CREATE EVENT':
     create-event. statement used to create the event, or of the last
     *note 'ALTER EVENT': alter-event. statement that modified the
     event.  The value shown in this column reflects the addition or
     subtraction of any 'INTERVAL' value included in the event's 'AT'
     clause.  For example, if an event is created using 'ON SCHEDULE AT
     CURRENT_TIMESTAMP + '1:6' DAY_HOUR', and the event was created at
     2018-02-09 14:05:30, the value shown in this column would be
     ''2018-02-10 20:05:30''.  If the event's timing is determined by an
     'EVERY' clause instead of an 'AT' clause (that is, if the event is
     recurring), the value of this column is 'NULL'.

   * 'INTERVAL_VALUE'

     For a recurring event, the number of intervals to wait between
     event executions.  For a transient event, the value is always
     'NULL'.

   * 'INTERVAL_FIELD'

     The time units used for the interval which a recurring event waits
     before repeating.  For a transient event, the value is always
     'NULL'.

   * 'SQL_MODE'

     The SQL mode in effect when the event was created or altered, and
     under which the event executes.  For the permitted values, see
     *note sql-mode::.

   * 'STARTS'

     The start date and time for a recurring event.  This is displayed
     as a *note 'DATETIME': datetime. value, and is 'NULL' if no start
     date and time are defined for the event.  For a transient event,
     this column is always 'NULL'.  For a recurring event whose
     definition includes a 'STARTS' clause, this column contains the
     corresponding *note 'DATETIME': datetime. value.  As with the
     'EXECUTE_AT' column, this value resolves any expressions used.  If
     there is no 'STARTS' clause affecting the timing of the event, this
     column is 'NULL'

   * 'ENDS'

     For a recurring event whose definition includes a 'ENDS' clause,
     this column contains the corresponding *note 'DATETIME': datetime.
     value.  As with the 'EXECUTE_AT' column, this value resolves any
     expressions used.  If there is no 'ENDS' clause affecting the
     timing of the event, this column is 'NULL'.

   * 'STATUS'

     The event status.  One of 'ENABLED', 'DISABLED', or
     'SLAVESIDE_DISABLED'.  'SLAVESIDE_DISABLED' indicates that the
     creation of the event occurred on another MySQL server acting as a
     replication master and replicated to the current MySQL server which
     is acting as a slave, but the event is not presently being executed
     on the slave.  For more information, see *note
     replication-features-invoked::.  information.

   * 'ON_COMPLETION'

     One of the two values 'PRESERVE' or 'NOT PRESERVE'.

   * 'CREATED'

     The date and time when the event was created.  This is a *note
     'TIMESTAMP': datetime. value.

   * 'LAST_ALTERED'

     The date and time when the event was last modified.  This is a
     *note 'TIMESTAMP': datetime. value.  If the event has not been
     modified since its creation, this value is the same as the
     'CREATED' value.

   * 'LAST_EXECUTED'

     The date and time when the event last executed.  This is a *note
     'DATETIME': datetime. value.  If the event has never executed, this
     column is 'NULL'.

     'LAST_EXECUTED' indicates when the event started.  As a result, the
     'ENDS' column is never less than 'LAST_EXECUTED'.

   * 'EVENT_COMMENT'

     The text of the comment, if the event has one.  If not, this value
     is empty.

   * 'ORIGINATOR'

     The server ID of the MySQL server on which the event was created;
     used in replication.  The default value is 0.

   * 'CHARACTER_SET_CLIENT'

     The session value of the 'character_set_client' system variable
     when the event was created.

   * 'COLLATION_CONNECTION'

     The session value of the 'collation_connection' system variable
     when the event was created.

   * 'DATABASE_COLLATION'

     The collation of the database with which the event is associated.

*Notes*

   * The *note 'EVENTS': events-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

   * Times in the *note 'EVENTS': events-table. table are displayed
     using the event time zone, the current session time zone, or UTC,
     as described in *note events-metadata::.

   * For more information about 'SLAVESIDE_DISABLED' and the
     'ORIGINATOR' column, see *note replication-features-invoked::.

*Example*

Suppose that the user ''jon'@'ghidora'' creates an event named
'e_daily', and then modifies it a few minutes later using an *note
'ALTER EVENT': alter-event. statement, as shown here:

     DELIMITER |

     CREATE EVENT e_daily
         ON SCHEDULE
           EVERY 1 DAY
         COMMENT 'Saves total number of sessions then clears the table each day'
         DO
           BEGIN
             INSERT INTO site_activity.totals (time, total)
               SELECT CURRENT_TIMESTAMP, COUNT(*)
                 FROM site_activity.sessions;
             DELETE FROM site_activity.sessions;
           END |

     DELIMITER ;

     ALTER EVENT e_daily
         ENABLE;

(Note that comments can span multiple lines.)

This user can then run the following *note 'SELECT': select. statement,
and obtain the output shown:

     mysql> SELECT * FROM INFORMATION_SCHEMA.EVENTS
            WHERE EVENT_NAME = 'e_daily'
            AND EVENT_SCHEMA = 'myschema'\G
     *************************** 1. row ***************************
            EVENT_CATALOG: def
             EVENT_SCHEMA: myschema
               EVENT_NAME: e_daily
                  DEFINER: jon@ghidora
                TIME_ZONE: SYSTEM
               EVENT_BODY: SQL
         EVENT_DEFINITION: BEGIN
             INSERT INTO site_activity.totals (time, total)
               SELECT CURRENT_TIMESTAMP, COUNT(*)
                 FROM site_activity.sessions;
             DELETE FROM site_activity.sessions;
           END
               EVENT_TYPE: RECURRING
               EXECUTE_AT: NULL
           INTERVAL_VALUE: 1
           INTERVAL_FIELD: DAY
                 SQL_MODE:
                   STARTS: 2018-08-08 11:06:34
                     ENDS: NULL
                   STATUS: ENABLED
            ON_COMPLETION: NOT PRESERVE
                  CREATED: 2018-08-08 11:06:34
             LAST_ALTERED: 2018-08-08 11:06:34
            LAST_EXECUTED: 2018-08-08 16:06:34
            EVENT_COMMENT: Saves total number of sessions then clears the
                           table each day
               ORIGINATOR: 1
     CHARACTER_SET_CLIENT: utf8
     COLLATION_CONNECTION: utf8_general_ci
       DATABASE_COLLATION: latin1_swedish_ci

Event information is also available from the *note 'SHOW EVENTS':
show-events. statement.  See *note show-events::.  The following
statements are equivalent:

     SELECT
         EVENT_SCHEMA, EVENT_NAME, DEFINER, TIME_ZONE, EVENT_TYPE, EXECUTE_AT,
         INTERVAL_VALUE, INTERVAL_FIELD, STARTS, ENDS, STATUS, ORIGINATOR,
         CHARACTER_SET_CLIENT, COLLATION_CONNECTION, DATABASE_COLLATION
       FROM INFORMATION_SCHEMA.EVENTS
       WHERE table_schema = 'DB_NAME'
       [AND column_name LIKE 'WILD']

     SHOW EVENTS
       [FROM DB_NAME]
       [LIKE 'WILD']


File: manual.info.tmp,  Node: status-table,  Next: variables-table,  Prev: events-table,  Up: information-schema

21.9 The INFORMATION_SCHEMA GLOBAL_STATUS and SESSION_STATUS Tables
===================================================================

The *note 'GLOBAL_STATUS': status-table. and *note 'SESSION_STATUS':
status-table. tables provide information about server status variables.
Their contents correspond to the information produced by the *note 'SHOW
GLOBAL STATUS': show-status. and *note 'SHOW SESSION STATUS':
show-status. statements (see *note show-status::).

*Notes*

   * The 'VARIABLE_VALUE' column for each of these tables is defined as
     'VARCHAR(1024)'.


File: manual.info.tmp,  Node: variables-table,  Next: key-column-usage-table,  Prev: status-table,  Up: information-schema

21.10 The INFORMATION_SCHEMA GLOBAL_VARIABLES and SESSION_VARIABLES Tables
==========================================================================

The *note 'GLOBAL_VARIABLES': variables-table. and *note
'SESSION_VARIABLES': variables-table. tables provide information about
server status variables.  Their contents correspond to the information
produced by the *note 'SHOW GLOBAL VARIABLES': show-variables. and *note
'SHOW SESSION VARIABLES': show-variables. statements (see *note
show-variables::).

*Notes*

   * The 'VARIABLE_VALUE' column for each of these tables is defined as
     'VARCHAR(1024)'.  For variables with very long values that are not
     completely displayed, use *note 'SELECT': select. as a workaround.
     For example:

          SELECT @@GLOBAL.innodb_data_file_path;


File: manual.info.tmp,  Node: key-column-usage-table,  Next: parameters-table,  Prev: variables-table,  Up: information-schema

21.11 The INFORMATION_SCHEMA KEY_COLUMN_USAGE Table
===================================================

The *note 'KEY_COLUMN_USAGE': key-column-usage-table. table describes
which key columns have constraints.

The *note 'KEY_COLUMN_USAGE': key-column-usage-table. table has these
columns:

   * 'CONSTRAINT_CATALOG'

     The name of the catalog to which the constraint belongs.  This
     value is always 'def'.

   * 'CONSTRAINT_SCHEMA'

     The name of the schema (database) to which the constraint belongs.

   * 'CONSTRAINT_NAME'

     The name of the constraint.

   * 'TABLE_CATALOG'

     The name of the catalog to which the table belongs.  This value is
     always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the table belongs.

   * 'TABLE_NAME'

     The name of the table that has the constraint.

   * 'COLUMN_NAME'

     The name of the column that has the constraint.

     If the constraint is a foreign key, then this is the column of the
     foreign key, not the column that the foreign key references.

   * 'ORDINAL_POSITION'

     The column's position within the constraint, not the column's
     position within the table.  Column positions are numbered beginning
     with 1.

   * 'POSITION_IN_UNIQUE_CONSTRAINT'

     'NULL' for unique and primary-key constraints.  For foreign-key
     constraints, this column is the ordinal position in key of the
     table that is being referenced.

   * 'REFERENCED_TABLE_SCHEMA'

     The name of the schema (database) referenced by the constraint.

   * 'REFERENCED_TABLE_NAME'

     The name of the table referenced by the constraint.

   * 'REFERENCED_COLUMN_NAME'

     The name of the column referenced by the constraint.

Suppose that there are two tables name 't1' and 't3' that have the
following definitions:

     CREATE TABLE t1
     (
         s1 INT,
         s2 INT,
         s3 INT,
         PRIMARY KEY(s3)
     ) ENGINE=InnoDB;

     CREATE TABLE t3
     (
         s1 INT,
         s2 INT,
         s3 INT,
         KEY(s1),
         CONSTRAINT CO FOREIGN KEY (s2) REFERENCES t1(s3)
     ) ENGINE=InnoDB;

For those two tables, the *note 'KEY_COLUMN_USAGE':
key-column-usage-table. table has two rows:

   * One row with 'CONSTRAINT_NAME' = ''PRIMARY'', 'TABLE_NAME' =
     ''t1'', 'COLUMN_NAME' = ''s3'', 'ORDINAL_POSITION' = '1',
     'POSITION_IN_UNIQUE_CONSTRAINT' = 'NULL'.

   * One row with 'CONSTRAINT_NAME' = ''CO'', 'TABLE_NAME' = ''t3'',
     'COLUMN_NAME' = ''s2'', 'ORDINAL_POSITION' = '1',
     'POSITION_IN_UNIQUE_CONSTRAINT' = '1'.


File: manual.info.tmp,  Node: parameters-table,  Next: partitions-table,  Prev: key-column-usage-table,  Up: information-schema

21.12 The INFORMATION_SCHEMA PARAMETERS Table
=============================================

The *note 'PARAMETERS': parameters-table. table provides information
about parameters for stored routines (stored procedures and stored
functions), and about return values for stored functions.  The *note
'PARAMETERS': parameters-table. table does not include built-in SQL
functions or user-defined functions (UDFs).  Parameter information is
similar to the contents of the 'param_list' column in the 'mysql.proc'
table.

The *note 'PARAMETERS': parameters-table. table has these columns:

   * 'SPECIFIC_CATALOG'

     The name of the catalog to which the routine containing the
     parameter belongs.  This value is always 'def'.

   * 'SPECIFIC_SCHEMA'

     The name of the schema (database) to which the routine containing
     the parameter belongs.

   * 'SPECIFIC_NAME'

     The name of the routine containing the parameter.

   * 'ORDINAL_POSITION'

     For successive parameters of a stored procedure or function, the
     'ORDINAL_POSITION' values are 1, 2, 3, and so forth.  For a stored
     function, there is also a row that applies to the function return
     value (as described by the 'RETURNS' clause).  The return value is
     not a true parameter, so the row that describes it has these unique
     characteristics:

        * The 'ORDINAL_POSITION' value is 0.

        * The 'PARAMETER_NAME' and 'PARAMETER_MODE' values are 'NULL'
          because the return value has no name and the mode does not
          apply.

   * 'PARAMETER_MODE'

     The mode of the parameter.  This value is one of 'IN', 'OUT', or
     'INOUT'.  For a stored function return value, this value is 'NULL'.

   * 'PARAMETER_NAME'

     The name of the parameter.  For a stored function return value,
     this value is 'NULL'.

   * 'DATA_TYPE'

     The parameter data type.

     The 'DATA_TYPE' value is the type name only with no other
     information.  The 'DTD_IDENTIFIER' value contains the type name and
     possibly other information such as the precision or length.

   * 'CHARACTER_MAXIMUM_LENGTH'

     For string parameters, the maximum length in characters.

   * 'CHARACTER_OCTET_LENGTH'

     For string parameters, the maximum length in bytes.

   * 'NUMERIC_PRECISION'

     For numeric parameters, the numeric precision.

   * 'NUMERIC_SCALE'

     For numeric parameters, the numeric scale.

   * 'CHARACTER_SET_NAME'

     For character string parameters, the character set name.

   * 'COLLATION_NAME'

     For character string parameters, the collation name.

   * 'DTD_IDENTIFIER'

     The parameter data type.

     The 'DATA_TYPE' value is the type name only with no other
     information.  The 'DTD_IDENTIFIER' value contains the type name and
     possibly other information such as the precision or length.

   * 'ROUTINE_TYPE'

     'PROCEDURE' for stored procedures, 'FUNCTION' for stored functions.


File: manual.info.tmp,  Node: partitions-table,  Next: plugins-table,  Prev: parameters-table,  Up: information-schema

21.13 The INFORMATION_SCHEMA PARTITIONS Table
=============================================

The *note 'PARTITIONS': partitions-table. table provides information
about table partitions.  Each row in this table corresponds to an
individual partition or subpartition of a partitioned table.  For more
information about partitioning tables, see *note partitioning::.

The *note 'PARTITIONS': partitions-table. table has these columns:

   * 'TABLE_CATALOG'

     The name of the catalog to which the table belongs.  This value is
     always 'def'.

   * 'TABLE_SCHEMA'

     The name of the database to which the table belongs.

   * 'TABLE_NAME'

     The name of the table containing the partition.

   * 'PARTITION_NAME'

     The name of the partition.

   * 'SUBPARTITION_NAME'

     If the *note 'PARTITIONS': partitions-table. table row represents a
     subpartition, the name of subpartition; otherwise 'NULL'.

   * 'PARTITION_ORDINAL_POSITION'

     All partitions are indexed in the same order as they are defined,
     with '1' being the number assigned to the first partition.  The
     indexing can change as partitions are added, dropped, and
     reorganized; the number shown is this column reflects the current
     order, taking into account any indexing changes.

   * 'SUBPARTITION_ORDINAL_POSITION'

     Subpartitions within a given partition are also indexed and
     reindexed in the same manner as partitions are indexed within a
     table.

   * 'PARTITION_METHOD'

     One of the values 'RANGE', 'LIST', 'HASH', 'LINEAR HASH', 'KEY', or
     'LINEAR KEY'; that is, one of the available partitioning types as
     discussed in *note partitioning-types::.

   * 'SUBPARTITION_METHOD'

     One of the values 'HASH', 'LINEAR HASH', 'KEY', or 'LINEAR KEY';
     that is, one of the available subpartitioning types as discussed in
     *note partitioning-subpartitions::.

   * 'PARTITION_EXPRESSION'

     The expression for the partitioning function used in the *note
     'CREATE TABLE': create-table. or *note 'ALTER TABLE': alter-table.
     statement that created the table's current partitioning scheme.

     For example, consider a partitioned table created in the 'test'
     database using this statement:

          CREATE TABLE tp (
              c1 INT,
              c2 INT,
              c3 VARCHAR(25)
          )
          PARTITION BY HASH(c1 + c2)
          PARTITIONS 4;

     The 'PARTITION_EXPRESSION' column in a *note 'PARTITIONS':
     partitions-table. table row for a partition from this table
     displays 'c1 + c2', as shown here:

          mysql> SELECT DISTINCT PARTITION_EXPRESSION
                 FROM INFORMATION_SCHEMA.PARTITIONS
                 WHERE TABLE_NAME='tp' AND TABLE_SCHEMA='test';
          +----------------------+
          | PARTITION_EXPRESSION |
          +----------------------+
          | c1 + c2              |
          +----------------------+

   * 'SUBPARTITION_EXPRESSION'

     This works in the same fashion for the subpartitioning expression
     that defines the subpartitioning for a table as
     'PARTITION_EXPRESSION' does for the partitioning expression used to
     define a table's partitioning.

     If the table has no subpartitions, this column is 'NULL'.

   * 'PARTITION_DESCRIPTION'

     This column is used for RANGE and LIST partitions.  For a 'RANGE'
     partition, it contains the value set in the partition's 'VALUES
     LESS THAN' clause, which can be either an integer or 'MAXVALUE'.
     For a 'LIST' partition, this column contains the values defined in
     the partition's 'VALUES IN' clause, which is a list of
     comma-separated integer values.

     For partitions whose 'PARTITION_METHOD' is other than 'RANGE' or
     'LIST', this column is always 'NULL'.

   * 'TABLE_ROWS'

     The number of table rows in the partition.

     For partitioned *note 'InnoDB': innodb-storage-engine. tables, the
     row count given in the 'TABLE_ROWS' column is only an estimated
     value used in SQL optimization, and may not always be exact.

     For *note 'NDB': mysql-cluster. tables, you can also obtain this
     information using the *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc. utility.

   * 'AVG_ROW_LENGTH'

     The average length of the rows stored in this partition or
     subpartition, in bytes.  This is the same as 'DATA_LENGTH' divided
     by 'TABLE_ROWS'.

     For *note 'NDB': mysql-cluster. tables, you can also obtain this
     information using the *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc. utility.

   * 'DATA_LENGTH'

     The total length of all rows stored in this partition or
     subpartition, in bytes; that is, the total number of bytes stored
     in the partition or subpartition.

     For *note 'NDB': mysql-cluster. tables, you can also obtain this
     information using the *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc. utility.

   * 'MAX_DATA_LENGTH'

     The maximum number of bytes that can be stored in this partition or
     subpartition.

     For *note 'NDB': mysql-cluster. tables, you can also obtain this
     information using the *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc. utility.

   * 'INDEX_LENGTH'

     The length of the index file for this partition or subpartition, in
     bytes.

     For partitions of *note 'NDB': mysql-cluster. tables, whether the
     tables use implicit or explicit partitioning, the 'INDEX_LENGTH'
     column value is always 0.  However, you can obtain equivalent
     information using the *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc. utility.

   * 'DATA_FREE'

     The number of bytes allocated to the partition or subpartition but
     not used.

     For *note 'NDB': mysql-cluster. tables, you can also obtain this
     information using the *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc. utility.

   * 'CREATE_TIME'

     The time that the partition or subpartition was created.

     Prior to MySQL 5.5.44, for partitioned *note 'InnoDB':
     innodb-storage-engine. tables, this column was always 'NULL'.  The
     correct creation time is shown in MySQL 5.5.44 and later.  (Bug
     #17299181, Bug #69990)

   * 'UPDATE_TIME'

     The time that the partition or subpartition was last modified.

     For partitioned *note 'InnoDB': innodb-storage-engine. tables, the
     value is always 'NULL'.

   * 'CHECK_TIME'

     The last time that the table to which this partition or
     subpartition belongs was checked.

     For partitioned *note 'InnoDB': innodb-storage-engine. tables, this
     column is always 'NULL'.

   * 'CHECKSUM'

     The checksum value, if any; otherwise 'NULL'.

   * 'PARTITION_COMMENT'

     The text of the comment, if the partition has one.  If not, this
     value is empty.

     In MySQL 5.5, the display width of this column is 80 characters,
     and partition comments which exceed this length are truncated to
     fit.  This issue is fixed in MySQL 5.6.  (Bug #11748924, Bug
     #37728)

   * 'NODEGROUP'

     This is the nodegroup to which the partition belongs.  This is
     relevant only to NDB Cluster tables; otherwise, the value is always
     '0'.

   * 'TABLESPACE_NAME'

     The name of the tablespace to which the partition belongs.  The
     value is always 'DEFAULT', unless the table uses the 'NDB' storage
     engine (see the 'Notes' at the end of this section).

*Notes*

   * The *note 'PARTITIONS': partitions-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

   * A table using any storage engine other than *note 'NDB':
     mysql-cluster. and which is not partitioned has one row in the
     *note 'PARTITIONS': partitions-table. table.  However, the values
     of the 'PARTITION_NAME', 'SUBPARTITION_NAME',
     'PARTITION_ORDINAL_POSITION', 'SUBPARTITION_ORDINAL_POSITION',
     'PARTITION_METHOD', 'SUBPARTITION_METHOD', 'PARTITION_EXPRESSION',
     'SUBPARTITION_EXPRESSION', and 'PARTITION_DESCRIPTION' columns are
     all 'NULL'.  Also, the 'PARTITION_COMMENT' column in this case is
     blank.

   * An 'NDB' table which is not explicitly partitioned has one row in
     the 'PARTITIONS' table for each data node in the NDB cluster.  For
     each such row:

        * The 'SUBPARTITION_NAME', 'SUBPARTITION_ORDINAL_POSITION',
          'SUBPARTITION_METHOD', 'PARTITION_EXPRESSION',
          'SUBPARTITION_EXPRESSION', 'CREATE_TIME', 'UPDATE_TIME',
          'CHECK_TIME', 'CHECKSUM', and 'TABLESPACE_NAME' columns are
          all 'NULL'.

        * The 'PARTITION_METHOD' is always 'KEY'.

        * The 'NODEGROUP' column is 'default'.

        * The 'PARTITION_EXPRESSION' and 'PARTITION_COMMENT' columns are
          empty.


File: manual.info.tmp,  Node: plugins-table,  Next: processlist-table,  Prev: partitions-table,  Up: information-schema

21.14 The INFORMATION_SCHEMA PLUGINS Table
==========================================

The *note 'PLUGINS': plugins-table. table provides information about
server plugins.

The *note 'PLUGINS': plugins-table. table has these columns:

   * 'PLUGIN_NAME'

     The name used to refer to the plugin in statements such as *note
     'INSTALL PLUGIN': install-plugin. and *note 'UNINSTALL PLUGIN':
     uninstall-plugin.

   * 'PLUGIN_VERSION'

     The version from the plugin's general type descriptor.

   * 'PLUGIN_STATUS'

     The plugin status, one of 'ACTIVE', 'INACTIVE', 'DISABLED', or
     'DELETED'.

   * 'PLUGIN_TYPE'

     The type of plugin, such as 'STORAGE ENGINE', 'INFORMATION_SCHEMA',
     or 'AUTHENTICATION'.

   * 'PLUGIN_TYPE_VERSION'

     The version from the plugin's type-specific descriptor.

   * 'PLUGIN_LIBRARY'

     The name of the plugin shared library file.  This is the name used
     to refer to the plugin file in statements such as *note 'INSTALL
     PLUGIN': install-plugin. and *note 'UNINSTALL PLUGIN':
     uninstall-plugin.  This file is located in the directory named by
     the 'plugin_dir' system variable.  If the library name is 'NULL',
     the plugin is compiled in and cannot be uninstalled with *note
     'UNINSTALL PLUGIN': uninstall-plugin.

   * 'PLUGIN_LIBRARY_VERSION'

     The plugin API interface version.

   * 'PLUGIN_AUTHOR'

     The plugin author.

   * 'PLUGIN_DESCRIPTION'

     A short description of the plugin.

   * 'PLUGIN_LICENSE'

     How the plugin is licensed (for example, 'GPL').

   * 'LOAD_OPTION'

     How the plugin was loaded.  The value is 'OFF', 'ON', 'FORCE', or
     'FORCE_PLUS_PERMANENT'.  See *note plugin-loading::.

*Notes*

   * The *note 'PLUGINS': plugins-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

   * For plugins installed with *note 'INSTALL PLUGIN': install-plugin,
     the 'PLUGIN_NAME' and 'PLUGIN_LIBRARY' values are also registered
     in the 'mysql.plugin' table.

   * For information about plugin data structures that form the basis of
     the information in the *note 'PLUGINS': plugins-table. table, see
     *note plugin-api::.

Plugin information is also available from the *note 'SHOW PLUGINS':
show-plugins. statement.  See *note show-plugins::.  These statements
are equivalent:

     SELECT
       PLUGIN_NAME, PLUGIN_STATUS, PLUGIN_TYPE,
       PLUGIN_LIBRARY, PLUGIN_LICENSE
     FROM INFORMATION_SCHEMA.PLUGINS;

     SHOW PLUGINS;


File: manual.info.tmp,  Node: processlist-table,  Next: profiling-table,  Prev: plugins-table,  Up: information-schema

21.15 The INFORMATION_SCHEMA PROCESSLIST Table
==============================================

The *note 'PROCESSLIST': processlist-table. table provides information
about which threads are running.

The *note 'PROCESSLIST': processlist-table. table has these columns:

   * 'ID'

     The connection identifier.  This is the same type of value
     displayed in the 'Id' column of the *note 'SHOW PROCESSLIST':
     show-processlist. statement and returned by the 'CONNECTION_ID()'
     function.

   * 'USER'

     The MySQL user who issued the statement.  A value of 'system user'
     refers to a nonclient thread spawned by the server to handle tasks
     internally.  This could be the I/O or SQL thread used on
     replication slaves or a delayed-row handler.  For 'system user',
     there is no host specified in the 'Host' column.  'unauthenticated
     user' refers to a thread that has become associated with a client
     connection but for which authentication of the client user has not
     yet been done.  'event_scheduler' refers to the thread that
     monitors scheduled events (see *note event-scheduler::).

   * 'HOST'

     The host name of the client issuing the statement (except for
     'system user', for which there is no host).  The host name for
     TCP/IP connections is reported in 'HOST_NAME:CLIENT_PORT' format to
     make it easier to determine which client is doing what.

   * 'DB'

     The default database, if one is selected; otherwise 'NULL'.

   * 'COMMAND'

     The type of command the thread is executing.  For descriptions for
     thread commands, see *note thread-information::.  The value of this
     column corresponds to the 'COM_XXX' commands of the client/server
     protocol and 'Com_XXX' status variables.  See *note
     server-status-variables::

   * 'TIME'

     The time in seconds that the thread has been in its current state.
     For a slave SQL thread, the value is the number of seconds between
     the timestamp of the last replicated event and the real time of the
     slave machine.  See *note replication-implementation-details::.

   * 'STATE'

     An action, event, or state that indicates what the thread is doing.
     Descriptions for 'STATE' values can be found at *note
     thread-information::.

     Most states correspond to very quick operations.  If a thread stays
     in a given state for many seconds, there might be a problem that
     needs to be investigated.

     For the *note 'SHOW PROCESSLIST': show-processlist. statement, the
     value of 'STATE' is 'NULL'.

   * 'INFO'

     The statement the thread is executing, or 'NULL' if it is not
     executing any statement.  The statement might be the one sent to
     the server, or an innermost statement if the statement executes
     other statements.  For example, if a 'CALL' statement executes a
     stored procedure that is executing a *note 'SELECT': select.
     statement, the 'INFO' value shows the *note 'SELECT': select.
     statement.

*Notes*

   * The *note 'PROCESSLIST': processlist-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

   * Like the output from the *note 'SHOW PROCESSLIST':
     show-processlist. statement, the *note 'PROCESSLIST':
     processlist-table. table shows information only about your own
     threads, unless you have the 'PROCESS' privilege, in which case you
     will see information about other threads, too.  As an anonymous
     user, you cannot see any rows at all.

   * If an SQL statement refers to the *note 'PROCESSLIST':
     processlist-table. table, MySQL populates the entire table once,
     when statement execution begins, so there is read consistency
     during the statement.  There is no read consistency for a
     multi-statement transaction.

The following statements are equivalent:

     SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST

     SHOW FULL PROCESSLIST


File: manual.info.tmp,  Node: profiling-table,  Next: referential-constraints-table,  Prev: processlist-table,  Up: information-schema

21.16 The INFORMATION_SCHEMA PROFILING Table
============================================

The *note 'PROFILING': profiling-table. table provides statement
profiling information.  Its contents correspond to the information
produced by the *note 'SHOW PROFILE': show-profile. and *note 'SHOW
PROFILES': show-profiles. statements (see *note show-profile::).  The
table is empty unless the 'profiling' session variable is set to 1.

The *note 'PROFILING': profiling-table. table has these columns:

   * 'QUERY_ID'

     A numeric statement identifier.

   * 'SEQ'

     A sequence number indicating the display order for rows with the
     same 'QUERY_ID' value.

   * 'STATE'

     The profiling state to which the row measurements apply.

   * 'DURATION'

     How long statement execution remained in the given state, in
     seconds.

   * 'CPU_USER', 'CPU_SYSTEM'

     User and system CPU use, in seconds.

   * 'CONTEXT_VOLUNTARY', 'CONTEXT_INVOLUNTARY'

     How many voluntary and involuntary context switches occurred.

   * 'BLOCK_OPS_IN', 'BLOCK_OPS_OUT'

     The number of block input and output operations.

   * 'MESSAGES_SENT', 'MESSAGES_RECEIVED'

     The number of communication messages sent and received.

   * 'PAGE_FAULTS_MAJOR', 'PAGE_FAULTS_MINOR'

     The number of major and minor page faults.

   * 'SWAPS'

     How many swaps occurred.

   * 'SOURCE_FUNCTION', 'SOURCE_FILE', and 'SOURCE_LINE'

     Information indicating where in the source code the profiled state
     executes.

*Notes*

   * The *note 'PROFILING': profiling-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

Profiling information is also available from the *note 'SHOW PROFILE':
show-profile. and *note 'SHOW PROFILES': show-profiles. statements.  See
*note show-profile::.  For example, the following queries are
equivalent:

     SHOW PROFILE FOR QUERY 2;

     SELECT STATE, FORMAT(DURATION, 6) AS DURATION
     FROM INFORMATION_SCHEMA.PROFILING
     WHERE QUERY_ID = 2 ORDER BY SEQ;


File: manual.info.tmp,  Node: referential-constraints-table,  Next: routines-table,  Prev: profiling-table,  Up: information-schema

21.17 The INFORMATION_SCHEMA REFERENTIAL_CONSTRAINTS Table
==========================================================

The *note 'REFERENTIAL_CONSTRAINTS': referential-constraints-table.
table provides information about foreign keys.

The *note 'REFERENTIAL_CONSTRAINTS': referential-constraints-table.
table has these columns:

   * 'CONSTRAINT_CATALOG'

     The name of the catalog to which the constraint belongs.  This
     value is always 'def'.

   * 'CONSTRAINT_SCHEMA'

     The name of the schema (database) to which the constraint belongs.

   * 'CONSTRAINT_NAME'

     The name of the constraint.

   * 'UNIQUE_CONSTRAINT_CATALOG'

     The name of the catalog containing the unique constraint that the
     constraint references.  This value is always 'def'.

   * 'UNIQUE_CONSTRAINT_SCHEMA'

     The name of the schema (database) containing the unique constraint
     that the constraint references.

   * 'UNIQUE_CONSTRAINT_NAME'

     The name of the unique constraint that the constraint references.

   * 'MATCH_OPTION'

     The value of the constraint 'MATCH' attribute.  The only valid
     value at this time is 'NONE'.

   * 'UPDATE_RULE'

     The value of the constraint 'ON UPDATE' attribute.  The possible
     values are 'CASCADE', 'SET NULL', 'SET DEFAULT', 'RESTRICT', 'NO
     ACTION'.

   * 'DELETE_RULE'

     The value of the constraint 'ON DELETE' attribute.  The possible
     values are 'CASCADE', 'SET NULL', 'SET DEFAULT', 'RESTRICT', 'NO
     ACTION'.

   * 'TABLE_NAME'

     The name of the table.  This value is the same as in the *note
     'TABLE_CONSTRAINTS': table-constraints-table. table.

   * 'REFERENCED_TABLE_NAME'

     The name of the table referenced by the constraint.


File: manual.info.tmp,  Node: routines-table,  Next: schemata-table,  Prev: referential-constraints-table,  Up: information-schema

21.18 The INFORMATION_SCHEMA ROUTINES Table
===========================================

The *note 'ROUTINES': routines-table. table provides information about
stored routines (stored procedures and stored functions).  The *note
'ROUTINES': routines-table. table does not include built-in SQL
functions or user-defined functions (UDFs).

The column named ''mysql.proc' Name' indicates the 'mysql.proc' table
column that corresponds to the 'INFORMATION_SCHEMA' *note 'ROUTINES':
routines-table. table column, if any.

The *note 'ROUTINES': routines-table. table has these columns:

   * 'SPECIFIC_NAME'

     The name of the routine.

   * 'ROUTINE_CATALOG'

     The name of the catalog to which the routine belongs.  This value
     is always 'def'.

   * 'ROUTINE_SCHEMA'

     The name of the schema (database) to which the routine belongs.

   * 'ROUTINE_NAME'

     The name of the routine.

   * 'ROUTINE_TYPE'

     'PROCEDURE' for stored procedures, 'FUNCTION' for stored functions.

   * 'DATA_TYPE'

     If the routine is a stored function, the return value data type.
     If the routine is a stored procedure, this value is empty.

     The 'DATA_TYPE' value is the type name only with no other
     information.  The 'DTD_IDENTIFIER' value contains the type name and
     possibly other information such as the precision or length.

   * 'CHARACTER_MAXIMUM_LENGTH'

     For stored function string return values, the maximum length in
     characters.  If the routine is a stored procedure, this value is
     'NULL'.

   * 'CHARACTER_OCTET_LENGTH'

     For stored function string return values, the maximum length in
     bytes.  If the routine is a stored procedure, this value is 'NULL'.

   * 'NUMERIC_PRECISION'

     For stored function numeric return values, the numeric precision.
     If the routine is a stored procedure, this value is 'NULL'.

   * 'NUMERIC_SCALE'

     For stored function numeric return values, the numeric scale.  If
     the routine is a stored procedure, this value is 'NULL'.

   * 'CHARACTER_SET_NAME'

     For stored function character string return values, the character
     set name.  If the routine is a stored procedure, this value is
     'NULL'.

   * 'COLLATION_NAME'

     For stored function character string return values, the collation
     name.  If the routine is a stored procedure, this value is 'NULL'.

   * 'DTD_IDENTIFIER'

     If the routine is a stored function, the return value data type.
     If the routine is a stored procedure, this value is empty.

     The 'DATA_TYPE' value is the type name only with no other
     information.  The 'DTD_IDENTIFIER' value contains the type name and
     possibly other information such as the precision or length.

   * 'ROUTINE_BODY'

     The language used for the routine definition.  This value is always
     'SQL'.

   * 'ROUTINE_DEFINITION'

     The text of the SQL statement executed by the routine.

   * 'EXTERNAL_NAME'

     This value is always 'NULL'.

   * 'EXTERNAL_LANGUAGE'

     The language of the stored routine.  MySQL calculates
     'EXTERNAL_LANGUAGE' thus:

        * If 'mysql.proc.language='SQL'', 'EXTERNAL_LANGUAGE' is 'NULL'

        * Otherwise, 'EXTERNAL_LANGUAGE' is what is in
          'mysql.proc.language'.  However, we do not have external
          languages yet, so it is always 'NULL'.

   * 'PARAMETER_STYLE'

     This value is always 'SQL'.

   * 'IS_DETERMINISTIC'

     'YES' or 'NO', depending on whether the routine is defined with the
     'DETERMINISTIC' characteristic.

   * 'SQL_DATA_ACCESS'

     The data access characteristic for the routine.  The value is one
     of 'CONTAINS SQL', 'NO SQL', 'READS SQL DATA', or 'MODIFIES SQL
     DATA'.

   * 'SQL_PATH'

     This value is always 'NULL'.

   * 'SECURITY_TYPE'

     The routine 'SQL SECURITY' characteristic.  The value is one of
     'DEFINER' or 'INVOKER'.

   * 'CREATED'

     The date and time when the routine was created.  This is a *note
     'TIMESTAMP': datetime. value.

   * 'LAST_ALTERED'

     The date and time when the routine was last modified.  This is a
     *note 'TIMESTAMP': datetime. value.  If the routine has not been
     modified since its creation, this value is the same as the
     'CREATED' value.

   * 'SQL_MODE'

     The SQL mode in effect when the routine was created or altered, and
     under which the routine executes.  For the permitted values, see
     *note sql-mode::.

   * 'ROUTINE_COMMENT'

     The text of the comment, if the routine has one.  If not, this
     value is empty.

   * 'DEFINER'

     The account of the user who created the routine, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'CHARACTER_SET_CLIENT'

     The session value of the 'character_set_client' system variable
     when the routine was created.

   * 'COLLATION_CONNECTION'

     The session value of the 'collation_connection' system variable
     when the routine was created.

   * 'DATABASE_COLLATION'

     The collation of the database with which the routine is associated.

*Notes*

   * Information about stored function return values is also available
     in the *note 'PARAMETERS': parameters-table. table.  The return
     value row for a stored function can be identified as the row that
     has an 'ORDINAL_POSITION' value of 0.


File: manual.info.tmp,  Node: schemata-table,  Next: schema-privileges-table,  Prev: routines-table,  Up: information-schema

21.19 The INFORMATION_SCHEMA SCHEMATA Table
===========================================

A schema is a database, so the *note 'SCHEMATA': schemata-table. table
provides information about databases.

The *note 'SCHEMATA': schemata-table. table has these columns:

   * 'CATALOG_NAME'

     The name of the catalog to which the schema belongs.  This value is
     always 'def'.

   * 'SCHEMA_NAME'

     The name of the schema.

   * 'DEFAULT_CHARACTER_SET_NAME'

     The schema default character set.

   * 'DEFAULT_COLLATION_NAME'

     The schema default collation.

   * 'SQL_PATH'

     This value is always 'NULL'.

Schema names are also available from the *note 'SHOW DATABASES':
show-databases. statement.  See *note show-databases::.  The following
statements are equivalent:

     SELECT SCHEMA_NAME AS `Database`
       FROM INFORMATION_SCHEMA.SCHEMATA
       [WHERE SCHEMA_NAME LIKE 'WILD']

     SHOW DATABASES
       [LIKE 'WILD']

You see only those databases for which you have some kind of privilege,
unless you have the global *note 'SHOW DATABASES': show-databases.
privilege.

*Caution*:

Because a global privilege is considered a privilege for all databases,
_any_ global privilege enables a user to see all database names with
*note 'SHOW DATABASES': show-databases. or by examining the
'INFORMATION_SCHEMA' *note 'SCHEMATA': schemata-table. table.


File: manual.info.tmp,  Node: schema-privileges-table,  Next: statistics-table,  Prev: schemata-table,  Up: information-schema

21.20 The INFORMATION_SCHEMA SCHEMA_PRIVILEGES Table
====================================================

The *note 'SCHEMA_PRIVILEGES': schema-privileges-table. table provides
information about schema (database) privileges.  It takes its values
from the 'mysql.db' system table.

The *note 'SCHEMA_PRIVILEGES': schema-privileges-table. table has these
columns:

   * 'GRANTEE'

     The name of the account to which the privilege is granted, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'TABLE_CATALOG'

     The name of the catalog to which the schema belongs.  This value is
     always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema.

   * 'PRIVILEGE_TYPE'

     The privilege granted.  The value can be any privilege that can be
     granted at the schema level; see *note grant::.  Each row lists a
     single privilege, so there is one row per schema privilege held by
     the grantee.

   * 'IS_GRANTABLE'

     'YES' if the user has the 'GRANT OPTION' privilege, 'NO' otherwise.
     The output does not list 'GRANT OPTION' as a separate row with
     'PRIVILEGE_TYPE='GRANT OPTION''.

*Notes*

   * The *note 'SCHEMA_PRIVILEGES': schema-privileges-table. table is a
     nonstandard 'INFORMATION_SCHEMA' table.

The following statements are _not_ equivalent:

     SELECT ... FROM INFORMATION_SCHEMA.SCHEMA_PRIVILEGES

     SHOW GRANTS ...


File: manual.info.tmp,  Node: statistics-table,  Next: tables-table,  Prev: schema-privileges-table,  Up: information-schema

21.21 The INFORMATION_SCHEMA STATISTICS Table
=============================================

The *note 'STATISTICS': statistics-table. table provides information
about table indexes.

The *note 'STATISTICS': statistics-table. table has these columns:

   * 'TABLE_CATALOG'

     The name of the catalog to which the table containing the index
     belongs.  This value is always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the table containing the
     index belongs.

   * 'TABLE_NAME'

     The name of the table containing the index.

   * 'NON_UNIQUE'

     0 if the index cannot contain duplicates, 1 if it can.

   * 'INDEX_SCHEMA'

     The name of the schema (database) to which the index belongs.

   * 'INDEX_NAME'

     The name of the index.  If the index is the primary key, the name
     is always 'PRIMARY'.

   * 'SEQ_IN_INDEX'

     The column sequence number in the index, starting with 1.

   * 'COLUMN_NAME'

     The column name.  See also the description for the 'EXPRESSION'
     column.

   * 'COLLATION'

     How the column is sorted in the index.  This can have values 'A'
     (ascending), 'D' (descending), or 'NULL' (not sorted).

   * 'CARDINALITY'

     An estimate of the number of unique values in the index.  To update
     this number, run *note 'ANALYZE TABLE': analyze-table. or (for
     'MyISAM' tables) *note 'myisamchk -a': myisamchk.

     'CARDINALITY' is counted based on statistics stored as integers, so
     the value is not necessarily exact even for small tables.  The
     higher the cardinality, the greater the chance that MySQL uses the
     index when doing joins.

   * 'SUB_PART'

     The index prefix.  That is, the number of indexed characters if the
     column is only partly indexed, 'NULL' if the entire column is
     indexed.

     *Note*:

     Prefix _limits_ are measured in bytes.  However, prefix _lengths_
     for index specifications in *note 'CREATE TABLE': create-table,
     *note 'ALTER TABLE': alter-table, and *note 'CREATE INDEX':
     create-index. statements are interpreted as number of characters
     for nonbinary string types (*note 'CHAR': char, *note 'VARCHAR':
     char, *note 'TEXT': blob.) and number of bytes for binary string
     types (*note 'BINARY': binary-varbinary, *note 'VARBINARY':
     binary-varbinary, *note 'BLOB': blob.).  Take this into account
     when specifying a prefix length for a nonbinary string column that
     uses a multibyte character set.

     For additional information about index prefixes, see *note
     column-indexes::, and *note create-index::.

   * 'PACKED'

     Indicates how the key is packed.  'NULL' if it is not.

   * 'NULLABLE'

     Contains 'YES' if the column may contain 'NULL' values and '''' if
     not.

   * 'INDEX_TYPE'

     The index method used ('BTREE', 'FULLTEXT', 'HASH', 'RTREE').

   * 'COMMENT'

     Information about the index not described in its own column, such
     as 'disabled' if the index is disabled.

   * 'INDEX_COMMENT'

     Any comment provided for the index with a 'COMMENT' attribute when
     the index was created.

*Notes*

   * There is no standard 'INFORMATION_SCHEMA' table for indexes.  The
     MySQL column list is similar to what SQL Server 2000 returns for
     'sp_statistics', except that 'QUALIFIER' and 'OWNER' are replaced
     with 'CATALOG' and 'SCHEMA', respectively.

Information about table indexes is also available from the *note 'SHOW
INDEX': show-index. statement.  See *note show-index::.  The following
statements are equivalent:

     SELECT * FROM INFORMATION_SCHEMA.STATISTICS
       WHERE table_name = 'TBL_NAME'
       AND table_schema = 'DB_NAME'

     SHOW INDEX
       FROM TBL_NAME
       FROM DB_NAME


File: manual.info.tmp,  Node: tables-table,  Next: tablespaces-table,  Prev: statistics-table,  Up: information-schema

21.22 The INFORMATION_SCHEMA TABLES Table
=========================================

The *note 'TABLES': tables-table. table provides information about
tables in databases.

The *note 'TABLES': tables-table. table has these columns:

   * 'TABLE_CATALOG'

     The name of the catalog to which the table belongs.  This value is
     always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the table belongs.

   * 'TABLE_NAME'

     The name of the table.

   * 'TABLE_TYPE'

     'BASE TABLE' for a table, 'VIEW' for a view, or 'SYSTEM VIEW' for
     an 'INFORMATION_SCHEMA' table.

     The *note 'TABLES': tables-table. table does not list 'TEMPORARY'
     tables.

   * 'ENGINE'

     The storage engine for the table.  See *note
     innodb-storage-engine::, and *note storage-engines::.

     For partitioned tables, 'ENGINE' shows the name of the storage
     engine used by all partitions.

   * 'VERSION'

     The version number of the table's '.frm' file.

   * 'ROW_FORMAT'

     The row-storage format ('Fixed', 'Dynamic', 'Compressed',
     'Redundant', 'Compact').  For 'MyISAM' tables, 'Dynamic'
     corresponds to what *note 'myisamchk -dvv': myisamchk. reports as
     'Packed'.  'InnoDB' table format is either 'Redundant' or 'Compact'
     when using the 'Antelope' file format, or 'Compressed' or 'Dynamic'
     when using the 'Barracuda' file format.

   * 'TABLE_ROWS'

     The number of rows.  Some storage engines, such as 'MyISAM', store
     the exact count.  For other storage engines, such as 'InnoDB', this
     value is an approximation, and may vary from the actual value by as
     much as 40% to 50%.  In such cases, use 'SELECT COUNT(*)' to obtain
     an accurate count.

     'TABLE_ROWS' is 'NULL' for 'INFORMATION_SCHEMA' tables.

     For *note 'InnoDB': innodb-storage-engine. tables, the row count is
     only a rough estimate used in SQL optimization.  (This is also true
     if the *note 'InnoDB': innodb-storage-engine. table is
     partitioned.)

   * 'AVG_ROW_LENGTH'

     The average row length.

     Refer to the notes at the end of this section for related
     information.

   * 'DATA_LENGTH'

     For 'MyISAM', 'DATA_LENGTH' is the length of the data file, in
     bytes.

     For 'InnoDB', 'DATA_LENGTH' is the approximate amount of space
     allocated for the clustered index, in bytes.  Specifically, it is
     the clustered index size, in pages, multiplied by the 'InnoDB' page
     size.

     Refer to the notes at the end of this section for information
     regarding other storage engines.

   * 'MAX_DATA_LENGTH'

     For 'MyISAM', 'MAX_DATA_LENGTH' is maximum length of the data file.
     This is the total number of bytes of data that can be stored in the
     table, given the data pointer size used.

     Unused for 'InnoDB'.

     Refer to the notes at the end of this section for information
     regarding other storage engines.

   * 'INDEX_LENGTH'

     For 'MyISAM', 'INDEX_LENGTH' is the length of the index file, in
     bytes.

     For 'InnoDB', 'INDEX_LENGTH' is the approximate amount of space
     allocated for non-clustered indexes, in bytes.  Specifically, it is
     the sum of non-clustered index sizes, in pages, multiplied by the
     'InnoDB' page size.

     Refer to the notes at the end of this section for information
     regarding other storage engines.

   * 'DATA_FREE'

     The number of allocated but unused bytes.

     'InnoDB' tables report the free space of the tablespace to which
     the table belongs.  For a table located in the shared tablespace,
     this is the free space of the shared tablespace.  If you are using
     multiple tablespaces and the table has its own tablespace, the free
     space is for only that table.  Free space means the number of bytes
     in completely free extents minus a safety margin.  Even if free
     space displays as 0, it may be possible to insert rows as long as
     new extents need not be allocated.

     For NDB Cluster, 'DATA_FREE' shows the space allocated on disk for,
     but not used by, a Disk Data table or fragment on disk.  (In-memory
     data resource usage is reported by the 'DATA_LENGTH' column.)

     For partitioned tables, this value is only an estimate and may not
     be absolutely correct.  A more accurate method of obtaining this
     information in such cases is to query the 'INFORMATION_SCHEMA'
     *note 'PARTITIONS': partitions-table. table, as shown in this
     example:

          SELECT SUM(DATA_FREE)
              FROM  INFORMATION_SCHEMA.PARTITIONS
              WHERE TABLE_SCHEMA = 'mydb'
              AND   TABLE_NAME   = 'mytable';

     For more information, see *note partitions-table::.

   * 'AUTO_INCREMENT'

     The next 'AUTO_INCREMENT' value.

   * 'CREATE_TIME'

     When the table was created.

     Prior to MySQL 5.5.44, for partitioned *note 'InnoDB':
     innodb-storage-engine. tables, the 'CREATE_TIME' column shows
     'NULL'.  This column shows the correct table creation time for such
     tables in MySQL 5.5.44 and later.  (Bug #17299181, Bug #69990)

   * 'UPDATE_TIME'

     When the data file was last updated.  For some storage engines,
     this value is 'NULL'.  For example, 'InnoDB' stores multiple tables
     in its system tablespace and the data file timestamp does not
     apply.  Even with file-per-table mode with each 'InnoDB' table in a
     separate '.ibd' file, change buffering can delay the write to the
     data file, so the file modification time is different from the time
     of the last insert, update, or delete.  For 'MyISAM', the data file
     timestamp is used; however, on Windows the timestamp is not updated
     by updates, so the value is inaccurate.

     For partitioned *note 'InnoDB': innodb-storage-engine. tables,
     'UPDATE_TIME' is always 'NULL'.

   * 'CHECK_TIME'

     When the table was last checked.  Not all storage engines update
     this time, in which case, the value is always 'NULL'.

     For partitioned *note 'InnoDB': innodb-storage-engine. tables,
     'CHECK_TIME' is always 'NULL'.

   * 'TABLE_COLLATION'

     The table default collation.  The output does not explicitly list
     the table default character set, but the collation name begins with
     the character set name.

   * 'CHECKSUM'

     The live checksum value, if any.

   * 'CREATE_OPTIONS'

     Extra options used with *note 'CREATE TABLE': create-table.  The
     original options from when *note 'CREATE TABLE': create-table. was
     executed are retained and the options reported here may differ from
     the active table settings and options.

     'CREATE_OPTIONS' shows 'partitioned' if the table is partitioned.

   * 'TABLE_COMMENT'

     The comment used when creating the table (or information as to why
     MySQL could not access the table information).

*Notes*

   * For *note 'NDB': mysql-cluster. tables, the output of this
     statement shows appropriate values for the 'AVG_ROW_LENGTH' and
     'DATA_LENGTH' columns, with the exception that *note 'BLOB': blob.
     columns are not taken into account.

   * For *note 'NDB': mysql-cluster. tables, 'DATA_LENGTH' includes data
     stored in main memory only; the 'MAX_DATA_LENGTH' and 'DATA_FREE'
     columns apply to Disk Data.

   * For NDB Cluster Disk Data tables, 'MAX_DATA_LENGTH' shows the space
     allocated for the disk part of a Disk Data table or fragment.
     (In-memory data resource usage is reported by the 'DATA_LENGTH'
     column.)

   * For 'MEMORY' tables, the 'DATA_LENGTH', 'MAX_DATA_LENGTH', and
     'INDEX_LENGTH' values approximate the actual amount of allocated
     memory.  The allocation algorithm reserves memory in large amounts
     to reduce the number of allocation operations.

   * For views, all *note 'TABLES': tables-table. columns are 'NULL'
     except that 'TABLE_NAME' indicates the view name and
     'TABLE_COMMENT' says 'VIEW'.

Table information is also available from the *note 'SHOW TABLE STATUS':
show-table-status. and *note 'SHOW TABLES': show-tables. statements.
See *note show-table-status::, and *note show-tables::.  The following
statements are equivalent:

     SELECT
         TABLE_NAME, ENGINE, VERSION, ROW_FORMAT, TABLE_ROWS, AVG_ROW_LENGTH,
         DATA_LENGTH, MAX_DATA_LENGTH, INDEX_LENGTH, DATA_FREE, AUTO_INCREMENT,
         CREATE_TIME, UPDATE_TIME, CHECK_TIME, TABLE_COLLATION, CHECKSUM,
         CREATE_OPTIONS, TABLE_COMMENT
       FROM INFORMATION_SCHEMA.TABLES
       WHERE table_schema = 'DB_NAME'
       [AND table_name LIKE 'WILD']

     SHOW TABLE STATUS
       FROM DB_NAME
       [LIKE 'WILD']

The following statements are equivalent:

     SELECT
       TABLE_NAME, TABLE_TYPE
       FROM INFORMATION_SCHEMA.TABLES
       WHERE table_schema = 'DB_NAME'
       [AND table_name LIKE 'WILD']

     SHOW FULL TABLES
       FROM DB_NAME
       [LIKE 'WILD']


File: manual.info.tmp,  Node: tablespaces-table,  Next: table-constraints-table,  Prev: tables-table,  Up: information-schema

21.23 The INFORMATION_SCHEMA TABLESPACES Table
==============================================

The *note 'TABLESPACES': tablespaces-table. table provides information
about active MySQL Cluster tablespaces.

The *note 'TABLESPACES': tablespaces-table. table has these columns:

   * 'TABLESPACE_NAME'

     The name of the tablespace.

   * 'ENGINE'

     The name of the storage engine that uses the tablespace.

   * 'TABLESPACE_TYPE'

     The tablespace type.

   * 'LOGFILE_GROUP_NAME'

     The name of the logfile group assigned to the tablespace.

   * 'EXTENT_SIZE'

     The size in bytes of the extents used by files that belong to the
     tablespace.

   * 'AUTOEXTEND_SIZE'

     Unused.

   * 'MAXIMUM_SIZE'

     Unused.

   * 'NODEGROUP_ID'

     Unused.

   * 'TABLESPACE_COMMENT'

     Unused.

*Notes*

   * The *note 'TABLESPACES': tablespaces-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

   * The 'TABLESPACES' table does not provide information about 'InnoDB'
     tablespaces.


File: manual.info.tmp,  Node: table-constraints-table,  Next: table-privileges-table,  Prev: tablespaces-table,  Up: information-schema

21.24 The INFORMATION_SCHEMA TABLE_CONSTRAINTS Table
====================================================

The *note 'TABLE_CONSTRAINTS': table-constraints-table. table describes
which tables have constraints.

The *note 'TABLE_CONSTRAINTS': table-constraints-table. table has these
columns:

   * 'CONSTRAINT_CATALOG'

     The name of the catalog to which the constraint belongs.  This
     value is always 'def'.

   * 'CONSTRAINT_SCHEMA'

     The name of the schema (database) to which the constraint belongs.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the table belongs.

   * 'TABLE_NAME'

     The name of the table.

   * The 'CONSTRAINT_TYPE'

     The type of constraint.  The value can be 'UNIQUE', 'PRIMARY KEY',
     'FOREIGN KEY', or 'CHECK'.  This is a *note 'CHAR': char. (not
     *note 'ENUM': enum.) column.  The 'CHECK' value is not available
     until MySQL supports 'CHECK'.

     The 'UNIQUE' and 'PRIMARY KEY' information is about the same as
     what you get from the 'Key_name' column in the output from *note
     'SHOW INDEX': show-index. when the 'Non_unique' column is '0'.


File: manual.info.tmp,  Node: table-privileges-table,  Next: triggers-table,  Prev: table-constraints-table,  Up: information-schema

21.25 The INFORMATION_SCHEMA TABLE_PRIVILEGES Table
===================================================

The *note 'TABLE_PRIVILEGES': table-privileges-table. table provides
information about table privileges.  It takes its values from the
'mysql.tables_priv' system table.

The *note 'TABLE_PRIVILEGES': table-privileges-table. table has these
columns:

   * 'GRANTEE'

     The name of the account to which the privilege is granted, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'TABLE_CATALOG'

     The name of the catalog to which the table belongs.  This value is
     always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the table belongs.

   * 'TABLE_NAME'

     The name of the table.

   * 'PRIVILEGE_TYPE'

     The privilege granted.  The value can be any privilege that can be
     granted at the table level; see *note grant::.  Each row lists a
     single privilege, so there is one row per table privilege held by
     the grantee.

   * 'IS_GRANTABLE'

     'YES' if the user has the 'GRANT OPTION' privilege, 'NO' otherwise.
     The output does not list 'GRANT OPTION' as a separate row with
     'PRIVILEGE_TYPE='GRANT OPTION''.

*Notes*

   * The *note 'TABLE_PRIVILEGES': table-privileges-table. table is a
     nonstandard 'INFORMATION_SCHEMA' table.

The following statements are _not_ equivalent:

     SELECT ... FROM INFORMATION_SCHEMA.TABLE_PRIVILEGES

     SHOW GRANTS ...


File: manual.info.tmp,  Node: triggers-table,  Next: user-privileges-table,  Prev: table-privileges-table,  Up: information-schema

21.26 The INFORMATION_SCHEMA TRIGGERS Table
===========================================

The *note 'TRIGGERS': triggers-table. table provides information about
triggers.  To see information about a table's triggers, you must have
the 'TRIGGER' privilege for the table.

The *note 'TRIGGERS': triggers-table. table has these columns:

   * 'TRIGGER_CATALOG'

     The name of the catalog to which the trigger belongs.  This value
     is always 'def'.

   * 'TRIGGER_SCHEMA'

     The name of the schema (database) to which the trigger belongs.

   * 'TRIGGER_NAME'

     The name of the trigger.

   * 'EVENT_MANIPULATION'

     The trigger event.  This is the type of operation on the associated
     table for which the trigger activates.  The value is 'INSERT' (a
     row was inserted), 'DELETE' (a row was deleted), or 'UPDATE' (a row
     was modified).

   * 'EVENT_OBJECT_CATALOG', 'EVENT_OBJECT_SCHEMA', and
     'EVENT_OBJECT_TABLE'

     As noted in *note triggers::, every trigger is associated with
     exactly one table.  These columns indicate the catalog and schema
     (database) in which this table occurs, and the table name,
     respectively.  The 'EVENT_OBJECT_CATALOG' value is always 'def'.

   * 'ACTION_ORDER'

     The ordinal position of the trigger's action within the list of all
     similar triggers on the same table.  This value is always '0'
     because it is not possible to have more than one trigger with the
     same 'EVENT_MANIPULATION' and 'ACTION_TIMING' on the same table.

   * 'ACTION_CONDITION'

     This value is always 'NULL'.

   * 'ACTION_STATEMENT'

     The trigger body; that is, the statement executed when the trigger
     activates.  This text uses UTF-8 encoding.

   * 'ACTION_ORIENTATION'

     This value is always 'ROW'.

   * 'ACTION_TIMING'

     Whether the trigger activates before or after the triggering event.
     The value is 'BEFORE' or 'AFTER'.

   * 'ACTION_REFERENCE_OLD_TABLE'

     This value is always 'NULL'.

   * 'ACTION_REFERENCE_NEW_TABLE'

     This value is always 'NULL'.

   * 'ACTION_REFERENCE_OLD_ROW' and 'ACTION_REFERENCE_NEW_ROW'

     The old and new column identifiers, respectively.  The
     'ACTION_REFERENCE_OLD_ROW' value is always 'OLD' and the
     'ACTION_REFERENCE_NEW_ROW' value is always 'NEW'.

   * 'CREATED'

     This value is always 'NULL'.

   * 'SQL_MODE'

     The SQL mode in effect when the trigger was created, and under
     which the trigger executes.  For the permitted values, see *note
     sql-mode::.

   * 'DEFINER'

     The account of the user who created the trigger, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'CHARACTER_SET_CLIENT'

     The session value of the 'character_set_client' system variable
     when the trigger was created.

   * 'COLLATION_CONNECTION'

     The session value of the 'collation_connection' system variable
     when the trigger was created.

   * 'DATABASE_COLLATION'

     The collation of the database with which the trigger is associated.

*Example*

The following example uses the 'ins_sum' trigger defined in *note
triggers:::

     mysql> SELECT * FROM INFORMATION_SCHEMA.TRIGGERS
            WHERE TRIGGER_SCHEMA='test' AND TRIGGER_NAME='ins_sum'\G
     *************************** 1. row ***************************
                TRIGGER_CATALOG: def
                 TRIGGER_SCHEMA: test
                   TRIGGER_NAME: ins_sum
             EVENT_MANIPULATION: INSERT
           EVENT_OBJECT_CATALOG: def
            EVENT_OBJECT_SCHEMA: test
             EVENT_OBJECT_TABLE: account
                   ACTION_ORDER: 0
               ACTION_CONDITION: NULL
               ACTION_STATEMENT: SET @sum = @sum + NEW.amount
             ACTION_ORIENTATION: ROW
                  ACTION_TIMING: BEFORE
     ACTION_REFERENCE_OLD_TABLE: NULL
     ACTION_REFERENCE_NEW_TABLE: NULL
       ACTION_REFERENCE_OLD_ROW: OLD
       ACTION_REFERENCE_NEW_ROW: NEW
                        CREATED: NULL
                       SQL_MODE:
                        DEFINER: me@localhost
           CHARACTER_SET_CLIENT: utf8
           COLLATION_CONNECTION: utf8_general_ci
             DATABASE_COLLATION: latin1_swedish_ci

Trigger information is also available from the *note 'SHOW TRIGGERS':
show-triggers. statement.  See *note show-triggers::.


File: manual.info.tmp,  Node: user-privileges-table,  Next: views-table,  Prev: triggers-table,  Up: information-schema

21.27 The INFORMATION_SCHEMA USER_PRIVILEGES Table
==================================================

The *note 'USER_PRIVILEGES': user-privileges-table. table provides
information about global privileges.  It takes its values from the
'mysql.user' system table.

The *note 'USER_PRIVILEGES': user-privileges-table. table has these
columns:

   * 'GRANTEE'

     The name of the account to which the privilege is granted, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'TABLE_CATALOG'

     The name of the catalog.  This value is always 'def'.

   * 'PRIVILEGE_TYPE'

     The privilege granted.  The value can be any privilege that can be
     granted at the global level; see *note grant::.  Each row lists a
     single privilege, so there is one row per global privilege held by
     the grantee.

   * 'IS_GRANTABLE'

     'YES' if the user has the 'GRANT OPTION' privilege, 'NO' otherwise.
     The output does not list 'GRANT OPTION' as a separate row with
     'PRIVILEGE_TYPE='GRANT OPTION''.

*Notes*

   * The *note 'USER_PRIVILEGES': user-privileges-table. table is a
     nonstandard 'INFORMATION_SCHEMA' table.

The following statements are _not_ equivalent:

     SELECT ... FROM INFORMATION_SCHEMA.USER_PRIVILEGES

     SHOW GRANTS ...


File: manual.info.tmp,  Node: views-table,  Next: innodb-i_s-tables,  Prev: user-privileges-table,  Up: information-schema

21.28 The INFORMATION_SCHEMA VIEWS Table
========================================

The *note 'VIEWS': views-table. table provides information about views
in databases.  You must have the 'SHOW VIEW' privilege to access this
table.

The *note 'VIEWS': views-table. table has these columns:

   * 'TABLE_CATALOG'

     The name of the catalog to which the view belongs.  This value is
     always 'def'.

   * 'TABLE_SCHEMA'

     The name of the schema (database) to which the view belongs.

   * 'TABLE_NAME'

     The name of the view.

   * 'VIEW_DEFINITION'

     The *note 'SELECT': select. statement that provides the definition
     of the view.  This column has most of what you see in the 'Create
     Table' column that *note 'SHOW CREATE VIEW': show-create-view.
     produces.  Skip the words before *note 'SELECT': select. and skip
     the words 'WITH CHECK OPTION'.  Suppose that the original statement
     was:

          CREATE VIEW v AS
            SELECT s2,s1 FROM t
            WHERE s1 > 5
            ORDER BY s1
            WITH CHECK OPTION;

     Then the view definition looks like this:

          SELECT s2,s1 FROM t WHERE s1 > 5 ORDER BY s1

   * 'CHECK_OPTION'

     The value of the 'CHECK_OPTION' attribute.  The value is one of
     'NONE', 'CASCADE', or 'LOCAL'.

   * 'IS_UPDATABLE'

     MySQL sets a flag, called the view updatability flag, at *note
     'CREATE VIEW': create-view. time.  The flag is set to 'YES' (true)
     if *note 'UPDATE': update. and *note 'DELETE': delete. (and similar
     operations) are legal for the view.  Otherwise, the flag is set to
     'NO' (false).  The 'IS_UPDATABLE' column in the *note 'VIEWS':
     views-table. table displays the status of this flag.  It means that
     the server always knows whether a view is updatable.

     If a view is not updatable, statements such *note 'UPDATE': update,
     *note 'DELETE': delete, and *note 'INSERT': insert. are illegal and
     are rejected.  (Even if a view is updatable, it might not be
     possible to insert into it; for details, refer to *note
     view-updatability::.)

   * 'DEFINER'

     The account of the user who created the view, in
     ''USER_NAME'@'HOST_NAME'' format.

   * 'SECURITY_TYPE'

     The view 'SQL SECURITY' characteristic.  The value is one of
     'DEFINER' or 'INVOKER'.

   * 'CHARACTER_SET_CLIENT'

     The session value of the 'character_set_client' system variable
     when the view was created.

   * 'COLLATION_CONNECTION'

     The session value of the 'collation_connection' system variable
     when the view was created.

*Notes*

MySQL permits different 'sql_mode' settings to tell the server the type
of SQL syntax to support.  For example, you might use the 'ANSI' SQL
mode to ensure MySQL correctly interprets the standard SQL concatenation
operator, the double bar ('||'), in your queries.  If you then create a
view that concatenates items, you might worry that changing the
'sql_mode' setting to a value different from 'ANSI' could cause the view
to become invalid.  But this is not the case.  No matter how you write
out a view definition, MySQL always stores it the same way, in a
canonical form.  Here is an example that shows how the server changes a
double bar concatenation operator to a 'CONCAT()' function:

     mysql> SET sql_mode = 'ANSI';
     Query OK, 0 rows affected (0.00 sec)

     mysql> CREATE VIEW test.v AS SELECT 'a' || 'b' as col1;
     Query OK, 0 rows affected (0.00 sec)

     mysql> SELECT VIEW_DEFINITION FROM INFORMATION_SCHEMA.VIEWS
            WHERE TABLE_SCHEMA = 'test' AND TABLE_NAME = 'v';
     +----------------------------------+
     | VIEW_DEFINITION                  |
     +----------------------------------+
     | select concat('a','b') AS `col1` |
     +----------------------------------+
     1 row in set (0.00 sec)

The advantage of storing a view definition in canonical form is that
changes made later to the value of 'sql_mode' do not affect the results
from the view.  However, an additional consequence is that comments
prior to *note 'SELECT': select. are stripped from the definition by the
server.


File: manual.info.tmp,  Node: innodb-i_s-tables,  Next: mysql-cluster-i_s-tables,  Prev: views-table,  Up: information-schema

21.29 INFORMATION_SCHEMA InnoDB Tables
======================================

* Menu:

* innodb-buffer-page-table::     The INFORMATION_SCHEMA INNODB_BUFFER_PAGE Table
* innodb-buffer-page-lru-table::  The INFORMATION_SCHEMA INNODB_BUFFER_PAGE_LRU Table
* innodb-buffer-pool-stats-table::  The INFORMATION_SCHEMA INNODB_BUFFER_POOL_STATS Table
* innodb-cmp-table::             The INFORMATION_SCHEMA INNODB_CMP and INNODB_CMP_RESET Tables
* innodb-cmpmem-table::          The INFORMATION_SCHEMA INNODB_CMPMEM and INNODB_CMPMEM_RESET Tables
* innodb-locks-table::           The INFORMATION_SCHEMA INNODB_LOCKS Table
* innodb-lock-waits-table::      The INFORMATION_SCHEMA INNODB_LOCK_WAITS Table
* innodb-trx-table::             The INFORMATION_SCHEMA INNODB_TRX Table

This section provides table definitions for 'InnoDB'
'INFORMATION_SCHEMA' tables.  For related information and examples, see
*note innodb-information-schema::.

'InnoDB' 'INFORMATION_SCHEMA' tables can be used to monitor ongoing
'InnoDB' activity, to detect inefficiencies before they turn into
issues, or to troubleshoot performance and capacity issues.  As your
database becomes bigger and busier, running up against the limits of
your hardware capacity, you monitor and tune these aspects to keep the
database running smoothly.


File: manual.info.tmp,  Node: innodb-buffer-page-table,  Next: innodb-buffer-page-lru-table,  Prev: innodb-i_s-tables,  Up: innodb-i_s-tables

21.29.1 The INFORMATION_SCHEMA INNODB_BUFFER_PAGE Table
-------------------------------------------------------

The *note 'INNODB_BUFFER_PAGE': innodb-buffer-page-table. table provides
information about each page in the 'InnoDB' buffer pool.

For related usage information and examples, see *note
innodb-information-schema-buffer-pool-tables::.

*Warning*:

Querying the *note 'INNODB_BUFFER_PAGE': innodb-buffer-page-table. table
can affect performance.  Do not query this table on a production system
unless you are aware of the performance impact and have determined it to
be acceptable.  To avoid impacting performance on a production system,
reproduce the issue you want to investigate and query buffer pool
statistics on a test instance.

The *note 'INNODB_BUFFER_PAGE': innodb-buffer-page-table. table has
these columns:

   * 'POOL_ID'

     The buffer pool ID. This is an identifier to distinguish between
     multiple buffer pool instances.

   * 'BLOCK_ID'

     The buffer pool block ID.

   * 'SPACE'

     The tablespace ID.

   * 'PAGE_NUMBER'

     The page number.

   * 'PAGE_TYPE'

     The page type.  The following table shows the permitted values.

     *INNODB_BUFFER_PAGE.PAGE_TYPE Values*

     Page Type              Description
                            
     'ALLOCATED'            Freshly allocated
                            page
                            
     'BLOB'                 Uncompressed BLOB
                            page
                            
     'COMPRESSED_BLOB2'     Subsequent comp BLOB
                            page
                            
     'COMPRESSED_BLOB'      First compressed
                            BLOB page
                            
     'EXTENT_DESCRIPTOR'    Extent descriptor
                            page
                            
     'FILE_SPACE_HEADER'    File space header
                            
     'IBUF_BITMAP'          Insert buffer bitmap
                            
     'IBUF_FREE_LIST'       Insert buffer free
                            list
                            
     'IBUF_INDEX'           Insert buffer index
                            
     'INDEX'                B-tree node
                            
     'INODE'                Index node
                            
     'SYSTEM'               System page
                            
     'TRX_SYSTEM'           Transaction system
                            data
                            
     'UNDO_LOG'             Undo log page
                            
     'UNKNOWN'              Unknown

   * 'FLUSH_TYPE'

     The flush type.

   * 'FIX_COUNT'

     The number of threads using this block within the buffer pool.
     When zero, the block is eligible to be evicted.

   * 'IS_HASHED'

     Whether a hash index has been built on this page.

   * 'NEWEST_MODIFICATION'

     The Log Sequence Number of the youngest modification.

   * 'OLDEST_MODIFICATION'

     The Log Sequence Number of the oldest modification.

   * 'ACCESS_TIME'

     An abstract number used to judge the first access time of the page.

   * 'TABLE_NAME'

     The name of the table the page belongs to.  This column is
     applicable only to pages with a 'PAGE_TYPE' value of 'INDEX'.

   * 'INDEX_NAME'

     The name of the index the page belongs to.  This can be the name of
     a clustered index or a secondary index.  This column is applicable
     only to pages with a 'PAGE_TYPE' value of 'INDEX'.

   * 'NUMBER_RECORDS'

     The number of records within the page.

   * 'DATA_SIZE'

     The sum of the sizes of the records.  This column is applicable
     only to pages with a 'PAGE_TYPE' value of 'INDEX'.

   * 'COMPRESSED_SIZE'

     The compressed page size.  'NULL' for pages that are not
     compressed.

   * 'PAGE_STATE'

     The page state.  The following table shows the permitted values.

     *INNODB_BUFFER_PAGE.PAGE_STATE Values*

     Page State         Description
                        
     'FILE_PAGE'        A buffered file page
                        
     'MEMORY'           Contains a main memory object
                        
     'NOT_USED'         In the free list
                        
     'NULL'             Clean compressed pages, compressed pages in the
                        flush list, pages used as buffer pool watch
                        sentinels
                        
     'READY_FOR_USE'    A free page
                        
     'REMOVE_HASH'      Hash index should be removed before placing in the
                        free list

   * 'IO_FIX'

     Whether any I/O is pending for this page: 'IO_NONE' = no pending
     I/O, 'IO_READ' = read pending, 'IO_WRITE' = write pending.

   * 'IS_OLD'

     Whether the block is in the sublist of old blocks in the LRU list.

   * 'FREE_PAGE_CLOCK'

     The value of the 'freed_page_clock' counter when the block was the
     last placed at the head of the LRU list.  The 'freed_page_clock'
     counter tracks the number of blocks removed from the end of the LRU
     list.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_BUFFER_PAGE WHERE BLOCK_ID=9\G
     *************************** 1. row ***************************
                 POOL_ID: 0
                BLOCK_ID: 9
                   SPACE: 0
             PAGE_NUMBER: 8019
               PAGE_TYPE: INDEX
              FLUSH_TYPE: 2
               FIX_COUNT: 0
               IS_HASHED: YES
     NEWEST_MODIFICATION: 226918754
     OLDEST_MODIFICATION: 0
             ACCESS_TIME: 3376847655
              TABLE_NAME: employees/salaries
              INDEX_NAME: PRIMARY
          NUMBER_RECORDS: 468
               DATA_SIZE: 14976
         COMPRESSED_SIZE: 0
              PAGE_STATE: FILE_PAGE
                  IO_FIX: IO_NONE
                  IS_OLD: YES
         FREE_PAGE_CLOCK: 8

*Notes*

   * This table is useful primarily for expert-level performance
     monitoring, or when developing performance-related extensions for
     MySQL.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.

   * When tables, table rows, partitions, or indexes are deleted,
     associated pages remain in the buffer pool until space is required
     for other data.  The *note 'INNODB_BUFFER_PAGE':
     innodb-buffer-page-table. table reports information about these
     pages until they are evicted from the buffer pool.  For more
     information about how the 'InnoDB' manages buffer pool data, see
     *note innodb-buffer-pool::.


File: manual.info.tmp,  Node: innodb-buffer-page-lru-table,  Next: innodb-buffer-pool-stats-table,  Prev: innodb-buffer-page-table,  Up: innodb-i_s-tables

21.29.2 The INFORMATION_SCHEMA INNODB_BUFFER_PAGE_LRU Table
-----------------------------------------------------------

The *note 'INNODB_BUFFER_PAGE_LRU': innodb-buffer-page-lru-table. table
provides information about the pages in the 'InnoDB' buffer pool; in
particular, how they are ordered in the LRU list that determines which
pages to evict from the buffer pool when it becomes full.

The *note 'INNODB_BUFFER_PAGE_LRU': innodb-buffer-page-lru-table. table
has the same columns as the *note 'INNODB_BUFFER_PAGE':
innodb-buffer-page-table. table, except that the *note
'INNODB_BUFFER_PAGE_LRU': innodb-buffer-page-lru-table. table has
'LRU_POSITION' and 'COMPRESSED' columns instead of 'BLOCK_ID' and
'PAGE_STATE' columns.

For related usage information and examples, see *note
innodb-information-schema-buffer-pool-tables::.

*Warning*:

Querying the *note 'INNODB_BUFFER_PAGE_LRU':
innodb-buffer-page-lru-table. table can affect performance.  Do not
query this table on a production system unless you are aware of the
performance impact and have determined it to be acceptable.  To avoid
impacting performance on a production system, reproduce the issue you
want to investigate and query buffer pool statistics on a test instance.

The *note 'INNODB_BUFFER_PAGE_LRU': innodb-buffer-page-lru-table. table
has these columns:

   * 'POOL_ID'

     The buffer pool ID. This is an identifier to distinguish between
     multiple buffer pool instances.

   * 'LRU_POSITION'

     The position of the page in the LRU list.

   * 'SPACE'

     The tablespace ID.

   * 'PAGE_NUMBER'

     The page number.

   * 'PAGE_TYPE'

     The page type.  The following table shows the permitted values.

     *INNODB_BUFFER_PAGE_LRU.PAGE_TYPE Values*

     Page Type              Description
                            
     'ALLOCATED'            Freshly allocated
                            page
                            
     'BLOB'                 Uncompressed BLOB
                            page
                            
     'COMPRESSED_BLOB2'     Subsequent comp BLOB
                            page
                            
     'COMPRESSED_BLOB'      First compressed
                            BLOB page
                            
     'EXTENT_DESCRIPTOR'    Extent descriptor
                            page
                            
     'FILE_SPACE_HEADER'    File space header
                            
     'IBUF_BITMAP'          Insert buffer bitmap
                            
     'IBUF_FREE_LIST'       Insert buffer free
                            list
                            
     'IBUF_INDEX'           Insert buffer index
                            
     'INDEX'                B-tree node
                            
     'INODE'                Index node
                            
     'SYSTEM'               System page
                            
     'TRX_SYSTEM'           Transaction system
                            data
                            
     'UNDO_LOG'             Undo log page
                            
     'UNKNOWN'              Unknown

   * 'FLUSH_TYPE'

     The flush type.

   * 'FIX_COUNT'

     The number of threads using this block within the buffer pool.
     When zero, the block is eligible to be evicted.

   * 'IS_HASHED'

     Whether a hash index has been built on this page.

   * 'NEWEST_MODIFICATION'

     The Log Sequence Number of the youngest modification.

   * 'OLDEST_MODIFICATION'

     The Log Sequence Number of the oldest modification.

   * 'ACCESS_TIME'

     An abstract number used to judge the first access time of the page.

   * 'TABLE_NAME'

     The name of the table the page belongs to.  This column is
     applicable only to pages with a 'PAGE_TYPE' value of 'INDEX'.

   * 'INDEX_NAME'

     The name of the index the page belongs to.  This can be the name of
     a clustered index or a secondary index.  This column is applicable
     only to pages with a 'PAGE_TYPE' value of 'INDEX'.

   * 'NUMBER_RECORDS'

     The number of records within the page.

   * 'DATA_SIZE'

     The sum of the sizes of the records.  This column is applicable
     only to pages with a 'PAGE_TYPE' value of 'INDEX'.

   * 'COMPRESSED_SIZE'

     The compressed page size.  'NULL' for pages that are not
     compressed.

   * 'COMPRESSED'

     Whether the page is compressed.

   * 'IO_FIX'

     Whether any I/O is pending for this page: 'IO_NONE' = no pending
     I/O, 'IO_READ' = read pending, 'IO_WRITE' = write pending.

   * 'IS_OLD'

     Whether the block is in the sublist of old blocks in the LRU list.

   * 'FREE_PAGE_CLOCK'

     The value of the 'freed_page_clock' counter when the block was the
     last placed at the head of the LRU list.  The 'freed_page_clock'
     counter tracks the number of blocks removed from the end of the LRU
     list.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_BUFFER_PAGE_LRU LIMIT 1\G
     *************************** 1. row ***************************
                 POOL_ID: 0
            LRU_POSITION: 0
                   SPACE: 0
             PAGE_NUMBER: 7485
               PAGE_TYPE: INDEX
              FLUSH_TYPE: 2
               FIX_COUNT: 0
               IS_HASHED: YES
     NEWEST_MODIFICATION: 216319316
     OLDEST_MODIFICATION: 0
             ACCESS_TIME: 3376846384
              TABLE_NAME: employees/salaries
              INDEX_NAME: emp_no
          NUMBER_RECORDS: 1300
               DATA_SIZE: 15600
         COMPRESSED_SIZE: 0
              COMPRESSED: NO
                  IO_FIX: IO_NONE
                  IS_OLD: YES
         FREE_PAGE_CLOCK: 0

*Notes*

   * This table is useful primarily for expert-level performance
     monitoring, or when developing performance-related extensions for
     MySQL.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.

   * Querying this table can require MySQL to allocate a large block of
     contiguous memory, more than 64 bytes times the number of active
     pages in the buffer pool.  This allocation could potentially cause
     an out-of-memory error, especially for systems with multi-gigabyte
     buffer pools.

   * Querying this table requires MySQL to lock the data structure
     representing the buffer pool while traversing the LRU list, which
     can reduce concurrency, especially for systems with multi-gigabyte
     buffer pools.

   * When tables, table rows, partitions, or indexes are deleted,
     associated pages remain in the buffer pool until space is required
     for other data.  The *note 'INNODB_BUFFER_PAGE_LRU':
     innodb-buffer-page-lru-table. table reports information about these
     pages until they are evicted from the buffer pool.  For more
     information about how the 'InnoDB' manages buffer pool data, see
     *note innodb-buffer-pool::.


File: manual.info.tmp,  Node: innodb-buffer-pool-stats-table,  Next: innodb-cmp-table,  Prev: innodb-buffer-page-lru-table,  Up: innodb-i_s-tables

21.29.3 The INFORMATION_SCHEMA INNODB_BUFFER_POOL_STATS Table
-------------------------------------------------------------

The *note 'INNODB_BUFFER_POOL_STATS': innodb-buffer-pool-stats-table.
table provides much of the same buffer pool information provided in
*note 'SHOW ENGINE INNODB STATUS': show-engine. output.  Much of the
same information may also be obtained using 'InnoDB' buffer pool *note
server status variables: server-status-variables.

The idea of making pages in the buffer pool 'young' or 'not young'
refers to transferring them between the sublists at the head and tail of
the buffer pool data structure.  Pages made 'young' take longer to age
out of the buffer pool, while pages made 'not young' are moved much
closer to the point of eviction.

For related usage information and examples, see *note
innodb-information-schema-buffer-pool-tables::.

The *note 'INNODB_BUFFER_POOL_STATS': innodb-buffer-pool-stats-table.
table has these columns:

   * 'POOL_ID'

     The buffer pool ID. This is an identifier to distinguish between
     multiple buffer pool instances.

   * 'POOL_SIZE'

     The 'InnoDB' buffer pool size in pages.

   * 'FREE_BUFFERS'

     The number of free pages in the 'InnoDB' buffer pool.

   * 'DATABASE_PAGES'

     The number of pages in the 'InnoDB' buffer pool containing data.
     This number includes both dirty and clean pages.

   * 'OLD_DATABASE_PAGES'

     The number of pages in the 'old' buffer pool sublist.

   * 'MODIFIED_DATABASE_PAGES'

     The number of modified (dirty) database pages.

   * 'PENDING_DECOMPRESS'

     The number of pages pending decompression.

   * 'PENDING_READS'

     The number of pending reads.

   * 'PENDING_FLUSH_LRU'

     The number of pages pending flush in the LRU.

   * 'PENDING_FLUSH_LIST'

     The number of pages pending flush in the flush list.

   * 'PAGES_MADE_YOUNG'

     The number of pages made young.

   * 'PAGES_NOT_MADE_YOUNG'

     The number of pages not made young.

   * 'PAGES_MADE_YOUNG_RATE'

     The number of pages made young per second (pages made young since
     the last printout / time elapsed).

   * 'PAGES_MADE_NOT_YOUNG_RATE'

     The number of pages not made per second (pages not made young since
     the last printout / time elapsed).

   * 'NUMBER_PAGES_READ'

     The number of pages read.

   * 'NUMBER_PAGES_CREATED'

     The number of pages created.

   * 'NUMBER_PAGES_WRITTEN'

     The number of pages written.

   * 'PAGES_READ_RATE'

     The number of pages read per second (pages read since the last
     printout / time elapsed).

   * 'PAGES_CREATE_RATE'

     The number of pages created per second (pages created since the
     last printout / time elapsed).

   * 'PAGES_WRITTEN_RATE'

     The number of pages written per second (pages written since the
     last printout / time elapsed).

   * 'NUMBER_PAGES_GET'

     The number of logical read requests.

   * 'HIT_RATE'

     The buffer pool hit rate.

   * 'YOUNG_MAKE_PER_THOUSAND_GETS'

     The number of pages made young per thousand gets.

   * 'NOT_YOUNG_MAKE_PER_THOUSAND_GETS'

     The number of pages not made young per thousand gets.

   * 'NUMBER_PAGES_READ_AHEAD'

     The number of pages read ahead.

   * 'NUMBER_READ_AHEAD_EVICTED'

     The number of pages read into the 'InnoDB' buffer pool by the
     read-ahead background thread that were subsequently evicted without
     having been accessed by queries.

   * 'READ_AHEAD_RATE'

     The read-ahead rate per second (pages read ahead since the last
     printout / time elapsed).

   * 'READ_AHEAD_EVICTED_RATE'

     The number of read-ahead pages evicted without access per second
     (read-ahead pages not accessed since the last printout / time
     elapsed).

   * 'LRU_IO_TOTAL'

     Total LRU I/O.

   * 'LRU_IO_CURRENT'

     LRU I/O for the current interval.

   * 'UNCOMPRESS_TOTAL'

     The total number of pages decompressed.

   * 'UNCOMPRESS_CURRENT'

     The number of pages decompressed in the current interval.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_BUFFER_POOL_STATS\G
     *************************** 1. row ***************************
                              POOL_ID: 0
                            POOL_SIZE: 8192
                         FREE_BUFFERS: 0
                       DATABASE_PAGES: 8014
                   OLD_DATABASE_PAGES: 2938
              MODIFIED_DATABASE_PAGES: 0
                   PENDING_DECOMPRESS: 0
                        PENDING_READS: 0
                    PENDING_FLUSH_LRU: 0
                   PENDING_FLUSH_LIST: 0
                     PAGES_MADE_YOUNG: 7380
                 PAGES_NOT_MADE_YOUNG: 0
                PAGES_MADE_YOUNG_RATE: 0
            PAGES_MADE_NOT_YOUNG_RATE: 0
                    NUMBER_PAGES_READ: 2723
                 NUMBER_PAGES_CREATED: 12657
                 NUMBER_PAGES_WRITTEN: 16181
                      PAGES_READ_RATE: 0
                    PAGES_CREATE_RATE: 0
                   PAGES_WRITTEN_RATE: 0
                     NUMBER_PAGES_GET: 28952710
                             HIT_RATE: 1000
         YOUNG_MAKE_PER_THOUSAND_GETS: 0
     NOT_YOUNG_MAKE_PER_THOUSAND_GETS: 0
              NUMBER_PAGES_READ_AHEAD: 2469
            NUMBER_READ_AHEAD_EVICTED: 0
                      READ_AHEAD_RATE: 0
              READ_AHEAD_EVICTED_RATE: 0
                         LRU_IO_TOTAL: 0
                       LRU_IO_CURRENT: 0
                     UNCOMPRESS_TOTAL: 0
                   UNCOMPRESS_CURRENT: 0

*Notes*

   * This table is useful primarily for expert-level performance
     monitoring, or when developing performance-related extensions for
     MySQL.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.


File: manual.info.tmp,  Node: innodb-cmp-table,  Next: innodb-cmpmem-table,  Prev: innodb-buffer-pool-stats-table,  Up: innodb-i_s-tables

21.29.4 The INFORMATION_SCHEMA INNODB_CMP and INNODB_CMP_RESET Tables
---------------------------------------------------------------------

The *note 'INNODB_CMP': innodb-cmp-table. and *note 'INNODB_CMP_RESET':
innodb-cmp-table. tables provide status information on operations
related to compressed 'InnoDB' tables.

The *note 'INNODB_CMP': innodb-cmp-table. and *note 'INNODB_CMP_RESET':
innodb-cmp-table. tables have these columns:

   * 'PAGE_SIZE'

     The compressed page size in bytes.

   * 'COMPRESS_OPS'

     The number of times a B-tree page of size 'PAGE_SIZE' has been
     compressed.  Pages are compressed whenever an empty page is created
     or the space for the uncompressed modification log runs out.

   * 'COMPRESS_OPS_OK'

     The number of times a B-tree page of size 'PAGE_SIZE' has been
     successfully compressed.  This count should never exceed
     'COMPRESS_OPS'.

   * 'COMPRESS_TIME'

     The total time in seconds used for attempts to compress B-tree
     pages of size 'PAGE_SIZE'.

   * 'UNCOMPRESS_OPS'

     The number of times a B-tree page of size 'PAGE_SIZE' has been
     uncompressed.  B-tree pages are uncompressed whenever compression
     fails or at first access when the uncompressed page does not exist
     in the buffer pool.

   * 'UNCOMPRESS_TIME'

     The total time in seconds used for uncompressing B-tree pages of
     the size 'PAGE_SIZE'.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_CMP\G
     *************************** 1. row ***************************
           page_size: 1024
        compress_ops: 0
     compress_ops_ok: 0
       compress_time: 0
      uncompress_ops: 0
     uncompress_time: 0
     *************************** 2. row ***************************
           page_size: 2048
        compress_ops: 0
     compress_ops_ok: 0
       compress_time: 0
      uncompress_ops: 0
     uncompress_time: 0
     *************************** 3. row ***************************
           page_size: 4096
        compress_ops: 0
     compress_ops_ok: 0
       compress_time: 0
      uncompress_ops: 0
     uncompress_time: 0
     *************************** 4. row ***************************
           page_size: 8192
        compress_ops: 199755
     compress_ops_ok: 112015
       compress_time: 83
      uncompress_ops: 74253
     uncompress_time: 13
     *************************** 5. row ***************************
           page_size: 16384
        compress_ops: 0
     compress_ops_ok: 0
       compress_time: 0
      uncompress_ops: 0
     uncompress_time: 0

*Notes*

   * Use these tables to measure the effectiveness of 'InnoDB' table
     compression in your database.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.

   * For usage information, see *note
     innodb-information-schema-examples-compression-sect::.


File: manual.info.tmp,  Node: innodb-cmpmem-table,  Next: innodb-locks-table,  Prev: innodb-cmp-table,  Up: innodb-i_s-tables

21.29.5 The INFORMATION_SCHEMA INNODB_CMPMEM and INNODB_CMPMEM_RESET Tables
---------------------------------------------------------------------------

The *note 'INNODB_CMPMEM': innodb-cmpmem-table. and *note
'INNODB_CMPMEM_RESET': innodb-cmpmem-table. tables provide status
information on compressed pages within the 'InnoDB' buffer pool.

The *note 'INNODB_CMPMEM': innodb-cmpmem-table. and *note
'INNODB_CMPMEM_RESET': innodb-cmpmem-table. tables have these columns:

   * 'PAGE_SIZE'

     The block size in bytes.  Each record of this table describes
     blocks of this size.

   * 'BUFFER_POOL_INSTANCE'

     A unique identifier for the buffer pool instance.

   * 'PAGES_USED'

     The number of blocks of size 'PAGE_SIZE' that are currently in use.

   * 'PAGES_FREE'

     The number of blocks of size 'PAGE_SIZE' that are currently
     available for allocation.  This column shows the external
     fragmentation in the memory pool.  Ideally, these numbers should be
     at most 1.

   * 'RELOCATION_OPS'

     The number of times a block of size 'PAGE_SIZE' has been relocated.
     The buddy system can relocate the allocated 'buddy neighbor' of a
     freed block when it tries to form a bigger freed block.  Reading
     from the *note 'INNODB_CMPMEM_RESET': innodb-cmpmem-table. table
     resets this count.

   * 'RELOCATION_TIME'

     The total time in microseconds used for relocating blocks of size
     'PAGE_SIZE'.  Reading from the table 'INNODB_CMPMEM_RESET' resets
     this count.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_CMPMEM\G
     *************************** 1. row ***************************
                page_size: 1024
     buffer_pool_instance: 0
               pages_used: 0
               pages_free: 0
           relocation_ops: 0
          relocation_time: 0
     *************************** 2. row ***************************
                page_size: 2048
     buffer_pool_instance: 0
               pages_used: 0
               pages_free: 0
           relocation_ops: 0
          relocation_time: 0
     *************************** 3. row ***************************
                page_size: 4096
     buffer_pool_instance: 0
               pages_used: 0
               pages_free: 0
           relocation_ops: 0
          relocation_time: 0
     *************************** 4. row ***************************
                page_size: 8192
     buffer_pool_instance: 0
               pages_used: 9043
               pages_free: 1
           relocation_ops: 2457
          relocation_time: 0
     *************************** 5. row ***************************
                page_size: 16384
     buffer_pool_instance: 0
               pages_used: 0
               pages_free: 0
           relocation_ops: 0
          relocation_time: 0

*Notes*

   * Use these tables to measure the effectiveness of 'InnoDB' table
     compression in your database.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.

   * For usage information, see *note
     innodb-information-schema-examples-compression-sect::.


File: manual.info.tmp,  Node: innodb-locks-table,  Next: innodb-lock-waits-table,  Prev: innodb-cmpmem-table,  Up: innodb-i_s-tables

21.29.6 The INFORMATION_SCHEMA INNODB_LOCKS Table
-------------------------------------------------

The *note 'INNODB_LOCKS': innodb-locks-table. table provides information
about each lock that an 'InnoDB' transaction has requested but not yet
acquired, and each lock that a transaction holds that is blocking
another transaction.

The *note 'INNODB_LOCKS': innodb-locks-table. table has these columns:

   * 'LOCK_ID'

     A unique lock ID number, internal to 'InnoDB'.  Treat it as an
     opaque string.  Although 'LOCK_ID' currently contains 'TRX_ID', the
     format of the data in 'LOCK_ID' is subject to change at any time.
     Do not write applications that parse the 'LOCK_ID' value.

   * 'LOCK_TRX_ID'

     The ID of the transaction holding the lock.  To obtain details
     about the transaction, join this column with the 'TRX_ID' column of
     the *note 'INNODB_TRX': innodb-trx-table. table.

   * 'LOCK_MODE'

     How the lock is requested.  Permitted lock mode descriptors are
     'S', 'X', 'IS', 'IX', 'GAP', 'AUTO_INC', and 'UNKNOWN'.  Lock mode
     descriptors may be used in combination to identify particular lock
     modes.  For information about 'InnoDB' lock modes, see *note
     innodb-locking::.

   * 'LOCK_TYPE'

     The type of lock.  Permitted values are 'RECORD' for a row-level
     lock, 'TABLE' for a table-level lock.

   * 'LOCK_TABLE'

     The name of the table that has been locked or contains locked
     records.

   * 'LOCK_INDEX'

     The name of the index, if 'LOCK_TYPE' is 'RECORD'; otherwise
     'NULL'.

   * 'LOCK_SPACE'

     The tablespace ID of the locked record, if 'LOCK_TYPE' is 'RECORD';
     otherwise 'NULL'.

   * 'LOCK_PAGE'

     The page number of the locked record, if 'LOCK_TYPE' is 'RECORD';
     otherwise 'NULL'.

   * 'LOCK_REC'

     The heap number of the locked record within the page, if
     'LOCK_TYPE' is 'RECORD'; otherwise 'NULL'.

   * 'LOCK_DATA'

     The data associated with the lock, if any.  A value is shown if the
     'LOCK_TYPE' is 'RECORD', otherwise the value is 'NULL'.  Primary
     key values of the locked record are shown for a lock placed on the
     primary key index.  Secondary index values of the locked record are
     shown for a lock placed on a unique secondary index.  Secondary
     index values are shown with primary key values appended if the
     secondary index is not unique.  If there is no primary key,
     'LOCK_DATA' shows either the key values of a selected unique index
     or the unique 'InnoDB' internal row ID number, according to the
     rules governing 'InnoDB' clustered index use (see *note
     innodb-index-types::).  'LOCK_DATA' reports 'supremum
     pseudo-record' for a lock taken on a supremum pseudo-record.  If
     the page containing the locked record is not in the buffer pool
     because it was written to disk while the lock was held, 'InnoDB'
     does not fetch the page from disk.  Instead, 'LOCK_DATA' reports
     'NULL'.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS\G
     *************************** 1. row ***************************
         lock_id: 3723:72:3:2
     lock_trx_id: 3723
       lock_mode: X
       lock_type: RECORD
      lock_table: `mysql`.`t`
      lock_index: PRIMARY
      lock_space: 72
       lock_page: 3
        lock_rec: 2
       lock_data: 1, 9
     *************************** 2. row ***************************
         lock_id: 3722:72:3:2
     lock_trx_id: 3722
       lock_mode: S
       lock_type: RECORD
      lock_table: `mysql`.`t`
      lock_index: PRIMARY
      lock_space: 72
       lock_page: 3
        lock_rec: 2
       lock_data: 1, 9

*Notes*

   * Use this table to help diagnose performance problems that occur
     during times of heavy concurrent load.  Its contents are updated as
     described in *note innodb-information-schema-internal-data::.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.

   * For usage information, see *note
     innodb-information-schema-examples::.


File: manual.info.tmp,  Node: innodb-lock-waits-table,  Next: innodb-trx-table,  Prev: innodb-locks-table,  Up: innodb-i_s-tables

21.29.7 The INFORMATION_SCHEMA INNODB_LOCK_WAITS Table
------------------------------------------------------

The *note 'INNODB_LOCK_WAITS': innodb-lock-waits-table. table contains
one or more rows for each blocked 'InnoDB' transaction, indicating the
lock it has requested and any locks that are blocking that request.

The *note 'INNODB_LOCK_WAITS': innodb-lock-waits-table. table has these
columns:

   * 'REQUESTING_TRX_ID'

     The ID of the requesting (blocked) transaction.

   * 'REQUESTED_LOCK_ID'

     The ID of the lock for which a transaction is waiting.  To obtain
     details about the lock, join this column with the 'LOCK_ID' column
     of the *note 'INNODB_LOCKS': innodb-locks-table. table.

   * 'BLOCKING_TRX_ID'

     The ID of the blocking transaction.

   * 'BLOCKING_LOCK_ID'

     The ID of a lock held by a transaction blocking another transaction
     from proceeding.  To obtain details about the lock, join this
     column with the 'LOCK_ID' column of the *note 'INNODB_LOCKS':
     innodb-locks-table. table.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS\G
     *************************** 1. row ***************************
     requesting_trx_id: 3B7
     requested_lock_id: 3B7:0:306:2
       blocking_trx_id: 3B6
      blocking_lock_id: 3B6:0:306:2

*Notes*

   * Use this table to help diagnose performance problems that occur
     during times of heavy concurrent load.  Its contents are updated as
     described in *note innodb-information-schema-internal-data::.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.

   * For usage information, see *note
     innodb-information-schema-examples::.


File: manual.info.tmp,  Node: innodb-trx-table,  Prev: innodb-lock-waits-table,  Up: innodb-i_s-tables

21.29.8 The INFORMATION_SCHEMA INNODB_TRX Table
-----------------------------------------------

The *note 'INNODB_TRX': innodb-trx-table. table provides information
about every transaction currently executing inside 'InnoDB', including
whether the transaction is waiting for a lock, when the transaction
started, and the SQL statement the transaction is executing, if any.

For usage information, see *note innodb-information-schema-examples::.

The *note 'INNODB_TRX': innodb-trx-table. table has these columns:

   * 'TRX_ID'

     A unique transaction ID number, internal to 'InnoDB'.  (Starting in
     MySQL 5.6, these IDs are not created for transactions that are read
     only and nonlocking.  See Optimizing InnoDB Read-Only Transactions
     (https://dev.mysql.com/doc/refman/5.6/en/innodb-performance-ro-txn.html)
     for details.)

   * 'TRX_WEIGHT'

     The weight of a transaction, reflecting (but not necessarily the
     exact count of) the number of rows altered and the number of rows
     locked by the transaction.  To resolve a deadlock, 'InnoDB' selects
     the transaction with the smallest weight as the 'victim' to roll
     back.  Transactions that have changed nontransactional tables are
     considered heavier than others, regardless of the number of altered
     and locked rows.

   * 'TRX_STATE'

     The transaction execution state.  Permitted values are 'RUNNING',
     'LOCK WAIT', 'ROLLING BACK', and 'COMMITTING'.

   * 'TRX_STARTED'

     The transaction start time.

   * 'TRX_REQUESTED_LOCK_ID'

     The ID of the lock the transaction is currently waiting for, if
     'TRX_STATE' is 'LOCK WAIT'; otherwise 'NULL'.  To obtain details
     about the lock, join this column with the 'LOCK_ID' column of the
     *note 'INNODB_LOCKS': innodb-locks-table. table.

   * 'TRX_WAIT_STARTED'

     The time when the transaction started waiting on the lock, if
     'TRX_STATE' is 'LOCK WAIT'; otherwise 'NULL'.

   * 'TRX_MYSQL_THREAD_ID'

     The MySQL thread ID. To obtain details about the thread, join this
     column with the 'ID' column of the 'INFORMATION_SCHEMA' *note
     'PROCESSLIST': processlist-table. table, but see *note
     innodb-information-schema-internal-data::.

   * 'TRX_QUERY'

     The SQL statement that is being executed by the transaction.

   * 'TRX_OPERATION_STATE'

     The transaction's current operation, if any; otherwise 'NULL'.

   * 'TRX_TABLES_IN_USE'

     The number of 'InnoDB' tables used while processing the current SQL
     statement of this transaction.

   * 'TRX_TABLES_LOCKED'

     The number of 'InnoDB' tables that the current SQL statement has
     row locks on.  (Because these are row locks, not table locks, the
     tables can usually still be read from and written to by multiple
     transactions, despite some rows being locked.)

   * 'TRX_LOCK_STRUCTS'

     The number of locks reserved by the transaction.

   * 'TRX_LOCK_MEMORY_BYTES'

     The total size taken up by the lock structures of this transaction
     in memory.

   * 'TRX_ROWS_LOCKED'

     The approximate number or rows locked by this transaction.  The
     value might include delete-marked rows that are physically present
     but not visible to the transaction.

   * 'TRX_ROWS_MODIFIED'

     The number of modified and inserted rows in this transaction.

   * 'TRX_CONCURRENCY_TICKETS'

     A value indicating how much work the current transaction can do
     before being swapped out, as specified by the
     'innodb_concurrency_tickets' system variable.

   * 'TRX_ISOLATION_LEVEL'

     The isolation level of the current transaction.

   * 'TRX_UNIQUE_CHECKS'

     Whether unique checks are turned on or off for the current
     transaction.  For example, they might be turned off during a bulk
     data load.

   * 'TRX_FOREIGN_KEY_CHECKS'

     Whether foreign key checks are turned on or off for the current
     transaction.  For example, they might be turned off during a bulk
     data load.

   * 'TRX_LAST_FOREIGN_KEY_ERROR'

     The detailed error message for the last foreign key error, if any;
     otherwise 'NULL'.

   * 'TRX_ADAPTIVE_HASH_LATCHED'

     Whether the adaptive hash index is locked by the current
     transaction.  (Only a single transaction at a time can modify the
     adaptive hash index.)

   * 'TRX_ADAPTIVE_HASH_TIMEOUT'

     Whether to relinquish the search latch immediately for the adaptive
     hash index, or reserve it across calls from MySQL. When there is no
     adaptive hash index contention, this value remains zero and
     statements reserve the latch until they finish.  During times of
     contention, it counts down to zero, and statements release the
     latch immediately after each row lookup.

*Example*

     mysql> SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX\G
     *************************** 1. row ***************************
                         trx_id: 3B7
                      trx_state: RUNNING
                    trx_started: 2014-11-19 14:33:45
          trx_requested_lock_id: NULL
               trx_wait_started: NULL
                     trx_weight: 1
            trx_mysql_thread_id: 2
                      trx_query: SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX
            trx_operation_state: NULL
              trx_tables_in_use: 0
              trx_tables_locked: 0
               trx_lock_structs: 1
          trx_lock_memory_bytes: 376
                trx_rows_locked: 0
              trx_rows_modified: 0
        trx_concurrency_tickets: 0
            trx_isolation_level: REPEATABLE READ
              trx_unique_checks: 1
         trx_foreign_key_checks: 1
     trx_last_foreign_key_error: NULL
      trx_adaptive_hash_latched: 0
      trx_adaptive_hash_timeout: 10000
     *************************** 2. row ***************************
                         trx_id: 3B6
                      trx_state: RUNNING
                    trx_started: 2014-11-19 14:32:38
          trx_requested_lock_id: NULL
               trx_wait_started: NULL
                     trx_weight: 94055
            trx_mysql_thread_id: 1
                      trx_query: DELETE FROM employees.salaries WHERE salary > 75000
            trx_operation_state: updating or deleting
              trx_tables_in_use: 1
              trx_tables_locked: 1
               trx_lock_structs: 841
          trx_lock_memory_bytes: 129464
                trx_rows_locked: 392752
              trx_rows_modified: 93214
        trx_concurrency_tickets: 0
            trx_isolation_level: REPEATABLE READ
              trx_unique_checks: 1
         trx_foreign_key_checks: 1
     trx_last_foreign_key_error: NULL
      trx_adaptive_hash_latched: 0
      trx_adaptive_hash_timeout: 10000

*Notes*

   * Use this table to help diagnose performance problems that occur
     during times of heavy concurrent load.  Its contents are updated as
     described in *note innodb-information-schema-internal-data::.

   * You must have the 'PROCESS' privilege to query this table.

   * Use the 'INFORMATION_SCHEMA' *note 'COLUMNS': columns-table. table
     or the *note 'SHOW COLUMNS': show-columns. statement to view
     additional information about the columns of this table, including
     data types and default values.


File: manual.info.tmp,  Node: mysql-cluster-i_s-tables,  Next: thread-pool-i_s-tables,  Prev: innodb-i_s-tables,  Up: information-schema

21.30 INFORMATION_SCHEMA NDB Cluster Tables
===========================================

* Menu:

* files-table::                  The INFORMATION_SCHEMA FILES Table
* ndb-transid-mysql-connection-map-table::  The INFORMATION_SCHEMA ndb_transid_mysql_connection_map Table

The following sections provide information about 'INFORMATION_SCHEMA'
tables which are specific to NDB Cluster.  The *note 'FILES':
files-table. table was added in MySQL Server 5.1 as part of NDB Cluster
data-on-disk support (it is available in standard MySQL 5.5 but is not
used there).  The *note 'ndb_transid_mysql_connection_map':
ndb-transid-mysql-connection-map-table. table was added as part of
additions made to NDB Cluster's *note 'ndbinfo': mysql-cluster-ndbinfo.
information database in MySQL NDB Cluster 7.2.2; it is implemented as an
'INFORMATION_SCHEMA' plugin available only in NDB Cluster binaries or
source, and does not exist in MySQL Server 5.5.

Additional statistical and other data about NDB Cluster transactions,
operations, threads, blocks, and other aspects of performance can be
obtained from the tables in the *note 'ndbinfo': mysql-cluster-ndbinfo.
database.  Information about these tables, see *note
mysql-cluster-ndbinfo::.


File: manual.info.tmp,  Node: files-table,  Next: ndb-transid-mysql-connection-map-table,  Prev: mysql-cluster-i_s-tables,  Up: mysql-cluster-i_s-tables

21.30.1 The INFORMATION_SCHEMA FILES Table
------------------------------------------

The *note 'FILES': files-table. table provides information about the
files in which MySQL *note 'NDB': mysql-cluster. Disk Data tables are
stored.

The *note 'FILES': files-table. table has these columns:

   * 'FILE_ID'

     A file identifier.  'FILE_ID' column values are auto-generated.

   * 'FILE_NAME'

     The name of an 'UNDO' log file created by *note 'CREATE LOGFILE
     GROUP': create-logfile-group. or *note 'ALTER LOGFILE GROUP':
     alter-logfile-group, or of a data file created by *note 'CREATE
     TABLESPACE': create-tablespace. or *note 'ALTER TABLESPACE':
     alter-tablespace.

   * 'FILE_TYPE'

     One of the values 'UNDO LOG', 'DATAFILE', or 'TABLESPACE'.

   * 'TABLESPACE_NAME'

     The name of the tablespace with which the file is associated.

   * 'TABLE_CATALOG'

     This value is always empty.

   * 'TABLE_SCHEMA'

     This value is always 'NULL'.

   * 'TABLE_NAME'

     The name of the Disk Data table with which the file is associated,
     if any.

   * 'LOGFILE_GROUP_NAME'

     The name of the log file group to which the log file or data file
     belongs.

   * 'LOGFILE_GROUP_NUMBER'

     For an 'UNDO' log file, the auto-generated ID number of the log
     file group to which the log file belongs.

   * 'ENGINE'

     For an NDB Cluster Disk Data log file or data file, this value
     always 'NDB' or 'NDBCLUSTER'.

   * 'FULLTEXT_KEYS'

     For an NDB Cluster Disk Data log file or data file, this value is
     always empty.

   * 'DELETED_ROWS'

     This value is always 'NULL'.

   * 'UPDATE_COUNT'

     This value is always 'NULL'.

   * 'FREE_EXTENTS'

     The number of extents which have not yet been used by the file.

   * 'TOTAL_EXTENTS'

     The total number of extents allocated to the file.

   * 'EXTENT_SIZE'

     The size of an extent for the file in bytes.

   * 'INITIAL_SIZE'

     The size of the file in bytes.  This is the same value that was
     used in the 'INITIAL_SIZE' clause of the *note 'CREATE LOGFILE
     GROUP': create-logfile-group, *note 'ALTER LOGFILE GROUP':
     alter-logfile-group, *note 'CREATE TABLESPACE': create-tablespace,
     or *note 'ALTER TABLESPACE': alter-tablespace. statement used to
     create the file.

   * 'MAXIMUM_SIZE'

     For NDB Cluster Disk Data files, this value is always the same as
     the 'INITIAL_SIZE' value.

   * 'AUTOEXTEND_SIZE'

     For NDB Cluster Disk Data files, this value is always empty.

   * 'CREATION_TIME'

     The date and time when the file was created.

   * 'LAST_UPDATE_TIME'

     The date and time when the file was last modified.

   * 'LAST_ACCESS_TIME'

     The date and time when the file was last accessed by the server.

   * 'RECOVER_TIME'

     For NDB Cluster Disk Data files, this value is always '0'.

   * 'TRANSACTION_COUNTER'

     For NDB Cluster Disk Data files, this value is always '0'.

   * 'VERSION'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'ROW_FORMAT'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'TABLE_ROWS'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'AVG_ROW_LENGTH'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'DATA_LENGTH'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'MAX_DATA_LENGTH'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'INDEX_LENGTH'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'DATA_FREE'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'CREATE_TIME'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'UPDATE_TIME'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'CHECK_TIME'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'CHECKSUM'

     For NDB Cluster Disk Data files, this value is always 'NULL'.

   * 'STATUS'

     For NDB Cluster Disk Data files, this value is always 'NORMAL'.

   * 'EXTRA'

     For NDB Cluster Disk Data files, the 'EXTRA' column shows which
     data node the file belongs to (each data node having its own copy),
     as well as the size of its undo buffer.  Suppose that you use this
     statement on an NDB Cluster with four data nodes:

          CREATE LOGFILE GROUP mygroup
              ADD UNDOFILE 'new_undo.dat'
              INITIAL_SIZE 2G
              ENGINE NDB;

     After running the *note 'CREATE LOGFILE GROUP':
     create-logfile-group. statement successfully, you should see a
     result similar to the one shown here for this query against the
     *note 'FILES': files-table. table:

          mysql> SELECT LOGFILE_GROUP_NAME, FILE_TYPE, EXTRA
                   FROM INFORMATION_SCHEMA.FILES
                   WHERE FILE_NAME = 'new_undo.dat';

          +--------------------+-----------+-----------------------------------------+
          | LOGFILE_GROUP_NAME | FILE_TYPE | EXTRA                                   |
          +--------------------+-----------+-----------------------------------------+
          | mygroup            | UNDO LOG  | CLUSTER_NODE=5;UNDO_BUFFER_SIZE=8388608 |
          | mygroup            | UNDO LOG  | CLUSTER_NODE=6;UNDO_BUFFER_SIZE=8388608 |
          | mygroup            | UNDO LOG  | CLUSTER_NODE=7;UNDO_BUFFER_SIZE=8388608 |
          | mygroup            | UNDO LOG  | CLUSTER_NODE=8;UNDO_BUFFER_SIZE=8388608 |
          +--------------------+-----------+-----------------------------------------+

*Notes*

   * The *note 'FILES': files-table. table is a nonstandard
     'INFORMATION_SCHEMA' table.

*NDB Notes*

   * This table provides information about Disk Data _files_ only; you
     cannot use it for determining disk space allocation or availability
     for individual 'NDB' tables.  However, it is possible to see how
     much space is allocated for each *note 'NDB': mysql-cluster. table
     having data stored on disk--as well as how much remains available
     for storage of data on disk for that table--using *note 'ndb_desc':
     mysql-cluster-programs-ndb-desc.  For more information, see *note
     mysql-cluster-programs-ndb-desc::.

   * The 'CREATION_TIME', 'LAST_UPDATE_TIME', and 'LAST_ACCESSED' values
     are as reported by the operating system, and are not supplied by
     the *note 'NDB': mysql-cluster. storage engine.  Where no value is
     provided by the operating system, these columns display '0000-00-00
     00:00:00'.

   * The difference between the 'TOTAL EXTENTS' and 'FREE_EXTENTS'
     columns is the number of extents currently in use by the file:

          SELECT TOTAL_EXTENTS - FREE_EXTENTS AS extents_used
              FROM INFORMATION_SCHEMA.FILES
              WHERE FILE_NAME = 'myfile.dat';

     To approximate the amount of disk space in use by the file,
     multiply that difference by the value of the 'EXTENT_SIZE' column,
     which gives the size of an extent for the file in bytes:

          SELECT (TOTAL_EXTENTS - FREE_EXTENTS) * EXTENT_SIZE AS bytes_used
              FROM INFORMATION_SCHEMA.FILES
              WHERE FILE_NAME = 'myfile.dat';

     Similarly, you can estimate the amount of space that remains
     available in a given file by multiplying 'FREE_EXTENTS' by
     'EXTENT_SIZE':

          SELECT FREE_EXTENTS * EXTENT_SIZE AS bytes_free
              FROM INFORMATION_SCHEMA.FILES
              WHERE FILE_NAME = 'myfile.dat';

     *Important*:

     The byte values produced by the preceding queries are
     approximations only, and their precision is inversely proportional
     to the value of 'EXTENT_SIZE'.  That is, the larger 'EXTENT_SIZE'
     becomes, the less accurate the approximations are.

     It is also important to remember that once an extent is used, it
     cannot be freed again without dropping the data file of which it is
     a part.  This means that deletes from a Disk Data table do _not_
     release disk space.

     The extent size can be set in a *note 'CREATE TABLESPACE':
     create-tablespace. statement.  For more information, see *note
     create-tablespace::.

   * An additional row is present in the *note 'FILES': files-table.
     table following the creation of a logfile group.  This row has
     'NULL' for the value of the 'FILE_NAME' column.  For this row, the
     value of the 'FILE_ID' column is always '0', that of the
     'FILE_TYPE' column is always 'UNDO LOG', and that of the 'STATUS'
     column is always 'NORMAL'.  The value of the 'ENGINE' column is
     always 'NDBCLUSTER'.

     The 'FREE_EXTENTS' column in this row shows the total number of
     free extents available to all undo files belonging to a given log
     file group whose name and number are shown in the
     'LOGFILE_GROUP_NAME' and 'LOGFILE_GROUP_NUMBER' columns,
     respectively.

     Suppose there are no existing log file groups on your NDB Cluster,
     and you create one using the following statement:

          mysql> CREATE LOGFILE GROUP lg1
                   ADD UNDOFILE 'undofile.dat'
                   INITIAL_SIZE = 16M
                   UNDO_BUFFER_SIZE = 1M
                   ENGINE = NDB;

     You can now see this 'NULL' row when you query the *note 'FILES':
     files-table. table:

          mysql> SELECT DISTINCT
                   FILE_NAME AS File,
                   FREE_EXTENTS AS Free,
                   TOTAL_EXTENTS AS Total,
                   EXTENT_SIZE AS Size,
                   INITIAL_SIZE AS Initial
                   FROM INFORMATION_SCHEMA.FILES;
          +--------------+---------+---------+------+----------+
          | File         | Free    | Total   | Size | Initial  |
          +--------------+---------+---------+------+----------+
          | undofile.dat |    NULL | 4194304 |    4 | 16777216 |
          | NULL         | 4184068 |    NULL |    4 |     NULL |
          +--------------+---------+---------+------+----------+

     The total number of free extents available for undo logging is
     always somewhat less than the sum of the 'TOTAL_EXTENTS' column
     values for all undo files in the log file group due to overhead
     required for maintaining the undo files.  This can be seen by
     adding a second undo file to the log file group, then repeating the
     previous query against the *note 'FILES': files-table. table:

          mysql> ALTER LOGFILE GROUP lg1
                   ADD UNDOFILE 'undofile02.dat'
                   INITIAL_SIZE = 4M
                   ENGINE = NDB;

          mysql> SELECT DISTINCT
                   FILE_NAME AS File,
                   FREE_EXTENTS AS Free,
                   TOTAL_EXTENTS AS Total,
                   EXTENT_SIZE AS Size,
                   INITIAL_SIZE AS Initial
                   FROM INFORMATION_SCHEMA.FILES;
          +----------------+---------+---------+------+----------+
          | File           | Free    | Total   | Size | Initial  |
          +----------------+---------+---------+------+----------+
          | undofile.dat   |    NULL | 4194304 |    4 | 16777216 |
          | undofile02.dat |    NULL | 1048576 |    4 |  4194304 |
          | NULL           | 5223944 |    NULL |    4 |     NULL |
          +----------------+---------+---------+------+----------+

     The amount of free space in bytes which is available for undo
     logging by Disk Data tables using this log file group can be
     approximated by multiplying the number of free extents by the
     initial size:

          mysql> SELECT
                   FREE_EXTENTS AS 'Free Extents',
                   FREE_EXTENTS * EXTENT_SIZE AS 'Free Bytes'
                   FROM INFORMATION_SCHEMA.FILES
                   WHERE LOGFILE_GROUP_NAME = 'lg1'
                   AND FILE_NAME IS NULL;
          +--------------+------------+
          | Free Extents | Free Bytes |
          +--------------+------------+
          |      5223944 |   20895776 |
          +--------------+------------+

     If you create an NDB Cluster Disk Data table and then insert some
     rows into it, you can see approximately how much space remains for
     undo logging afterward, for example:

          mysql> CREATE TABLESPACE ts1
                   ADD DATAFILE 'data1.dat'
                   USE LOGFILE GROUP lg1
                   INITIAL_SIZE 512M
                   ENGINE = NDB;

          mysql> CREATE TABLE dd (
                   c1 INT NOT NULL PRIMARY KEY,
                   c2 INT,
                   c3 DATE
                   )
                   TABLESPACE ts1 STORAGE DISK
                   ENGINE = NDB;

          mysql> INSERT INTO dd VALUES
                   (NULL, 1234567890, '2007-02-02'),
                   (NULL, 1126789005, '2007-02-03'),
                   (NULL, 1357924680, '2007-02-04'),
                   (NULL, 1642097531, '2007-02-05');

          mysql> SELECT
                   FREE_EXTENTS AS 'Free Extents',
                   FREE_EXTENTS * EXTENT_SIZE AS 'Free Bytes'
                   FROM INFORMATION_SCHEMA.FILES
                   WHERE LOGFILE_GROUP_NAME = 'lg1'
                   AND FILE_NAME IS NULL;
          +--------------+------------+
          | Free Extents | Free Bytes |
          +--------------+------------+
          |      5207565 |   20830260 |
          +--------------+------------+

   * An additional row is present in the *note 'FILES': files-table.
     table for any NDB Cluster tablespace, whether or not any data files
     are associated with the tablespace.  This row has 'NULL' for the
     value of the 'FILE_NAME' column.  For this row, the value of the
     'FILE_ID' column is always '0', that of the 'FILE_TYPE' column is
     always 'TABLESPACE', and that of the 'STATUS' column is always
     'NORMAL'.  The value of the 'ENGINE' column is always 'NDBCLUSTER'.

   * For additional information, and examples of creating and dropping
     NDB Cluster Disk Data objects, see *note mysql-cluster-disk-data::.


File: manual.info.tmp,  Node: ndb-transid-mysql-connection-map-table,  Prev: files-table,  Up: mysql-cluster-i_s-tables

21.30.2 The INFORMATION_SCHEMA ndb_transid_mysql_connection_map Table
---------------------------------------------------------------------

The 'ndb_transid_mysql_connection_map' table provides a mapping between
'NDB' transactions, 'NDB' transaction coordinators, and MySQL Servers
attached to an NDB Cluster as API nodes.  This information is used when
populating the *note 'server_operations':
mysql-cluster-ndbinfo-server-operations. and *note
'server_transactions': mysql-cluster-ndbinfo-server-transactions. tables
of the *note 'ndbinfo': mysql-cluster-ndbinfo. NDB Cluster information
database.

The *note 'ndb_transid_mysql_connection_map':
ndb-transid-mysql-connection-map-table. table has these columns:

   * 'mysql_connection_id'

     The MySQL server connection ID.

   * 'node_id'

     The transaction coordinator node ID.

   * 'ndb_transid'

     The *note 'NDB': mysql-cluster. transaction ID.

*Notes*

The 'mysql_connection_id' value is the same as the connection or session
ID shown in the output of *note 'SHOW PROCESSLIST': show-processlist.

There are no 'SHOW' statements associated with this table.

This is a nonstandard table, added in MySQL NDB Cluster 7.2.2.  It is
implemented as an 'INFORMATION_SCHEMA' plugin; you can verify that it is
supported by checking the output of *note 'SHOW PLUGINS': show-plugins.
If 'ndb_transid_mysql_connection_map' support is enabled, the output
from this statement includes a plugin having this name, of type
'INFORMATION SCHEMA', and having status 'ACTIVE', as shown here (using
emphasized text):

     mysql> SHOW PLUGINS;
     +----------------------------------+--------+--------------------+---------+---------+
     | Name                             | Status | Type               | Library | License |
     +----------------------------------+--------+--------------------+---------+---------+
     | binlog                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | mysql_native_password            | ACTIVE | AUTHENTICATION     | NULL    | GPL     |
     | mysql_old_password               | ACTIVE | AUTHENTICATION     | NULL    | GPL     |
     | CSV                              | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | MEMORY                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | MRG_MYISAM                       | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | MyISAM                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | PERFORMANCE_SCHEMA               | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | BLACKHOLE                        | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | ARCHIVE                          | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | ndbcluster                       | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | ndbinfo                          | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     _| ndb_transid_mysql_connection_map | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |_
     | InnoDB                           | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     | INNODB_TRX                       | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_LOCKS                     | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_LOCK_WAITS                | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMP                       | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMP_RESET                 | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMPMEM                    | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | INNODB_CMPMEM_RESET              | ACTIVE | INFORMATION SCHEMA | NULL    | GPL     |
     | partition                        | ACTIVE | STORAGE ENGINE     | NULL    | GPL     |
     +----------------------------------+--------+--------------------+---------+---------+
     22 rows in set (0.00 sec)

The plugin is enabled by default.  You can disable it (or force the
server not to run unless the plugin starts) by starting the server with
the '--ndb-transid-mysql-connection-map' option.  If the plugin is
disabled, the status is shown by *note 'SHOW PLUGINS': show-plugins. as
'DISABLED'.  The plugin cannot be enabled or disabled at runtime.

Although the names of this table and its columns are displayed using
lowercase, you can use uppercase or lowercase when referring to them in
SQL statements.

For this table to be created, the MySQL Server must be a binary supplied
with the NDB Cluster distribution, or one built from the NDB Cluster
sources with *note 'NDB': mysql-cluster. storage engine support enabled.
It is not available in the standard MySQL 5.5 Server.


File: manual.info.tmp,  Node: thread-pool-i_s-tables,  Next: extended-show,  Prev: mysql-cluster-i_s-tables,  Up: information-schema

21.31 INFORMATION_SCHEMA Thread Pool Tables
===========================================

* Menu:

* tp-thread-group-state-table::  The INFORMATION_SCHEMA TP_THREAD_GROUP_STATE Table
* tp-thread-group-stats-table::  The INFORMATION_SCHEMA TP_THREAD_GROUP_STATS Table
* tp-thread-state-table::        The INFORMATION_SCHEMA TP_THREAD_STATE Table

The following sections describe the 'INFORMATION_SCHEMA' tables
associated with the thread pool plugin (see *note thread-pool::).  They
provide information about thread pool operation:

   * *note 'TP_THREAD_GROUP_STATE': tp-thread-group-state-table.:
     Information about thread pool thread group states

   * *note 'TP_THREAD_GROUP_STATS': tp-thread-group-stats-table.: Thread
     group statistics

   * *note 'TP_THREAD_STATE': tp-thread-state-table.: Information about
     thread pool thread states

Rows in these tables represent snapshots in time.  In the case of *note
'TP_THREAD_STATE': tp-thread-state-table, all rows for a thread group
comprise a snapshot in time.  Thus, the MySQL server holds the mutex of
the thread group while producing the snapshot.  But it does not hold
mutexes on all thread groups at the same time, to prevent a statement
against *note 'TP_THREAD_STATE': tp-thread-state-table. from blocking
the entire MySQL server.

The thread pool 'INFORMATION_SCHEMA' tables are implemented by
individual plugins and the decision whether to load one can be made
independently of the others (see *note thread-pool-installation::).
However, the content of all the tables depends on the thread pool plugin
being enabled.  If a table plugin is enabled but the thread pool plugin
is not, the table becomes visible and can be accessed but will be empty.


File: manual.info.tmp,  Node: tp-thread-group-state-table,  Next: tp-thread-group-stats-table,  Prev: thread-pool-i_s-tables,  Up: thread-pool-i_s-tables

21.31.1 The INFORMATION_SCHEMA TP_THREAD_GROUP_STATE Table
----------------------------------------------------------

The *note 'TP_THREAD_GROUP_STATE': tp-thread-group-state-table. table
has one row per thread group in the thread pool.  Each row provides
information about the current state of a group.

The *note 'TP_THREAD_GROUP_STATE': tp-thread-group-state-table. table
has these columns:

   * 'TP_GROUP_ID'

     The thread group ID. This is a unique key within the table.

   * 'CONSUMER THREADS'

     The number of consumer threads.  There is at most one thread ready
     to start executing if the active threads become stalled or blocked.

   * 'RESERVE_THREADS'

     The number of threads in the reserved state.  This means that they
     will not be started until there is a need to wake a new thread and
     there is no consumer thread.  This is where most threads end up
     when the thread group has created more threads than needed for
     normal operation.  Often a thread group needs additional threads
     for a short while and then does not need them again for a while.
     In this case, they go into the reserved state and remain until
     needed again.  They take up some extra memory resources, but no
     extra computing resources.

   * 'CONNECT_THREAD_COUNT'

     The number of threads that are processing or waiting to process
     connection initialization and authentication.  There can be a
     maximum of four connection threads per thread group; these threads
     expire after a period of inactivity.

     This column was added in MySQL 5.5.55.

   * 'CONNECTION_COUNT'

     The number of connections using this thread group.

   * 'QUEUED_QUERIES'

     The number of statements waiting in the high-priority queue.

   * 'QUEUED_TRANSACTIONS'

     The number of statements waiting in the low-priority queue.  These
     are the initial statements for transactions that have not started,
     so they also represent queued transactions.

   * 'STALL_LIMIT'

     The value of the 'thread_pool_stall_limit' system variable for the
     thread group.  This is the same value for all thread groups.

   * 'PRIO_KICKUP_TIMER'

     The value of the 'thread_pool_prio_kickup_timer' system variable
     for the thread group.  This is the same value for all thread
     groups.

   * 'ALGORITHM'

     The value of the 'thread_pool_algorithm' system variable for the
     thread group.  This is the same value for all thread groups.

   * 'THREAD_COUNT'

     The number of threads started in the thread pool as part of this
     thread group.

   * 'ACTIVE_THREAD_COUNT'

     The number of threads active in executing statements.

   * 'STALLED_THREAD_COUNT'

     The number of stalled statements in the thread group.  A stalled
     statement could be executing, but from a thread pool perspective it
     is stalled and making no progress.  A long-running statement
     quickly ends up in this category.

   * 'WAITING_THREAD_NUMBER'

     If there is a thread handling the polling of statements in the
     thread group, this specifies the thread number within this thread
     group.  It is possible that this thread could be executing a
     statement.

   * 'OLDEST_QUEUED'

     How long in milliseconds the oldest queued statement has been
     waiting for execution.

   * 'MAX_THREAD_IDS_IN_GROUP'

     The maximum thread ID of the threads in the group.  This is the
     same as 'MAX(TP_THREAD_NUMBER)' for the threads when selected from
     the *note 'TP_THREAD_STATE': tp-thread-state-table. table.  That
     is, these two queries are equivalent:

          SELECT TP_GROUP_ID, MAX_THREAD_IDS_IN_GROUP
          FROM TP_THREAD_GROUP_STATE;

          SELECT TP_GROUP_ID, MAX(TP_THREAD_NUMBER)
          FROM TP_THREAD_STATE GROUP BY TP_GROUP_ID;


File: manual.info.tmp,  Node: tp-thread-group-stats-table,  Next: tp-thread-state-table,  Prev: tp-thread-group-state-table,  Up: thread-pool-i_s-tables

21.31.2 The INFORMATION_SCHEMA TP_THREAD_GROUP_STATS Table
----------------------------------------------------------

The *note 'TP_THREAD_GROUP_STATS': tp-thread-group-stats-table. table
reports statistics per thread group.  There is one row per group.

The *note 'TP_THREAD_GROUP_STATS': tp-thread-group-stats-table. table
has these columns:

   * 'TP_GROUP_ID'

     The thread group ID. This is a unique key within the table.

   * 'CONNECTIONS_STARTED'

     The number of connections started.

   * 'CONNECTIONS_CLOSED'

     The number of connections closed.

   * 'QUERIES_EXECUTED'

     The number of statements executed.  This number is incremented when
     a statement starts executing, not when it finishes.

   * 'QUERIES_QUEUED'

     The number of statements received that were queued for execution.
     This does not count statements that the thread group was able to
     begin executing immediately without queuing, which can happen under
     the conditions described in *note thread-pool-operation::.

   * 'THREADS_STARTED'

     The number of threads started.

   * 'PRIO_KICKUPS'

     The number of statements that have been moved from low-priority
     queue to high-priority queue based on the value of the
     'thread_pool_prio_kickup_timer' system variable.  If this number
     increases quickly, consider increasing the value of that variable.
     A quickly increasing counter means that the priority system is not
     keeping transactions from starting too early.  For *note 'InnoDB':
     innodb-storage-engine, this most likely means deteriorating
     performance due to too many concurrent transactions..

   * 'STALLED_QUERIES_EXECUTED'

     The number of statements that have become defined as stalled due to
     executing for longer than the value of the
     'thread_pool_stall_limit' system variable.

   * 'BECOME_CONSUMER_THREAD'

     The number of times thread have been assigned the consumer thread
     role.

   * 'BECOME_RESERVE_THREAD'

     The number of times threads have been assigned the reserve thread
     role.

   * 'BECOME_WAITING_THREAD'

     The number of times threads have been assigned the waiter thread
     role.  When statements are queued, this happens very often, even in
     normal operation, so rapid increases in this value are normal in
     the case of a highly loaded system where statements are queued up.

   * 'WAKE_THREAD_STALL_CHECKER'

     The number of times the stall check thread decided to wake or
     create a thread to possibly handle some statements or take care of
     the waiter thread role.

   * 'SLEEP_WAITS'

     The number of 'THD_WAIT_SLEEP' waits.  These occur when threads go
     to sleep; for example, by calling the 'SLEEP()' function.

   * 'DISK_IO_WAITS'

     The number of 'THD_WAIT_DISKIO' waits.  These occur when threads
     perform disk I/O that is likely to not hit the file system cache.
     Such waits occur when the buffer pool reads and writes data to
     disk, not for normal reads from and writes to files.

   * 'ROW_LOCK_WAITS'

     The number of 'THD_WAIT_ROW_LOCK' waits for release of a row lock
     by another transaction.

   * 'GLOBAL_LOCK_WAITS'

     The number of 'THD_WAIT_GLOBAL_LOCK' waits for a global lock to be
     released.

   * 'META_DATA_LOCK_WAITS'

     The number of 'THD_WAIT_META_DATA_LOCK' waits for a metadata lock
     to be released.

   * 'TABLE_LOCK_WAITS'

     The number of 'THD_WAIT_TABLE_LOCK' waits for a table to be
     unlocked that the statement needs to access.

   * 'USER_LOCK_WAITS'

     The number of 'THD_WAIT_USER_LOCK' waits for a special lock
     constructed by the user thread.

   * 'BINLOG_WAITS'

     The number of 'THD_WAIT_BINLOG_WAITS' waits for the binary log to
     become free.

   * 'GROUP_COMMIT_WAITS'

     The number of 'THD_WAIT_GROUP_COMMIT' waits.  These occur when a
     group commit must wait for the other parties to complete their part
     of a transaction.

   * 'FSYNC_WAITS'

     The number of 'THD_WAIT_SYNC' waits for a file sync operation.


File: manual.info.tmp,  Node: tp-thread-state-table,  Prev: tp-thread-group-stats-table,  Up: thread-pool-i_s-tables

21.31.3 The INFORMATION_SCHEMA TP_THREAD_STATE Table
----------------------------------------------------

The *note 'TP_THREAD_STATE': tp-thread-state-table. table has one row
per thread created by the thread pool to handle connections.

The *note 'TP_THREAD_STATE': tp-thread-state-table. table has these
columns:

   * 'TP_GROUP_ID'

     The thread group ID.

   * 'TP_THREAD_NUMBER'

     The ID of the thread within its thread group.  'TP_GROUP_ID' and
     'TP_THREAD_NUMBER' together provide a unique key within the table.

   * 'PROCESS_COUNT'

     The 10ms interval in which the statement that uses this thread is
     currently executing.  0 means no statement is executing, 1 means it
     is in the first 10ms, and so forth.

   * 'WAIT_TYPE'

     The type of wait for the thread.  'NULL' means the thread is not
     blocked.  Otherwise, the thread is blocked by a call to
     'thd_wait_begin()' and the value specifies the type of wait.  The
     'XXX_WAIT' columns of the *note 'TP_THREAD_GROUP_STATS':
     tp-thread-group-stats-table. table accumulate counts for each wait
     type.

     The 'WAIT_TYPE' value is a string that describes the type of wait,
     as shown in the following table.

     *TP_THREAD_STATE Table WAIT_TYPE Values*

     Wait Type                 Meaning
                               
     'THD_WAIT_SLEEP'          Waiting for sleep
                               
     'THD_WAIT_DISKIO'         Waiting for Disk IO
                               
     'THD_WAIT_ROW_LOCK'       Waiting for row lock
                               
     'THD_WAIT_GLOBAL_LOCK'    Waiting for global lock
                               
     'THD_WAIT_META_DATA_LOCK' Waiting for metadata lock
                               
     'THD_WAIT_TABLE_LOCK'     Waiting for table lock
                               
     'THD_WAIT_USER_LOCK'      Waiting for user lock
                               
     'THD_WAIT_BINLOG'         Waiting for binlog
                               
     'THD_WAIT_GROUP_COMMIT'   Waiting for group commit
                               
     'THD_WAIT_SYNC'           Waiting for fsync


File: manual.info.tmp,  Node: extended-show,  Prev: thread-pool-i_s-tables,  Up: information-schema

21.32 Extensions to SHOW Statements
===================================

Some extensions to *note 'SHOW': show. statements accompany the
implementation of 'INFORMATION_SCHEMA':

   * *note 'SHOW': show. can be used to get information about the
     structure of 'INFORMATION_SCHEMA' itself.

   * Several *note 'SHOW': show. statements accept a 'WHERE' clause that
     provides more flexibility in specifying which rows to display.

'INFORMATION_SCHEMA' is an information database, so its name is included
in the output from *note 'SHOW DATABASES': show-databases.  Similarly,
*note 'SHOW TABLES': show-tables. can be used with 'INFORMATION_SCHEMA'
to obtain a list of its tables:

     mysql> SHOW TABLES FROM INFORMATION_SCHEMA;
     +---------------------------------------+
     | Tables_in_INFORMATION_SCHEMA          |
     +---------------------------